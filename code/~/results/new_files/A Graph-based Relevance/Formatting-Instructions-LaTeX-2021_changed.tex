\def\year{2021}\relax
\documentclass[letterpaper]{article}
\usepackage{adjustbox}
 % DO NOT CHANGE THIS
\usepackage{aaai21}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet} % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS


\usepackage{cite}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage[switch]{lineno}





\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.




\title{A Graph-based Relevance Matching Model for Ad-hoc Retrieval}
\author{\textbf{Yufeng Zhang\textsuperscript{\rm 1}\thanks{Equal contribution}, Jinghao Zhang\textsuperscript{\rm 1,\rm 2}\footnotemark[1], Zeyu Cui\textsuperscript{\rm 1,\rm 2}, Shu Wu\textsuperscript{\rm 1,\rm2,\rm 3}\thanks{Corresponding author} and Liang Wang\textsuperscript{\rm 1,\rm 2}} \\
}
\affiliations{\textsuperscript{\rm 1}Institute of Automation, Chinese Academy of Sciences \\
  \textsuperscript{\rm 2}University of Chinese Academy of Sciences \\
  \textsuperscript{\rm 3}Artificial Intelligence Research, Chinese Academy of Sciences \\
  \texttt{\{yufeng.zhang,jinghao.zhang\}@cripac.ia.ac.cn} \\ \texttt{\{zeyu.cui,shu.wu,wangliang\}@nlpr.ia.ac.cn}\\}

\begin{document}

\maketitle

\begin{abstract}
To retrieve more relevant, appropriate and useful documents given a query, finding clues about that query through the text is crucial. Recent deep learning models regard the task as a term-level matching problem, which seeks exact or similar query patterns in the document. However, we argue that they are inherently based on local interactions and do not generalise to ubiquitous, non-consecutive contextual relationships. In this work, we propose a novel relevance matching model based on graph neural networks to leverage the document-level word relationships for ad-hoc retrieval. In addition to the local interactions, we explicitly incorporate all contexts of a term through the graph-of-word text format. Matching patterns can be revealed accordingly to provide a more accurate relevance score. Our approach significantly outperforms strong baselines on two ad-hoc benchmarks. We also experimentally compare our model with BERT and show our advantages on long documents.



\end{abstract}

\input{body/intro}

\input{body/relatedwork}

\input{body/model}

\input{body/exp}

\input{body/conclusion}

\input{body/acknowledgement}

Repudiandae provident neque, eum consequatur fugiat aliquam earum, quibusdam molestiae nesciunt aperiam non sapiente mollitia iste, quaerat delectus in harum iusto voluptate error eligendi dolor, fugit aperiam est voluptatem?Quos iusto nulla ut, aliquid incidunt ad reprehenderit rem voluptate exercitationem eum vel molestiae ratione, expedita sit pariatur autem placeat quae tempore, eaque laborum quia libero nulla culpa accusamus?Ut quae nam illum, iste inventore saepe, obcaecati maiores blanditiis libero tenetur similique itaque, hic est fugit repudiandae in perferendis quasi?Sit repudiandae deleniti corporis neque velit quaerat maiores est ut repellat enim, voluptate amet
\bibliography{ref.bib}
\end{document}