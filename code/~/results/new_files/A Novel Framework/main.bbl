\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Agrawal, Batra, and Parikh}{2016}]{29}
Agrawal, A.; Batra, D.; and Parikh, D.
\newblock 2016.
\newblock Analyzing the behavior of visual question answering models.
\newblock {\em arXiv preprint arXiv:1606.07356}.

\bibitem[\protect\citeauthoryear{Antol \bgroup et al\mbox.\egroup }{2015}]{4}
Antol, S.; Agrawal, A.; Lu, J.; Mitchell, M.; Batra, D.; Lawrence~Zitnick, C.;
  and Parikh, D.
\newblock 2015.
\newblock Vqa: Visual question answering.
\newblock In {\em CVPR},  2425--2433.

\bibitem[\protect\citeauthoryear{Banerjee and Lavie}{2005}]{69}
Banerjee, S., and Lavie, A.
\newblock 2005.
\newblock Meteor: An automatic metric for mt evaluation with improved
  correlation with human judgments.
\newblock In {\em ACLW}, volume~29,  65--72.

\bibitem[\protect\citeauthoryear{Ben-younes \bgroup et al\mbox.\egroup
  }{2017}]{57}
Ben-younes, H.; Cadene, R.; Cord, M.; and Thome, N.
\newblock 2017.
\newblock Mutan: Multimodal tucker fusion for visual question answering.
\newblock In {\em ICCV}.

\bibitem[\protect\citeauthoryear{Chen \bgroup et al\mbox.\egroup }{2016}]{15}
Chen, K.; Wang, J.; Chen, L.-C.; Gao, H.; Xu, W.; and Nevatia, R.
\newblock 2016.
\newblock Abc-cnn: An attention based convolutional neural network for visual
  question answering.
\newblock In {\em CVPRW}.

\bibitem[\protect\citeauthoryear{Chung \bgroup et al\mbox.\egroup }{2014}]{10}
Chung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y.
\newblock 2014.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em arXiv preprint arXiv:1412.3555}.

\bibitem[\protect\citeauthoryear{Elliott and Keller}{2013}]{70}
Elliott, D., and Keller, F.
\newblock 2013.
\newblock Image description using visual dependency representations.
\newblock In {\em EMNLP},  1292--1302.

\bibitem[\protect\citeauthoryear{Fang \bgroup et al\mbox.\egroup }{2015}]{48}
Fang, H.; Gupta, S.; Iandola, F.; Srivastava, R.~K.; Deng, L.; Doll{\'a}r, P.;
  Gao, J.; He, X.; Mitchell, M.; Platt, J.~C.; et~al.
\newblock 2015.
\newblock From captions to visual concepts and back.
\newblock In {\em CVPR},  1473--1482.

\bibitem[\protect\citeauthoryear{Fawzi, Moosavi~Dezfooli, and
  Frossard}{2017}]{61}
Fawzi, A.; Moosavi~Dezfooli, S.~M.; and Frossard, P.
\newblock 2017.
\newblock A geometric perspective on the robustness of deep networks.
\newblock Technical report, IEEE.

\bibitem[\protect\citeauthoryear{Fukui \bgroup et al\mbox.\egroup }{2016}]{58}
Fukui, A.; Park, D.~H.; Yang, D.; Rohrbach, A.; Darrell, T.; and Rohrbach, M.
\newblock 2016.
\newblock Multimodal compact bilinear pooling for visual question answering and
  visual grounding.
\newblock In {\em EMNLP}.

\bibitem[\protect\citeauthoryear{Gao \bgroup et al\mbox.\egroup }{2015}]{33}
Gao, H.; Mao, J.; Zhou, J.; Huang, Z.; Wang, L.; and Xu, W.
\newblock 2015.
\newblock Are you talking to a machine? dataset and methods for multilingual
  image question.
\newblock In {\em NIPS},  2296--2304.

\bibitem[\protect\citeauthoryear{Huang, Alfadly, and Ghanem}{2017a}]{65}
Huang, J.-H.; Alfadly, M.; and Ghanem, B.
\newblock 2017a.
\newblock Robustness analysis of visual qa models by basic questions.
\newblock {\em arXiv preprint arXiv:1709.04625}.

\bibitem[\protect\citeauthoryear{Huang, Alfadly, and Ghanem}{2017b}]{66}
Huang, J.-H.; Alfadly, M.; and Ghanem, B.
\newblock 2017b.
\newblock Vqabq: Visual question answering by basic questions.
\newblock {\em CVPRW}.

\bibitem[\protect\citeauthoryear{Kafle and Kanan}{2017}]{72}
Kafle, K., and Kanan, C.
\newblock 2017.
\newblock Visual question answering: Datasets, algorithms, and future
  challenges.
\newblock {\em CVIU}.

\bibitem[\protect\citeauthoryear{Karpathy and Fei-Fei}{2015}]{27}
Karpathy, A., and Fei-Fei, L.
\newblock 2015.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock In {\em CVPR},  3128--3137.

\bibitem[\protect\citeauthoryear{Kim \bgroup et al\mbox.\egroup }{2017}]{59}
Kim, J.-H.; On, K.-W.; Lim, W.; Kim, J.; Ha, J.-W.; and Zhang, B.-T.
\newblock 2017.
\newblock Hadamard product for low-rank bilinear pooling.
\newblock In {\em ICLR}.

\bibitem[\protect\citeauthoryear{Kiros \bgroup et al\mbox.\egroup }{2015}]{43}
Kiros, R.; Zhu, Y.; Salakhutdinov, R.~R.; Zemel, R.; Urtasun, R.; Torralba, A.;
  and Fidler, S.
\newblock 2015.
\newblock Skip-thought vectors.
\newblock In {\em NIPS},  3294--3302.

\bibitem[\protect\citeauthoryear{Kiros, Salakhutdinov, and Zemel}{2014}]{26}
Kiros, R.; Salakhutdinov, R.; and Zemel, R.~S.
\newblock 2014.
\newblock Multimodal neural language models.
\newblock In {\em Icml}, volume~14,  595--603.

\bibitem[\protect\citeauthoryear{Kulkarni \bgroup et al\mbox.\egroup
  }{2011}]{71}
Kulkarni, G.; Premraj, V.; Dhar, S.; Li, S.; Choi, Y.; Berg, A.~C.; and Berg,
  T.~L.
\newblock 2011.
\newblock Baby talk: Understanding and generating image descriptions.
\newblock In {\em CVPR}.
\newblock Citeseer.

\bibitem[\protect\citeauthoryear{Li and Jia}{2016}]{42}
Li, R., and Jia, J.
\newblock 2016.
\newblock Visual question answering with question representation update (qru).
\newblock In {\em NIPS},  4655--4663.

\bibitem[\protect\citeauthoryear{Lin \bgroup et al\mbox.\egroup }{2014}]{51}
Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.;
  Doll{\'a}r, P.; and Zitnick, C.~L.
\newblock 2014.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV},  740--755.
\newblock Springer.

\bibitem[\protect\citeauthoryear{Lin}{2004}]{68}
Lin, C.-Y.
\newblock 2004.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em ACLW}, volume~8.
\newblock Barcelona, Spain.

\bibitem[\protect\citeauthoryear{Lu \bgroup et al\mbox.\egroup }{2016}]{41}
Lu, J.; Yang, J.; Batra, D.; and Parikh, D.
\newblock 2016.
\newblock Hierarchical question-image co-attention for visual question
  answering.
\newblock In {\em NIPS},  289--297.

\bibitem[\protect\citeauthoryear{Malinowski, Rohrbach, and Fritz}{2015}]{9}
Malinowski, M.; Rohrbach, M.; and Fritz, M.
\newblock 2015.
\newblock Ask your neurons: A neural-based approach to answering questions
  about images.
\newblock In {\em ICCV},  1--9.

\bibitem[\protect\citeauthoryear{Mikolov \bgroup et al\mbox.\egroup
  }{2013}]{47}
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G.~S.; and Dean, J.
\newblock 2013.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em NIPS},  3111--3119.

\bibitem[\protect\citeauthoryear{Mostafazadeh \bgroup et al\mbox.\egroup
  }{2016}]{19}
Mostafazadeh, N.; Misra, I.; Devlin, J.; Mitchell, M.; He, X.; and Vanderwende,
  L.
\newblock 2016.
\newblock Generating natural questions about an image.
\newblock {\em arXiv preprint arXiv:1603.06059}.

\bibitem[\protect\citeauthoryear{Noh, Hongsuck~Seo, and Han}{2016}]{31}
Noh, H.; Hongsuck~Seo, P.; and Han, B.
\newblock 2016.
\newblock Image question answering using convolutional neural network with
  dynamic parameter prediction.
\newblock In {\em CVPR},  30--38.

\bibitem[\protect\citeauthoryear{Papineni \bgroup et al\mbox.\egroup
  }{2002}]{49}
Papineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J.
\newblock 2002.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em ACL},  311--318.
\newblock ACL.

\bibitem[\protect\citeauthoryear{Pennington, Socher, and Manning}{2014}]{11}
Pennington, J.; Socher, R.; and Manning, C.~D.
\newblock 2014.
\newblock Glove: Global vectors for word representation.
\newblock In {\em EMNLP}, volume~14,  1532--1543.

\bibitem[\protect\citeauthoryear{Rips}{1994}]{74}
Rips, L.~J.
\newblock 1994.
\newblock {\em The psychology of proof: Deductive reasoning in human thinking}.
\newblock Mit Press.

\bibitem[\protect\citeauthoryear{Shih, Singh, and Hoiem}{2016}]{13}
Shih, K.~J.; Singh, S.; and Hoiem, D.
\newblock 2016.
\newblock Where to look: Focus regions for visual question answering.
\newblock In {\em CVPR},  4613--4621.

\bibitem[\protect\citeauthoryear{Vedantam, Lawrence~Zitnick, and
  Parikh}{2015}]{67}
Vedantam, R.; Lawrence~Zitnick, C.; and Parikh, D.
\newblock 2015.
\newblock Cider: Consensus-based image description evaluation.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Vinyals \bgroup et al\mbox.\egroup
  }{2015}]{28}
Vinyals, O.; Toshev, A.; Bengio, S.; and Erhan, D.
\newblock 2015.
\newblock Show and tell: A neural image caption generator.
\newblock In {\em CVPR},  3156--3164.

\bibitem[\protect\citeauthoryear{Wu \bgroup et al\mbox.\egroup }{2016}]{37}
Wu, Q.; Wang, P.; Shen, C.; Dick, A.; and van~den Hengel, A.
\newblock 2016.
\newblock Ask me anything: Free-form visual question answering based on
  knowledge from external sources.
\newblock In {\em CVPR},  4622--4630.

\bibitem[\protect\citeauthoryear{Xiong, Merity, and Socher}{2016}]{54}
Xiong, C.; Merity, S.; and Socher, R.
\newblock 2016.
\newblock Dynamic memory networks for visual and textual question answering.
\newblock {\em arXiv} 1603.

\bibitem[\protect\citeauthoryear{Xu \bgroup et al\mbox.\egroup }{2015}]{1}
Xu, K.; Ba, J.; Kiros, R.; Cho, K.; Courville, A.~C.; Salakhutdinov, R.; Zemel,
  R.~S.; and Bengio, Y.
\newblock 2015.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In {\em ICML}, volume~14,  77--81.

\bibitem[\protect\citeauthoryear{Xu, Caramanis, and Mannor}{2009}]{63}
Xu, H.; Caramanis, C.; and Mannor, S.
\newblock 2009.
\newblock Robustness and regularization of support vector machines.
\newblock {\em JMLR} 10(Jul):1485--1510.

\bibitem[\protect\citeauthoryear{Yang \bgroup et al\mbox.\egroup }{2016}]{35}
Yang, Z.; He, X.; Gao, J.; Deng, L.; and Smola, A.
\newblock 2016.
\newblock Stacked attention networks for image question answering.
\newblock In {\em CVPR},  21--29.

\end{thebibliography}
