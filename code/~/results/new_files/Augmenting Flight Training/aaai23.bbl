\begin{thebibliography}{12}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Bignold et~al.(2021)Bignold, Cruz, Taylor, Brys, Dazeley, Vamplew,
  and Foale}]{bignold21}
Bignold, A.; Cruz, F.; Taylor, M.~E.; Brys, T.; Dazeley, R.; Vamplew, P.; and
  Foale, C. 2021.
\newblock A conceptual framework for externally-influenced agents: an assisted
  reinforcement learning review.
\newblock \emph{Journal of Ambient Intelligence and Humanized Computing}.

\bibitem[{Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei}]{ChristianoLBMLA17}
Christiano, P.~F.; Leike, J.; Brown, T.~B.; Martic, M.; Legg, S.; and Amodei,
  D. 2017.
\newblock Deep Reinforcement Learning from Human Preferences.
\newblock In \emph{Neural Information Processing Systems}, 4299--4307.

\bibitem[{Cui et~al.(2021)Cui, Koppol, Admoni, Niekum, Simmons, Steinfeld, and
  Fitzgerald}]{cui:21}
Cui, Y.; Koppol, P.; Admoni, H.; Niekum, S.; Simmons, R.~G.; Steinfeld, A.; and
  Fitzgerald, T. 2021.
\newblock Understanding the Relationship between Interactions and Outcomes in
  Human-in-the-Loop Machine Learning.
\newblock In \emph{IJCAI}, 4382--4391.

\bibitem[{Da~Silva\textbf{*} et~al.(2020)Da~Silva\textbf{*}, Hernandez-Leal,
  Kartal, and Taylor}]{da2020uncertainty}
Da~Silva\textbf{*}, F.~L.; Hernandez-Leal, P.; Kartal, B.; and Taylor, M.~E.
  2020.
\newblock Uncertainty-Aware Action Advising for Deep Reinforcement Learning
  Agents.
\newblock In \emph{Proceedings of AAAI Conference on Artificial Intelligence}.

\bibitem[{Georgila et~al.(2019)Georgila, Core, Nye, Karumbaiah, Auerbach, and
  Ram}]{georgila2019using}
Georgila, K.; Core, M.~G.; Nye, B.~D.; Karumbaiah, S.; Auerbach, D.; and Ram,
  M. 2019.
\newblock Using reinforcement learning to optimize the policies of an
  intelligent tutoring system for interpersonal skills training.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}.

\bibitem[{Morales and Sammut(2004)}]{morales2004learning}
Morales, E.~F.; and Sammut, C. 2004.
\newblock Learning to fly by combining reinforcement learning with behavioural
  cloning.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, 76.

\bibitem[{{Oliver Wyman}(2022)}]{Wyman:22}
{Oliver Wyman}. 2022.
\newblock After COVID-19, Aviation Faces a Pilot Shortage.
\newblock
  \url{https://www.oliverwyman.com/our-expertise/insights/2021/mar/after-covid-19-aviation-faces-a-pilot-shortage.html}.
\newblock Accessed: 2022-09-15.

\bibitem[{Pomerleau(1988)}]{pomerleau1988alvinn}
Pomerleau, D.~A. 1988.
\newblock Alvinn: An autonomous land vehicle in a neural network.
\newblock \emph{Advances in neural information processing systems}, 1.

\bibitem[{Raffin et~al.(2019)Raffin, Hill, Ernestus, Gleave, Kanervisto, and
  Dormann}]{stable-baselines3}
Raffin, A.; Hill, A.; Ernestus, M.; Gleave, A.; Kanervisto, A.; and Dormann, N.
  2019.
\newblock Stable Baselines3.
\newblock \url{https://github.com/DLR-RM/stable-baselines3}.

\bibitem[{Sandstr{\"o}m, Luotsinen, and Oskarsson(2022)}]{sandstrom2022fighter}
Sandstr{\"o}m, V.; Luotsinen, L.; and Oskarsson, D. 2022.
\newblock Fighter Pilot Behavior Cloning.
\newblock In \emph{2022 International Conference on Unmanned Aircraft Systems
  (ICUAS)}, 686--695. IEEE.

\bibitem[{Shute(2008)}]{shute:08}
Shute, V.~J. 2008.
\newblock Focus on formative feedback.
\newblock \emph{Review of educational research}, 78(1): 153--189.

\bibitem[{Wang(2018)}]{wang2018reinforcement}
Wang, F. 2018.
\newblock Reinforcement learning in a pomdp based intelligent tutoring system
  for optimizing teaching strategies.
\newblock \emph{International Journal of Information and Education Technology}.

\end{thebibliography}
