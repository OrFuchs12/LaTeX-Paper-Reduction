\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Bilen \bgroup et al\mbox.\egroup }{2016}]{DIN}
Bilen, H.; Fernando, B.; Gavves, E.; Vedaldi, A.; and Gould, S.
\newblock 2016.
\newblock Dynamic image networks for action recognition.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Chatfield \bgroup et al\mbox.\egroup
  }{2014}]{M2048}
Chatfield, K.; Simonyan, K.; Vedaldi, A.; and Zisserman, A.
\newblock 2014.
\newblock Return of the devil in the details: Delving deepinto convolutional
  nets.
\newblock In {\em CoRR abs/1405.3531}.

\bibitem[\protect\citeauthoryear{Cherian \bgroup et al\mbox.\egroup
  }{2017}]{cherian2017generalized}
Cherian, A.; Fernando, B.; Harandi, M.; and Gould, S.
\newblock 2017.
\newblock Generalized rank pooling for activity recognition.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{De~Boer \bgroup et al\mbox.\egroup
  }{2005}]{crossentropy}
De~Boer, P.; Kroese, D.; Mannor, S.; and Rubinstein, R.
\newblock 2005.
\newblock A tutorial on the cross-entropy method.
\newblock {\em Annals of Operations Research} 134(1):19--67.

\bibitem[\protect\citeauthoryear{Deng \bgroup et al\mbox.\egroup
  }{2009}]{ImageNet}
Deng, J.; Dong, W.; Socher, R.; Li, L.; Li, K.; and Fei-Fei, L.
\newblock 2009.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Donahue \bgroup et al\mbox.\egroup
  }{2015}]{LSTM}
Donahue, J.; Anne~Hendricks, L.; Guadarrama, S.; Rohrbach, M.; Venugopalan, S.;
  Saenko, K.; and Darrell, T.
\newblock 2015.
\newblock Long-term recurrent convolutional networks for visual recognition and
  description.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Duta \bgroup et al\mbox.\egroup
  }{2017}]{dutaspatio}
Duta, I.~C.; Ionescu, B.; Aizawa, K.; and Sebe, N.
\newblock 2017.
\newblock Spatio-temporal vector of locally max pooled features for action
  recognition in videos.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Feichtenhofer, Pinz, and Wildes}{2016}]{nips}
Feichtenhofer, C.; Pinz, A.; and Wildes, R.
\newblock 2016.
\newblock Spatiotemporal residual networks for video action recognition.
\newblock In {\em NIPS}.

\bibitem[\protect\citeauthoryear{Feichtenhofer, Pinz, and
  Zisserman}{2016}]{twostreamfuse}
Feichtenhofer, C.; Pinz, A.; and Zisserman, A.
\newblock 2016.
\newblock Convolutional two-stream network fusion for video action recognition.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Graves, Mohamed, and Hinton}{2013}]{LSTM2}
Graves, A.; Mohamed, A.~R.; and Hinton, G.
\newblock 2013.
\newblock Speech recognition with deep recurrent neural networks.
\newblock In {\em ICASSP}.

\bibitem[\protect\citeauthoryear{Ji \bgroup et al\mbox.\egroup }{2013}]{3dcnn2}
Ji, S.; Xu, W.; Yang, M.; and Yu, K.
\newblock 2013.
\newblock 3d convolutional neural networks for human action recognition.
\newblock {\em IEEE Trans. Pattern Anal. Mach. Intell.} 35(1):221--231.

\bibitem[\protect\citeauthoryear{Jia \bgroup et al\mbox.\egroup }{2014}]{caffe}
Jia, Y.; Shelhamer, E.; Donahue, J.; Karayev, S.; Long, J.; Girshick, R.;
  Guadarrama, S.; and Darrell, T.
\newblock 2014.
\newblock Caffe: Convolutional architecture for fast feature embedding.
\newblock In {\em ACM MM}.

\bibitem[\protect\citeauthoryear{Kar \bgroup et al\mbox.\egroup
  }{2017}]{kar2016adascan}
Kar, A.; Rai, N.; Sikka, K.; and Sharma, G.
\newblock 2017.
\newblock Adascan: Adaptive scan pooling in deep convolutional neural networks
  for human action recognition in videos.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Kataoka \bgroup et al\mbox.\egroup
  }{2016}]{3stream2}
Kataoka, H.; He, Y.; Shirakabe, S.; and Satoh, Y.
\newblock 2016.
\newblock Motion representation with acceleration images.
\newblock In {\em ECCVW}.

\bibitem[\protect\citeauthoryear{Kuehne \bgroup et al\mbox.\egroup
  }{2011}]{hmdb51}
Kuehne, H.; Jhuang, H.; Garrote, E.; Poggio, T.; and Serre, T.
\newblock 2011.
\newblock {HMDB: a large video database for human motion recognition}.
\newblock In {\em ICCV}.

\bibitem[\protect\citeauthoryear{Liu \bgroup et al\mbox.\egroup
  }{2016}]{liu2016two}
Liu, J.; Gao, C.; Meng, D.; and Zuo, W.
\newblock 2016.
\newblock Two-stream contextualized cnn for fine-grained image classification.
\newblock In {\em AAAI}.

\bibitem[\protect\citeauthoryear{Scovanner, Ali, and Shah}{2007}]{3dsift}
Scovanner, P.; Ali, S.; and Shah, M.
\newblock 2007.
\newblock {A 3-dimensional SIFT descriptor and its application to action
  recognition}.
\newblock In {\em ACM MM}.

\bibitem[\protect\citeauthoryear{Sharma, Kiros, and
  Salakhutdinov}{2015}]{visualattention}
Sharma, S.; Kiros, R.; and Salakhutdinov, R.
\newblock 2015.
\newblock Action recognition using visual attention.
\newblock In {\em CoRR abs/1511.04119}.

\bibitem[\protect\citeauthoryear{Shen \bgroup et al\mbox.\egroup
  }{2017}]{skeleton}
Shen, W.; Zhao, K.; Jiang, Y.; Wang, Y.; Bai, X.; and Yuille, A.
\newblock 2017.
\newblock Deepskeleton: Learning multi-task scale-associated deep side outputs
  for object skeleton extraction in natural images.
\newblock {\em IEEE Trans. Image Processing}.

\bibitem[\protect\citeauthoryear{Shi \bgroup et al\mbox.\egroup
  }{2017}]{3stream}
Shi, Y.; Tian, Y.; Wang, Y.; and Huang, T.
\newblock 2017.
\newblock {Sequential deep trajectory descriptor for action recognition with
  three-stream CNN}.
\newblock {\em IEEE Trans. Multimedia}.

\bibitem[\protect\citeauthoryear{Simonyan and Zisserman}{2014}]{baseline}
Simonyan, K., and Zisserman, A.
\newblock 2014.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock In {\em NIPS}.

\bibitem[\protect\citeauthoryear{Song \bgroup et al\mbox.\egroup
  }{2017}]{song2017end}
Song, S.; Lan, C.; Xing, J.; Zeng, W.; and Liu, J.
\newblock 2017.
\newblock An end-to-end spatio-temporal attention model for human action
  recognition from skeleton data.
\newblock In {\em AAAI}.

\bibitem[\protect\citeauthoryear{Soomro, Zamir, and Shah}{2012}]{ucf101}
Soomro, K.; Zamir, A.~R.; and Shah, M.
\newblock 2012.
\newblock {UCF101: a dataset of 101 human actions classes from videos in the
  wild}.
\newblock In {\em CoRR abs/1212.0402}.

\bibitem[\protect\citeauthoryear{Sun \bgroup et al\mbox.\egroup
  }{2017}]{lstmiccv2017}
Sun, L.; Jia, K.; Chen, K.; Yeung, D.~Y.; Shi, B.~E.; and Savarese, S.
\newblock 2017.
\newblock Lattice long short-term memory for human action recognition.
\newblock In {\em ICCV}.

\bibitem[\protect\citeauthoryear{Tran \bgroup et al\mbox.\egroup }{2015}]{c3d}
Tran, D.; Bourdev, L.; Fergus, R.; Torresani, L.; and Paluri, M.
\newblock 2015.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In {\em ICCV}.

\bibitem[\protect\citeauthoryear{Wang \bgroup et al\mbox.\egroup }{2013}]{iDT}
Wang, H.; Klaser, A.; Schmid, C.; and Liu, C.
\newblock 2013.
\newblock Dense trajectories and motion boundary descriptors for action
  recognition.
\newblock {\em Intl. Journal Comp. Vision} 103(1):60--79.

\bibitem[\protect\citeauthoryear{Wang \bgroup et al\mbox.\egroup
  }{2016a}]{twocnn2}
Wang, J.; Wei, Z.; Zhang, T.; and Zeng, W.
\newblock 2016a.
\newblock Deeply fused nets.
\newblock In {\em CoRR abs/1605.07716}.

\bibitem[\protect\citeauthoryear{Wang \bgroup et al\mbox.\egroup }{2016b}]{TSN}
Wang, L.; Xiong, Y.; Wang, Z.; Qiao, Y.; Lin, D.; Tang, X.; and Van~Gool, L.
\newblock 2016b.
\newblock Temporal segment networks: Towards good practices for deep action
  recognition.
\newblock In {\em ECCV}.

\bibitem[\protect\citeauthoryear{Wang, Farhadi, and Gupta}{2016}]{transform}
Wang, X.; Farhadi, A.; and Gupta, A.
\newblock 2016.
\newblock Actions~ transformations.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Wang, Qiao, and Tang}{2015}]{TDDIDT}
Wang, L.; Qiao, Y.; and Tang, X.
\newblock 2015.
\newblock Action recognition with trajectory-pooled deep-convolutional
  descriptors.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Wu \bgroup et al\mbox.\egroup
  }{2015}]{wumultifusion}
Wu, Z.; Wang, X.; Jiang, Y.; Ye, H.; and Xue, X.
\newblock 2015.
\newblock Modeling spatial-temporal clues in a hybrid deep learning framework
  for video classification.
\newblock In {\em ACM MM}.

\bibitem[\protect\citeauthoryear{Wu \bgroup et al\mbox.\egroup
  }{2016}]{jointattention}
Wu, J.; Wang, G.; Yang, W.; and Ji, X.
\newblock 2016.
\newblock Action recognition with joint attention on multi-level deep features.
\newblock In {\em CoRR abs/1607.02556}.

\bibitem[\protect\citeauthoryear{Xiao \bgroup et al\mbox.\egroup
  }{2015}]{twocnn}
Xiao, T.; Xu, Y.; Yang, K.; Zhang, J.; Peng, Y.; and Zhang, Z.
\newblock 2015.
\newblock The application of two-level attention models in deep convolutional
  neural network for fine-grained image classification.
\newblock In {\em CVPR}.

\bibitem[\protect\citeauthoryear{Xie and Tu}{2015}]{skeleton2}
Xie, S., and Tu, Z.
\newblock 2015.
\newblock Holistically-nested edge detection.
\newblock In {\em ICCV}.

\bibitem[\protect\citeauthoryear{Zhu \bgroup et al\mbox.\egroup }{2016}]{KVMF}
Zhu, W.; Hu, J.; Sun, G.; Cao, X.; and Qiao, Y.
\newblock 2016.
\newblock A key volume mining deep framework for action recognition.
\newblock In {\em CVPR}.

\end{thebibliography}
