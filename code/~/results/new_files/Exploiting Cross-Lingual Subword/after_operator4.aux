\relax 
\citation{devlin-19}
\citation{strassel-16}
\citation{klementiev-12}
\citation{shi-10}
\citation{andrade-15}
\citation{banea-08-fixed}
\citation{wan-09-fixed}
\citation{zhou-16}
\citation{mimno-09-fixed}
\citation{yuan-18}
\citation{klementiev-12}
\citation{wu-19}
\citation{pinter-17}
\citation{xu-17}
\citation{graves-05}
\citation{iyyer-15-fixed}
\citation{ling-15a}
\citation{ballesteros-15}
\citation{lample-16}
\citation{iyyer-15-fixed}
\citation{chen-18}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:model}{{1}{2}{\let \reserved@d = *\def \@@par \parindent \caption@parindent \hangindent \caption@hangindent }{}{}}
\newlabel{sec:model}{{2}{2}{}{}{}}
\citation{mortensen-18}
\citation{collobert-11b}
\citation{mikolov-13b}
\citation{collobert-11b}
\citation{pinter-17}
\citation{xu-17}
\newlabel{ssec:char}{{2.2}{3}{}{}{}}
\newlabel{ssec:objective}{{2.3}{3}{}{}{}}
\newlabel{eq:full_obj}{{11}{3}{}{}{}}
\citation{lewis-04}
\citation{klementiev-12}
\citation{klementiev-12}
\citation{strassel-16}
\citation{ammar-16}
\newlabel{tab:model}{{1}{4}{Comparison of models used in our experiments (introduced in Section\nobreakspace  {}\ref {ssec:model}). For each model, we list its required resources and average accuracy on \textsc  {rcv2} over eight related language pairs (accuracy for each pair in Table\nobreakspace  {}\ref {tab:rcv2}). We compare \textsc  {caco}{} variants with two high-resource models: a \textsc  {clwe}-based model (\textsc  {clwe}) and a lightly supervised target language model (\textsc  {sup}). Both baselines require more target language resources than \textsc  {caco}{} variants, and yet they have lower average accuracy than some \textsc  {caco}{} variants, which confirms that character-level knowledge transfer is highly efficient. We also experiment with a model that combines \textsc  {clwe} with \textsc  {caco}{} (\textsc  {com}). This combined model has the highest average accuracy, indicating that \textsc  {clwe} and \textsc  {caco}{} are complementary when both options are available. }{}{}}
\newlabel{sec:experiments}{{3}{4}{}{}{}}
\newlabel{ssec:model}{{3.2}{4}{}{}{}}
\citation{ammar-16}
\newlabel{tab:rcv2}{{2}{5}{\textsc  {cldc} experiments between eight related European language pairs on \textsc  {rcv2} topic identification. The average accuracy of \textsc  {caco}{} models are competitive with word-based models that use \emph  {more resources} such as target language corpora or labeled data (Table\nobreakspace  {}\ref {tab:model}). The combined model (\textsc  {com}) has the highest average test accuracy. We \textbf  {boldface} the best result for each row.}{}{}}
\newlabel{tab:lorelei}{{3}{5}{\textsc  {cldc} experiments between Amharic and Tigrinya on \textsc  {lorelei} disaster response dataset. \textsc  {caco}{} models are only slightly worse than \textsc  {clwe}-based models without using any target language data. For \textsc  {am}-\textsc  {ti}, knowledge distillation (\textsc  {src\textsuperscript  {p}{}} and \textsc  {mim\textsuperscript  {p}{}}) further improves \textsc  {caco}{} models. We do not experiment with knowledge distillation on \textsc  {ti} because we cannot find enough unlabeled parallel text in the language pack. Combining \textsc  {caco}{} with pre-trained \textsc  {clwe} gives the highest test accuracy.}{}{}}
\newlabel{sec:hyperparameter}{{3.4}{5}{}{}{}}
\citation{kingma-15}
\citation{conneau-18}
\newlabel{tab:unrelated}{{4}{6}{\textsc  {cldc} experiments between languages from different families on \textsc  {rcv2}. When transferring from a North Germanic language to a Romance language, \textsc  {caco}{} models score much lower than \textsc  {clwe}-based models (left). Surprisingly, \textsc  {caco}{} models are on par with \textsc  {clwe}-based when transferring from a Romance language to a North Germanic language (right). We \textbf  {boldface} the best result for each row.}{}{}}
\newlabel{ssec:analysis}{{3.5}{6}{}{}{}}
\citation{shi-10}
\citation{andrade-15}
\citation{banea-08-fixed}
\citation{wan-09-fixed}
\citation{zhou-16}
\citation{klementiev-12}
\citation{devlin-19}
\citation{wu-19}
\citation{conneau-18}
\citation{artetxe-18b}
\citation{zhang-19}
\citation{yuan-19}
\citation{sogaard-18}
\citation{fujinuma-19}
\citation{czarnowska-19}
\citation{kann-17}
\citation{cotterell-17a}
\citation{kim-17}
\citation{bharadwaj-16}
\citation{cotterell-17b}
\citation{lin-18}
\citation{rijhwani-19}
\bibdata{aaai}
\bibstyle{aaai}
\newlabel{sec:related}{{4}{7}{}{}{}}
\newlabel{tab:multisrc}{{5}{7}{Results of \textsc  {cldc} experiments using two source languages. Models trained on two source languages are generally better than models trained on only one source language (Table\nobreakspace  {}\ref {tab:rcv2}).}{}{}}
\newlabel{tab:bli}{{6}{7}{Word translation accuracies (P@1) for different embeddings. The \textsc  {caco}{} embeddings are generated by the embedder of a \textsc  {src} model trained on the source language. Without any cross-lingual signal, the \textsc  {caco}{} embedder has competitive word translation accuracy as \textsc  {clwe} pre-trained on large target language corpora and dictionaries.}{}{}}
\newlabel{sec:conclusion}{{5}{7}{}{}{}}
\gdef \@abspage@last{7}
