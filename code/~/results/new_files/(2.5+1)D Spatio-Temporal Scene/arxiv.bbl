\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Alamri et~al.(2019{\natexlab{a}})Alamri, Cartillier, Das, Wang,
  Cherian, Essa, Batra, Marks, Hori, Anderson et~al.}]{alamri2019audio}
Alamri, H.; Cartillier, V.; Das, A.; Wang, J.; Cherian, A.; Essa, I.; Batra,
  D.; Marks, T.~K.; Hori, C.; Anderson, P.; et~al. 2019{\natexlab{a}}.
\newblock Audio visual scene-aware dialog.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 7558--7567.

\bibitem[{Alamri et~al.(2019{\natexlab{b}})Alamri, Hori, Marks, Batra, and
  Parikh}]{AVSD@DSTC7}
Alamri, H.; Hori, C.; Marks, T.~K.; Batra, D.; and Parikh, D.
  2019{\natexlab{b}}.
\newblock Audio Visual Scene-aware dialog ({AVSD}) Track for Natural Language
  Generation in {DSTC7}.
\newblock In \emph{AAAI workshop on the 7th edition of Dialog System Technology
  Challenge (DSTC7)}.

\bibitem[{Anderson et~al.(2018)Anderson, He, Buehler, Teney, Johnson, Gould,
  and Zhang}]{anderson2018bottom}
Anderson, P.; He, X.; Buehler, C.; Teney, D.; Johnson, M.; Gould, S.; and
  Zhang, L. 2018.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 6077--6086.

\bibitem[{Antol et~al.(2015)Antol, Agrawal, Lu, Mitchell, Batra, Zitnick, and
  Parikh}]{antol2015vqa}
Antol, S.; Agrawal, A.; Lu, J.; Mitchell, M.; Batra, D.; Zitnick, C.~L.; and
  Parikh, D. 2015.
\newblock Vqa: Visual question answering.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2425--2433.

\bibitem[{Armeni et~al.(2019)Armeni, He, Gwak, Zamir, Fischer, Malik, and
  Savarese}]{armeni20193d}
Armeni, I.; He, Z.-Y.; Gwak, J.; Zamir, A.~R.; Fischer, M.; Malik, J.; and
  Savarese, S. 2019.
\newblock {3D Scene Graph}: A structure for unified semantics, 3d space, and
  camera.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 5664--5673.

\bibitem[{Bar et~al.(2020)Bar, Herzig, Wang, Chechik, Darrell, and
  Globerson}]{bar2020compositional}
Bar, A.; Herzig, R.; Wang, X.; Chechik, G.; Darrell, T.; and Globerson, A.
  2020.
\newblock Compositional video synthesis with action graphs.
\newblock \emph{arXiv preprint arXiv:2006.15327}.

\bibitem[{Bello(2021)}]{bello2021lambdanetworks}
Bello, I. 2021.
\newblock {Lambda Networks}: Modeling long-range interactions without
  attention.
\newblock \emph{arXiv preprint arXiv:2102.08602}.

\bibitem[{Carreira and Zisserman(2017)}]{carreira2017quo}
Carreira, J.; and Zisserman, A. 2017.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 6299--6308.

\bibitem[{Chatterjee et~al.(2021)Chatterjee, Le~Roux, Ahuja, and
  Cherian}]{chatterjee2021visual}
Chatterjee, M.; Le~Roux, J.; Ahuja, N.; and Cherian, A. 2021.
\newblock Visual Scene Graphs for Audio Source Separation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 1204--1213.

\bibitem[{Chen et~al.(2020)Chen, Yan, Xiao, Zhang, Pu, and
  Zhuang}]{chen2020counterfactual}
Chen, L.; Yan, X.; Xiao, J.; Zhang, H.; Pu, S.; and Zhuang, Y. 2020.
\newblock Counterfactual samples synthesizing for robust visual question
  answering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10800--10809.

\bibitem[{Choromanski et~al.(2021)Choromanski, Lin, Chen, and
  Parker-Holder}]{choromanski2021graph}
Choromanski, K.; Lin, H.; Chen, H.; and Parker-Holder, J. 2021.
\newblock Graph Kernel Attention Transformers.
\newblock \emph{arXiv preprint arXiv:2107.07999}.

\bibitem[{Cong et~al.(2021)Cong, Liao, Ackermann, Rosenhahn, and
  Yang}]{cong2021spatial}
Cong, Y.; Liao, W.; Ackermann, H.; Rosenhahn, B.; and Yang, M.~Y. 2021.
\newblock Spatial-temporal transformer for dynamic scene graph generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 16372--16382.

\bibitem[{Dang et~al.(2021)Dang, Le, Le, and Tran}]{dang2021hierarchical}
Dang, L.~H.; Le, T.~M.; Le, V.; and Tran, T. 2021.
\newblock Hierarchical Object-oriented Spatio-Temporal Reasoning for Video
  Question Answering.
\newblock \emph{arXiv preprint arXiv:2106.13432}.

\bibitem[{Dornadula et~al.(2019)Dornadula, Narcomey, Krishna, Bernstein, and
  Li}]{dornadula2019visual}
Dornadula, A.; Narcomey, A.; Krishna, R.; Bernstein, M.; and Li, F.-F. 2019.
\newblock Visual relationships as functions: Enabling few-shot scene graph
  prediction.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}.

\bibitem[{Fan et~al.(2019)Fan, Zhang, Zhang, Wang, Zhang, and
  Huang}]{fan2019heterogeneous}
Fan, C.; Zhang, X.; Zhang, S.; Wang, W.; Zhang, C.; and Huang, H. 2019.
\newblock Heterogeneous memory enhanced multimodal attention model for video
  question answering.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 1999--2007.

\bibitem[{Fu et~al.(2018)Fu, Gong, Wang, Batmanghelich, and Tao}]{fu2018deep}
Fu, H.; Gong, M.; Wang, C.; Batmanghelich, K.; and Tao, D. 2018.
\newblock Deep ordinal regression network for monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2002--2011.

\bibitem[{Gao et~al.(2018)Gao, Ge, Chen, and Nevatia}]{gao2018motion}
Gao, J.; Ge, R.; Chen, K.; and Nevatia, R. 2018.
\newblock Motion-appearance co-memory networks for video question answering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 6576--6585.

\bibitem[{Geng et~al.(2021)Geng, Gao, Chatterjee, Hori, Le~Roux, Zhang, Li, and
  Cherian}]{geng2021dynamic}
Geng, S.; Gao, P.; Chatterjee, M.; Hori, C.; Le~Roux, J.; Zhang, Y.; Li, H.;
  and Cherian, A. 2021.
\newblock Dynamic graph representation learning for video dialog via
  multi-modal shuffled transformers.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}.

\bibitem[{Ghosh et~al.(2019)Ghosh, Burachas, Ray, and
  Ziskind}]{ghosh2019generating}
Ghosh, S.; Burachas, G.; Ray, A.; and Ziskind, A. 2019.
\newblock Generating natural language explanations for visual question
  answering using scene graphs and visual attention.
\newblock \emph{arXiv:1902.05715}.

\bibitem[{Girdhar et~al.(2019)Girdhar, Carreira, Doersch, and
  Zisserman}]{girdhar2019video}
Girdhar, R.; Carreira, J.; Doersch, C.; and Zisserman, A. 2019.
\newblock Video action transformer network.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 244--253.

\bibitem[{Girdhar and Ramanan(2019)}]{girdhar2019cater}
Girdhar, R.; and Ramanan, D. 2019.
\newblock CATER: A diagnostic dataset for Compositional Actions and TEmporal
  Reasoning.
\newblock \emph{arXiv preprint arXiv:1910.04744}.

\bibitem[{Hartley and Zisserman(2004)}]{multiview}
Hartley, R.~I.; and Zisserman, A. 2004.
\newblock \emph{Multiple View Geometry in Computer Vision}.
\newblock Cambridge University Press, ISBN: 0521540518, second edition.

\bibitem[{Herzig et~al.(2019)Herzig, Levi, Xu, Gao, Brosh, Wang, Globerson, and
  Darrell}]{herzig2019spatio}
Herzig, R.; Levi, E.; Xu, H.; Gao, H.; Brosh, E.; Wang, X.; Globerson, A.; and
  Darrell, T. 2019.
\newblock Spatio-temporal action graph networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}.

\bibitem[{Hori et~al.(2019)Hori, Alamri, Wang, Wichern, Hori, Cherian, Marks,
  Cartillier, Lopes, Das et~al.}]{hori2019end}
Hori, C.; Alamri, H.; Wang, J.; Wichern, G.; Hori, T.; Cherian, A.; Marks,
  T.~K.; Cartillier, V.; Lopes, R.~G.; Das, A.; et~al. 2019.
\newblock End-to-end audio visual scene-aware dialog using multimodal
  attention-based video features.
\newblock In \emph{ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing}, 2352--2356.

\bibitem[{Jang et~al.(2019)Jang, Song, Kim, Yu, Kim, and Kim}]{jang2019video}
Jang, Y.; Song, Y.; Kim, C.~D.; Yu, Y.; Kim, Y.; and Kim, G. 2019.
\newblock Video question answering with spatio-temporal reasoning.
\newblock \emph{International Journal of Computer Vision}, 127(10): 1385--1412.

\bibitem[{Jang et~al.(2017)Jang, Song, Yu, Kim, and Kim}]{jang2017tgif}
Jang, Y.; Song, Y.; Yu, Y.; Kim, Y.; and Kim, G. 2017.
\newblock Tgif-qa: Toward spatio-temporal reasoning in visual question
  answering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2758--2766.

\bibitem[{Ji et~al.(2020)Ji, Krishna, Fei-Fei, and Niebles}]{ji2019action}
Ji, J.; Krishna, R.; Fei-Fei, L.; and Niebles, J.~C. 2020.
\newblock Action Genome: Actions as Composition of Spatio-temporal Scene
  Graphs.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}.

\bibitem[{Jiang and Han(2020)}]{jiang2020reasoning}
Jiang, P.; and Han, Y. 2020.
\newblock Reasoning with heterogeneous graph alignment for video question
  answering.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, 11109--11116.

\bibitem[{Jiang et~al.(2019)Jiang, Gao, Guo, Zhang, Xiang, and
  Pan}]{Jiang_Gao_Guo_Zhang_Xiang_Pan_2019}
Jiang, Z.; Gao, P.; Guo, C.; Zhang, Q.; Xiang, S.; and Pan, C. 2019.
\newblock Video object detection with locally-weighted deformable neighbors.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, 8529--8536.

\bibitem[{Johnson et~al.(2015)Johnson, Krishna, Stark, Li, Shamma, Bernstein,
  and Fei-Fei}]{johnson2015image}
Johnson, J.; Krishna, R.; Stark, M.; Li, L.-J.; Shamma, D.; Bernstein, M.; and
  Fei-Fei, L. 2015.
\newblock Image retrieval using scene graphs.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 3668--3678.

\bibitem[{Krishna et~al.(2017)Krishna, Hata, Ren, Fei-Fei, and
  Carlos~Niebles}]{krishna2017visual}
Krishna, R.; Hata, K.; Ren, F.; Fei-Fei, L.; and Carlos~Niebles, J. 2017.
\newblock Dense-captioning events in videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 706--715.

\bibitem[{Le et~al.(2019)Le, Sahoo, Chen, and Hoi}]{le2019multimodal}
Le, H.; Sahoo, D.; Chen, N.~F.; and Hoi, S.~C. 2019.
\newblock Multimodal transformer networks for end-to-end video-grounded
  dialogue systems.
\newblock \emph{arXiv preprint arXiv:1907.01166}.

\bibitem[{Le et~al.(2020)Le, Le, Venkatesh, and Tran}]{le2020hierarchical}
Le, T.~M.; Le, V.; Venkatesh, S.; and Tran, T. 2020.
\newblock Hierarchical conditional relation networks for video question
  answering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 9972--9981.

\bibitem[{Li et~al.(2020)Li, Gordon, Zhao, Casser, and
  Angelova}]{li2020unsupervised}
Li, H.; Gordon, A.; Zhao, H.; Casser, V.; and Angelova, A. 2020.
\newblock Unsupervised monocular depth learning in dynamic scenes.
\newblock \emph{arXiv preprint arXiv:2010.16404}.

\bibitem[{Li et~al.(2019)Li, Gan, Cheng, and Liu}]{li2019relation}
Li, L.; Gan, Z.; Cheng, Y.; and Liu, J. 2019.
\newblock Relation-aware Graph Attention Network for Visual Question Answering.
\newblock \emph{arXiv:1903.12314}.

\bibitem[{Li and Jiang(2019)}]{li2019know}
Li, X.; and Jiang, S. 2019.
\newblock Know more say less: Image captioning based on scene graphs.
\newblock \emph{IEEE Transactions on Multimedia}, 21(8): 2117--2130.

\bibitem[{Pan et~al.(2020)Pan, Cai, Huang, Lee, Gaidon, Adeli, and
  Niebles}]{pan2020spatio}
Pan, B.; Cai, H.; Huang, D.-A.; Lee, K.-H.; Gaidon, A.; Adeli, E.; and Niebles,
  J.~C. 2020.
\newblock Spatio-temporal graph for video captioning with knowledge
  distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10870--10879.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Radford, A.; Kim, J.~W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry,
  G.; Askell, A.; Mishkin, P.; Clark, J.; et~al. 2021.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}.

\bibitem[{Ranftl et~al.(2019)Ranftl, Lasinger, Hafner, Schindler, and
  Koltun}]{ranftl2019towards}
Ranftl, R.; Lasinger, K.; Hafner, D.; Schindler, K.; and Koltun, V. 2019.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock \emph{arXiv preprint arXiv:1907.01341}.

\bibitem[{Rashid, Kjellstrom, and Lee(2020)}]{rashid2020action}
Rashid, M.; Kjellstrom, H.; and Lee, Y.~J. 2020.
\newblock Action graphs: Weakly-supervised action localization with graph
  convolution networks.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, 615--624.

\bibitem[{Ren et~al.(2015)Ren, He, Girshick, and Sun}]{ren2015faster}
Ren, S.; He, K.; Girshick, R.; and Sun, J. 2015.
\newblock Faster {R-CNN}: Towards real-time object detection with region
  proposal networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 28: 91--99.

\bibitem[{Shamsian et~al.(2020)Shamsian, Kleinfeld, Globerson, and
  Chechik}]{shamsian2020learning}
Shamsian, A.; Kleinfeld, O.; Globerson, A.; and Chechik, G. 2020.
\newblock Learning object permanence from video.
\newblock In \emph{European Conference on Computer Vision}, 35--50. Springer.

\bibitem[{Teney et~al.(2018)Teney, Anderson, He, and Van
  Den~Hengel}]{teney2018tips}
Teney, D.; Anderson, P.; He, X.; and Van Den~Hengel, A. 2018.
\newblock Tips and tricks for visual question answering: Learnings from the
  2017 challenge.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 4223--4232.

\bibitem[{Tsai et~al.(2019{\natexlab{a}})Tsai, Bai, Yamada, Morency, and
  Salakhutdinov}]{tsai2019Transformer}
Tsai, Y.-H.~H.; Bai, S.; Yamada, M.; Morency, L.-P.; and Salakhutdinov, R.
  2019{\natexlab{a}}.
\newblock Transformer Dissection: A Unified Understanding of Transformer's
  Attention via the Lens of Kernel.
\newblock \emph{arXiv preprint arXiv:1908.11775}.

\bibitem[{Tsai et~al.(2019{\natexlab{b}})Tsai, Divvala, Morency, Salakhutdinov,
  and Farhadi}]{tsai2019video}
Tsai, Y.-H.~H.; Divvala, S.; Morency, L.-P.; Salakhutdinov, R.; and Farhadi, A.
  2019{\natexlab{b}}.
\newblock Video relationship reasoning using gated spatio-temporal energy
  graph.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10424--10433.

\bibitem[{Tung et~al.(2020)Tung, Xian, Prabhudesai, Lal, and
  Fragkiadaki}]{tung20203d}
Tung, H.-Y.~F.; Xian, Z.; Prabhudesai, M.; Lal, S.; and Fragkiadaki, K. 2020.
\newblock {3D-OES}: Viewpoint-invariant object-factorized environment
  simulators.
\newblock \emph{arXiv preprint arXiv:2011.06464}.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.;
  Kaiser, {\L}.; and Polosukhin, I. 2017.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems},
  5998--6008.

\bibitem[{Wang et~al.(2018)Wang, Girshick, Gupta, and He}]{wang2018non}
Wang, X.; Girshick, R.; Gupta, A.; and He, K. 2018.
\newblock Non-local neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 7794--7803.

\bibitem[{Wang and Gupta(2018)}]{Wang2018videos}
Wang, X.; and Gupta, A. 2018.
\newblock Videos as space-time region graphs.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  399--417.

\bibitem[{Wu et~al.(2017)Wu, Teney, Wang, Shen, Dick, and van~den
  Hengel}]{wu2017visual}
Wu, Q.; Teney, D.; Wang, P.; Shen, C.; Dick, A.; and van~den Hengel, A. 2017.
\newblock Visual question answering: A survey of methods and datasets.
\newblock \emph{Computer Vision and Image Understanding}, 163: 21--40.

\bibitem[{Wu et~al.(2021)Wu, Wald, Tateno, Navab, and
  Tombari}]{wu2021scenegraphfusion}
Wu, S.-C.; Wald, J.; Tateno, K.; Navab, N.; and Tombari, F. 2021.
\newblock SceneGraphFusion: Incremental 3D Scene Graph Prediction from RGB-D
  Sequences.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 7515--7525.

\bibitem[{Xiao et~al.(2021)Xiao, Shang, Yao, and Chua}]{xiao2021next}
Xiao, J.; Shang, X.; Yao, A.; and Chua, T.-S. 2021.
\newblock NExT-QA: Next Phase of Question-Answering to Explaining Temporal
  Actions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 9777--9786.

\bibitem[{Zhang et~al.(2021)Zhang, Yu, Song, and Cai}]{zhang2021exploiting}
Zhang, C.; Yu, J.; Song, Y.; and Cai, W. 2021.
\newblock Exploiting Edge-Oriented Reasoning for 3D Point-based Scene Graph
  Analysis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 9705--9715.

\end{thebibliography}
