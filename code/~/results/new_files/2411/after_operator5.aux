\relax 
\bibstyle{aaai24}
\citation{dgcnn,wang2019graphattenconv}
\citation{dgcnn,wang2019graphattenconv}
\citation{shi2020pointgnn,de2023iterativepfn,zhang2020pointfilter}
\citation{defferrard2016convolutional,chung1997spectral}
\citation{qi20173d,landrieu2018large,bi2019graph,yi2023graph}
\citation{dgcnn}
\citation{wang2019graphattenconv}
\providecommand \oddpage@label [2]{}
\newlabel{sec:intro}{{1}{1}{}{}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro_pic}{{1}{1}{ \textbf  {First row:} Constructing the ground truth graph for \textit  {our self-supervised hop distance reconstruction task}. (a): Voxelizing the point cloud into parts, taking each part as a graph node. (b): The topology of the ground truth graph. Two nodes are adjacent if their scaled bounding boxes are intersected. (c): The shortest path between a node (enlarged red point) and other nodes. The number on each node denotes the hop distance which motivates \textit  {our self-supervised task}. \textbf  {Second row:} Sampling and grouping based strategy \citep  {dgcnn, wang2019graphattenconv}. (d): Sampling center points and grouping local point sets. (e): Constructing a local graph for each point set. We explore the contextual relationships between parts, while previous strategies focus on extracting local features of point sets. }{}{}}
\citation{qi2017pointnet}
\citation{pointnet++}
\citation{wu2021self}
\citation{xie2020pointcontrast,chen20214dcontrast,gao2020graphter}
\citation{afham2022crosspoint}
\citation{yang2018foldingnet,yu2022point,pang2022masked}
\citation{wang2021unsupervised}
\citation{defferrard2016convolutional}
\citation{defferrard2016convolutional,kipf2016semi}
\citation{dgcnn}
\citation{3dgcn}
\citation{adaptconv}
\citation{deepgcns}
\citation{pointmlp}
\citation{vaswani2017attention}
\citation{gat}
\citation{wang2019graphattenconv}
\citation{guo2021pct}
\newlabel{sec:method}{{3}{2}{}{}{}}
\citation{qi2017pointnet}
\citation{dgcnn}
\citation{adaptconv}
\citation{dgcnn}
\citation{dgcnn}
\citation{adaptconv}
\newlabel{fig:netarchi}{{2}{3}{ \textbf  {DHGCN architecture}: We feed the input point cloud to PointFeatureConv for extracting point-wise representations, which are then taken as input by Hop Graph Convolution (HopGraphConv), to extract more accurate local geometric representations. \textbf  {Hop Graph Convolution}: The HopGraphConv layer takes the point features as input, and achieves part features through part-level pooling. We construct a complete graph by taking parts as nodes and connecting each pair of them, and use PartConv and HGA to extract graph edge features. We propose the self-supervised hop distance reconstruction task to predict the distance matrix of the complete graph from edge features. \(\lambda \) controls whether the HGA embeds hop distance. Finally, edge features are aggregated and repeated at the part-level, providing additional representations for the point-based backbone network. }{}{}}
\newlabel{sec:volumetricpartition}{{3.1}{3}{}{}{}}
\newlabel{sec:partfeatureextractor}{{3.2}{3}{}{}{}}
\newlabel{sec:dynamichopconv}{{3.3}{3}{}{}{}}
\citation{dgcnn,pointnet++,guo2021pct}
\newlabel{fig:hop_distance}{{3}{4}{ Given the input point cloud, we first voxelize it into parts. For each part, we compute its scaled axis-aligned bounding box to calculate the adjacent relation between parts. We construct a ground truth graph along with its distance matrix for supervision in each layer. }{}{}}
\citation{latentgan}
\citation{yang2018foldingnet}
\citation{yang2018foldingnet}
\citation{latentgan}
\citation{zhao20193d}
\citation{zhao20193d}
\citation{han2019view}
\citation{hassani2019unsupervised}
\citation{huang2021spatio}
\citation{han2019mapvae}
\citation{chen2021shape}
\citation{gao2020graphter}
\citation{afham2022crosspoint}
\citation{rao2020global}
\citation{chang2015shapenet}
\citation{wu20153d}
\citation{yang2018foldingnet}
\citation{jiang2023masked}
\citation{yang2018foldingnet}
\newlabel{fig:feature_vis}{{4}{5}{Attention maps (row 1) for different query parts and feature distance from the query point (indicated by star, row 2 (ours) and row 3 (DGCNN)) to all other points, with yellow to red indicating increasing attention weight or closer distance.}{}{}}
\newlabel{sec:results}{{4}{5}{}{}{}}
\citation{uy2019revisiting}
\citation{qi2017pointnet}
\citation{pointnet++}
\citation{li2018pointcnn}
\citation{dgcnn}
\citation{yu2022point}
\citation{pang2022masked}
\citation{sauder2019self}
\citation{wang2021unsupervised}
\citation{huang2021spatio}
\citation{afham2022crosspoint}
\citation{yi2016scalable}
\citation{qi2017pointnet}
\citation{pointnet++}
\citation{dgcnn}
\citation{thomas2019kpconv}
\citation{xu2021paconv}
\citation{yu2022point}
\citation{latentgan}
\citation{han2019mapvae}
\citation{gao2020graphter}
\citation{jiang2023unsupervised}
\citation{li2018so}
\citation{zhao20193d}
\citation{hassani2019unsupervised}
\citation{xie2020pointcontrast}
\citation{chen2021shape}
\newlabel{table:unsuperMN}{{1}{6}{Classification results of \textit  {unsupervised} methods (including ours) on ModelNet40. `SN/MN' denotes `ShapeNet/ModelNet40' and `\# Points' indicates the point number in pretraining. }{}{}}
\newlabel{table:limited_data}{{2}{6}{Comparison results of 3D object classification with limited training data (different ratios) on ModelNet40. DGCNN is taken as the backbone. }{}{}}
\newlabel{table:scanobjectnn}{{3}{6}{Classification results of our method and state-of-the-art methods on ScanObjectNN. DGCNN is used as backbone. `Sup.' denotes the method is supervised ({\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 51}) or unsupervised ({\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 55}). Results of Jigsaw, OcCo, and STRL are from CrossPoint, and ``-'' indicates no previous results. }{}{}}
\newlabel{table:partseg}{{4}{7}{Shape part segmentation results of our method and state-of-the-art techniques on ShapeNet Part dataset. PAConv is used as backbone. `Sup.' denotes the method is supervised learning ({\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 51}) or unsupervised learning ({\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 55}).}{}{}}
\newlabel{table:limited_data_seg}{{5}{7}{Comparison results of shape part segmentation with limited training data (different ratios) on ShapeNet Part. PAConv is taken as the backbone. }{}{}}
\newlabel{table:attention}{{6}{7}{ Different attention mechanisms. Experiments are conducted on ModelNet40 with AdaptConv as the backbone. SA denotes self-attention, and HGA denotes Hop Graph Attention. Accuracy results of hop distance prediction and point cloud classification are reported. }{}{}}
\newlabel{table:ablation}{{7}{7}{Ablation results on different \(\sigma ^2\) in the Gaussian kernel. Experiments are conducted on ModelNet40 for classification with AdaptConv as the backbone.}{}{}}
\bibdata{aaai24}
\gdef \@abspage@last{8}
