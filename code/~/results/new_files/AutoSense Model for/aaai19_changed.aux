\relax 
\citation{stevenson2003word}
\citation{jurgens2013semeval}
\citation{song2007efficient}
\citation{chang2014inducing}
\citation{komninos2016structured}
\citation{blei2003latent}
\citation{brody2009bayesian}
\citation{wang2015sense}
\citation{chang2014inducing}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:wsi_example}{{1}{1}{Three senses of the noun \textit  {cold} and six of 17 senses of the noun \textit  {play} in WordNet. Sense granularity problem refers to the inflexibility of the model to the different number of senses different words may have (i.e. 3 vs. 17).}{}{}}
\citation{teh2004sharing}
\citation{lau2013unimelb}
\citation{manandhar2010semeval}
\citation{jurgens2013semeval}
\citation{almuhareb2006msda}
\citation{tsvetkov2014augmenting}
\citation{yao2012expectations}
\citation{jurgens2013semeval}
\citation{baskaya2013ai}
\citation{lau2013unimelb}
\citation{blei2003latent}
\citation{goyal2014unsupervised}
\citation{chang2014inducing}
\citation{wang2015sense}
\citation{teh2004sharing}
\citation{yao2011nonparametric}
\citation{lau2012word}
\citation{lau2013unimelb}
\citation{mikolov2013distributed}
\citation{wang2015sense}
\citation{song2016word}
\citation{pelevina2016making}
\citation{chang2018efficient}
\citation{komninos2016structured}
\citation{shu2009latent}
\citation{tang2012unified}
\citation{blei2003latent}
\citation{wang2015sense}
\citation{chang2014inducing}
\newlabel{fig:intuition}{{2}{2}{Example induced senses when the target word is \textit  {cold} from LDA and AutoSense. Applying our observations to LDA introduces both garbage and fine-grained senses.}{}{}}
\citation{chang2014inducing}
\citation{wang2015sense}
\citation{heckerman2000dependency}
\citation{brown1993mathematics}
\newlabel{fig:condsptm}{{3}{3}{Graphical representation of AutoSense. Nodes are random variables, edges are dependencies, and plates are replications. Nodes shaded in black are observed. The node shaded in red is the observed target word. The dependency edges of $\theta _{s|t}$, $\theta _{t|s}$, and $\theta _{st}$ are not shown for clarity: They are all generated by the Dirichlet prior $\alpha $. Moreover, sense variables are dependent to $\theta _{s|t}$ and $\theta _{st}$, while topic variables are dependent to $\theta _{t|s}$ and $\theta _{st}$.}{}{}}
\newlabel{tab:notations}{{1}{3}{Meanings of the notations in AutoSense}{}{}}
\citation{griffiths2004finding}
\citation{manandhar2010semeval}
\citation{jurgens2013semeval}
\citation{manning2014stanford}
\citation{wang2015sense}
\citation{griffiths2004finding}
\citation{chemudugunta2006modeling}
\citation{wang2015sense}
\citation{lau2012word}
\citation{goyal2014unsupervised}
\citation{wang2015sense}
\citation{manandhar2010semeval}
\citation{wang2015sense}
\newlabel{eq:induction}{{1}{4}{}{}{}}
\newlabel{sec:results}{{}{4}{}{}{}}
\citation{goyal2014unsupervised}
\citation{chang2014inducing}
\citation{song2016word}
\citation{wang2015sense}
\citation{jurgens2013semeval}
\citation{wang2015sense}
\citation{chang2018efficient}
\citation{komninos2016structured}
\citation{wang2015sense}
\citation{chang2014inducing}
\citation{wang2015sense}
\citation{wang2015sense}
\citation{lau2013unimelb}
\citation{chang2014inducing}
\newlabel{tab:semeval2010}{{2a}{5}{SemEval 2010 WSI dataset}{}{}}
\newlabel{sub@tab:semeval2010}{{a}{5}{SemEval 2010 WSI dataset}{}{}}
\newlabel{tab:semeval2013}{{2b}{5}{SemEval 2013 WSI dataset}{}{}}
\newlabel{sub@tab:semeval2013}{{b}{5}{SemEval 2013 WSI dataset}{}{}}
\newlabel{tab:results}{{2}{5}{Performance of different models on the datasets. Best scores are bold-faced. LVMs are Latent Variable Models, while NBEs are Neural-based Embeddings.}{}{}}
\newlabel{sec:sensegran}{{}{5}{}{}{}}
\citation{blei2003latent}
\citation{wang2015sense}
\citation{chang2014inducing}
\citation{teh2004sharing}
\citation{tang2012unified}
\newlabel{tab:sample}{{3}{6}{Six of the 15 senses of the target verb \textit  {book} using AutoSense with $S=15$. The word lists shown are preprocessed to remove stopwords and the target word. The first three senses are senses which are assigned at least once to an instance document. The last three are \textit  {garbage senses}.}{}{}}
\newlabel{sec:senses}{{}{6}{}{}{}}
\newlabel{fig:clusters}{{4}{6}{Cluster error of models with different number of senses $S$. The vertical dashed lines correspond to the \textcolor {blue}{mean} and the \textcolor {red}{max} of the actual number of senses. The x-axes are log-scaled.}{}{}}
\citation{blei2003latent}
\citation{chang2014inducing}
\citation{wang2015sense}
\citation{tang2012unified}
\citation{cen2013author}
\citation{tang2012unified}
\citation{tang2012unified}
\bibdata{aaai19}
\bibstyle{aaai}
\newlabel{tab:stat}{{4}{7}{Statistics of the number of senses of target words/names in the datasets used in the paper.}{}{}}
\newlabel{fig:andresults}{{5}{7}{Paired F1 measures of competing models with different number of senses $S$ on UAND datasets.}{}{}}
\gdef \@abspage@last{8}
