\relax 
\bibstyle{aaai23}
\citation{transformer}
\citation{bert,t5,scao2022bloom}
\citation{mobilebert}
\citation{li2020train}
\citation{parrot}
\citation{parrot}
\citation{qiu2020pre,han2021pre,xu2021survey}
\citation{pabee,sun2021early}
\newlabel{sec:metrics}{{2.1}{1}{}{}{}}
\citation{albert}
\citation{bert}
\citation{lacoste2019quantifying}
\citation{henderson2020towards}
\citation{xu2021beyond}
\citation{stanton2021does}
\citation{xu2021beyond,stanton2021does}
\citation{stanton2021does}
\citation{su2018is}
\citation{xu2021beyond}
\citation{du2021compressed}
\citation{glue}
\citation{superglue}
\citation{squad}
\citation{efficientqa}
\citation{wang2020overview}
\citation{superglue}
\citation{henderson2020towards}
\citation{liu2021towards}
\citation{obd}
\citation{han2016deep}
\citation{l0}
\citation{sanh2020movement}
\citation{sanh2020movement}
\citation{sanh2020movement}
\citation{transformer}
\citation{li2020train}
\citation{transformer}
\citation{xia2019tied}
\citation{rothe2020leveraging}
\citation{transformer}
\citation{dabre2019recurrent}
\citation{dehghani2019universal}
\citation{albert}
\citation{takase2021lessons}
\citation{reid2021subformer}
\citation{sainath2013low}
\newlabel{sec:benchmarks}{{2.2}{2}{}{}{}}
\citation{grachev2017neural}
\citation{winata2019effectiveness}
\citation{elmo}
\citation{ma2019tensorized}
\citation{btd}
\citation{noach2020compressing}
\citation{chen2021drone}
\citation{tahaei2021kroneckerbert,kroneckergpt}
\citation{albert}
\citation{reid2021subformer}
\citation{obd}
\citation{mishra2021accelerating}
\citation{see2016}
\citation{han2016deep}
\citation{see2016}
\citation{narang2017exploring}
\citation{wang2020on}
\citation{zhang2020one}
\citation{gordon2020compressing}
\citation{sanh2020movement}
\citation{guo2021parameter}
\citation{l0}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:prune}{{1}{3}{A summary of various pruning methods. $\mathbf  {S}$ are saliency scores used to determine which weights to prune. The table style is borrowed from \citet  {sanh2020movement}.}{}{}}
\newlabel{sec:pruning}{{3.3}{3}{}{}{}}
\citation{narang2017block}
\citation{narang2017exploring}
\citation{yuan2006model}
\citation{16heads}
\citation{voita2019analyzing}
\citation{drophead}
\citation{snip}
\citation{lagunas2021block}
\citation{sanh2020movement}
\citation{cofipruning}
\citation{lottery}
\citation{han2016deep}
\citation{chen2020lottery}
\citation{prasanna2020when}
\citation{nakkiran2020deep}
\citation{zafrir2019q8bert}
\citation{jacob2018quantization}
\citation{jacob2018quantization}
\citation{bengio2013estimating}
\citation{prato2020fully}
\citation{ibert}
\citation{qbert}
\citation{hawq}
\citation{gobo}
\citation{ternarybert}
\citation{binarybert}
\citation{tao2022compression}
\newlabel{fig:kd}{{1}{4}{A summary of different KD approaches. ``GT'' represents ground-truth labels.}{}{}}
\citation{hinton2015distilling}
\citation{hinton2015distilling}
\citation{tang2019distilling}
\citation{sanh2019distilbert}
\citation{turc2019well}
\citation{sanh2019distilbert,pkd}
\citation{mixkd}
\citation{mixup}
\citation{pkd}
\citation{aguilar2020knowledge}
\citation{tinybert}
\citation{minilm,minilmv2}
\citation{wu2021one}
\citation{dynabert}
\citation{mobilebert}
\citation{pkd}
\citation{tinybert}
\citation{liu2022multi}
\citation{bot}
\citation{huang2022sparse}
\citation{glue}
\citation{shi2020learning}
\citation{beck2003mirror}
\citation{zhou2021meta}
\citation{raptilemeta}
\citation{deebert}
\citation{schwartz2020right}
\citation{fastbert}
\citation{geng2021romebert}
\citation{skipbert}
\citation{pabee}
\citation{sun2021early}
\citation{leebert}
\citation{liao2021global}
\citation{pceebert}
\citation{xin2021berxit}
\citation{schuster2021consistent}
\newlabel{sec:ee}{{3.6}{5}{}{}{}}
\citation{park2015big,branchynet,shallowdeep}
\citation{deebert}
\citation{schwartz2020right}
\citation{fastbert}
\citation{geng2021romebert}
\citation{skipbert}
\citation{pabee}
\citation{sun2021early}
\citation{leebert}
\citation{liao2021global}
\citation{pceebert}
\citation{xin2021berxit}
\citation{schuster2021consistent}
\citation{powerbert}
\citation{trbert}
\citation{lat}
\citation{ltp}
\citation{transkimmer}
\citation{transkimmer}
\citation{powerbert}
\citation{trbert}
\citation{lat}
\citation{ltp}
\citation{transkimmer}
\newlabel{tab:ee}{{2}{6}{A summary of three types of early exit methods: confidence estimation, internal ensemble, and learning to exit. $\theta $ is a predefined threshold for exiting.}{}{}}
\newlabel{tab:token_skipping}{{3}{6}{A summary of token skipping methods. This table is adapted from \citet  {transkimmer}.}{}{}}
\citation{glue}
\citation{superglue}
\citation{kim2020fastformers,sanh2020movement,xu2021beyond}
\citation{stanton2021does,xu2021beyond}
\citation{du2021compressed,xu2021beyond}
\citation{stanton2021does,xu2021beyond}
\citation{maml}
\citation{darts}
\bibdata{custom.bib}
\newlabel{fig:decision}{{2}{7}{An \textit  {oversimplified} decision tree for model compression and acceleration.}{}{}}
\gdef \@abspage@last{8}
