\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Ardizzone et~al.(2018)Ardizzone, Kruse, Wirkert, Rahner, Pellegrini,
  Klessen, Maier-Hein, Rother, and K{\"o}the}]{ardizzone2018analyzing}
Ardizzone, L.; Kruse, J.; Wirkert, S.; Rahner, D.; Pellegrini, E.~W.; Klessen,
  R.~S.; Maier-Hein, L.; Rother, C.; and K{\"o}the, U. 2018.
\newblock Analyzing inverse problems with invertible neural networks.
\newblock \emph{arXiv preprint arXiv:1808.04730}.

\bibitem[{Ardizzone et~al.(2019)Ardizzone, L{\"u}th, Kruse, Rother, and
  K{\"o}the}]{ardizzone2019guided}
Ardizzone, L.; L{\"u}th, C.; Kruse, J.; Rother, C.; and K{\"o}the, U. 2019.
\newblock Guided image generation with conditional invertible neural networks.
\newblock \emph{arXiv preprint arXiv:1907.02392}.

\bibitem[{Asim et~al.(2020)Asim, Daniels, Leong, Ahmed, and
  Hand}]{asim2020invertible}
Asim, M.; Daniels, M.; Leong, O.; Ahmed, A.; and Hand, P. 2020.
\newblock Invertible generative models for inverse problems: mitigating
  representation error and dataset bias.
\newblock In \emph{International Conference on Machine Learning}, 399--409.
  PMLR.

\bibitem[{Bendsoe and Sigmund(2013)}]{bendsoe2013topology}
Bendsoe, M.~P.; and Sigmund, O. 2013.
\newblock \emph{Topology optimization: theory, methods, and applications}.
\newblock Springer Science \& Business Media.

\bibitem[{Bishop(1994)}]{bishop1994mixture}
Bishop, C.~M. 1994.
\newblock Mixture density networks.

\bibitem[{Bishop(2006)}]{bishop2006pattern}
Bishop, C.~M. 2006.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer.

\bibitem[{Bl{\"o}chl(1994)}]{RN141}
Bl{\"o}chl, P.~E. 1994.
\newblock Projector augmented-wave method.
\newblock \emph{Physical review B}, 50(24): 17953.

\bibitem[{Caflisch et~al.(1998)}]{caflisch1998monte}
Caflisch, R.~E.; et~al. 1998.
\newblock Monte carlo and quasi-monte carlo methods.
\newblock \emph{Acta numerica}, 1998: 1--49.

\bibitem[{Daras et~al.(2021)Daras, Dean, Jalal, and
  Dimakis}]{daras2021intermediate}
Daras, G.; Dean, J.; Jalal, A.; and Dimakis, A.~G. 2021.
\newblock Intermediate layer optimization for inverse problems using deep
  generative models.
\newblock \emph{arXiv preprint arXiv:2102.07364}.

\bibitem[{Deng et~al.(2021)Deng, Ren, Fan, Malof, and Padilla}]{deng2021neural}
Deng, Y.; Ren, S.; Fan, K.; Malof, J.~M.; and Padilla, W.~J. 2021.
\newblock Neural-adjoint method for the inverse design of all-dielectric
  metasurfaces.
\newblock \emph{Optics Express}, 29(5): 7526--7534.

\bibitem[{Dinh, Sohl-Dickstein, and Bengio(2016)}]{dinh2016density}
Dinh, L.; Sohl-Dickstein, J.; and Bengio, S. 2016.
\newblock Density estimation using real nvp.
\newblock \emph{arXiv preprint arXiv:1605.08803}.

\bibitem[{Dudarev et~al.(1998)Dudarev, Botton, Savrasov, Humphreys, and
  Sutton}]{RN147}
Dudarev, S.; Botton, G.; Savrasov, S.; Humphreys, C.; and Sutton, A. 1998.
\newblock Electron-energy-loss spectra and the structural stability of nickel
  oxide: An LSDA+ U study.
\newblock \emph{Physical Review B}, 57(3): 1505.

\bibitem[{Durkan et~al.(2019)Durkan, Bekasov, Murray, and
  Papamakarios}]{durkan2019neural}
Durkan, C.; Bekasov, A.; Murray, I.; and Papamakarios, G. 2019.
\newblock Neural spline flows.
\newblock \emph{arXiv preprint arXiv:1906.04032}.

\bibitem[{Ertl and Schuffenhauer(2009)}]{ertl2009estimation}
Ertl, P.; and Schuffenhauer, A. 2009.
\newblock Estimation of synthetic accessibility score of drug-like molecules
  based on molecular complexity and fragment contributions.
\newblock \emph{Journal of cheminformatics}, 1(1): 1--11.

\bibitem[{Forrester and Keane(2009)}]{forrester2009recent}
Forrester, A.~I.; and Keane, A.~J. 2009.
\newblock Recent advances in surrogate-based optimization.
\newblock \emph{Progress in aerospace sciences}, 45(1-3): 50--79.

\bibitem[{Fung et~al.(2022)Fung, Jia, Zhang, Bi, Yin, and
  Ganesh}]{fung2022atomic}
Fung, V.; Jia, S.; Zhang, J.; Bi, S.; Yin, J.; and Ganesh, P. 2022.
\newblock Atomic structure generation from reconstructing structural
  fingerprints.
\newblock \emph{Machine Learning: Science and Technology}.

\bibitem[{Fung et~al.(2021)Fung, Zhang, Hu, Ganesh, and
  Sumpter}]{fung2021inverse}
Fung, V.; Zhang, J.; Hu, G.; Ganesh, P.; and Sumpter, B.~G. 2021.
\newblock Inverse design of two-dimensional materials with invertible neural
  networks.
\newblock \emph{npj Computational Materials}, 7(1): 1--9.

\bibitem[{G{\'o}mez-Bombarelli et~al.(2018)G{\'o}mez-Bombarelli, Wei, Duvenaud,
  Hern{\'a}ndez-Lobato, S{\'a}nchez-Lengeling, Sheberla, Aguilera-Iparraguirre,
  Hirzel, Adams, and Aspuru-Guzik}]{gomez2018automatic}
G{\'o}mez-Bombarelli, R.; Wei, J.~N.; Duvenaud, D.; Hern{\'a}ndez-Lobato,
  J.~M.; S{\'a}nchez-Lengeling, B.; Sheberla, D.; Aguilera-Iparraguirre, J.;
  Hirzel, T.~D.; Adams, R.~P.; and Aspuru-Guzik, A. 2018.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS central science}, 4(2): 268--276.

\bibitem[{Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and
  Duvenaud}]{grathwohl2018ffjord}
Grathwohl, W.; Chen, R.~T.; Bettencourt, J.; Sutskever, I.; and Duvenaud, D.
  2018.
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}.

\bibitem[{Gretton et~al.(2012{\natexlab{a}})Gretton, Borgwardt, Rasch,
  Sch{\"o}lkopf, and Smola}]{gretton2012kernel}
Gretton, A.; Borgwardt, K.~M.; Rasch, M.~J.; Sch{\"o}lkopf, B.; and Smola, A.
  2012{\natexlab{a}}.
\newblock A kernel two-sample test.
\newblock \emph{The Journal of Machine Learning Research}, 13(1): 723--773.

\bibitem[{Gretton et~al.(2012{\natexlab{b}})Gretton, Sejdinovic, Strathmann,
  Balakrishnan, Pontil, Fukumizu, and Sriperumbudur}]{gretton2012optimal}
Gretton, A.; Sejdinovic, D.; Strathmann, H.; Balakrishnan, S.; Pontil, M.;
  Fukumizu, K.; and Sriperumbudur, B.~K. 2012{\natexlab{b}}.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In \emph{Advances in neural information processing systems},
  1205--1213. Citeseer.

\bibitem[{Kingma and Dhariwal(2018)}]{kingma2018glow}
Kingma, D.~P.; and Dhariwal, P. 2018.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{arXiv preprint arXiv:1807.03039}.

\bibitem[{Kothari et~al.(2021)Kothari, Khorashadizadeh, Maarten, and
  Dokmanic}]{kothari2021trumpets}
Kothari, K.; Khorashadizadeh, A.; Maarten, V.; and Dokmanic, I. 2021.
\newblock Trumpets: Injective Flows for Inference and Inverse Problems.

\bibitem[{Kresse and Furthm{\"u}ller(1996{\natexlab{a}})}]{RN138}
Kresse, G.; and Furthm{\"u}ller, J. 1996{\natexlab{a}}.
\newblock Efficiency of ab-initio total energy calculations for metals and
  semiconductors using a plane-wave basis set.
\newblock \emph{Computational materials science}, 6(1): 15--50.

\bibitem[{Kresse and Furthm{\"u}ller(1996{\natexlab{b}})}]{RN144}
Kresse, G.; and Furthm{\"u}ller, J. 1996{\natexlab{b}}.
\newblock Efficient iterative schemes for ab initio total-energy calculations
  using a plane-wave basis set.
\newblock \emph{Physical review B}, 54(16): 11169.

\bibitem[{Kruse et~al.(2021)Kruse, Ardizzone, Rother, and
  K{\"o}the}]{kruse2021benchmarking}
Kruse, J.; Ardizzone, L.; Rother, C.; and K{\"o}the, U. 2021.
\newblock Benchmarking invertible architectures on inverse problems.
\newblock \emph{arXiv preprint arXiv:2101.10763}.

\bibitem[{Kucherenko, Albrecht, and Saltelli(2015)}]{kucherenko2015exploring}
Kucherenko, S.; Albrecht, D.; and Saltelli, A. 2015.
\newblock Exploring multi-dimensional spaces: A comparison of Latin hypercube
  and quasi Monte Carlo sampling techniques.
\newblock \emph{arXiv preprint arXiv:1505.02350}.

\bibitem[{Lavin et~al.(2021)Lavin, Zenil, Paige, Krakauer, Gottschlich,
  Mattson, Anandkumar, Choudry, Rocki, Baydin et~al.}]{lavin2021simulation}
Lavin, A.; Zenil, H.; Paige, B.; Krakauer, D.; Gottschlich, J.; Mattson, T.;
  Anandkumar, A.; Choudry, S.; Rocki, K.; Baydin, A.~G.; et~al. 2021.
\newblock Simulation intelligence: Towards a new generation of scientific
  methods.
\newblock \emph{arXiv preprint arXiv:2112.03235}.

\bibitem[{Li and Chen(2006)}]{li2006probability}
Li, J.; and Chen, J.-B. 2006.
\newblock The probability density evolution method for dynamic response
  analysis of non-linear stochastic structures.
\newblock \emph{International Journal for Numerical Methods in Engineering},
  65(6): 882--903.

\bibitem[{Li et~al.(2022)Li, Zhang, Liu, and Liu}]{li2022auditing}
Li, Z.; Zhang, J.; Liu, L.; and Liu, J. 2022.
\newblock Auditing Privacy Defenses in Federated Learning via Generative
  Gradient Leakage.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10132--10142.

\bibitem[{Liu, Zhang, and Pei(2022)}]{liu2022machine}
Liu, X.; Zhang, J.; and Pei, Z. 2022.
\newblock Machine learning for high-entropy alloys: Progress, challenges and
  opportunities.
\newblock \emph{Progress in Materials Science}, 101018.

\bibitem[{Ma et~al.(2019)Ma, Cheng, Xu, Wen, and Liu}]{ma2019probabilistic}
Ma, W.; Cheng, F.; Xu, Y.; Wen, Q.; and Liu, Y. 2019.
\newblock Probabilistic representation and inverse design of metamaterials
  based on a deep generative model with semi-supervised learning strategy.
\newblock \emph{Advanced Materials}, 31(35): 1901111.

\bibitem[{Mao, He, and Zhao(2020)}]{mao2020designing}
Mao, Y.; He, Q.; and Zhao, X. 2020.
\newblock Designing complex architectured materials with generative adversarial
  networks.
\newblock \emph{Science Advances}, 6(17): eaaz4169.

\bibitem[{McKay, Beckman, and Conover(2000)}]{mckay2000comparison}
McKay, M.~D.; Beckman, R.~J.; and Conover, W.~J. 2000.
\newblock A comparison of three methods for selecting values of input variables
  in the analysis of output from a computer code.
\newblock \emph{Technometrics}, 42(1): 55--61.

\bibitem[{Monkhorst and Pack(1976)}]{RN148}
Monkhorst, H.~J.; and Pack, J.~D. 1976.
\newblock Special points for Brillouin-zone integrations.
\newblock \emph{Physical review B}, 13(12): 5188.

\bibitem[{Nielsen et~al.(2020)Nielsen, Jaini, Hoogeboom, Winther, and
  Welling}]{nielsen2020survae}
Nielsen, D.; Jaini, P.; Hoogeboom, E.; Winther, O.; and Welling, M. 2020.
\newblock Survae flows: Surjections to bridge the gap between vaes and flows.
\newblock \emph{Advances in Neural Information Processing Systems}, 33.

\bibitem[{Perdew, Burke, and Ernzerhof(1996)}]{RN145}
Perdew, J.~P.; Burke, K.; and Ernzerhof, M. 1996.
\newblock Generalized gradient approximation made simple.
\newblock \emph{Physical review letters}, 77(18): 3865.

\bibitem[{Ren, Padilla, and Malof(2020)}]{ren2020benchmarking}
Ren, S.; Padilla, W.; and Malof, J. 2020.
\newblock Benchmarking deep inverse models over time, and the neural-adjoint
  method.
\newblock \emph{arXiv preprint arXiv:2009.12919}.

\bibitem[{Rezende and Mohamed(2015)}]{rezende2015variational}
Rezende, D.; and Mohamed, S. 2015.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International Conference on Machine Learning}, 1530--1538.
  PMLR.

\bibitem[{Ricca et~al.(2020)Ricca, Timrov, Cococcioni, Marzari, and
  Aschauer}]{RN6481}
Ricca, C.; Timrov, I.; Cococcioni, M.; Marzari, N.; and Aschauer, U. 2020.
\newblock Self-consistent DFT+ U+ V study of oxygen vacancies in SrTiO 3.
\newblock \emph{Physical review research}, 2(2): 023313.

\bibitem[{Rombach, Esser, and Ommer(2020)}]{rombach2020network}
Rombach, R.; Esser, P.; and Ommer, B. 2020.
\newblock Network-to-Network Translation with Conditional Invertible Neural
  Networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 33.

\bibitem[{Sanchez-Lengeling and Aspuru-Guzik(2018)}]{sanchez2018inverse}
Sanchez-Lengeling, B.; and Aspuru-Guzik, A. 2018.
\newblock Inverse molecular design using machine learning: Generative models
  for matter engineering.
\newblock \emph{Science}, 361(6400): 360--365.

\bibitem[{Shields and Zhang(2016)}]{shields2016generalization}
Shields, M.~D.; and Zhang, J. 2016.
\newblock The generalization of Latin hypercube sampling.
\newblock \emph{Reliability Engineering \& System Safety}, 148: 96--108.

\bibitem[{Sohn, Lee, and Yan(2015)}]{sohn2015learning}
Sohn, K.; Lee, H.; and Yan, X. 2015.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock \emph{Advances in neural information processing systems}, 28:
  3483--3491.

\bibitem[{Song et~al.(2021)Song, Shen, Xing, and Ermon}]{song2021solving}
Song, Y.; Shen, L.; Xing, L.; and Ermon, S. 2021.
\newblock Solving Inverse Problems in Medical Imaging with Score-Based
  Generative Models.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Stein(1987)}]{stein1987large}
Stein, M. 1987.
\newblock Large sample properties of simulations using Latin hypercube
  sampling.
\newblock \emph{Technometrics}, 29(2): 143--151.

\bibitem[{Sun and Bouman(2020)}]{sun2020deep}
Sun, H.; and Bouman, K.~L. 2020.
\newblock Deep Probabilistic Imaging: Uncertainty Quantification and
  Multi-modal Solution Characterization for Computational Imaging.
\newblock \emph{arXiv preprint arXiv:2010.14462}.

\bibitem[{Tokura, Kawasaki, and Nagaosa(2017)}]{RN6466}
Tokura, Y.; Kawasaki, M.; and Nagaosa, N. 2017.
\newblock Emergent functions of quantum materials.
\newblock \emph{Nature Physics}, 13(11): 1056--1068.

\bibitem[{Tonolini et~al.(2020)Tonolini, Radford, Turpin, Faccio, and
  Murray-Smith}]{tonolini2020variational}
Tonolini, F.; Radford, J.; Turpin, A.; Faccio, D.; and Murray-Smith, R. 2020.
\newblock Variational inference for computational imaging inverse problems.
\newblock \emph{Journal of Machine Learning Research}, 21(179): 1--46.

\bibitem[{Wang, Ye, and De~Man(2020)}]{wang2020deep}
Wang, G.; Ye, J.~C.; and De~Man, B. 2020.
\newblock Deep learning for tomographic image reconstruction.
\newblock \emph{Nature Machine Intelligence}, 2(12): 737--748.

\bibitem[{Wang et~al.(2018)Wang, Liu, Zhu, Tao, Kautz, and
  Catanzaro}]{wang2018high}
Wang, T.-C.; Liu, M.-Y.; Zhu, J.-Y.; Tao, A.; Kautz, J.; and Catanzaro, B.
  2018.
\newblock High-resolution image synthesis and semantic manipulation with
  conditional gans.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 8798--8807.

\bibitem[{Whang, Lei, and Dimakis(2021)}]{whang2021solving}
Whang, J.; Lei, Q.; and Dimakis, A. 2021.
\newblock Solving Inverse Problems with a Flow-based Noise Model.
\newblock In \emph{International Conference on Machine Learning}, 11146--11157.
  PMLR.

\bibitem[{Whang, Lindgren, and Dimakis(2021)}]{whang2021composing}
Whang, J.; Lindgren, E.; and Dimakis, A. 2021.
\newblock Composing Normalizing Flows for Inverse Problems.
\newblock In \emph{International Conference on Machine Learning}, 11158--11169.
  PMLR.

\bibitem[{White et~al.(2019)White, Arrighi, Kudo, and
  Watts}]{white2019multiscale}
White, D.~A.; Arrighi, W.~J.; Kudo, J.; and Watts, S.~E. 2019.
\newblock Multiscale topology optimization using neural network surrogate
  models.
\newblock \emph{Computer Methods in Applied Mechanics and Engineering}, 346:
  1118--1135.

\bibitem[{Wu, K{\"o}hler, and No{\'e}(2020)}]{wu2020stochastic}
Wu, H.; K{\"o}hler, J.; and No{\'e}, F. 2020.
\newblock Stochastic normalizing flows.
\newblock \emph{arXiv preprint arXiv:2002.06707}.

\bibitem[{Yang, Strukov, and Stewart(2013)}]{RN6431}
Yang, J.~J.; Strukov, D.~B.; and Stewart, D.~R. 2013.
\newblock Memristive devices for computing.
\newblock \emph{Nature Nanotechnology}, 8(1): 13--24.

\bibitem[{Yang et~al.(2018)Yang, Dai, Kiyavash, and He}]{yang2018predictive}
Yang, Y.; Dai, B.; Kiyavash, N.; and He, N. 2018.
\newblock Predictive approximate Bayesian computation via saddle points.
\newblock \emph{Proceedings of Machine Learning Research}.

\bibitem[{Yao et~al.(2021)Yao, S{\'a}nchez-Lengeling, Bobbitt, Bucior, Kumar,
  Collins, Burns, Woo, Farha, Snurr et~al.}]{yao2021inverse}
Yao, Z.; S{\'a}nchez-Lengeling, B.; Bobbitt, N.~S.; Bucior, B.~J.; Kumar, S.
  G.~H.; Collins, S.~P.; Burns, T.; Woo, T.~K.; Farha, O.~K.; Snurr, R.~Q.;
  et~al. 2021.
\newblock Inverse design of nanoporous crystalline reticular materials with
  deep generative models.
\newblock \emph{Nature Machine Intelligence}, 3(1): 76--86.

\bibitem[{Zhang, Zhang, and Hinkle(2019)}]{zhang2019learning}
Zhang, G.; Zhang, J.; and Hinkle, J. 2019.
\newblock Learning nonlinear level sets for dimensionality reduction in
  function approximation.
\newblock \emph{Advances in Neural Information Processing Systems}, 32.

\bibitem[{Zhang(2021)}]{zhang2021modern}
Zhang, J. 2021.
\newblock Modern Monte Carlo methods for efficient uncertainty quantification
  and propagation: A survey.
\newblock \emph{Wiley Interdisciplinary Reviews: Computational Statistics},
  13(5): e1539.

\bibitem[{Zhang, Bi, and Zhang(2021)}]{zhang2021scalable}
Zhang, J.; Bi, S.; and Zhang, G. 2021.
\newblock A Scalable Gradient Free Method for Bayesian Experimental Design with
  Implicit Models.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 3745--3753. PMLR.

\bibitem[{Zhang and Shields(2018{\natexlab{a}})}]{zhang2018effect}
Zhang, J.; and Shields, M.~D. 2018{\natexlab{a}}.
\newblock The effect of prior probabilities on quantification and propagation
  of imprecise probabilities resulting from small datasets.
\newblock \emph{Computer Methods in Applied Mechanics and Engineering}, 334:
  483--506.

\bibitem[{Zhang and Shields(2018{\natexlab{b}})}]{zhang2018quantification}
Zhang, J.; and Shields, M.~D. 2018{\natexlab{b}}.
\newblock On the quantification and efficient propagation of imprecise
  probabilities resulting from small datasets.
\newblock \emph{Mechanical Systems and Signal Processing}, 98: 465--483.

\bibitem[{Zhang et~al.(2021)Zhang, Tran, Lu, and Zhang}]{zhang2021enabling}
Zhang, J.; Tran, H.; Lu, D.; and Zhang, G. 2021.
\newblock Enabling long-range exploration in minimization of multimodal
  functions.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 1639--1649. PMLR.

\bibitem[{Zhang et~al.(2016)Zhang, Liu, Zhuang, Kent, Cooper, Ganesh, and
  Xu}]{RN6480}
Zhang, L.; Liu, B.; Zhuang, H.; Kent, P.~R.; Cooper, V.~R.; Ganesh, P.; and Xu,
  H. 2016.
\newblock Oxygen vacancy diffusion in bulk SrTiO3 from density functional
  theory calculations.
\newblock \emph{Computational Materials Science}, 118: 309--315.

\bibitem[{Zhu et~al.(2020)Zhu, Zhang, Yang, and Huang}]{RN6467}
Zhu, J.; Zhang, T.; Yang, Y.; and Huang, R. 2020.
\newblock A comprehensive review on emerging artificial neuromorphic devices.
\newblock 7(1): 011312.

\end{thebibliography}
