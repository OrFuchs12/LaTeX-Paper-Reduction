\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai22}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
%\nocopyright
%
% PDF Info Is REQUIRED.
% For /Title, write your title in Mixed Case.
% Don't use accents or commands. Retain the parentheses.
% For /Author, add all authors within the parentheses,
% separated by commas. No accents, special characters
% or commands are allowed.
% Keep the /TemplateVersion tag as is
\pdfinfo{
/Title (Learning Probably Approximately Complete and Safe Action Models for Stochastic Worlds)
/Author (Brendan Juba, Roni Stern)
/TemplateVersion (2022.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{paralist}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}


\newcommand{\eff}{\textit{eff}}
\newcommand{\pre}{\textit{pre}}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1 \right \rangle }}
\newcommand{\goal}{\textit{goal}}
\newcommand{\sam}{\textit{SAM}}
\newcommand{\ip}{\textit{IP}}

\usepackage{xspace}
\newcommand{\swimriver}{\textit{swim-river}\xspace}
\newcommand{\swimisland}{\textit{swim-island}\xspace}
\newcommand{\traverserocks}{\textit{traverse-rocks}\xspace}

\newcommand{\inoffice}{\textit{in-office}\xspace}
\newcommand{\hasumbrella}{\textit{has-umbrella}\xspace}
\newcommand{\iswet}{\textit{is-wet}\xspace}
\newcommand{\hascoffee}{\textit{has-coffee}\xspace}
\newcommand{\userhascofee}{\textit{user-has-coffee}\xspace}

\newcommand{\buycofee}{\textit{buy-coffee}\xspace}
\newcommand{\movetoofficewithumbrella}{\textit{move-to-office-with-umbrella}\xspace}
\newcommand{\leaveofficewithumbrella}{\textit{leave-office-with-umbrella}\xspace}
\newcommand{\movetoofficewithoutumbrella}{\textit{move-to-office-without-umbrella}\xspace}
\newcommand{\leaveofficewithoutumbrella}{\textit{leave-office-without-umbrella}\xspace}
\newcommand{\getumbrella}{\textit{get-umbrella}\xspace}
\newcommand{\delivercoffee}{\textit{deliver-coffee}\xspace}


\usepackage{booktabs}
\usepackage{multirow}




\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Learning Probably  Approximately Complete and Safe Action Models for Stochastic Worlds}
%\author{Submission 6194}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar, \textsuperscript{\rm 2}
%     % J. Scott Penberthy, \textsuperscript{\rm 3}
%     % George Ferguson,\textsuperscript{\rm 4}
%     % Hans Guesgen, \textsuperscript{\rm 5}.
%     % Note that the comma should be placed BEFORE the superscript for optimum readability

%     2275 East Bayshore Road, Suite 160\\
%     Palo Alto, California 94303\\
%     % email address must be in roman text type, not monospace or sans serif
%     publications22@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it

\title{An Example of the SAM+ Algorithm for Learning Action Models for Stochastic Worlds}
\author {
    % Authors
    Brendan Juba,\equalcontrib\textsuperscript{\rm 1}
    Roni Stern\equalcontrib\textsuperscript{\rm 2}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Washington University in St.\ Louis\\
    \textsuperscript{\rm 2} Ben Gurion University \& Xerox PARC\\
    bjuba@wustl.edu, rstern@parc.com, sternron@post.bgu.ac.il
}



% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

% \begin{abstract}
% We consider the problem of learning action models for planning 
% in stochastic, unknown, environments, that can be defined using the Probabilistic Planning Domain Description Language (PPDDL). 
% As input, we are given set of previously executed trajectories, and the main challenge is to learn an action model that has a similar goal achievement probability to the policies used to create these trajectories. 
% To this end, we introduce a variant of PPDDL in which there is uncertainty about the transition probabilities, specified by an interval for each factor that contains the respective true transition probabilities. 
% Then, we present SAM+, an algorithm that learns such an imprecise-PPDDL environment model. 
% SAM+ has a polynomial time and sample complexity, and guarantees that with high probability, the true environment is indeed captured by the defined intervals. 
% We prove that the action model SAM+ outputs has a goal achievement probability that is almost as good or better than that of the policies used to produced the training trajectories.   
% Then, we show how to produce a PPDDL model based on this imprecise-PPDDL that has similar properties. 
% %that optimal policies under this model will provably achieve a success rate at future goals that is almost as good or better than the policies that produced the training trajectories. 
% \end{abstract}

% \section{Introduction}





% \section{Appendix: Example of SAM+}


% Describe the domain
In this technical report, we provide a complete example of running the SAM+ algorithm~\cite{juba2022learning}, an algorithm for learning stochastic planning action models, on a simplified PPDDL version of the \emph{Coffee} problem~\cite{dearden1997abstraction}. 
We provide a very brief description of the SAM+ algorithm and detailed description of our simplified version of the Coffee domain. 
For a complete description of SAM+ see Juba and Stern~\shortcite{juba2022learning}. 


% In this technical report, we provide a complete example of running the SAM+ algorithm~\cite{juba2022learning}, an algorithm for learning stochastic planning action models, on the PPDDL \emph{River} problem~\cite{little2007probabilistic}. 
% We provide a very brief description of the SAM+ algorithm and the River PPDDL domain before describing our example. 
% For a complete description of SAM+ or the rationale for the River domain, see Juba and Stern~\shortcite{juba2022learning} or Little and Thiebaux~\shortcite{little2007probabilistic}, respectively. 


\subsection{The SAM+ Algorithm}


% Intro to SAM+: we capture the approxiamtely using credal sets
The SAM+ algorithm takes a set of trajectories $\mathcal{T}$ and a parameter $\delta>0$, and outputs a PPDDL-IP action model denoted $M_\delta$. We describe the preconditions and effects of $M_\delta$ below. 

\noindent \textbf{Preconditions.} 
Let $\mathcal{T}(a)$ be all the action triplets for action $a$. 
States $s$ and $s'$ are said to be a \emph{pre-} and \emph{post-state} of $a$, respectively, if there is an action triplet $\tuple{s,a,s'}\in \mathcal{T}(a)$. 
SAM+ sets the preconditions of an action $a$ to be intersection over all the literals that were true in a pre-state of $a$. 
\begin{equation}
\small
        \pre_{M_\delta}(a) =  \bigcap_{\tuple{s, a, s'}\in \mathcal{T}(a)} s \label{eq:pre} 
\end{equation}        

% Actual effect learning
\noindent \textbf{Effects.} 
Note that we cannot distinguish whether or not $\ell$ was an effect of action $a$ if $\ell\in s$, as it holds in $s'$ in either case. We thus restrict attention to triplets where $\ell\notin s$ to estimate the credal set for $\ell$: 
Let $\#_a(\ell\in s'\setminus s)$ and $\#_a(\ell\notin s)$ 
be the number of action triplets in $\mathcal{T}(a)$ in which $\ell$ is in the post-state and not the pre-state ($|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s'\setminus s\}|$), 
and the number of action triplets in which $\ell$ was not in the pre-state 
($|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\notin s\}|$), respectively. 
SAM+ denotes the intervals $K_{M_\delta}[s'(\ell)|a,s(\ell)]$ 
by $K_\delta(s'(\ell)|a,s(\neg \ell))$, and computes them as follows.
\begin{enumerate}
\item If $\ell \in \bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s$ and $\ell \in \bigcap_{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s}s'$, 
then 
\begin{equation}
%\small
    K_\delta(s'(\ell)|a,s(\neg \ell)) = \left[1-\frac{\ln(1/\delta)}{\#_a(\ell\notin s)},1\right]
    \label{eq:det-effects}
\end{equation}
    \item If $\ell \in \bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s$ and $\ell \notin \bigcap_{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s}s'$, 
then 
\begin{equation}
%\small
    K_\delta(s'(\ell)|a,s(\neg \ell)) = \frac{\#_a(\ell\in s'\setminus s)}{\#_a(\ell\notin s)} \pm\sqrt{\frac{\ln(2/\delta)}{2\#_a(\ell\notin s)}}
    \label{eq:present-effects}
\end{equation}
\item If $\ell\notin\bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s$, then 
\begin{equation}
%\small
    K_\delta(s'(\ell)|a,s(\neg \ell)) = \left[0,\frac{\ln(1/\delta)}{\#_a(\ell\notin s)}\right]
    \label{eq:missing-effects}
\end{equation}
\end{enumerate}
If $\#_a(\ell\notin s)=0$, then $K_\delta(s'(\ell)|a,s(\neg\ell))=[0,1]$. (In any case, we cap the credal sets at $0$ and $1$.) We remark that while the second interval is always valid, the first and third are smaller -- i.e., more accurate -- hence preferable for literals that appear deterministic.



Instead of these intervals, it is possible to use the following factors and still maintain reasonable forms of safety: For $\ell\in\bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s $ with $\ell \notin \bigcap_{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s}s'$, the transition probability factor for $\ell$ given $\ell\notin s$ and $a$ is an empirical estimate of the probability:
\begin{equation}
\label{eq:ppddl-exact}
%\small
\Pr[s'(\ell)|a,s(\neg\ell)]=\frac{|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s'\setminus s\}|}{|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell \notin s\}|}
\end{equation}
for $\ell\in\bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s $ with $\ell \in \bigcap_{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\in s}s'$ it is
\begin{equation}
\label{eq:ppddl-exact-det}
\Pr[s'(\ell)|a,s(\neg\ell)]=1-\frac{\ln(2|F||A|/\delta)}{2|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\notin s\}|}
\end{equation}
and otherwise (i.e., for $\ell\notin\bigcup_{\tuple{s, a, s'}\in \mathcal{T}(a)} s'\setminus s $),
\begin{equation}
\label{eq:ppddl-exact-missing}
%\small
\Pr[s'(\ell)|a,s(\neg\ell)]=\frac{\ln(2|F||A|/\delta)}{2|\{\tuple{s, a, s'}\in \mathcal{T}(a):\ell\notin s\}|}
\end{equation}
i.e., the midpoints of our previous intervals.
Using the corresponding PPDDL model enables using PPDDL planners. 



\section{The Simplified Coffee Domain}


% \begin{figure}
%     \centering
% \begin{verbatim}
% (define (domain simplified-coffee)
% (:requirements :negative-preconditions)
% (:predicates 
%     (in-office) (has-umbrella) (is-wet)
%     (has-coffee) (user-has-coffee))

% (:action buy-coffee
% :precondition (not (in-office)
% :effect (probabilistic 
%             0.8 (has-coffee)))

% (:action move-to-office-with-umbrella
% :precondition (and (not (in-office))
%                 (has-umbrella))
% :effect (probabilistic 
%             0.9 (in-office)))

% (:action leave-office-with-umbrella
% :precondition (and (in-office)
%                 (has-umbrella))
% :effect (probabilistic 
%             0.9 (not (in-office))))

% (:action move-to-office-without-umbrella
% :precondition (and (not (in-office))
%                 (not (has-umbrella)))
% :effect (and (probabilistic 
%                 0.9 (in-office))
%             (probabilistic 
%                 0.9 (is-wet))))

% (:action leave-office-without-umbrella
% :precondition (and (in-office)
%                 (not (has-umbrella)))
% :effect (and 
%          (probabilistic 
%                 0.9 (not (in-office)))
% 		 (probabilistic 
% 		        0.9 (is-wet))))

% (:action get-umbrella
% :precondition (and (in-office)
%                 (not (has-umbrella)))
% :effect (probabilistic 
%             0.9 (has-umbrella)))

% (:action deliver-coffee
% :precondition (and (in-office)
%                 (has-coffee)
%                 (not (user-has-coffee)))
% :effect (and (not (has-coffee))
%         (probabilistic 
%             0.8 (user-has-coffee)))))
% \end{verbatim}
%     \caption{PPDDL of the Simplified Coffee domain.}
%     \label{fig:coffee-domain}
% \end{figure}



\begin{figure}
    \centering
\begin{verbatim}
(define (domain simplified-coffee)
(:requirements :negative-preconditions)
(:predicates 
    (in-office) (has-umbrella) (is-wet)
    (has-coffee) (user-has-coffee))

(:action buy-coffee
:precondition (not (in-office))
:effect (and (has-coffee)))

(:action move-to-office-with-umbrella
:precondition (and (not (in-office))
                (has-umbrella))
:effect (and (in-office)))

(:action leave-office-with-umbrella
:precondition (and (in-office)
                (has-umbrella))
:effect (and (not (in-office))))

(:action move-to-office-without-umbrella
:precondition (and (not (in-office))
                (not (has-umbrella)))
:effect (and (in-office)
             (probabilistic 
                0.9 (is-wet))))

(:action leave-office-without-umbrella
:precondition (and (in-office)
                (not (has-umbrella)))
:effect (and (not (in-office))
		     (probabilistic 
		        0.9 (is-wet))))

(:action get-umbrella
:precondition (and (in-office)
                (not (has-umbrella)))
:effect (and (has-umbrella)))

(:action deliver-coffee
:precondition (and (in-office)
                (has-coffee)
                (not (user-has-coffee)))
:effect (and (not (has-coffee) 
            (user-has-coffee)))))
\end{verbatim}
    \caption{PPDDL of the Simplified Coffee domain.}
    \label{fig:coffee-domain}
\end{figure}


The Simplified Coffee domain is simplified version of the Coffee domain introduced by Dearden and Boutilier~\shortcite{dearden1997abstraction}. 
This domain models a robot agent designed to buy coffee from a coffee shop and bring it to the office on a rainy day. 
A state in this domain is defined by five fluents: \inoffice, \hasumbrella, \iswet, \hascoffee, and \userhascofee, abbreviated as IO, HU, IW, HC, and UHC, respectively. 
The agent has 6 actions:
\buycofee, 
\movetoofficewithumbrella, 
\leaveofficewithumbrella, 
\movetoofficewithoutumbrella,
\leaveofficewithoutumbrella, 
\getumbrella,
and 
\delivercoffee, abbreviated as BC, MTOWU, LOWU, MTOWOU, LOWOU, GU, and DC, respectively. 
Figure~\ref{fig:coffee-domain} lists the full PPDDL description of this domain, which includes the preconditions and the stochastic effects of each action. 
For example, \leaveofficewithoutumbrella can only be performed if the agent is in the office and it does not have an umbrella ($IO$ and $\neg HU$), and has the effect of the agent not being in the office ($\neg IO$) and, with probability 0.9, the effect of getting wet ($IW$). 


\begin{figure}
    \centering
    \begin{verbatim}
(:define coffee-delivery-problem
    (:init (and 
            (not (user-has-coffee))
            (not (has-coffee))
            (not (has-umbrella))
            (in-office)
            (not (is-wet))
            ))
    (:goal (and (user-has-coffee) 
        (not (is-wet)))))               
    \end{verbatim}
    \caption{PPDDL for a problem in the simplified coffee maker domain.}
    \label{fig:coffee-problem}
\end{figure}
Figure~\ref{fig:coffee-problem} lists the PPDDL description of a problem in the Simplified Coffee domain. 
In this problem, the user does not have coffee yet ($\neg UHC$), 
nor does the agent ($\neg HC$), 
the agent does not have an umbrella ($\neg HU$), it is still in the office ($IO$), 
and it is not wet ($\neg IW$). 
Its goal is to get coffee to the user ($UHC$) without getting wet ($\neg IW$).\footnote{In the original Coffee domain, getting wet introduces a negative reward. Also, note that our goal of avoiding getting wet only states that the agent should not be wet at the goal state. However, since we do not have any action that undoes becoming wet, this means the agent must remain not wet if it aims to achieve this goal.}




\section{SAM+ on the Simplified Coffee Domain}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
\begin{table}[]
\begin{tabular}{@{}cccccccc@{}}
\toprule
T                   & State & IO & HU & IW & HC & UHC & Action \\ \midrule
\multirow{2}{*}{T1} & S0    & T  & F  & F  & F  & F   & LOWOU  \\
                    & S1    & F  & F  & T  & F  & F   &   -     \\ \midrule
\multirow{4}{*}{T2} & S0    & T  & F  & F  & F  & F   & LOWOU  \\
                    & S2    & F  & F  & F  & F  & F   & BC     \\
                    & S3    & F  & F  & F  & T  & F   & MTOWOU \\
                    & S4    & T  & F  & T  & T  & F   &   -     \\ \midrule
\multirow{5}{*}{T3} & S0    & T  & F  & F  & F  & F   & LOWOU  \\
                    & S2    & F  & F  & F  & F  & F   & BC     \\
                    & S3    & F  & F  & F  & T  & F   & MTOWU  \\
                    & S5    & T  & F  & F  & T  & F   & DC     \\
                    & S6    & T  & F  & F  & F  & T   &   -     \\ \midrule
\multirow{6}{*}{T4} & S0    & T  & F  & F  & F  & F   & GU     \\
                    & S7    & T  & T  & F  & F  & F   & LOWU   \\
                    & S8    & F  & T  & F  & F  & F   & BC     \\
                    & S9    & F  & T  & F  & T  & F   & MTOWU   \\
                    & S10   & T  & T  & F  & T  & F   & DC     \\
                    & S11   & T  & T  & F  & F  & T   &   -     \\ \bottomrule 
\end{tabular}

\caption{Trajectories T1, T2, T3, and T4 in our example of SAM+ for the Simplified Coffee domain.}\label{tab:trajectories-coffee}
\end{table}

Consider observing the following set of trajectories, all of which start as in the problem listed in Figure~\ref{fig:coffee-problem}, i.e., the agent is in the office without an umbrella, and neither the agent nor the user have coffee. 
In the first three trajectories, denoted T1, T2, and T3, the agent leaves the office without an umbrella. In T1, it gets wet while leaving the office, in T2 it gets wet while moving back to the office after buying the coffee, and in T3 it successfully returns to the office and delivers the coffee. 
Trajectory T4 starts by having the agent picking up an umbrella when it is in the office, and then leaving the office, buying the coffee, returning to the office, and delivering it to the user. Table~\ref{tab:trajectories-coffee} lists these trajectories, including the state before and after each action in them. 



Consider the action model learned by applying SAM+ 
after observing each trajectory once, i.e., $\mathcal{T}=\{T1,T2,T3,T4\}$, setting $\delta=0.1$. 
In this model, the preconditions for \leaveofficewithoutumbrella, which has been observed in trajectories T1, T2, and T3, are $\{IO, \neg HU, \neg IW, \neg HC, \neg UHC\}$, matching the initial state S0. 
In general, in SAM+ the effects of each action comprise of literals for which Equation~\ref{eq:det-effects} applies, literals for which Equation~\ref{eq:present-effects} applies, and all other literals, for which  Equation~\ref{eq:missing-effects} applies. 
For the \leaveofficewithoutumbrella action, $\neg IO$ comprises the first group. Applying Equation~\ref{eq:det-effects}, we get that $\neg IO$ is added with some probability in the interval $[0.23,1]$.
The second group consists of $IW$. 
Applying Equation~\ref{eq:present-effects}, we get that 
$IW$ is added with probability $1/3\pm 0.71$ (which we cap to $[0,1]$). 
If we observe each trajectory 100 times, the confidence margins respectively decrease from 0.77 to 0.008 and from 0.71 to 0.07; note the order-of-magnitude improvement from Equation~\ref{eq:det-effects} over Equation~\ref{eq:present-effects} here. 
The literals $HU$, $HC$, and $UHC$ may also be an effect of \leaveofficewithoutumbrella even though they are not added in any of the trajectories, since they do not appear in the pre-state of \leaveofficewithoutumbrella.   
Applying Equation~\ref{eq:missing-effects} on these literals, we have that in our action model the probability of each of these literals to be added (given that we observe each trajectory 100 times) is in [0,0.008]. 
The corresponding PPDDL action model using Equations~\ref{eq:ppddl-exact}, \ref{eq:ppddl-exact-det}, and~\ref{eq:ppddl-exact-missing} yields an action model that assumes 
the effects of \leaveofficewithoutumbrella are to add $\neg IO$ with probability 0.99,
$IW$ with probability 1/3,
$HU$ with probability 0.01,
$HC$ with probability 0.01, 
and $UHC$ with probability 0.01. 


The trajectory T1 is more likely than T2 and T3, and so the assumption that we observe each trajectory the same number of times may not be realistic. 
Instead, assume that we observe T1 895 times, T2 95 times, T3 10 times, and T4 1000 times. 
In this case the corresponding effects for \leaveofficewithoutumbrella 
are to add $\neg IO$ with probability 0.999,
$IW$ with probability 0.9,
$HU$ with probability 0.002,
$HC$ with probability 0.002, 
and $UHC$ with probability 0.002. 
Similarly, for the same distribution of observed trajectories (895, 95, 19, and 1000 for T1, T2, T3, and T4, respectively) the preconditions of \movetoofficewithoutumbrella in the learned model are 
$\{\neg IO, \neg HU, \neg IW, HC, \neg UHC\}$ and the 
effects in the corresponding PPDDL domain are 
$IO$ with probability 0.988, 
$IW$ with probabiltiy 0.988, 
and $HU$, $UHC$, and $\neg HC$ each with probability 0.3. 
% Similarly, the preconditions for \getumbrella are $\{IO, \neg HU, \neg IW, \neg HC, \neg UHC\}$, and its effect is $HU$ with probability $1\pm 0.71$. In the corresponding PPDDL action model, \getumbrella adds $HU$ with probability 1.0. 




% \section{The River Domain}


% \begin{figure}
%     \centering
% \begin{verbatim}
% (define (domain river)
%   (:requirements :typing :strips 
%             :probabilistic-effects)
%   (:predicates (on-near-bank) (on-far-bank) 
%               (on-island) (alive))
%   (:action traverse-rocks :parameters ()
%      :precondition (and (on-near-bank))
%      :effect (and (not (on-near-bank))
%     		  (probabilistic
%     		   0.25 (on-far-bank)
%     		   0.50 (on-island)
%     		   0.25 (not (alive)))))
%   (:action swim-river :parameters ()
%      :precondition (and (on-near-bank))
%      :effect (and (not (on-near-bank))
% 		      (probabilistic 
% 		       0.50 (on-far-bank)
% 		       0.50 (not (alive)))))
%   (:action swim-island :parameters ()
%      :precondition (and (on-island))
%      :effect (and (not (on-island))
%     		  (probabilistic
%     		   0.8 (on-far-bank)
%     		   0.2 (not (alive))))))

% (define (problem river-problem)
%   (:domain river)
%   (:init (on-near-bank) (alive))
%   (:goal (and (on-far-bank))))
% \end{verbatim}
%     \caption{The River domain~\cite{little2007probabilistic}.}
%     \label{fig:example-river-domain}
% \end{figure}

% The River domain has been introduced by Little and Thiebaux~\shortcite{little2007probabilistic} and depicted in Figure~\ref{fig:example-river-domain}. 
% In this domain, the agent is either on the near bank of a river, on the far bank of a river, or on an island in the river. 
% The corresponding fluents are \textit{on-near-bank}, \textit{on-far-bank}, \textit{on-island}, \textit{alive}, abbreviated as ONB, OFB, OI, and A, respectively. 
% It has three actions: \traverserocks, \swimriver, and \swimisland. The first two actions correspond to trying to get from the near bank to the far river bank, where in \traverserocks the agent attempts to traverse the river via slippery rocks and in \swimriver it attempts to swim directly there. The third action, \swimisland, requires the agent to already be in the island, and corresponds to trying to swim from the island to the far river bank. 


% With some probability, all actions end in the agent reaching the far river bank. 
% This occurs with probability 0.25, 0.50, and 0.80 for the actions \traverserocks, \swimriver, and \swimisland, respectively. 
% with some probability, however, all actions end in a dead-end state in which the agent is not alive. 
% This occurs with probability 0.25, 0.50, and 0.20 for the actions \traverserocks, \swimriver, and \swimisland, respectively. 
% Only the \traverserocks action has a third possible outcome, in which the agent drifts to the island. This occurs with probability 0.5. 


% % The domain
% Effectively, the agent in this domain has only one choice: should it attempt to go through the rocks (\traverserocks) or swim (\swimriver). If the agent ends up in the island, it will use the only action applicable to it --- \swimisland. 
% Clearly, the safest policy is to move the agent from the near river bank tot he far one is to apply \traverserocks and if needed \swimisland. The probability of reaching the goal with this policy is $0.25+0.5\cdot 0.8=0.65$, which is higher than 0.50, the probability of reaching the far river bank if doing \swimriver. 



% \section{SAM+ on the River Domain}


% % Please add the following required packages to your document preamble:
% % \usepackage{booktabs}
% % \usepackage{multirow}
% \begin{table}
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{@{}l|ccccccc@{}}
% % Traj.                   & State & Action & NearBank & Island & FarBank & Alive \\
% \toprule
% $T$ & $p$                   & State & Action & ONB & OI & OFB & A \\ \midrule
% % \multirow{2}{*}{Swim1}  & S0    & \swimriver  & 1        & 0      & 0       & 1     \\ 
% %                         & S1    &       & 0        & 0      & 1       & 1     \\ \midrule
% T1  &       & S0    & \traverserocks  & 1        & 0      & 0       & 1     \\
%     & 0.50  & S1    & \swimisland  & 0        & 1      & 0       & 1     \\
%     & 0.80  & S2    &       & 0        & 0      & 1       & 1     \\ \midrule
% T2  &       & S0    & \traverserocks  & 1        & 0      & 0       & 1     \\
%     & 0.50  & S1    & \swimisland  & 0        & 1      & 0       & 1     \\
%     & 0.20  & S3    &       & 0        & 0      & 0       & 0     \\ \midrule
% T3  &       & S0    & \traverserocks  & 1        & 0      & 0       & 1     \\
%     & 0.25  & S2    &       & 0        & 0      & 0       & 1    \\ \bottomrule
% T4  &       & S0    & \traverserocks  & 1        & 0      & 0       & 1     \\
%     & 0.25  & S3    &       & 0        & 0      & 0       & 0    \\ \bottomrule
% T5  &       & S0  & \swimriver  & 1        & 0      & 0       & 1     \\ 
%     & 0.50  & S2    &       & 0        & 0      & 1       & 1     \\ \midrule
% T6  &       & S0    & \swimriver  & 1        & 0      & 0       & 1     \\
%     & 0.50  & S3    &       & 0        & 0      & 0       & 0     \\ \midrule
% \end{tabular}
% }

% \caption{The possible trajectories in the River domain when starting from the near river bank.}\label{tab:trajectories}
% \end{table}


% Note that, in this simple domain there are only 4 possible states and 6 possible trajectories, when starting at the near river bank. 
% These states are (S0) the agent is alive at the near river bank, 
% (S1) the agent is alive on the island, 
% (S2) the agent is alive at the far river bank, 
% and (S3) the agent is not alive. 
% The possible trajectories are listed and named in Table~\ref{tab:trajectories}. 
% Column $p$ shows the probabilities of reaching a state from the previous state in each trajectory. 
% Consider the action model learned by applying SAM+ after observing each trajectory once, i.e., $\mathcal{T}=\{T1,T2,T3,T4,T5, T6\}$. 
% In this model, the preconditions for \traverserocks and for \swimriver are $\{ONB, \neg OI, \neg OFB, A\}$, matching exactly the initial state S0. 
% The preconditions for \swimisland are $\{\neg ONB, OI, \neg OFB, A\}$, matching exactly the only state where this action has been applied, S1. 
% The effects of each action comprise of literal for which Equation~\ref{eq:present-effects} applies and literals for literals for which Equation~\ref{eq:missing-effects} applies, where the second group of literals is always the complement of the first group. 
% Consider the \traverserocks action, where the literals in the first group are $\{\neg ONB, OI, \neg A, OFB\}$. 
%     After observing every possible trajectories 100 times, and applying Equation~\ref{eq:present-effects}, we get that $\neg ONB$, $OI$, $\neg A$, and $OFB$ occurs with probability $1\pm 0.061$, $0.5\pm 0.061$, $0.25\pm 0.061$, and $0.25\pm 0.061$, respectively.
%     The corresponding PPDDL action model using Equation~\ref{eq:ppddl-exact} yields an action model in which  $\neg ONB$, $OI$, $\neg A$, and $OFB$ occurs after doing \traverserocks with probabilities
%     1.0, 0.53, 0.28, and 0.28, respectively. 
    


% For \swimisland, the literals in the first group are $\{\neg OI, \neg A, OFB\}$.
% For \swimriver, the literals in the first group are $\{\neg ONB, \neg A, OFB\}$. 
% The probabilities ....[TODO]

% Quote from their paper: 
%You are on one side of a river, and want to get to the other side. There are some rocks that look like they could be traversed. They are slippery though, so there is a 75% chance you would slip and fall. If that happened, there would be a 1 in 3 chance that you would drown in the current, but you would probably be able to make it to a small island in the middle of the river. An as alternative, there is a place further down the river where you might be able to swim across. The current is strong through, so you give yourself an even chance of making it. If you could get to the island you would have a better chance, around 80%. There is no way of swimming there directly, though; the current is just too strong. What do you to to maximise your chance of getting to the other side without drowning?




% (:define coffee-delivery-problem
% (:init (and (not (user-has-coffee)
%             (not (has-umbrella)
%             (probabilistic 
%                 0.8 (in-office)
%                 0.2 (not (in-office))))
% (:goal (and (user-has-coffee) 
%         (not (is-wet)))))


\section*{Acknowledgements}
We thank our reviewers for their constructive comments.
This research is partially funded by NSF awards IIS-1908287 and CCF-1718380,
and BSF grant \#2018684 to Roni Stern, 
and by the Defense Advanced
Research Projects Agency (DARPA) as part of the SAIL-ON program. % Brendan, is there an issue with me adding this?


\bibliography{library}

\end{document}



% % Please add the following required packages to your document preamble:
% % \usepackage{booktabs}
% \begin{table}[]
% \begin{tabular}{@{}cccccc@{}}
% \toprule
% Trajectory  & State & NearBank & Island & FarBank & Alive \\ \midrule
% Swim1  & S0    & 1        & 0      & 0       & 1     \\
% Swim1  & S1    & 0        & 0      & 1       & 1     \\ \midrule
% Swim2  & S0    & 1        & 0      & 0       & 1     \\
% Swim2  & S1    & 0        & 0      & 0       & 0     \\ \midrule
% Rocks1 & S0    & 1        & 0      & 0       & 1     \\
% Rocks1 & S1    & 0        & 1      & 0       & 1     \\
% Rocks1 & S2    & 0        & 0      & 1       & 1     \\ \midrule
% Rocks2 & S0    & 1        & 0      & 0       & 1     \\
% Rocks2 & S1    & 0        & 1      & 0       & 1     \\
% Rocks2 & S2    & 0        & 0      & 0       & 0     \\ \midrule
% Rocks3 & S0    & 1        & 0      & 0       & 1     \\
% Rocks3 & S1    & 0        & 0      & 0       & 0     \\ \bottomrule
% \end{tabular}
% \end{table}

% % Please add the following required packages to your document preamble:
% % \usepackage{booktabs}
% \begin{table}[]
% \begin{tabular}{@{}cccccc@{}}
% \toprule
% State & Action & NearBank & Island & FarBank & Alive \\ \midrule
% S0    & SwimR  & 1        & 0      & 0       & 1     \\
% S1    &        & 0        & 0      & 1       & 1     \\ \midrule
% S0    & SwimR  & 1        & 0      & 0       & 1     \\
% S1    &        & 0        & 0      & 0       & 0     \\ \midrule
% S0    & Rocks  & 1        & 0      & 0       & 1     \\
% S1    & SwimI  & 0        & 1      & 0       & 1     \\
% S2    &        & 0        & 0      & 1       & 1     \\ \midrule
% S0    & Rocks  & 1        & 0      & 0       & 1     \\
% S1    & SwimI  & 0        & 1      & 0       & 1     \\
% S2    &        & 0        & 0      & 0       & 0     \\ \midrule
% S0    & Rocks  & 1        & 0      & 0       & 1     \\
% S1    &        & 0        & 0      & 0       & 0    \\ \bottomrule
% \end{tabular}
% \end{table}



