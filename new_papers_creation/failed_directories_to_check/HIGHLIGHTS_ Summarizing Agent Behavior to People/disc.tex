\section{Discussion \& Future Work}
\label{sec:disc}
With the growing use of intelligent agents, it is important to provide ways for people become more familiar with the the behaviors of such agents, their capabilities and limitations. This paper proposes a new approach for increasing the familiarity of users with agents -- generating summaries of agent behaviors. Our results show that presenting people with ``highlights'' summaries of an agent behavior can help people evaluate the capabilities of different agents. These results provide initial evidence for the potential usefulness of the proposed approach. We next discuss several limitations of the developed HIGHLIGHTS algorithms and possible ways to address them, as well as additional directions for future work. 

%In this work, we  considered two criteria for selecting states to include in the summary: state importance, and the diversity of states. 
The algorithms we described can be improved in several ways. First, the importance measure we used is sensitive to the distribution of Q-values in different states (e.g., it might not make sense in domains where there are many possible actions at any given state, because agents will never consider the worst action). In future work we will define more sophisticated importance measures, e.g., by considering the variance in 
Q-values or regret values. In addition, because the importance assessment was based on the agent's own Q-values, different agents might consider different states as important, and in particular low-quality agents might not be able to recognize states that people will consider important. To mitigate this problem, we will explore ways of assessing importance that do not rely solely on the judgment of the agent itself. For example, aggregating importance values of different agents. In addition, importance could be computed for an entire trajectory rather than for a specific state. Similarly, the diversity of the summary can also be computed based on complete trajectories. We note that while our approach assumed an MDP representation for importance computations, similar notions could also be defined for other decision-making models. For example, with hierarchical plans it might be possible to define a measure that assesses the impact of an action on the ability to achieve a goal.

While considering importance and diversity criteria already improved people's ability to evaluate the performance of different agents compared to the baselines, there are other criteria that should be taken into consideration when generating summaries. For example, in our experiments, participants sometimes referred to specific events when justifying their choice of agents. To ensure that people do not overweight or underweight specific events, the likelihood of encountering states should be reflected in the summary and conveyed to users. In addition, we hypothesize that different summaries may be effective in different contexts. For instance, if the goal of the user is to compare two agents, summaries highlighting states in which their actions differ might be more helpful than summaries that produced for each of the agents separately. Evaluation criteria for summaries can also be extended to include additional metrics such as the ability of people to predict an agent's actions and their ability to collaborate with the agent on a task. 

Our formulation of the summary generation problem assumed a limited budget for the number of trajectories that can be included in the summary. A different way of approaching strategy summarization is framing it as an optimization problem where the goal is to create a minimal summary that satisfies certain criteria (e.g., with respect to coverage of the state space). We will explore such formulations in future work. 

The presentation of summaries is likely to depend on the characteristics of different domains. In the Pacman domain used in our study, presenting a video-clip of the agent was appropriate for conveying the agent's behavior, and showing trajectories that include neighboring states provided people with sufficient context for assessing the agent's actions. This approach could apply more generally to domains where there is a physical agent (e.g., a robot or a self-driving car), but may not be appropriate for some virtual agents (e.g., a personal assistant). In the latter domains, different visualization methods of states will likely be required (e.g., showing some feature-based representation of a state). 

Finally, while automatically generated summaries can provide users with a basic overview of an agent's behavior, in some situations users may require more detailed information, tailored to their needs. To this end, we plan to design collaborative interfaces that let people adjust summaries and explore the behavior of agents in different states. This is particularly important as our experiment showed that people's confidence did not always correlate with the correctness of their assessments, highlighting the importance of providing users with more information about the summaries they observe and more ways to explore them. 




%Our results show that presenting people with ``highlights'' summaries of an agent behavior based on state importance criteria can help them assess the capabilities of different agents, and that considering diversity of trajectories in the summary can further improve these assessments. 

%With the growing use of intelligent agents, it is important to help users understand the capabilities and limitations of such agents. We proposed presenting users with ``highlights'' summaries of agent behaviors to help them gain a better understanding of an agent's global behavior. We 
