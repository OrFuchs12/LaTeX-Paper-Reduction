\begin{abstract}
In order for conversational AI systems to hold more natural and broad-ranging conversations, they will require much more commonsense, including the ability to identify unstated {\em presumptions} of their conversational partners. For example, in the command ``If it snows at night then wake me up early because I don't want to be late for work'' the speaker relies on commonsense reasoning of the listener to infer the implicit presumption that they wish to be woken only if it snows enough to cause traffic slowdowns.  We consider here the problem of understanding such imprecisely stated natural language commands given in the form of {\bf if-(state), then-(action), because-(goal)} statements.  More precisely, we consider the problem of identifying the unstated {\em presumptions} of the speaker that allow the requested action to achieve the desired goal from the given state (perhaps elaborated by making the implicit presumptions explicit).  We release a benchmark data set for this task, collected from humans and annotated with commonsense presumptions. We present a neuro-symbolic theorem prover that extracts multi-hop reasoning chains, and apply it to this problem.  Furthermore, to accommodate the reality that current AI commonsense systems lack full coverage, we also present an interactive conversational framework built on our neuro-symbolic system, that conversationally evokes commonsense knowledge from humans to complete its reasoning chains.
% \vspace{-1em}
\end{abstract}
% Commonsense reasoning refers to humans' ability to make \emph{presumptions} about their daily experiences, activities and interactions with others. In this paper, we propose a new commonsense reasoning benchmark where the task is to uncover commonsense \emph{presumptions} in a specific type of natural language command. We propose a neuro-symbolic and conversationally interactive approach that uncovers presumptions by extracting chains of reasoning. Our contributions are threefold. 1) We propose a commonsense reasoning task: inferring presumptions in if-then-because commands and release a benchmark data set for it, collected from humans and annotated with commonsense presumptions. 2) we propose a neuro-symbolic theorem prover that extracts multi-hop reasoning chains and apply it to our proposed commonsense reasoning problem 3) we propose an interactive conversational framework that evokes commonsense knowledge from humans for completing reasoning chains.

%Commonsense reasoning refers to humans' ability to make \emph{presumptions} about their daily experiences, activities and interactions with others. We propose a new commonsense reasoning benchmark where the task is to uncover commonsense \emph{presumptions} in a specific type of an if-then-because natural language command and release a benchmark data set for it, collected from humans and annotated with commonsense presumptions. We developed a neuro-symbolic theorem prover that extracts multi-hop reasoning chains and apply it to our proposed commonsense reasoning problem. We further develop an interactive conversational framework that evokes commonsense knowledge from humans for completing reasoning chains.
% engine that infers commonsense presumptions by conversing with humans. 
% alternative names: 1. COSMIC	(Conversational neurO SyMbolIc Commonsense reasoning) 2. COSMOS	(COnversational neuro SyMbolic cOmmonsense reaSoning)
% Commonsense reasoning refers to humans' ability to make \emph{presumptions} about their daily experiences, activities and interactions with others. In this paper, we reveal a gap in the commonsense reasoning literature mainly due to lack of relevant benchmarks. We propose a neuro-symbolic framework that uncovers the presumptions that humans would make for our proposed type of natural language statements, by extracting multi-hop reasoning chains using a knowledge base of commonsense facts. However, even the largest knowledge bases gathered to date are incomplete. Therefore, we propose to equip reasoning engines with a conversational interaction strategy to extract missing knowledge from humans just-in-time. Our contributions are threefold. 1) We propose a commonsense reasoning task: inferring presumptions in if-then-because commands and release a benchmark data set for it, collected from humans and annotated with commonsense presumptions. 2) we propose a neuro-symbolic reasoning engine that extracts multi-hop reasoning chains for a given natural language statement and apply it to our proposed commonsense reasoning problem 3) we propose an interactive reasoning engine that infers commonsense presumptions by conversing with humans. 
% and release a data set annotated with commonsense presumptions. 
% mainly due to lack of relevant benchmarks. % maybe better to say reveal a gap in the commonsense reasoning literature?
% we reveal, for the first time, the lack of this commonsense reasoning ability in current computing systems
% Moreover, we propose a conversational interaction
% \tmcomment{too broad}, 
% Humans accumulate commonsense knowledge as they interact with the world around them throughout their lifetime. 
% Currently, almost all reasoning engines rely on querying a large knowledge base. 
% because there is currently no technology that has the capacity to store and query the sum total of all human knowledge. 
% Therefore, our reasoning system is equipped with an instruction strategy to extract missing knowledge from humans just-in-time by conversing with them.
% we present a commonsense reasoning benchmark and release a data set of natural language statements, collected from humans, annotated with commonsense presumptions.
% \tmcomment{we release a benchmark dataset for a specific type of commonsense reasoning: infering presumptions in if-then-because commands}
% that they would make in each statement. 
% conversational strategy in order to deal with missing knowledge. \tmcomment{interactive commonsense reasoning for inferring these presumption, missing knowledge is not the best word}
% \tmcomment{inference of unstated intents, let's find a name for it   }
% we release a dataset collected from humans with this paper that can be used as a benchmark for evaluating commonsense reasoning. 
% In this paper we propose a neuro-symbolic reasoning engine that outputs multi-hop reasoning chains 
% What's my main message?
% neuro-symbolic commonsense reasoning. 
% why neuro-symbolic?
% why commonsense reasoning?
% what are my main contributions:
% 1. neuro-symbolic theorem prover
% 2. commonsense dataset
% 3. interactive knowledge base completion
% Commonsense reasoning, a task so natural for us humans, remains far from reach of our current computing devices. In this paper, we propose a neuro-symbolic commonsense reasoning method
% Despite the success of machine learning and artificial intelligence in the last few decades, we are still far from computers that are capable of doing
% still doing commonsense, the simplest of things that humans do so naturally remains out of reach for current machines. Commonsense allows machines to interact with humans more naturally and make decision making easier for computers in domains where machines often interact with humans such as self-driving cars and conversational agents.
% In this paper, we propose a neuro-symbolic commonsense reasoning system that returns commonsense chains of reasoning using First Order Logic (FOL) inference. This neuro-symbolic reasoning algorithm conversationally interacts with humans and learns embeddings for FOL rules to deal with variations in natural language.
% % In this paper, we propose a neuro-symbolic reasoning system that learns embeddings for first-order-logic statements. We use this neuro-symbolic system to address the problem of commonsense reasoning.
% % Nuero-symbolic systems are hybrid models that combine two major directions in Artificial Intelligence (AI) research, namely neural networks and symbolic computation. These models overcome the limitation of symbolic computation, which is dealing with noise and uncertainty using a neural approach.
% Currently, almost all reasoning engines rely on querying a large knowledge base containing background knowledge of the world. However, it is known that even the largest knowledge bases gathered to date are incomplete. This is expected, since there is currently no technology that has the capacity to store and query the sum total of all human knowledge. Therefore, our reasoning system is equipped with an instruction strategy for completing reasoning tasks where only a small amount of background knowledge is available. When faced with missing knowledge, our engine initiates a conversation with a human user and extracts that knowledge from them just-in-time. Our contributions are threefold. First, we present a benchmark for commonsense reasoning and release a data set containing natural language statements collected from humans. Second, in order to deal with variations of natural language in conversation, we propose a neuro-symbolic reasoning engine that enables ``soft'' 
% logical inference. Third, we propose a conversational commonsense reasoning strategy in order to deal with missing knowledge. 
% Nuero-symbolic systems are hybrid models that combine two major directions in Artificial Intelligence (AI) research, namely neural networks and symbolic computation. In this paper, we propose a neuro-symbolic reasoning engine that 
% These models overcome the limitation of symbolic computation, which is dealing with noise and uncertainty using a neural approach. The result is taking advantage of the interpretabiliy of symbolic AI. \facomment{symbolic AI is vague}
% Commonsense reasoning is one of the most challenging problems in AI and despite the efforts of AI researchers since 1950's remains to be unsolved. In this paper we develop a neuro-symbolic learning algorithm for commonsense reasoning. We have also carefully collected a set of tasks for measuring commonsense in computers that we release with this paper. We hope that the released data set will be a benchmark for researchers to measure the performance of commonsense. 

