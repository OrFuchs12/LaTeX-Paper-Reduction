% \vspace{-1em}
\subsection{Related Work} %Amos: I guess there is no room for a section? I find paragraph a little odd, since there are multiple paragraphs here.
% Commonsense reasoning has been studied since the birth of AI 
The literature on commonsense reasoning dates back to the very beginning of the field of AI
\cite{winograd1972understanding,mueller2014commonsense,davis2015commonsense} and is studied in several contexts. 
One aspect focuses on building a large knowledge base (KB) of commonsense facts. %Examples are p
Projects like CYC \cite{lenat1990cyc}, ConceptNet \cite{liu2004conceptnet,havasi2007conceptnet, speer2017conceptnet} and ATOMIC \cite{sap2018atomic,rashkin2018event2mind} are examples of such KBs (see \cite{davis2015commonsense} for a comprehensive list). Recently, \citet{bosselut2019comet} proposed \comet{}, a neural knowledge graph that generates knowledge tuples by learning on examples of structured knowledge.
% trained on ConceptNet and ATOMIC, that generates commonsense facts. 
These KBs provide background knowledge for tasks that require common sense. % are developed to be used in other systems whose down stream task requires common sense. %Amos: does "this research effort" refer to \cite{bosselut2019comet} or to our paper? Forough: it refers to all the works in this paragraph
% Although it is important to have access to large knowledge bases in reasoning,
However, it is known that knowledge bases are incomplete, and most have ambiguities and inconsistencies \cite{davis2015commonsense} that must be clarified
% on the spot when being used 
for particular reasoning tasks. %Amos: I don't like the expression "on the spot" maybe "at the moment of"? Forough: is it better?
Therefore, we argue that 
% even with access to a knowledge base, 
reasoning engines can benefit greatly from a \emph{conversational interaction strategy} to ask humans about their missing or inconsistent knowledge. 
% We show here that it is reasonable to rely on humans for knowledge extraction. 
Closest in nature to this proposal is the work by \citet{hixon2015learning} on relation extraction through conversation for question answering and \citet{wu2018learning}'s system that learns to form simple concepts through interactive dialogue with a user. 
% \facomment{not sure if we should keep the following}
The advent of intelligent agents and advancements in natural language processing have given learning from conversational interactions a good momentum in the last few years
% Due to advances in natural language processing and the development of recent intelligent assistants, learning through conversational interactions has gained momentum in the past few years 
\citep{azaria2016instructable,labutov2018lia,srivastava2018teaching,goldwasser2014learning,christmann2019look,guo2018dialog,li2018appinite,li2017programming,li2017sugilite}.
% \cite{srivastava2017parsing,srivastava2017joint,}.
%Another counterpart of this type of learning is teaching by demonstration \citep{li2018appinite,li2017programming,li2017sugilite}. The reinforcement learning community has also seen recent interest in using natural language statements as instruction \citep{hu2019hierarchical,luketina2019survey,wang2016learning}.

A current challenge in commonsense reasoning is lack of benchmarks \cite{davis2015commonsense}. Benchmark tasks in commonsense reasoning include the Winograd Schema Challenge (WSC) \cite{levesque2012winograd}, its variations \cite{kocijan2020review}, and its recently scaled up counterpart, Winogrande \cite{sakaguchi2019winogrande} 
% (see \cite{kocijan2020review} for a comprehensive list of all variants of the WSC)
; ROCStories \cite{mostafazadeh2017lsdsem}, COPA \cite{roemmele2011choice}, Triangle COPA \cite{maslan2015one}, and {\art} \cite{bhagavatula2019abductive}, where the task is to choose a plausible outcome, cause or explanation for an input scenario; and the TimeTravel benchmark \cite{qin2019counterfactual} where the task to revise a story to make
it compatible with a given counterfactual
event. 
% in which given a story and two possible endings, the computer should indicate a plausible ending; and COPA \cite{roemmele2011choice} in which the computer should correctly choose the plausible cause of a given premise among two alternatives. Recently, \cite{bhagavatula2019abductive} released a challenge data set for abductive commonsense reasoning. 
Other than TimeTravel, most of these benchmarks have a multiple choice design format. 
% and it has been shown that some are prone to biases easily detectable by language models \cite{sakaguchi2019winogrande}. 
However, in the real world the computer is usually not given multiple choice questions.
% \tmcomment{if need to save space, delete next sentence.} Moreover, some incorrect answers in these benchmarks could be ruled out due to biases easily detectable by language models \cite{trinh2018simple, sakaguchi2019winogrande} resulting in an over-estimation of machine commonsense. 
None of these benchmarks targets the extraction of unspoken details in a natural language statement, which is a challenging task for computers known since the 1970's \cite{grice1975logic}. Note than inferring commonsense presumptions is different from intent understanding \cite{janivcek2010abductive,tur2011spoken} where the goal is to understand the intent of a speaker when they say, e.g., ``pick up the mug''. It is also different from implicature and presupposition \cite{sbisa1999presupposition,simons2013conversational,sakama2016abduction} which are concerned with what can be presupposed or implicated by a text.
% save space: Our proposed task has a more realistic design and is more challenging for computers. %\tmcomment{add that this benchmark is more realistic}
% Therefore, we propose a new benchmark for commonsense reasoning: extracting hidden commonsense presumptions given a natural language statement. 
% Commonsense reasoning has also been studied in textual and visual QA \cite{saeidi2018interpretation, yi2018neural,wu2018chain,zellers2019recognition,hudson2018compositional,narasimhan2018out,johnson2017inferring}, but an in depth review of these falls out of the scope of this work.

% We propose a neuro-symbolic solution (CORGI) that uncovers hidden presumptions in a given natural language statement using an extracted multi-hop reasoning chain. 
CORGI has a neuro-symbolic logic theorem prover. Neuro-symbolic systems are hybrid models that leverage the robustness of connectionist methods and the soundness of symbolic reasoning to effectively integrate learning and reasoning \cite{garcez2015neural,besold2017neural}. They have shown promise in different areas of logical reasoning ranging from classical logic to propositional logic, probabilistic logic, abductive logic, and inductive logic \cite{mao2019neuro, manhaeve2018deepproblog,dong2019neural,marra2019integrating,zhou2019abductive,evans2018learning}. To the best of our knowledge, neuro-symbolic solutions for commonsense reasoning have not been proposed before. Examples of commonsense reasoning engines are: AnalogySpace \cite{speer2008analogyspace,havasi2009digital} that uses dimensionality reduction
% such as PCA
and \citet{mueller2014commonsense} that uses the event calculus formal language. 
% Recently, \cite{wang2019satnet} proposed a differentiable maximum satisfiability solver for learning logical structures from data. The goal of works such as \cite{tran2016deep,hu2016harnessing}, which use logical rules in deep learning, is to improve the interpretability or performance of neural networks and are of less relevance here.
% In another line of research, logical rules have been used in deep learning to improve the interpretability or performance of neural networks \cite{tran2016deep,hu2016harnessing}. The goal of these works is not to directly address reasoning problems and is rather to improve the performance of neural networks by constraining their learning using a set of logical rules 
% essentially jointly learning using examples and rules 
% and is of less relevance to our work. %Although more recently \cite{wang2019satnet} proposed a maxSAT solver
% CORGI finds a chain of reasoning in a given commonsense knowledge base containing FOL facts and rules.
% Multi-hop reasoning is more challenging and indicates a higher capacity in performing reasoning
% Multi-hop reasoning for question answering has recently been explored and challenging benchmark data sets have been created in the community for it \citep{weston2015towards,welbl2018constructing,johnson2017clevr}. %\kmcomment{capacity for what? 'reasoning' is a bit circular}
% Chain of reasoning can be performed through logical inference and there are several interesting works that attempt to bridge the gap between symbolic reasoning and the recent advances in AI and machine learning \cite{liang2018symbolic,wang2019satnet}. %\cite{besold2017neural,}
% Another method that performs reasoning through logical inference is
TensorLog \citep{cohen2016tensorlog} converts a first-order logical database into a factor graph and proposes a differentiable strategy for belief propagation over the graph. DeepProbLog \cite{manhaeve2018deepproblog} developed a probabilistic logic programming language 
% and introduces the concept of a neural predicate. DeepProbLog 
that is suitable for applications containing categorical variables. %Amos: I think that the remainder of this section can be better organized.
Contrary to our approach, both these methods do not learn embeddings for logical rules that are needed
to make CORGI robust to natural language variations. 
Therefore, we propose an end-to-end differentiable solution that uses a Prolog \cite{colmerauer1990introduction} proof trace to learn rule embeddings from data. Our proposal is closest to the neural programmer interpreter \citep{reed2015neural} that uses the trace of algorithms such as addition and sort to learn their execution. 
The use of Prolog for performing multi-hop logical reasoning has been studied in \citet{rocktaschel2017end} and \citet{weber2019nlprolog}.
% where neural networks are integrated into Prolog to perform soft unification in backward chaining. 
% In these works, the authors propose differentiable ``AND'' and ``OR'' operations that convert unification to a differentiable process. 
These methods perform Inductive Logic Programming to learn rules from data, and are not applicable to our problem. 
% In order to address the scalability issues of \cite{rocktaschel2017end}, NLprolog \cite{weber2019nlprolog} proposes a non end-to-end differentiable solution. 
% a program \tmcomment{what program are they using?} to learn program execution.
DeepLogic \cite{cingillioglu2018deeplogic}, \citet{rocktaschel2014low}, and  \citet{wang2016blearning} also learn representations for logical rules using neural networks. 
% Other examples of works that learn low-dimensional embeddings for logic are 
%are %is [kmm- rephrase]
% \citep{rocktaschel2014low,wang2016blearning}. 
% \facomment{also cite: \cite{manhaeve2018deepproblog}}
Very recently, transformers were used for temporal logic \cite{finkbeiner2020teaching} and to do multi-hop reasoning \cite{clark2020transformers} using logical facts and rules stated in natural language. 
% Although the results are interesting, 
A purely connectionist approach to reasoning suffers from some limitations. For example, the input token size limit of transformers restricts \citet{clark2020transformers} to small knowledge bases. Moreover, generalizing to arbitrary number of variables or an arbitrary inference depth is not trivial for them. 
% it is not clear if the framework is able to handle more than one variable in a single rule. Lastly, generalizing to a larger unseen inference depth is not trivial for them. 
Since symbolic reasoning can inherently handle all these challenges, a hybrid approach to reasoning takes the burden of handling them off of the neural component. 
% \vspace{-1em}
% One of these is the literature on knowledge base construction and completion where the goal is to construct a large commonsense knowledge base and develop automated completion methods for it \cite{lenat1990cyc,liu2004conceptnet,havasi2007conceptnet,sap2018atomic,rashkin2018event2mind,bosselut2019comet}. Serafini et al. \cite{serafini2016logic} perform logical reasoning using neural networks for knowledge base completion. Another line of work is on ``if-then'' reasoning in which given a snapshot observation of an event, the computer reasons about the unobserved causes and effects of the event similar to humans
% \cite{sap2018atomic,rashkin2018event2mind}. %Amos: can remove "In our work" if it helps saving some space
% In our work, in contrast to these studies, we start from a small amount of knowledge. We hypothesize that since no computing system has the capacity to store the sum total of all human commonsense knowledge, we need to develop methods that extract commonsense knowledge on a need-driven basis through conversation. Closest in nature to our proposal is Hixon et al.,'s work \cite{hixon2015learning} on relation extraction through conversation for question answering.
%\citeauthor{gerber2010open} extract commonsense knowledge from open-domain text using discourse parsing.

% Abductive commonsense reasoning and abductive reasoning has been studied recently \cite{bhagavatula2019abductive, zhou2019abductive}.

% commonsense reasoning engines. AnalogySpace \cite{speer2008analogyspace,havasi2009digital} of conceptNet and CYC \cite{lenat1990cyc} of Cycorp

% benchmark tasks in commonsense reasoning include the Winograd Schema Challenge \cite{levesque2012winograd} and its scaled up Winogrande \cite{sakaguchi2019winogrande}. Another example is ROCstories \cite{mostafazadeh2017lsdsem} in which given a story and two possible endings the computer should indicate a plausible ending and COPA \cite{roemmele2011choice} the choice of plausible alternatives that evaluates machine commonsense in the scenario where given a premise, the computer should correctly choose the plausible cause of the premise among two alternatives.

% There is also literature on visual commonsense reasoning \cite{zellers2019recognition}.

% Commonsense reasoning is also studied in the question answering and visual question answering (VQA) literature. Saeidi et al. \cite{saeidi2018interpretation} perform question answering for a dialog assistant that attempts to understand the context of the dialog and initiates clarifying question with the user to answer questions effectively.
%\citeauthor{trinh2018simple} 
%scores % [kmm- if this refers to 'attempts' it should be 'score'; if it refers to {trinh2018simple} then 'scores' is most clear] [fa- when we use \citeaithor it inserts a name + et. al. Would that be singular still?]
%multiple choice question answers to find the correct answer to commonsense reasoning questions.
%However, this method relies on eliminating wrong answers rather than finding the correct answer. 
% The literature on commonsense reasoning for visual question answering is also vast \cite{yi2018neural,wu2018chain}. Hudson et al. \cite{hudson2018compositional} 
% study %study [kmm- 'a work' is singular, but 'the authors of a work' is plural; not sure which is meant here][-fa: i think this should be study because we are referring to the authors?]
% VQA using end-to-end differentiable methods. %\cite{narasimhan2018out,johnson2017inferring}
% However, more recently there have %has [kmm- attempts->have]
% been more attempts at commonsense  
% Commonsense reasoning is also defined as question answering and 

%A parallel literature studies the reasoning capabilities of neural networks in general. For example \citeauthor{barrett2018measuring} measure the abstract reasoning capabilities of neural networks and \citeauthor{saxton2019analysing} analyze the mathematical reasoning capabilities of neural networks.





% In general, There seems to be a shift in interest towards neural symbolic methods. For a survey take a look at \cite{besold2017neural}.
% Our work is in essence similar to the works that tend to bridge the gap between symbolic reasoning and data intensive machine learning. Recent examples of such endeavours are works such as \cite{liang2018symbolic,chen2019deep,zhou2019abductive,wang2019satnet}

%In almost all these papers, it is assumed that the logical query is given as input. However, in this work we have an extra step of extracting the logical query out of a natural language utterance.
%Researchers have worked on extracting horn clauses and logical forms from natural language statements \citep{banko2007open,levy2017zero}. Moreover there are many works that use statistical learning methods for introducing logical predicates \citep{kok2007statistical}. In this paper, we use a dependency parser to extract the predicate and the arguments of the predicate and construct if then rules using this strategy from input natural language utterances. %\cite{davis2007change,}

% fa - I think these are not relevant as much so I am omitting the text in bracets: {
% in this work \citep{wang2015efficient} the authors propose a fast method for inference over logical statements that is more efficient than markov logic networks \citep{richardson2006markov}.

% Explanation based learning and its probabilistic counterparts are marginally relevant to this work \citep{dejong2012investigating,kimmig2007probabilistic}.

% Inductive logic programming reference \citep{muggleton1994inductive}.

% IFTTT: https://ifttt.com/ to motivate if this then that }






% Semantic parsing is also another realm where natural language statements are mapped to the logical form 
% representations %representation [kmm- statements->representations]
% of their meaning, usually in the form of lambda calculus expressions \citep{zettlemoyer2012learning,dong2016language}

% We are familiar with \citep{hixon2015learning} that performs knowledge base completion using human dialogs. %Amos: you spell dialogue as dialog earlier, please be consistent. 


% Developing commonsense reasoning for machines remains an open challenge in the field of artificial intelligence and machine learning. Currently, almost all the reasoning engines rely on gathering the largest possible knowledge base and querying it to extract commonsense knowledge. It has been shown that no matter how large the gathered knowledge bases are, there are still instances where they fail at performing the simplest reasoning for a specific user. Therefore, in this paper, we test the hypothesis in which we start from a very small amount of knowledge that contains basic background knowledge about the world. Whenever a commonsense fails, we initiate a conversation with the user and extract just-in-time information from them that completes the missing knowledge and performs reasoning. This will also grow the agent's knowledge in due time as interactions with the user increase. 

% \facomment{"Children develop their knowledge of the world around them as they interact with their environment directly and indirectly. The direct experiences children have in their homes, schools and communities certainly provide the greatest amount of input to the world knowledge base. Much of this knowledge base is developed incidentally without direct instruction. -- argue maybe that reasoning engines will need to have both the ability to query a large knowledge base AND the ability to interact with the world and other humans to build their commonsense reasoning and discuss that our work is a step towards that... We believe that this is a component missing from current reasoning engines and mention that they need to have a method to interact with the world around them and extract information on top of having access to a big background knowledge}
