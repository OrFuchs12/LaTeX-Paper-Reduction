
% Problem def., informal
Thus, we consider the following problem: Given a software system
composed of a set of software components $\mathcal{C}=\{C_1, C_2, \ldots C_n\}$,
and a fixed-time budget $B$, the problem is how to best exploit this time budget
to generate tests that will identify the largest number of bugs in the future.

% Abstractions and simplification
We assume the availability of test generation tools such as EvoSuite~\cite{fraser2011evosuite}
that is, tools that accept a class, and outputs a suite of tests
that check this class. Experimentally, we observed that the time spent by
EvoSuite to generate a test for a class was not highly affected by the class
size, but rather by the time spent during the search process. 
%% i did not got good results to justify the statement, but i found a research that will make a point 
In addition, we followed the experiment that was done on Defects4J data set ~\cite{shamshiri2015automatically}. They found out that, a search budget of three minutes is sufficient for the search in EvoSuite to converge in most cases, such that more time would not further change the tests. We also observed that investing time beyond that fixed time was not worthwhile. Thus, the question of how to
spend the time budget $B$ in test generation can be simplified to the question
of which classes to generate tests for. Thus, we assume that the time budget $B$
is expressed as the number of components from $\mathcal{C}$ that the test
generation tool can generate tests for until the time budget is up. If $B$ is
larger than the number of components then we can generate tests for
($\mathcal{C}$), then the trivial solution is to generate tests for all
components. In this research, we consider scenarios in which $B$ is much smaller
than the number of classes. We call this problem
the \btg problem and define it as follows.


%ERAN::%In addition, we observed that there is a fixed time budget per class that works best, and investing time beyond that fixed time was not worthwhile. [add some justification]

\begin{definition}[The \btg Problem]
The input to a \btg problem is a software system composed
of a set of component $\mathcal{C}=\{C_1, C_2, \ldots, C_n\}$, a test generation tool
that accepts a $C\in \mathcal{C}$ and outputs a test suite for it, and given a
fixed number $B$. The output is a set of $B$ tests suites generated by the test
generation tool.
\end{definition}

The quality of a solution to a \btg problem is measured by the number of bugs detected.
%














%fix version and buggy version
We make a reasonable common assumption in the field of software testing, that the buggy version is the predecessor of the fixed commit that reported in \ac{ITS}.
\Roni{Not clear.}
%
%% Eran  write something about the Labeling process, we used the Most config}
For the decision of which components on each bug were faulty, we used the ``most modified'' on the \fp algorithm ~\cite{elmishali2019debguer}, it assumes that the component in the Buggy version that caused the bug is the component whose revisions were most extensive. This is measured by counting the number of lines of code in the components that were either modified, added, or deleted. 
%%%end of section%%%%%%%%




% more details about the train set, test set and validation set.
A common way is splitting the data in ML project is to randomly divide the data into the various sets and repeat such a division several times. This technique is called k-fold cross validation. However, in order to build a \fp model that is based on the actual development process, we decided to split the data following the time of the version date of the projects. The train set contained the versions and the reported bugs the were released before the buggy version, because the imbalanced nature of the data-set, the validation set contained one version that released after the buggy version, in order to use the knowledge from all previous bugs, and the test set contains bugs from the buggy version that. Thus, we train the model on the bugs that were reported first on in the development process, and test it on the bugs that were reported later, similarly to a real-world development process.
\Eran{I hope that setting the validation on a version that released, later on, is considered reasonable }\Roni{I'm not sure I understand}




 If every line of code is equally likely to have a bug, a test that is intended to cover more lines of code is more likely to find
    bugs. We call the algorithm that returns the $B$ components with the largest
    number of lines of codes, the \loc \btg algorithm. 
    
    
    
    
    
    
    
We propose the following alternative scoring functions: 
\begin{}


\begin{itemize}
    \item \textbf{Fault Prediction (\fp).} This score function simply returns \fp($C$).
    
    \item \textbf{\loc.} This score function returns the number of lines of code of the given component. 
    
    \item \textbf{\mix.} This is a parametric score function that is a linear combination of the previous two functions. It accepts a parameter $\alpha$ and outputs for a given class $C$ the score
    \begin{equation}
      score(C)=\alpha\cdot \fp(C)+(1-\alpha)\cdot \loc(C)
      \end{equation}
    
    While a \fp model can be generated for many projects, its reliability may vary.
    With this in mind, we propose a natural hybrid approach, in which every component
    $C$ is associated with a score:
      \begin{equation}
      score(C)=\alpha\cdot \fp(C)+(1-\alpha)\cdot \loc(C)
      \end{equation}
    where $\alpha$ is a parameter in the range $[0,1]$ and $\loc(C)$ is the
    number of \loc in $C$. The $B$ components with the highest score are
    returned and passed to the test generation tool. We call the algorithm that
    returns the $B$ components with the highest score the $\mix(\alpha)$ \btg
    algorithm.
    
    
    
    For projects without many previously reported bugs, we considered the extreme case in which a reliable FP model is unavailable. In such a case, a
    reasonable approach is to generate tests for the largest software
    components, i.e., the software components that contains the most \loc. If every line of code is equally likely to have a bug, a
    test that is intended to cover more lines of code is more likely to find
    bugs. We call the algorithm that returns the $B$ components with the largest
    number of lines of codes, the \loc \btg algorithm. The use of a \loc
    algorithm is somewhat similar to the common test generation approach of maximizing coverage.
    
    
    exactly the The \fp scoring function 
    
    relies on the accuracy of the learned \fp model. While modern software \fp algorithms are
    quite accurate, they are not perfect. In particular, they are less effective
    for projects without many previously reported bugs.

    \item \textbf{\loc.} For projects without many previously reported bugs, we considered the extreme case in which a reliable FP model is unavailable. In such a case, a
    reasonable approach is to generate tests for the largest software
    components, i.e., the software components that contains the most \loc. If every line of code is equally likely to have a bug, a
    test that is intended to cover more lines of code is more likely to find
    bugs. We call the algorithm that returns the $B$ components with the largest
    number of lines of codes, the \loc \btg algorithm. The use of a \loc
    algorithm is somewhat similar to the common test generation approach of maximizing coverage.
    
    
    \item \textbf{\mix.} While a \fp model can be generated for many projects, its reliability may vary.
    With this in mind, we propose a natural hybrid approach, in which every component
    $C$ is associated with a score:
      \begin{equation}
      score(C)=\alpha\cdot \fp(C)+(1-\alpha)\cdot \loc(C)
      \end{equation}
    where $\alpha$ is a parameter in the range $[0,1]$ and $\loc(C)$ is the
    number of \loc in $C$. The $B$ components with the highest score are
    returned and passed to the test generation tool. We call the algorithm that
    returns the $B$ components with the highest score the $\mix(\alpha)$ \btg
    algorithm.
\end{itemize}
























In
addition, we observed empirically that to create multiple tests suites for a
single class was very useful. This was because EvoSuite applied an evolutionary algorithm to generate tests, which included stochastic elements. Thus, re-running EvoSuite on the same class could yield different tests. % \Rui{why?}.
% Eran answer for Rui Question 
As mentioned before EvoSuite is stochastic test generation tool, by defaults EvoSuite stochastic parameters
However, note that if one set all probabilistic parameters to false, \Roni{What are these probabilitic parameters?} Evosuite will not generate exactly the same result as time can be influenced by other processes running on the same machine.
%--------------------end 
Every generated test suite is referred to as a
"replication", and we observed empirically that performing 5
replications for all projects provided the most cost-effective solution.











%Recommend beginning a new paragraph%
Table~\ref{tab:prediction} shows the performance of the resulting \fp
models for each of the projects. 
The table's columns are the different projects. 
The AUC row shows the average area under the receiver operating characteristic (ROC) curve,
which is a standard metric for evaluating classifiers. Briefly, AUC plots the true positive rate against the false positive rates for different classification thresholds.
The row labelled ``Imbalance
ratio'' shows for each project the ratio between
the number of buggy and not buggy components for each project.
As can be seen, we were clearly dealing with an imbalanced dataset. 
AUC is less suited to evaluate classifiers in such datasets. Therefore, the row labelled ``PRC'' shows the average area under the  precision-recall curve (PRC). PRC is a common alternative to AUC that is more 
suitable for data that is \emph{imbalanced}. For more details on these standard metrics, see~\cite{davis2006relationship}. 

The results show that our \fp was more accurate for the Net, Imag., and Lnag. projects, while it was not very accurate for Math. Later, we observe the impact of these results on the performance of \quadrant with the different scoring function.

%(``AUC''), area under the p recision-recall curve (``PRC''), precision, recall, F1 score, and the imbalanced ratio (``Imb.'').  Precision, recall, F1, AUC, and PRC, are all standard metrics in supervised learning.  The imbalanced ratio is the ratio between components with and without a reported bug in the training set. Supervised learning algorithms are, in general, less effective for datasets with low imbalanced ratio. Briefly, AUC is the area under the ROC curve, which plots the true positive rate against the false positive rates for different classification thresholds. An AUC of one means perfect prediction.  However, in imbalanced datasets the AUC tends to be high. Thus,  Briefly, AUC is the area under the ROC curve, which plots the true positive rate against the false positive rates for different classification thresholds. PRC is a common alternative to AUC that is more suitable for imbalanced data set: it plots the precision and recall obtained for different classification thresholds, and returns the area under the resulting curve. For more details on these standard metrics, see~\cite{davis2006relationship}.


%Table~\ref{tab:prediction} shows the average area under the ROC curve (``AUC''), area under the p recision-recall curve (``PRC''), precision, recall, F1 score, and the imbalanced ratio (``Imb.'').  Precision, recall, F1, AUC, and PRC, are all standard metrics in supervised learning.  The imbalanced ratio is the ratio between components with and without a reported bug in the training set. Supervised learning algorithms are, in general, less effective for datasets with low imbalanced ratio. Briefly, AUC is the area under the ROC curve, which plots the true positive rate against the false positive rates for different classification thresholds. An AUC of one means perfect prediction.  However, in imbalanced datasets the AUC tends to be high. Thus,  Briefly, AUC is the area under the ROC curve, which plots the true positive rate against the false positive rates for different classification thresholds. PRC is a common alternative to AUC that is more suitable for imbalanced data set: it plots the precision and recall obtained for different classification thresholds, and returns the area under the resulting curve. For more details on these standard metrics, see~\cite{davis2006relationship}.







%\Eran{results by Eran}
% Trend #1 fault prediction is indeed useful
The first clear trend is that in all configurations, \fp$_{0.9}$ and \fp$_{0.7}$ performed best, and almost always significantly better than Random and \loc in term of gain. For example, see  the results for Compress in Table ~\ref{tab:gain-2}. When $B$ is set to two, the gain of Random and \loc is 0.15 and 0.54, respectively, while the gain with \fp$_{0.9}$ is 0.81. This establishes the benefit of using a fault prediction to prioritize test generation. 

















% Limitation: parameter
A limitation of the \mix algorithm is that it is parametric, and we do not
provide an exact method to set its parameter ($\alpha$). However, the results
show that setting $\alpha$ between 0.7 to 0.9 provides peak performance across
most cases. Moreover, even running with \fp alone (equivalent to setting
$\alpha$ to 1) is almost always better than random and \loc.

\Eran{Maybe it is possible to learn the best fit alpha from a data set of previous reported bugs, using some kind of ML algorithm}


\begin{figure}
    \centering
    %\includegraphics[width=1.5\columnwidth]{quadrant_new.pdf}
    \includegraphics[width=1\columnwidth]{Charts/MATH_chart.png}
    \caption{Math project. $y$-axis shows the number of killed bug for different budgets and \btg algorithms ($x$-axis). The black line indicates the number of bugs killed by Oracle. .}
    \label{fig:math}
\end{figure}


\begin{figure}
    \centering
    %\includegraphics[width=1.5\columnwidth]{quadrant_new.pdf}
    \includegraphics[width=1\columnwidth]{Charts/LANG_chart.png}
    \caption{Lang project. $y$-axis shows the number of killed bug for different budgets and \btg algorithms ($x$-axis). The black line indicates the number of bugs killed by Oracle. .}
    \label{fig:lang}
\end{figure}


\begin{figure}
    \centering
    %\includegraphics[width=1.5\columnwidth]{quadrant_new.pdf}
    \includegraphics[width=1\columnwidth]{Charts/COMP_chart.png}
    \caption{Compress project. $y$-axis shows the number of killed bug for different budgets and \btg algorithms ($x$-axis). The black line indicates the number of bugs killed by Oracle. .}
    \label{fig:comp}
\end{figure}

% \label{sec:quadrant}
% \begin{figure*}
%     \centering
%     %\includegraphics[width=1.5\columnwidth]{quadrant_new.pdf}
%     \includegraphics[width=1\columnwidth]{Charts/IMAG_chart.png}
%     \caption{Math project. $y$-axis shows the number of killed bug for different budgets and \btg algorithms ($x$-axis). The black line indicates the number of bugs killed by Oracle. .}
%     \label{fig:imaging}
% \end{figure*}
\begin{table}[]
\begin{tabular}{l|llll|llll|}
         & \multicolumn{4}{l}{IMAGING} & \multicolumn{4}{l|}{OPENNLP} \\\hline
Budget   & 1        & 2       & 3       & 4             & 1       & 2       & 3   & 4  \\ \hline
FP       & \textbf{10}&\textbf{12}& 12         & 13             & 4         & 8         & 8     & 8    \\
LOC      & 4          & 6         & 9          & 11             & 3         & 5         & 7     & 7    \\
MIX(0.1) & 4          & 7         & 10         & 12             & 3         & 5         & 7     & 7    \\
MIX(0.2) & 4          & 8         & 10         & 12             & 4         & 5         & 7     & 8    \\
MIX(0.3) & 5          & 8         & 10         & \textbf{13}    & 4         & 5         & 6     &\textbf{9}    \\
MIX(0.4) & 5          & 8         & 11         & \textbf{13}    & 4         & 5         & 6     & 8    \\
MIX(0.5) & 7          & 9         & 12         & \textbf{13}    &\textbf{5} & 6         & 7     & 8    \\
MIX(0.6) & 7          & 9         & 12         & \textbf{13}    &\textbf{5} & 6         & 7     & 8    \\
MIX(0.7) & 8          & 10        & \textbf{13}& \textbf{13}    & 4         & 7         & 8     & 8    \\
MIX(0.8) & 8          & 11        & 12         & \textbf{13}    & 4         &\textbf{8} & 8     & 8    \\
MIX(0.9) & \textbf{10}&\textbf{12}& 12         & \textbf{13}    &\textbf{5} &\textbf{8} & 8     & 8    \\
Random   & 1          & 2         & 2          & 3              & 1         & 3         & 3     & 4    \\  \midrule
Oracle   & 13         & 13        & 13         & 13             & 11        & 11        & 11    & 11   \\ \bottomrule
\end{tabular}
\caption{Number of killed bugs for the Imaging and OpenNLP projects.}
\label{tab:imaging_opennlp}
\end{table}

% Commons - Compress Results
% \begin{table}[]
% \begin{tabular}{lllll}
% \hline
% Budget   & 1           & 2           & 3           & 4           \\ \midrule
% FP       & 15      & 21      & 23       & 23  \\ 
% LOC      & 9        & 14      & 18      & 22 \\ 
% MIX(0.1) & 13      & 21      & 21       & 21  \\ 
% MIX(0.2) & 15      & 21      & 22       & 22  \\ 
% MIX(0.3) & 15      & 20      & 22       & 23  \\ 
% MIX(0.4) & 16      & 20      & 23       & 23  \\ 
% MIX(0.5) & 16      & 19      & 23       & 23  \\ 
% MIX(0.6) & 16      & 20      & 23       & 24  \\ 
% MIX(0.7) & 16      & 20      & 23       & 24  \\ 
% MIX(0.8) & 16      & 20      & 23       & 24  \\ 
% MIX(0.9) & 15      & 21      & 23       & 24  \\ 
% Random   & 3        & 4  & 7            & 8       \\ \midrule
% Oracle   & 26      & 26      & 26       & 26 \\ \bottomrule
% \end{tabular}
% \caption{umber of killed bugs for the Compress project. TODO: make a graph}
% \label{tab:compress}
% \end{table}


% % Commons - Imaging Results
% \begin{table}[]
% \begin{tabular}{lllll}
% Budget   & 1           & 2           & 3           & 4           \\ \midrule
% FP       &      10 &      12 &      12 &      13 \\
% LOC      &      4   &      6   &      9  &      11 \\
% MIX(0.1) &      4   &      7   &      10 &      12 \\
% MIX(0.2) &      4   &      8   &      10 &     12 \\
% MIX(0.3) &      5   &      8   &      10 &      13 \\
% MIX(0.4) &      5   &      8   &      11 &      13 \\
% MIX(0.5) &      7   &      9 &      12 &      13 \\
% MIX(0.6) &      7   &      9  &      12 &      13 \\
% MIX(0.7) &      8   &      10 &      12 &      13 \\
% MIX(0.8) &      8   &      11 &      12 &      13 \\
% MIX(0.9) &      10 &      12 &      12 &      13 \\
% Random   &      1   &      2   &      2   &      3   \\ \midrule
% Oracle   &      13 &      13 &      13 &      13 \\ \bottomrule
% \end{tabular}
% \caption{Number of killed bugs for the Imaging project.}
% \label{tab:imaging}
% \end{table}

% % Commons - Lang Results
% \begin{table}[]
% \begin{tabular}{lllll}
% Budget   & 1           & 2           & 3           & 4           \\\midrule
% FP       &      24 &      30 &      34 &      36 \\
% LOC      &      20 &      28 &      30 &      32 \\
% Mix(0.1) &      20 &      28 &      30 &      33 \\
% Mix(0.2) &      20 &      28 &      30 &      33 \\
% Mix(0.3) &      20 &      28 &      31 &      34 \\
% Mix(0.4) &      20 &      28 &      31 &      34 \\
% Mix(0.5) &      21 &      30 &      32 &      34 \\
% Mix(0.6) &      22 &      32 &      32 &      34 \\
% Mix(0.7) &      22 &      32 &      33 &      35 \\
% Mix(0.8) &      23 &      32 &      35 &      37 \\
% Mix(0.9) &      23 &      31 &      34 &      37 \\
% Random   &      5   &      9  &      12 &      14 \\\midrule
% Oracle   &      40 &      40 &      40 &      40\\\bottomrule
% \end{tabular}
% \caption{Number of killed bugs for the Lang project. }
% \label{tab:lang}
% \end{table}


% % Commons - MATH Results 
% \begin{table}[]
% \begin{tabular}{lllll}
% Budget   & 1           & 2           & 3           & 4           \\ \midrule
% FP       &      34 &     43 &      46 &       51 \\
% LOC      &      36 &      44 &      47 &      48 \\
% Mix(0.1) &      39 &      48 &      52 &      52 \\
% Mix(0.2) &      40 &      46 &      50 &      52 \\
% Mix(0.3) &      39 &      46 &      49 &      51 \\
% Mix(0.4) &      40 &      46 &      49 &      51 \\
% Mix(0.5) &      40 &      46 &      49 &      51 \\
% Mix(0.6) &      40 &      46 &      49 &      51 \\
% Mix(0.7) &      39 &      46 &      50 &      52 \\
% Mix(0.8) &      39 &       46 &      48 &     53 \\
% Mix(0.9) &      37 &      45 &      48 &      53 \\
% Random   &      5   &      12 &      17 &     21 \\ \midrule
% Oracle   &      61 &      61 &      61 &      61\\\bottomrule
% \end{tabular}
% \caption{Number of killed bugs for the Math project.}
% \label{tab:math}
% \end{table}


% % OpneNLP Results
% \begin{table}[]
% \begin{tabular}{lllll}
% Budget   & 1           & 2           & 3           & 4           \\ \midrule
% FP       & 4        &      8     &     8  &     8  \\
% LOC      & 3        &      5    &      7   &    7  \\
% Mix(0.1) & 3        &      5   &      7   &     7  \\
% Mix(0.2) & 4        &      5   &      7   &     8  \\
% Mix(0.3) & 4        &      5   &      6   &     9  \\
% Mix(0.4) & 4        &      5   &      6   &     8  \\
% Mix(0.5) & 5        &      6   &      7   &     8  \\
% Mix(0.6) & 5        &      6   &      7   &     8  \\
% Mix(0.7) & 4        &      7   &      8   &     8  \\
% Mix(0.8) & 4        &      8   &      8   &     8  \\
% Mix(0.9) & 5        &      8   &      8   &     8  \\
% Random   & 1        &      3   &      3   &     4        \\ \midrule
% Oracle   &     11 &     11 &     11 &     11\\\bottomrule
% \end{tabular}
% \caption{Number of killed bugs for the  OpenNLP project.}
% \label{tab:nlp}
% \end{table}

%\label{sec:quadrant}
%\begin{figure*}
%    \centering
%    %\includegraphics[width=1.5\columnwidth]{quadrant_new.pdf}
%    \includegraphics[width=1\columnwidth]{Charts/NLP_chart.png}
%    \caption{OpenNlp project. $y$-axis shows the number of killed bug for different budgets and \btg lgorithms %($x$-axis). The black line indicates the number of bugs killed by Oracle. .}
%    \label{fig:quadrant}
%\end{figure*}



%  NET results
\begin{table}[]
\begin{tabular}{lllll}
Budget   & 1         & 2         & 3         & 4         \\ \midrule
FP       & \textbf{6}&\textbf{6}      &\textbf{6}      & \textbf{6}      \\
LOC      & 0      & 1      & 3      & 4      \\
Mix(0.1) & 2      & 3      & 4      &\textbf{6}      \\
Mix(0.2) & 4      &\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.3) & 5      &\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.4) & 5      &\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.5) & 5      &\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.6) & \textbf{6}&\textbf{6}      &\textbf{6}     &\textbf{6}      \\
Mix(0.7) & \textbf{6}&\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.8) & \textbf{6}&\textbf{6}      &\textbf{6}      &\textbf{6}      \\
Mix(0.9) & \textbf{6}&\textbf{6}      &\textbf{6}     &\textbf{6}      \\
Random   & 2      & 2      & 3      & 4      \\ \midrule
Oracle   & 6      & 6      & 6      & 6     \\\bottomrule
\end{tabular}
\caption{Number of killed bugs for the Net project.}
\label{tab:net}
\end{table}

% Commons - Lang Results number of test 
\begin{table}[]
\begin{tabular}{lllll}
Budget   & 1           & 2           & 3           & 4           \\\midrule
FP       & 24     (24) & 32     (30) & 38     (34) & 41     (36) \\
LOC      & 20     (20) & 29     (28) & 31     (30) & 33     (32) \\
Mix(0.9) & 23     (23) & 32     (31) & 36     (34) & 42     (37) \\
Random   & 5      (5)  & 10     (9)  & 13     (12) & 16     (14) \\\midrule
Oracle   & 40     (40) & 40     (40) & 40     (40) & 40     (40)\\\bottomrule
\end{tabular}
\caption{Number of killed bugs for the Lang project.}
\label{tab:lang2}
\end{table}




%best FP model Net and Imaging 
Table~\ref{tab:net} show the number of bugs killed  is the best result for every budget. In the Net project, EvoSuite failed to generate tests that identify bugs, as can be seen by the poor performance of Oracle: only 6 bugs were detected out of the 178 bugs we extracted from the \ac{ITS}. The performance of the \fp algorithm is correlated with the relatively high accuracy of the model with the result of the (PRC=0.4). Nevertheless, \fp and \mix with $\alpha>0.7$ are able to match the performance
of Oracle with a single test. This corresponds to the fault prediction model's
performance for this project, which was the highest among the evaluated projects
(PRC=0.4). By contrast, \loc and random cannot kill the 6 bugs even with a
budget of 4.

% number of tests that where generated by EvoSuite and find a bug 
Table ~\ref{tab:lang2} shows the number of tests that were able to detect a reported bug, along with the number of killed bugs in brackets. Intuitively, one can immediately notices that the number of tests must be greater or equal to the number of killed bugs. The \fp algorithm with a budget of 4, generated 41 tests that detected and killed 36 reported bugs, while on \loc the number of tests that were detected and kill the 33 bugs was 34, this implies that the likelihood of the \fp to find and kill a bug with a stochastic tool like EvoSuite is much more higher than an algorithm that does not take into to consider the \fp model, as mentioned before EvoSuite might need many replications to generate a test suite that will detect an arbitrary bug.
\Eran{Eran: it can tell us something about the connection between the classes???}

