\section{Discussion and Future Work} \label{sec:conclusion} 
With the maturing of AI, circumstances which require people to choose between alternative market-available solutions, are likely to arise. The necessity of distinguishing between alternative agents becomes ever more clear. Moreover, distinguishing between policies is key for developers when analyzing different algorithms and  configurations. 

This paper presented a new approach for comparing RL agents by generating policy disagreement summaries. Experimental results show summaries help convey agent behaviour differences and improve users' ability to identify superior agents, when one exists. 


% These
% summaries emphasize the differences between agents, supporting people's a and helped people correctly identify the superior
% agent,  as shown in our experiment results. They also led to higher rates of confidence and
% explanation satisfaction rates.


% As the demand for intelligent agent solutions increases, so the supply is sure to follow. The
% necessity of distinguishing between agent behaviors becomes ever more clear. this paper proposes a
% new approach for comparing agents one against the other by generating summaries of the
% disagreements between them. These summaries magnify the differences between agents and help
% people, as shown in our experiment results, correctly identify the superior agent. 


% We now discuss several limitations of the developed \disalg~ algorithm and possible ways to address them, as well as additional directions for future work.

As for future work, we note the following possible directions: \textit{i)} expanding \disalg~ to enable comparison of more than two agents; \textit{ii)} testing additional state and trajectory importance methods; \textit{iii)} further enhancing the diversity between trajectories in the summary, and  \textit{iv)} formulating and defining disagreement ``types'' for generating further user-specific summaries.


%%% currently limited to two agents
% The current implementation of the algorithm can only compare two agents simultaneously, and these
% too have a required ordering of Leader and Disagreer. A natural first step would be obtaining a
% single summary that takes into account both configurations of Leader and Disagreer for each agent.
% Possible future directions to pursue would be making \disalg~ compatible for multiple agents by
% identifying common disagreements between all or generating some meta analysis between all pairs.

%%% mention other methods of importance
% We mention two methods for evaluating the importance of disagreement states (or trajectories), numerous others exist and are worth testing. 
% Some possible alternatives are:
% \textit{i)} evaluating the extent of the disagreement in a state through the second highest
% confidence value, in a fashion similar to the HIGHLIGHTS importance criterion; \textit{ii)} a
% summation over all states in a trajectory, \textit{iii)} observing the minimal and maximal values in
% a trajectory, and more. 

%%% diversity of disagreements
% Another direction we wish to pursue is enhancing the diversity between trajectories in the summary.
% We plan to identify key features of disagreement trajectories allowing us to formulate a distance
% function between states or trajectories. This will reduce the probability of similar trajectories
% appearing the summary. Doing so will remove redundant information, thus giving way to more
% informative trajectories.

%%% value based on agent estimation 
% The assessment of a state's value, i.e. importance, is currently a function of both agents'
% $Q$-values, which may differ significantly. In future work we will define more sophisticated methods
% for determining the ``ground-truth'' value of a state by exploring ways of assessing importance that
% do not rely solely on the judgment of the agent itself, for instance utilizing state features or
% aggregating previously compared agent valuations.


%%% disagreements in user specified areas or scenarios
% Finally, disagreements summaries provide users with the top-most important policy differences between agents. We plan on exploring methods for allowing users to obtain summaries of different disagreement types based on their preferences.

% however, in some situations, the desire may be for observing
% specific kinds of disagreements.
% We plan on allowing users to specify disagreement types they wish
% the summary to focus on, these will include location-based disagreements (e.g. in the river) and
% action-based disagreements (e.g. when the agent chooses the \emph{go-down} action). 
% This will
% provide users with specific information regarding the conflicts between the compared agents'
% strategies and will hopefully increase users' confidence in their choice of agent.  

