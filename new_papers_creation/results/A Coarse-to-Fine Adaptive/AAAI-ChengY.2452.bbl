\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{{Alshawi}, {Long}, and
  {AlRegib}}{2018}]{2018_alshawi_saliency}
{Alshawi}, T.; {Long}, Z.; and {AlRegib}, G.
\newblock 2018.
\newblock Unsupervised uncertainty estimation using spatiotemporal cues in
  video saliency detection.
\newblock {\em IEEE Transactions on Image Processing} 27(6):2818--2827.

\bibitem[\protect\citeauthoryear{Baluja and
  Pomerleau}{1994}]{1994_baluja_firstneural}
Baluja, S., and Pomerleau, D.
\newblock 1994.
\newblock Non-intrusive gaze tracking using artificial neural networks.
\newblock In {\em Annual Conference on Neural Information Processing Systems
  (NeurIPS)},  753--760.

\bibitem[\protect\citeauthoryear{Brandon, Ludwiczuk, and
  Mahadev}{2016}]{2016_amos_openface}
Brandon, A.; Ludwiczuk, B.; and Mahadev, S.
\newblock 2016.
\newblock Openface: A general-purpose face recognition library with mobile
  applications.
\newblock Technical report, CMU-CS-16-118, CMU School of Computer Science.

\bibitem[\protect\citeauthoryear{Chen and Shi}{2018}]{2018_zhao_dilated}
Chen, Z., and Shi, B.~E.
\newblock 2018.
\newblock Appearance-based gaze estimation using dilated-convolutions.
\newblock In {\em Asian Conference on Computer Vision (ACCV)}.

\bibitem[\protect\citeauthoryear{Cheng, Lu, and
  Zhang}{2018}]{2018_cheng_asymmetric}
Cheng, Y.; Lu, F.; and Zhang, X.
\newblock 2018.
\newblock Appearance-based gaze estimation via evaluation-guided asymmetric
  regression.
\newblock In {\em European Conference on Computer Vision (ECCV)}.

\bibitem[\protect\citeauthoryear{Cho \bgroup et al\mbox.\egroup
  }{2014}]{2014_cho_gru}
Cho, K.; Van~Merri{\"e}nboer, B.; Gulcehre, C.; Bahdanau, D.; Bougares, F.;
  Schwenk, H.; and Bengio, Y.
\newblock 2014.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}.

\bibitem[\protect\citeauthoryear{Dzmitry~Bahdanau}{2015}]{2015_bah_attention}
Dzmitry~Bahdanau, Kyunghyun~Cho, Y.~B.
\newblock 2015.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[\protect\citeauthoryear{Fischer, Chang, and
  Demiris}{2018}]{2018_tobias_rt}
Fischer, T.; Chang, H.; and Demiris, Y.
\newblock 2018.
\newblock Rt-gene: Real-time eye gaze estimation in natural environments.
\newblock In {\em European Conference on Computer Vision (ECCV)}.

\bibitem[\protect\citeauthoryear{Funes~Mora and
  Odobez}{2014}]{2014_mora_geometric}
Funes~Mora, K.~A., and Odobez, J.-M.
\newblock 2014.
\newblock Geometric generative gaze estimation (g3e) for remote rgb-d cameras.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)},  1773--1780.

\bibitem[\protect\citeauthoryear{Guestrin and
  Eizenman}{2006}]{2006_guestrin_remote}
Guestrin, E., and Eizenman, M.
\newblock 2006.
\newblock General theory of remote gaze estimation using the pupil center and
  corneal reflections.
\newblock {\em IEEE Transactions on Biomedical Engineering} 53(6):1124--1133.

\bibitem[\protect\citeauthoryear{Hansen and Ji}{2010}]{2010_hansen_survey}
Hansen, D., and Ji, Q.
\newblock 2010.
\newblock In the eye of the beholder: A survey of models for eyes and gaze.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}
  32(3):478--500.

\bibitem[\protect\citeauthoryear{He \bgroup et al\mbox.\egroup
  }{2015}]{2015_he_msra}
He, K.; Zhang, X.; Ren, S.; and Jian, S.
\newblock 2015.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In {\em International Conference on Computer Vision (ICCV)}.

\bibitem[\protect\citeauthoryear{Ioffe and Szegedy}{2015}]{2015_Ioffe_batch}
Ioffe, S., and Szegedy, C.
\newblock 2015.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International Conference on Machine Learning (ICML)},
  448â€“456.

\bibitem[\protect\citeauthoryear{Karen and Andrew}{2014}]{2014_karen_vgg}
Karen, S., and Andrew, Z.
\newblock 2014.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}.

\bibitem[\protect\citeauthoryear{Krafka \bgroup et al\mbox.\egroup
  }{2016}]{2016_krafka_itrack}
Krafka, K.; Khosla, A.; Kellnhofer, P.; Kannan, H.; Bhandarkar, S.; Matusik,
  W.; and Torralba, A.
\newblock 2016.
\newblock Eye tracking for everyone.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)},  2176--2184.

\bibitem[\protect\citeauthoryear{{Lecun} \bgroup et al\mbox.\egroup
  }{1998}]{1998_lecun_lenet}
{Lecun}, Y.; {Bottou}, L.; {Bengio}, Y.; and {Haffner}, P.
\newblock 1998.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE} 86(11):2278--2324.

\bibitem[\protect\citeauthoryear{Liu \bgroup et al\mbox.\egroup
  }{2018}]{2018_liu_differential}
Liu, G.; Yu, Y.; Funes~Mora, K.~A.; and Odobez, J.-M.
\newblock 2018.
\newblock A differential approach for gaze estimation with calibration.
\newblock In {\em British Machine Vision Conference (BMVC)}.

\bibitem[\protect\citeauthoryear{Lu \bgroup et al\mbox.\egroup
  }{2014a}]{2014_lu_headmotion}
Lu, F.; Okabe, T.; Sugano, Y.; and Sato, Y.
\newblock 2014a.
\newblock Learning gaze biases with head motion for head pose-free gaze
  estimation.
\newblock {\em Image and Vision Computing (IVC)} 32(3):169--179.

\bibitem[\protect\citeauthoryear{Lu \bgroup et al\mbox.\egroup
  }{2014b}]{2014_lu_adaptive}
Lu, F.; Sugano, Y.; Okabe, T.; and Sato, Y.
\newblock 2014b.
\newblock Adaptive linear regression for appearance-based gaze estimation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}
  36(10):2033--2046.

\bibitem[\protect\citeauthoryear{Lu \bgroup et al\mbox.\egroup
  }{2015}]{2015_lu_synthesis}
Lu, F.; Okabe, T.; Sugano, Y.; and Sato, Y.
\newblock 2015.
\newblock Gaze estimation from eye appearance: A head pose-free method via eye
  image synthesis.
\newblock {\em IEEE Transactions on Image Processing} 24(11):3680--3693.

\bibitem[\protect\citeauthoryear{Lu \bgroup et al\mbox.\egroup
  }{2017}]{2017_lu_uncalibrated}
Lu, F.; Chen, X.; ; and Sato, Y.
\newblock 2017.
\newblock Appearance-based gaze estimation via uncalibrated gaze pattern
  recovery.
\newblock {\em IEEE Transactions on Image Processing} 26(4):1543--1553.

\bibitem[\protect\citeauthoryear{Mora, Monay, and
  Odobez}{2014}]{2014_mora_eyediap}
Mora, K. A.~F.; Monay, F.; and Odobez, J.~M.
\newblock 2014.
\newblock Eyediap:a database for the development and evaluation of gaze
  estimation algorithms from rgb and rgb-d cameras.
\newblock In {\em Eye Tracking Research and Applications Symposium (ETRA)},
  255--258.

\bibitem[\protect\citeauthoryear{Nakazawa and
  Nitschke}{2012}]{2012_nakazawa_point}
Nakazawa, A., and Nitschke, C.
\newblock 2012.
\newblock Point of gaze estimation through corneal surface reflection in an
  active illumination environment.
\newblock In {\em European Conference on Computer Vision (ECCV)},  159--172.

\bibitem[\protect\citeauthoryear{Park \bgroup et al\mbox.\egroup
  }{2019}]{2019_park_fewshot}
Park, S.; Mello, S.~D.; Molchanov, P.; Iqbal, U.; Hilliges, O.; and Kautz, J.
\newblock 2019.
\newblock Few-shot adaptive gaze estimation.
\newblock In {\em International Conference on Computer Vision (ICCV)}.

\bibitem[\protect\citeauthoryear{Patney \bgroup et al\mbox.\egroup
  }{2016}]{2016_anjul_vr}
Patney, A.; Kim, J.; Salvi, M.; Kaplanyan, A.; and Luebke, D.
\newblock 2016.
\newblock Perceptually-based foveated virtual reality.
\newblock In {\em Acm SIGGRAPH Emerging Technologies}.

\bibitem[\protect\citeauthoryear{Ranjan, De~Mello, and
  Kautz}{2018}]{2018_ranjan_light}
Ranjan, R.; De~Mello, S.; and Kautz, J.
\newblock 2018.
\newblock Light-weight head pose invariant gaze tracking.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW)}.

\bibitem[\protect\citeauthoryear{Tan, Kriegman, and
  Ahuja}{2002}]{2002_karhan_appearancebased}
Tan, K.; Kriegman, D.; and Ahuja, N.
\newblock 2002.
\newblock Appearance-based eye gaze estimation.
\newblock In {\em IEEE Workshop on Applications of Computer Vision (WACV)},
  191--195.

\bibitem[\protect\citeauthoryear{Valenti, Sebe, and
  Gevers}{2012}]{2012_valenti_combineheadpose}
Valenti, R.; Sebe, N.; and Gevers, T.
\newblock 2012.
\newblock Combining head pose and eye location information for gaze estimation.
\newblock {\em IEEE Transactions on Image Processing} 21(2):802--815.

\bibitem[\protect\citeauthoryear{Vaswani \bgroup et al\mbox.\egroup
  }{2017}]{2017_ash_attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.;
  Kaiser, L.~u.; and Polosukhin, I.
\newblock 2017.
\newblock Attention is all you need.
\newblock In {\em Annual Conference on Neural Information Processing Systems
  (NeurIPS)}.
\newblock  5998--6008.

\bibitem[\protect\citeauthoryear{Williams, Blake, and
  Cipolla}{2006}]{2006_williams_sparse}
Williams, O.; Blake, A.; and Cipolla, R.
\newblock 2006.
\newblock Sparse and semi-supervised visual mapping with the
  {S\textsuperscript{3}GP}.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)},  230--237.

\bibitem[\protect\citeauthoryear{Xiong and Kim}{2019}]{2019_xiong_mixed}
Xiong, Y., and Kim, H.~J.
\newblock 2019.
\newblock Mixed effects neural networks (menets) with applications to gaze
  estimation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}.

\bibitem[\protect\citeauthoryear{Xiong \bgroup et al\mbox.\egroup
  }{2014}]{2014_xiong_rgbdcamera}
Xiong, X.; Liu, Z.; Cai, Q.; and Zhang, Z.
\newblock 2014.
\newblock Eye gaze tracking using an rgbd camera: a comparison with a rgb
  solution.
\newblock {\em Proceedings of the 2014 ACM International Joint Conference on
  Pervasive and Ubiquitous Computing: Adjunct Publication}  1113--1121.

\bibitem[\protect\citeauthoryear{Xu, Machin, and
  Sheppard}{1998}]{1998_xu_novel}
Xu, L.~Q.; Machin, D.; and Sheppard, P.
\newblock 1998.
\newblock A novel approach to real-time non-intrusive gaze finding.
\newblock In {\em British Machine Vision Conference (BMVC)},  428--437.

\bibitem[\protect\citeauthoryear{Yu, Liu, and Odobez}{2018}]{2018_yu_deep}
Yu, Y.; Liu, G.; and Odobez, J.-M.
\newblock 2018.
\newblock Deep multitask gaze estimation with a constrained landmark-gaze
  model.
\newblock In {\em European Conference on Computer Vision Workshops (ECCVW)}.

\bibitem[\protect\citeauthoryear{Zhang \bgroup et al\mbox.\egroup
  }{2015}]{2015_zhang_appearancewild}
Zhang, X.; Sugano, Y.; Fritz, M.; and Bulling, A.
\newblock 2015.
\newblock Appearance-based gaze estimation in the wild.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)},  4511--4520.

\bibitem[\protect\citeauthoryear{Zhang \bgroup et al\mbox.\egroup
  }{2017a}]{2017_zhang_fullface}
Zhang, X.; Sugano, Y.; Fritz, M.; and Bulling, A.
\newblock 2017a.
\newblock Itâ€™s written all over your face: Full-face appearance-based gaze
  estimation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW))}.

\bibitem[\protect\citeauthoryear{Zhang \bgroup et al\mbox.\egroup
  }{2017b}]{2017_zhang_gazenet}
Zhang, X.; Sugano, Y.; Fritz, M.; and Bulling, A.
\newblock 2017b.
\newblock Mpiigaze: Real-world dataset and deep appearance-based gaze
  estimation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}
  PP.

\bibitem[\protect\citeauthoryear{Zhang, Sugano, and
  Bulling}{2017}]{2017_zhang_contact}
Zhang, X.; Sugano, Y.; and Bulling, A.
\newblock 2017.
\newblock Everyday eye contact detection using unsupervised gaze target
  discovery.
\newblock In {\em ACM Symposium on User Interface Software and Technology
  (UIST)}.

\bibitem[\protect\citeauthoryear{Zhu and Deng}{2017}]{2017_zhu_monocular}
Zhu, W., and Deng, H.
\newblock 2017.
\newblock Monocular free-head 3d gaze tracking with deep learning and geometry
  constraints.
\newblock In {\em International Conference on Computer Vision (ICCV)}.

\end{thebibliography}
