\section{Conclusion}
We propose the game of chess as a testbed for evaluating how well language models capture the underlying world state. 
We show that with an appropriate choice of chess notation, a language model can be probed for different aspects of the board state via simple prompts.
The simple and precise dynamics of chess allow for (a) training models with varying amount of explicit state, and (b) evaluating 
model predictions at a fine-grained level.
Results show that transformer language models are able to track the board state when given enough
data, but with limited data, %
providing access to board state information during training can yield consistent improvement. 

 \paragraph{Wider Implications for Natural Language Processing.}
Our results shed light on the following properties of transformers: (a) they are robust to RAP-like changes in input distribution, and (b) for high performance the models require access to the entire context, as well as large training sets (Section~\ref{sec:limited_history}). 
Future work can use the first finding to introduce the world state, or more specifically the output of linguistic analyzers such as coreference,  via RAP-like tokens during pre-training and fine-tuning of transformers. 
RAP-like tokens can also be used for debugging/diagnosing a model's understanding, similarly to the starting square prediction tasks. 
The second finding implies that the proposed benchmark can guide the search for new transformer architectures that are adept at understanding long text, and that can learn from small training sets.  
The proposed framework allows for probing and understanding new architectures that address these challenges.   

