\relax 
\bibstyle{aaai22}
\citation{vaswani2017attention,devlin-etal-2019-bert,brown2020language}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:algebraic_notation}{{1a}{2}{Square naming}{}{}}
\newlabel{sub@fig:algebraic_notation}{{a}{2}{Square naming}{}{}}
\newlabel{fig:move_notation}{{1b}{2}{Board state before (left) and after (right) the bishop at \texttt  {f1} is moved to \texttt  {b5}. UCI notation represents the move as \texttt  {f1b5}.}{}{}}
\newlabel{sub@fig:move_notation}{{b}{2}{Board state before (left) and after (right) the bishop at \texttt  {f1} is moved to \texttt  {b5}. UCI notation represents the move as \texttt  {f1b5}.}{}{}}
\newlabel{sec:chess}{{2}{2}{}{}{}}
\newlabel{tab:model_vocab}{{1}{2}{Model Vocabulary}{}{}}
\newlabel{sec:probing}{{3}{2}{}{}{}}
\citation{ir-book}
\newlabel{tab:token_seq}{{2}{3}{Token sequences corresponding to the move sequence \texttt  {e2e4 e7e5 g1f3} for different notations during training and inference. Notice that regardless of the RAP probability used during training, at inference time the token sequences have no piece types.}{}{}}
\newlabel{sec:rap_board}{{3.1}{3}{}{}{}}
\newlabel{sec:cloze}{{3.2}{3}{}{}{}}
\citation{python-chess}
\citation{vaswani2017attention,radford2019language}
\citation{kitaev2020reformer}
\citation{choromanski2021rethinking}
\citation{kingma2014adam}
\citation{micikevicius2018mixed}
\citation{falcon2019pytorch,pytorch}
\citation{Wolf2019HuggingFacesTS}
\newlabel{tab:tasks}{{3}{4}{Examples of each probing task, as well as the corresponding exact move (ExM\xspace  ) and legal move (LgM\xspace  ) correct answers, are shown below. All examples assume the language model was fed the prefix \texttt  {e2e4 e7e5 g1f3 b8c6 d2d4 h7h6} (see Figure\nobreakspace  {}\ref {fig:move_notation}), and that the actual next move was \texttt  {f1b5}. While there is only one valid prompt token for both End-Actual and Start-Actual tasks, there are many valid prompt tokens for the other tasks, and we show just one possibility for each. Start-tasks (bottom sub-table) assume the model was trained on games described in UCI+RAP notation.}{}{}}
\newlabel{sec:setup}{{4}{4}{}{}{}}
\newlabel{tab:perplexity}{{4}{5}{Canonical validation and test set perplexity. By canonical we mean that one move, say \texttt  {f1b5}, counts as one token.}{}{}}
\newlabel{fig:rap_vals}{{2}{5}{Validation set perplexities as a function of RAP probabilities for the different training set sizes. RAP $0$ is the standard UCI notation. RAP $100$ is not shown as perplexities are too high. }{}{}}
\newlabel{sec:perplexity_res}{{5.1}{5}{}{}{}}
\newlabel{sec:state_tracking_res}{{5.2}{5}{}{}{}}
\citation{hochreiter1997long}
\citation{kitaev2020reformer,katharopoulos20,choromanski2021rethinking}
\newlabel{tab:results-starting}{{5}{6}{Accuracies and R-Precisions (\%) for predicting starting squares (``Start-Actual'' and ``Start-Other'' tasks). S, M, L in the first column refer to the training set sizes. }{}{}}
\newlabel{tab:results-ending}{{6}{6}{Accuracies and R-Precisions (\%) for predicting ending squares (``End-Actual'' and ``End-Other'' tasks). S, M, L in the first column refer to the training set sizes. }{}{}}
\newlabel{tab:results-ending-window}{{7}{6}{Accuracy and R-Precision (\%) for predicting ending squares (``End-Actual'' and ``End-Other'' tasks) with varying attention window sizes. LSTM + RAP refers to LSTM trained with UCI + RAP. }{}{}}
\newlabel{sec:other_models}{{5.3}{6}{}{}{}}
\citation{kitaev2020reformer}
\citation{choromanski2021rethinking}
\citation{weston2015aicomplete}
\citation{cote18textworld}
\citation{hermann17grounded}
\citation{hill17understanding}
\citation{hermann2015cnn,hill2016cbt}
\citation{paperno-etal-2016-lambada}
\citation{mostafazadeh-etal-2016-corpus,ettinger2020bert}
\citation{mostafazadeh-etal-2017-lsdsem}
\citation{petroni-etal-2019-language}
\citation{hill2016cbt}
\citation{ettinger-etal-2016-probing,Alain2017UnderstandingIL,adi17probing,tenney2019probing,hewitt-liang-2019-designing}
\citation{pimentel-etal-2020-information}
\citation{david16deepchess,Oshri2015PredictingMI}
\citation{silver18general}
\citation{presser2020chess,cheng2020chess,noever2020chess}
\bibdata{0-main}
\newlabel{sec:limited_history}{{5.3}{7}{}{}{}}
\gdef \@abspage@last{8}
