\begin{table}[]
    \small
    \begin{tabularx}{0.6\textwidth} { 
      | >{\raggedright\arraybackslash}p{1.5cm}
      | >{\raggedright\arraybackslash}p{1.25cm}
      | >{\raggedright\arraybackslash}p{1.5cm}
      | >{\raggedright\arraybackslash}X 
      | >{\raggedright\arraybackslash}X | }
     \hline
     \textbf{Layer} & \textbf{Number of Units} & \textbf{Activation Type} & \textbf{Output Shape} & \textbf{Layer-specific parameters} \\ [0.5ex] 
     \hline
     Embedding & 256 & - & (Batch\_size, 256, 100) & Vocabulary\_ size = 256 \\
     \hline
     GRU & 100 & Tanh & (Batch\_size, 100, 100) & Bias\_initializer= 0 \\
     \hline
     Fully Connected Layer & 128 & Softmax & (Batch\_size, 100, 256) & Bias\_initializer= 0 \\
     \hline
     \multicolumn{5}{|l|}{Learning Rate = 0.01, Batch\_size = 10, Systematic Sampling Rate: $10^{-4}$}\\
     \hline
    \end{tabularx}
\end{table}