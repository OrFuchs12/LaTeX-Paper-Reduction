\begin{table}[H]
    \caption{MalRNN Specifications}
    \small
    \begin{tabularx}{1\textwidth} { 
      | >{\centering\arraybackslash}p{0.05\textwidth} 
      | >{\centering\arraybackslash}p{0.071\textwidth} 
      | >{\centering\arraybackslash}p{0.033\textwidth}
      | >{\centering\arraybackslash}p{0.066\textwidth} 
      | >{\centering\arraybackslash}p{0.13\textwidth}
      | >{\centering\arraybackslash}p{0.07\textwidth} |}
     \cline{1-6}
     \multicolumn{2}{|c|}{\textbf{Layer}} & \textbf{\# of Units} & \textbf{Activation Type} & \textbf{Output Shape} & \textbf{Layer-specific} \\ 
     \cline{1-6}
     \multirow{2}{*}{Encoder} & Embedding & 256 & - & (B-size, 256, 100) & Vocabulary size=256 \\
     \cline{2-6}
      & GRU & 100 & Tanh & (B-size, 100, 100) & Initial bias=0 \\
     \cline{1-6}
     \multirow{2}{*}{Decoder} & GRU & 100 & Tanh & (B-size, 100, 100) & Initial bias=0 \\
     \cline{2-6}
      & Fully Connected Layer & 128 & Softmax & (B-size, 100, 256) & Initial bias=0 \\
     \cline{1-6}
     \multicolumn{6}{|l|}{Learning Rate=0.01, B-size (Batch size)=10, Systematic sampling rate=$10^{-3}$,}\\
     \multicolumn{6}{|l|}{Maximum number of attempts: 50, Maximum append size: 40\%.}\\
     \cline{1-6}
    \end{tabularx}
\label{model_parameters}
\end{table}