% \vspace{-1em}
\section{Conclusions}
% \vspace{-1em}
In this paper, we introduced a benchmark task for commonsense reasoning that aims at uncovering unspoken intents that humans can easily uncover in a given statement by making presumptions supported by their common sense. In order to solve this task, we propose
CORGI (COmmon-sense ReasoninG by Instruction),  a neuro-symbolic theorem prover that performs commonsense reasoning by initiating a conversation with a user. CORGI has access to a small knowledge base of commonsense facts and completes it as she interacts with the user. We further conduct a user study that indicates the possibility of using conversational interactions with humans for evoking commonsense knowledge and verifies the effectiveness of our proposed theorem prover.
% We defined common-sense reasoning as the process of finding a chain of reasoning in a logic program given an if/then/because statement. We showed that obtaining the because statement is crucial in extracting a relevant chain of reasoning given an if/then statement. Moreover, we introduced a soft backward chaining algorithm that allows us to combat variations in natural language by learning embeddings for the facts and rules in the knowledge base. This algorithm combines symbolic AI with neural approaches allowing us to bridge a gap between symbolic AI and the recent advances in deep learning.