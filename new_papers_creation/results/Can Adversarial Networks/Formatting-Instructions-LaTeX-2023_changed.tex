%File: formatting-instructions-latex-2023.tex
%release 2023.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{amsfonts}



%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
%  -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
%  -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Can Adversarial Networks Make Uninformative Colonoscopy Video Frames Clinically Informative? (Student Abstract)}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Vanshali Sharma,
    M.K. Bhuyan,
    Pradip K. Das
}
\affiliations{
    %Afiliations
    Indian Institute of Technology Guwahati, Assam, India-781039\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar, \textsuperscript{\rm 2}
    % J. Scott Penberthy, \textsuperscript{\rm 3}
    % George Ferguson,\textsuperscript{\rm 4}
    % Hans Guesgen, \textsuperscript{\rm 5}.
    % Note that the comma should be placed BEFORE the superscript for optimum readability

    %1900 Embarcadero Road, Suite 101\\
    %Palo Alto, California 94303-3310 USA\\
    % email address must be in roman text type, not monospace or sans serif
     \{vanshalisharma, mkb, pkdas\}@iitg.ac.in
%
% See more examples next
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name,\textsuperscript{\rm 1,\rm 2}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
%\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
Various artifacts, such as ghost colors, interlacing, and motion blur, hinder diagnosing colorectal cancer (CRC) from videos acquired during colonoscopy. The frames containing these artifacts are called uninformative frames and are present in large proportions in colonoscopy videos. To alleviate the impact of artifacts,  we propose an adversarial network based framework to convert uninformative frames to clinically relevant frames. We examine the effectiveness of the proposed approach by evaluating the translated frames for polyp detection using YOLOv5. Preliminary results present improved detection performance along with elegant qualitative outcomes. We also examine the failure cases to determine the directions for future work.
\end{abstract}

\section{Introduction}

Colonoscopy is a minimally invasive procedure widely adopted for polyp detection to diagnose colorectal cancer (CRC). In a colonoscopy, diagnostic accuracy relies on the correct analysis of the acquired recordings. However, the traditional assessment approaches by physicians suffer from inter-observer variations and demand extensive manual efforts. In recent years, accessibility to several colonoscopy datasets has paved the way for many machine learning based research works for automated CRC detection. However, the well-trained models proposed in the existing works still report limited diagnostic success. This limited success of automated methods is attributed to low-quality frames in the video samples, which contain artifacts, namely, ghost colors, low-illumination, interlacing due to camera motion, and fecal depositions due to inadequate patient preparation.

\par To overcome the low-quality frames, some related fields of laparoscopy and endoscopy followed keyframe selection \cite{ma2020keyframe} or performed super-resolution \cite{almalioglu2020endol2h}, but no work in the colonoscopy domain explored the idea of extracting obscured clinical details from such low-quality uninformative video frames. Therefore, our work investigates whether GANs can convert uninformative frames to informative frames. In this direction, we propose a GAN-based image-to-image translation approach to generate informative frames from the degraded frames of the colonoscopy videos. We highlight the cases where GANs fail and where it helps, which gives us directions for future work.
The main contributions are summarized below:

\begin{enumerate}
    \item To the best of our knowledge, this is the first framework to address the issue of uninformative colonoscopy frames using adversarial networks.
    \item We investigate the impact of translating uninformative frames on polyp detection performance and discuss future directions in this context.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[height=130pt, width=\columnwidth]{gan_dia.png}
    \caption{The proposed framework contains two generators $G_{AB}$ and $G_{BA}$ and two discriminators $D_A$ and $D_B$.}
    \label{fig:gan}
\end{figure}




\section{Methodology}
The overview of the proposed framework is shown in Fig. \ref{fig:gan}. Given the uninformative colonoscopy frames $\{a_i\}_{i=1}^N$ from domain A, the aim is to learn a mapping function $G_{AB}: A \rightarrow B$ to generate frames such that the data distribution of obtained frames is indistinguishable from that of informative colonoscopy frames $\{b_j\}_{j=1}^M$ of domain B. Due to the unavailability of paired data, our work is inspired by the unpaired translation approach of CycleGAN \cite{zhu2017unpaired}. Hence, another mapping function $G_{BA}: B \rightarrow A$ is also introduced. Our implementation involves ResNet-based generators and PatchGAN discriminators $D_A$ and $D_B$. The CycleGAN objective integrates adversarial loss and cycle-consistency loss. The adversarial loss can be expressed as:

\begin{equation}
\label{adv}
  \begin{split}
    L_{adv}(G_{AB}, D_B) &= \mathbb{E}_{b\sim p_{data}(b)}[(D_B (b)-1)^2] \\ & + \mathbb{E}_{a\sim p_{data}(a)}[(D_B(G_{AB}(a)))^2]
     \end{split}
\end{equation}
$G_{AB}$ aims to translate uninformative frames such that they appear similar to the informative frames, while $D_B$ tries to distinguish the translated frames from the high-quality, informative frames of domain B. In other words, $D_B$ is trained to minimize $L_{adv}(G_{AB}, D_B)$ and $G_{AB}$ is trained to minimize $\mathbb{E}_{a\sim p_{data}(a)}[(D_B(G_{AB}(a))-1)^2]$.

To ensure cycle-consistency and to reduce randomness in mapping, a cycle-consistency loss is used, which is given by:
\begin{equation}
   \begin{split}
    L_{cyc}(G_{AB}, G_{BA}) & = \mathbb{E}_{a\sim p_{data}(a)}[\lVert G_{BA}(G_{AB}(a))-a\rVert_1] \\ & + \mathbb{E}_{b\sim p_{data}(b)}[\lVert G_{AB}(G_{BA}(b))-b\rVert_1]
  \end{split}
\end{equation}
An identity mapping loss is also added to help preserve color in translated images.
With this model, we intend to determine the clinically relevant details obscured by the artifacts. Furthermore, we carried out the following investigations:
\begin{enumerate}
    \item Polyp detection is performed using YOLOv5 \cite{yolov5} to determine the impact of GAN-translated frames.
    \item Qualitative analysis is done to identify the artifacts successfully handled by the CycleGAN and analyze the ones that still persist in the translated frames.
\end{enumerate}




\section{Experiments}
To assess the effectiveness of the adversarial approach in mitigating the impact of artifacts, we conducted experiments using a publicly available SUN database \cite{misawa2021development} consisting of $1,09,554$ non-polyp and $49,136$ polyp frames. In addition to the localization information, the polyp frames are manually annotated by experts as informative or uninformative. We used only the polyp frames with a patient-wise split.
The translation is done on a Titan Xp GPU at 14 frames per second.
%ratio of approximately 80, 10, 10 for training, validation, and test set, respectively.
We report the results based on visual perception and consider feature space representation by evaluating the polyp detection outcomes using YOLOv5. We conducted training and testing in two scenarios using: a) Raw frames comprising both high and low-quality frames and b) Translated frames along with high-quality frames. The results in Table \ref{tab:localization} show that the translated frames complement the detection ability of YOLOv5 in terms of precision, recall, F1-score, and mAP@0.5. The detector correctly identified more polyps with lower deviations, presenting a more robust model. However, this is achieved with slightly less precise bounding boxes, as indicated by a minor decrease in mAP@0.5:0.95. Fecal depositions, ghost colors, and low-illumination are significantly reduced using CycleGAN, as shown in Fig. \ref{fig:sample_res}. However, motion blur and interlacing are not handled adequately in the process. This could be overcome by adopting blur removal approaches.


\begin{figure}
 \centering
 \large
  \resizebox{\columnwidth}{!}{
    \begin{tabular}{cccc}
          \includegraphics[width=0.28\textwidth,height=130pt]{a1_15_old.jpg} \hfill
          \includegraphics[width=0.28\textwidth,height=130pt]{a3_40_old.jpg} \hfill
          \includegraphics[width=0.28\textwidth,height=130pt]{a7_38_old.jpg} \hfill
          \includegraphics[width=0.28\textwidth,height=130pt]{a42_38_old.jpg}
           \\
            (a)
          \\

          \includegraphics[width=0.28\textwidth,height=160pt]{dia1.png}  \hfill
          \includegraphics[width=0.28\textwidth,height=160pt]{dia2.png}  \hfill
          \includegraphics[width=0.28\textwidth,height=160pt]{dia3.png} \hfill
          \includegraphics[width=0.28\textwidth,height=160pt]{dia4.png} \\
           (b)



    \end{tabular}
    }
     \caption{ Detection performance using: (a) Raw frames and (b) Translated frames. Green bounding boxes denote the ground truth. Ticks and cross marks represent the successful and unsuccessful artifacts translations, respectively.
     }
      \label{fig:sample_res}

\end{figure}

\begin{table}

    \centering
    \large
    \resizebox{0.85\columnwidth}{!}{
    \begin{tabular}{ccc}

      \toprule % <-- Toprule here
          & \multicolumn{2}{c}{\textbf{SUN Database}}  \\
      \cline{2-3}
      \rule{0pt}{3ex}
        \textbf{Metrics} & \textbf{Raw Frames} & \textbf{Translated Frames} \\
      \midrule

      \textbf{Precision (\%)} &
      92.03$\pm$0.60 & \textbf{93$\pm$0.87} \\

      \textbf{Recall (\%)} &
      88.9$\pm$3.12 &
      \textbf{90.2$\pm$1.3} \\


      \textbf{F1-score (\%)} &
      90.4$\pm$1.51 &
      \textbf{91.57$\pm$0.38} \\

      \textbf{mAP@0.5 (\%)} &
      95.37$\pm$0.95 &
      \textbf{95.6$\pm$0.21} \\

      \textbf{mAP@0.5:0.95 (\%)} &
      \textbf{57.53$\pm$0.32} &
      57.07$\pm$0.31 \\

      \bottomrule % <-- Bottomrule here
    \end{tabular}
    }


     \caption{Comparative analysis of polyp detection results}
     \label{tab:localization}
\end{table}







\section{Conclusion and Future Work}
In this work, we propose a GAN-based framework to translate uninformative colonoscopy frames into clinically significant frames. We showed that the translated frames improve polyp detection F1-score and mAP@0.5, with negligible reduction in mAP@0.5:0.95. We analyzed the types of artifacts where the CycleGAN performed well and identified the scope of improvements. Since the artifacts in colonoscopy video frames alter the various aspects of images, such as structure, texture, and color, this work lays the foundation for a more interesting future work of developing a standalone model to address all the artifacts in one go.

\section{Acknowledgments}

Vanshali Sharma would like to thank the Department of Science and Technology, Government of India, for providing the INSPIRE fellowship (IF190362).


\fontsize{9.0pt}{10.0pt} \selectfont

%\bibentry{c:23}

Sint sit atque saepe inventore architecto dolore tempora quam dolorem ea, odit voluptatem explicabo assumenda culpa alias nobis.Accusamus alias tempore corporis sequi sint illum ab assumenda beatae laboriosam, tempora maxime dolorum.Labore ullam sint ex vero perferendis provident sequi, odio sunt neque, consequuntur assumenda harum laborum maxime corrupti minima enim cum a laboriosam, eaque facilis explicabo obcaecati assumenda cumque aliquam corrupti repudiandae inventore sequi harum.Maxime blanditiis harum exercitationem quia modi corrupti beatae sequi, cumque similique illum sint quia autem aliquid ut id fuga unde debitis, iure qui consequuntur a cumque aspernatur officiis deserunt voluptatum ipsam, neque velit minus corrupti alias distinctio similique?Animi voluptate doloremque alias provident ducimus nostrum sequi dignissimos dolorum, placeat tempore dignissimos inventore laudantium eaque tempora tenetur animi?Sint cumque neque, possimus dolorum totam tenetur fugiat commodi, consectetur culpa fugiat, consectetur ab quos mollitia aliquam labore deserunt adipisci accusantium amet accusamus illo, exercitationem recusandae minima dolor tenetur velit tempore accusantium assumenda.Culpa amet suscipit facere perspiciatis exercitationem accusamus velit eius eum, consectetur maiores ea dolore, delectus repellendus ullam itaque voluptatem quis ut iusto iure consectetur.Illo ipsa ea culpa ex hic sequi voluptate dolor sit beatae velit, minus sapiente incidunt voluptatem, sint nisi magni labore voluptate ab tempore ad accusamus?Tempora excepturi quod deserunt reiciendis vero laborum, voluptates dolores
\bibliography{aaai23}

\end{document}