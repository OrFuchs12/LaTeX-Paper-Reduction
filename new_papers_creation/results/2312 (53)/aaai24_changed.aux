\relax 
\providecommand{\transparent@use}[1]{}
\bibstyle{aaai24}
\citation{perkins1992transfer,weiss2016survey,zhuang2020comprehensive}
\citation{sun2015survey}
\citation{feng2021kd3a}
\citation{fang2022source}
\citation{han2023discriminability}
\citation{yang2023pick}
\citation{lee2019learning}
\citation{ahmed2021unsupervised}
\citation{dong2021confident,han2023discriminability}
\citation{li2022source}
\citation{wang2020generalizing}
\providecommand \oddpage@label [2]{}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:setup}{{1}{1}{\textbf  {Problem Setting of Multi-Source-Free Transfer Learning.} The transfer to the target task is based on the source models (whose access in our redefined MSF setting is also restricted) trained on the inaccessible source data. }{}{}}
\citation{huang2019information}
\citation{wang2020generalizing}
\citation{hoffman2018cycada}
\citation{peng2019moment}
\citation{ahmed2021unsupervised}
\citation{xu2020maximal}
\citation{bao2019information}
\citation{huang2019universal}
\citation{bao2019information,ibrahim2022newer}
\citation{hirschfeld1935connection,gebelein1941statistische,renyi1959measures}
\citation{huang2019universal}
\citation{huang2019universal}
\citation{christodoulidis2016multisource}
\citation{crammer2008learning,mansour2008domain,ben2010theory,tong2021mathematical,chen2023algorithm}
\citation{sun2011two,lee2019learning,shui2021aggregating}
\citation{agostinelli2022transferability}
\citation{huang2012boosting,xu2012multi,fang2019adapted}
\citation{sun2015survey}
\newlabel{sec:H-score}{{}{2}{}{}{}}
\newlabel{sec:multisource}{{}{2}{}{}{}}
\citation{feller1991introduction}
\citation{xu2020maximal}
\citation{xu2020maximal}
\newlabel{tab:setting}{{1}{3}{\textbf  {Comparison across Relative Problem Settings,} involving the aspects of whether there are multi-sources, no source data, no source model details, and different target learning approaches. The abbreviation `DA' represents domain adaptation, `{\fontencoding  {U}\fontfamily  {ding}\selectfont  \symbol  {'041}}' represents obtaining the corresponding aspects, while `{\fontencoding  {U}\fontfamily  {ding}\selectfont  \symbol  {'045}}' the opposite. Among all settings, ours is relatively restrictive.}{}{}}
\newlabel{tab:notation}{{2}{3}{\textbf  {Notation.} We omit $\{\cdot \}_{j=1}^M$ for simplification.}{}{}}
\newlabel{py}{{1}{3}{}{}{}}
\newlabel{pxy}{{2}{3}{}{}{}}
\newlabel{definition}{{3}{3}{}{}{}}
\newlabel{targetfeature}{{4}{3}{}{}{}}
\citation{huang2019universal}
\citation{huang2019information}
\newlabel{fig:framework}{{2}{4}{\textbf  {Framework of H-Ensemble.} The framework consists of three modules. The target data firstly flow into Target Feature Extractor. Then the Weight Optimizer will utilize the outputs of source feature extractors and target label to derive the optimal source weight $\boldsymbol  {\alpha }$, which makes the parameter in deriving target feature. Finally the Target Classifier will be trained and used together with the extractor for test according to a generalization of maximal correlation regression (MCR).}{}{}}
\newlabel{gnet}{{7}{4}{}{}{}}
\newlabel{getg}{{1}{4}{}{}{}}
\newlabel{hscore}{{8}{4}{}{}{}}
\newlabel{def:hscore}{{1}{4}{}{}{}}
\citation{huang2019information,bao2019information,xu2020maximal}
\newlabel{htrain}{{1}{5}{}{}{}}
\newlabel{singlehscore}{{9}{5}{}{}{}}
\newlabel{def:singlehscore}{{2}{5}{}{}{}}
\newlabel{hscoremeaning}{{11}{5}{}{}{}}
\newlabel{theo:hscore}{{2}{5}{}{}{}}
\newlabel{nhscore}{{12}{5}{}{}{}}
\newlabel{tscore}{{13}{5}{}{}{}}
\newlabel{def:tscore}{{3}{5}{}{}{}}
\citation{peng2017visda}
\citation{saenko2010adapting}
\citation{gong2012geodesic}
\citation{venkateswara2017deep}
\citation{peng2019moment}
\citation{lee2019learning}
\citation{ahmed2021unsupervised}
\citation{han2023discriminability}
\newlabel{theo:convex}{{3}{6}{}{}{}}
\newlabel{exp}{{}{6}{}{}{}}
\newlabel{fig:weight}{{3}{6}{\textbf  {Source Weights derived in Different Methods.} (VisDA-2017, target v3, 10-shot) The source weight in H-ensemble (red) conforms most to intuition, emphasizing on tasks from the same domain (v0, v1, v2).}{}{}}
\newlabel{tab:comparison}{{3}{7}{\textbf  {Accuracy Comparison on VisDA-2017 (10-shot).} `R' stands for the rest tasks. The highest/second-highest accuracy is marked in \textbf  {Bold}/\underline  {Underscore} form respectively. Our method achieves the overall best performance. }{}{}}
\newlabel{tab:ablation}{{4}{7}{\textbf  {Ablation Study on Office Datasets (8-shot).} Our weighting strategy and optimal MCR classifier both contribute to the overall effectiveness. }{}{}}
\newlabel{fig:tsne}{{4}{7}{\textbf  {Feature extracted by different models,} visualized by t-SNE. From left to right: random source, Average W. and H-ensemble. It turns out that features generated by our method have the greatest discriminability. }{}{}}
\bibdata{aaai24}
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{8}
