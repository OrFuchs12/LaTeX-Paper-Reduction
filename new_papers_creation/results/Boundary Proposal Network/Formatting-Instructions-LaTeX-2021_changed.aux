\relax 
\bibstyle{aaai21}
\citation{DBLP:conf/iccv/GaoSYN17,DBLP:conf/iccv/HendricksWSSDR17}
\citation{DBLP:conf/eccv/ShaoXZHQL18}
\citation{DBLP:conf/emnlp/LeiYBB18,xiao2020hierarchical,ye2017video}
\citation{DBLP:conf/iccv/GaoSYN17,DBLP:conf/emnlp/HendricksWSSDR18,DBLP:conf/mm/LiuWN0CC18,DBLP:conf/aaai/ChenJ19a,DBLP:conf/wacv/GeGCN19,DBLP:conf/aaai/Xu0PSSS19,DBLP:conf/cvpr/ZhangDWWD19,ChenCMJC18,DBLP:conf/aaai/Wang0J20}
\citation{DBLP:conf/nips/RenHGS15}
\@LN@col{1}
\@LN@col{2}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure1}{{1}{1}{(a) An illustrative example of the NLVL task. Given a video and a query, NLVL is to localize the video segment corresponding to the query with the start point (11.91s) and the end point (40.74s). (b) Anchor-based approach: A number of temporal bounding boxes are placed on the video as candidates and the best-matching one (\emph  {e.g.}, the green one) is chosen as the result. (c) Anchor-free approach: Each frame is determined whether it is the boundary frame. }{}{}}
\newlabel{figure1@cref}{{[figure][1][]1}{[1][1][]1}}
\citation{DBLP:conf/aaai/ChenLTXZTL20,DBLP:conf/aaai/ChenJ19a,DBLP:conf/aaai/YuanM019,LuCTLX19,DBLP:conf/acl/ZhangSJZ20,DBLP:conf/wacv/OpazoMSLG20,DBLP:conf/cvpr/MunCH20}
\citation{DBLP:conf/iccv/HendricksWSSDR17,DBLP:conf/iccv/GaoSYN17}
\citation{DBLP:conf/iccv/GaoSYN17,DBLP:conf/iccv/HendricksWSSDR17,DBLP:conf/emnlp/HendricksWSSDR18,DBLP:conf/mm/LiuWN0CC18,DBLP:conf/sigir/LiuWN0CC18,DBLP:conf/aaai/Xu0PSSS19,DBLP:conf/cvpr/ZhangDWWD19}
\citation{DBLP:conf/iccv/GaoSYN17}
\citation{DBLP:conf/iccv/HendricksWSSDR17}
\citation{DBLP:conf/aaai/Xu0PSSS19}
\citation{DBLP:conf/cvpr/ZhangDWWD19}
\citation{DBLP:conf/mm/LiuWN0CC18}
\citation{DBLP:conf/sigir/LiuWN0CC18}
\citation{DBLP:conf/aaai/YuanM019,LuCTLX19,DBLP:conf/aaai/ChenLTXZTL20,ChenCMJC18,DBLP:conf/acl/ZhangSJZ20}
\citation{DBLP:conf/aaai/YuanM019}
\citation{DBLP:conf/acl/ZhangSJZ20}
\citation{LuCTLX19}
\citation{DBLP:conf/aaai/ChenLTXZTL20}
\citation{DBLP:conf/aaai/HeZHLLW19,DBLP:conf/cvpr/WangHW19}
\citation{DBLP:conf/nips/RenHGS15,DBLP:conf/nips/DaiLHS16}
\citation{DBLP:conf/eccv/LawD18,DBLP:conf/iccv/DuanBXQH019}
\citation{DBLP:conf/eccv/Duan}
\@LN@col{1}
\@LN@col{2}
\citation{DBLP:conf/iccv/TranBFTP15}
\citation{DBLP:conf/emnlp/PenningtonSM14}
\citation{DBLP:conf/acl/ZhangSJZ20}
\citation{DBLP:conf/iclr/YuDLZ00L18}
\newlabel{figure2}{{2}{3}{(a) A standard framework of anchor-free approach which conducts classification on frame-level visual feature. (b) A standard framework of anchor-based approach which does classification and regression on segment-level feature. (c) Architecture of the proposed two-stage framework: it first utilizes an anchor-free method to generate segment candidates and then computes a matching score with the query, which exploits both frame-level and segment-level information. }{}{}}
\newlabel{figure2@cref}{{[figure][2][]2}{[1][2][]3}}
\@LN@col{1}
\@LN@col{2}
\newlabel{BPG}{{}{3}{}{}{}}
\newlabel{BPG@cref}{{}{[1][3][]3}}
\newlabel{equation1}{{1}{3}{}{}{}}
\newlabel{equation1@cref}{{[equation][1][]1}{[1][3][]3}}
\@LN@col{1}
\newlabel{equation2}{{2}{4}{}{}{}}
\newlabel{equation2@cref}{{[equation][2][]2}{[1][4][]4}}
\newlabel{equation3}{{3}{4}{}{}{}}
\newlabel{equation3@cref}{{[equation][3][]3}{[1][4][]4}}
\newlabel{equation45}{{5}{4}{}{}{}}
\newlabel{equation45@cref}{{[equation][5][]5}{[1][4][]4}}
\newlabel{equation6}{{6}{4}{}{}{}}
\newlabel{equation6@cref}{{[equation][6][]6}{[1][4][]4}}
\newlabel{VLM}{{}{4}{}{}{}}
\newlabel{VLM@cref}{{}{[1][4][]4}}
\newlabel{equation7}{{7}{4}{}{}{}}
\newlabel{equation7@cref}{{[equation][7][]7}{[1][4][]4}}
\@LN@col{2}
\newlabel{figure3}{{3}{4}{The backbone of BPNet (a variant of the QANet). The embedding encoder consists of several conv-layers, a self-attention layer and a feed-forward layer. For each layer, layer normalization and residual connection are employed. }{}{}}
\newlabel{figure3@cref}{{[figure][3][]3}{[1][4][]4}}
\newlabel{equation8}{{8}{4}{}{}{}}
\newlabel{equation8@cref}{{[equation][8][]8}{[1][4][]4}}
\newlabel{training}{{}{4}{}{}{}}
\newlabel{training@cref}{{}{[1][4][]4}}
\newlabel{equation9}{{9}{4}{}{}{}}
\newlabel{equation9@cref}{{[equation][9][]9}{[1][4][]4}}
\newlabel{equation10}{{10}{4}{}{}{}}
\newlabel{equation10@cref}{{[equation][10][]10}{[1][4][]4}}
\citation{DBLP:conf/iccv/GaoSYN17}
\citation{DBLP:conf/iccv/GaoSYN17}
\citation{DBLP:conf/iccv/KrishnaHRFN17}
\citation{DBLP:conf/aaai/YuanM019}
\citation{DBLP:conf/iccv/TranBFTP15}
\citation{DBLP:conf/iccv/GaoSYN17}
\citation{DBLP:conf/sigir/LiuWN0CC18}
\citation{DBLP:conf/mm/LiuWN0CC18}
\citation{DBLP:conf/ijcai/WuH18}
\citation{DBLP:conf/wacv/GeGCN19}
\citation{DBLP:conf/aaai/ChenJ19a}
\citation{DBLP:conf/aaai/Xu0PSSS19}
\citation{ChenCMJC18}
\citation{DBLP:conf/cvpr/ZhangDWWD19}
\citation{DBLP:conf/aaai/Chen0CJL19}
\citation{DBLP:conf/aaai/YuanM019}
\citation{LuCTLX19}
\citation{DBLP:conf/naacl/GhoshAPH19}
\citation{DBLP:conf/aaai/ChenLTXZTL20}
\citation{DBLP:conf/acl/ZhangSJZ20}
\citation{DBLP:conf/aaai/HeZHLLW19}
\citation{DBLP:conf/cvpr/WangHW19}
\citation{DBLP:conf/acl/ZhangSJZ20}
\citation{DBLP:conf/cvpr/CarreiraZ17}
\@LN@col{1}
\newlabel{equation11}{{11}{5}{}{}{}}
\newlabel{equation11@cref}{{[equation][11][]11}{[1][4][]5}}
\newlabel{Dataset}{{}{5}{}{}{}}
\newlabel{Dataset@cref}{{}{[1][5][]5}}
\newlabel{Metrics}{{}{5}{}{}{}}
\newlabel{Metrics@cref}{{}{[1][5][]5}}
\newlabel{Implementation}{{}{5}{}{}{}}
\newlabel{Implementation@cref}{{}{[1][5][]5}}
\@LN@col{2}
\newlabel{table1}{{1}{5}{Performance (\%) of ``R@$n$, IoU=$\theta $" and ``mIoU" compared with the state-of-the-art NLVL models on Charades-STA.}{}{}}
\newlabel{table1@cref}{{[table][1][]1}{[1][5][]5}}
\newlabel{Comparison}{{}{5}{}{}{}}
\newlabel{Comparison@cref}{{}{[1][5][]5}}
\citation{DBLP:conf/aaai/ZhangPFL20,DBLP:conf/cvpr/ZengXHCTG20}
\@LN@col{1}
\newlabel{table2}{{2}{6}{Performance (\%) of ``R@$n$, IoU=$\theta $" and ``mIoU" compared with the state-of-the-art NLVL models on TACoS.}{}{}}
\newlabel{table2@cref}{{[table][2][]2}{[1][5][]6}}
\newlabel{table3}{{3}{6}{Performance (\%) of ``R@$n$, IoU=$\theta $" and ``mIoU" compared with the state-of-the-art NLVL models on ActivityNet Captions.}{}{}}
\newlabel{table3@cref}{{[table][3][]3}{[1][5][]6}}
\newlabel{ablation}{{}{6}{}{}{}}
\newlabel{ablation@cref}{{}{[1][6][]6}}
\@LN@col{2}
\newlabel{table4}{{4}{6}{Performance (\%) comparisons of the anchor-free model, anchor-based model and BPNet with the same backbone on three benchmarks. }{}{}}
\newlabel{table4@cref}{{[table][4][]4}{[1][5][]6}}
\newlabel{table5}{{5}{6}{Performance (\%) comparisons with the anchor-based model in different settings on TACoS.}{}{}}
\newlabel{table5@cref}{{[table][5][]5}{[1][6][]6}}
\citation{chen2021ref}
\bibdata{my.bib}
\newlabel{figure4}{{4}{7}{The qualitative results of BPNet on ActivityNet Captions.}{}{}}
\newlabel{figure4@cref}{{[figure][4][]4}{[1][6][]7}}
\@LN@col{1}
\newlabel{table6}{{6}{7}{Performance (\%) comparisons on Charades-STA. BPNet w/o vlf represent the BPNet without the Visual-Language Fusion layer.}{}{}}
\newlabel{table6@cref}{{[table][6][]6}{[1][6][]7}}
\@LN@col{2}
\@LN@col{1}
\@LN@col{2}
\gdef \@abspage@last{8}
