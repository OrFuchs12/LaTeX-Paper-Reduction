\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem[{Agirre et~al.(2009)Agirre, Alfonseca, Hall, Kravalova, Pa{\c{s}}ca,
  and Soroa}]{agirre-etal-2009-study}
Agirre, E.; Alfonseca, E.; Hall, K.; Kravalova, J.; Pa{\c{s}}ca, M.; and Soroa,
  A. 2009.
\newblock A Study on Similarity and Relatedness Using Distributional and
  {W}ord{N}et-based Approaches.
\newblock In \emph{Proceedings of Human Language Technologies: The 2009 Annual
  Conference of the North {A}merican Chapter of the Association for
  Computational Linguistics}, 19--27. Boulder, Colorado: Association for
  Computational Linguistics.
\newblock \urlprefix\url{https://www.aclweb.org/anthology/N09-1003}.

\bibitem[{Arora et~al.(2016)Arora, Li, Liang, Ma, and
  Risteski}]{arora-etal-2016-latent}
Arora, S.; Li, Y.; Liang, Y.; Ma, T.; and Risteski, A. 2016.
\newblock A Latent Variable Model Approach to {PMI}-based Word Embeddings.
\newblock \emph{Transactions of the Association for Computational Linguistics}
  4: 385--399.
\newblock \doi{10.1162/tacl_a_00106}.
\newblock \urlprefix\url{https://www.aclweb.org/anthology/Q16-1028}.

\bibitem[{Attardi(2015)}]{Wikiextractor2015}
Attardi, G. 2015.
\newblock WikiExtractor.
\newblock \url{https://github.com/attardi/wikiextractor}.

\bibitem[{Bouraoui, Camacho-Collados, and
  Schockaert(2020)}]{bouraoui2019inducing}
Bouraoui, Z.; Camacho-Collados, J.; and Schockaert, S. 2020.
\newblock Inducing Relational Knowledge from BERT.
\newblock \emph{AAAI} .

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei}]{brown2020language}
Brown, T.~B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhariwal, P.;
  Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal, S.;
  Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
  D.~M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
  S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
  I.; and Amodei, D. 2020.
\newblock Language Models are Few-Shot Learners .

\bibitem[{Bruni, Tran, and Baroni(2014)}]{bruni2014multimodal}
Bruni, E.; Tran, N.-K.; and Baroni, M. 2014.
\newblock Multimodal distributional semantics.
\newblock \emph{Journal of Artificial Intelligence Research} 49: 1--47.

\bibitem[{Brunner et~al.(2019)Brunner, Liu, Pascual, Richter, and
  Wattenhofer}]{brunner2019validity}
Brunner, G.; Liu, Y.; Pascual, D.; Richter, O.; and Wattenhofer, R. 2019.
\newblock On the validity of self-attention as explanation in transformer
  models.
\newblock \emph{arXiv preprint arXiv:1908.04211} .

\bibitem[{Clark et~al.(2019)Clark, Khandelwal, Levy, and
  Manning}]{clark2019what}
Clark, K.; Khandelwal, U.; Levy, O.; and Manning, C.~D. 2019.
\newblock What Does {BERT} Look At? An Analysis of BERT's Attention.
\newblock \emph{BlackboxNLP} .

\bibitem[{Clark et~al.(2020)Clark, Luong, Le, and Manning}]{clark2020electra}
Clark, K.; Luong, M.-T.; Le, Q.~V.; and Manning, C.~D. 2020.
\newblock Electra: Pre-training text encoders as discriminators rather than
  generators.
\newblock \emph{ICLR 2020} .

\bibitem[{Coenen et~al.(2019)Coenen, Reif, Yuan, Kim, Pearce, Vi{\'e}gas, and
  Wattenberg}]{coenen2019visualizing}
Coenen, A.; Reif, E.; Yuan, A.; Kim, B.; Pearce, A.; Vi{\'e}gas, F.; and
  Wattenberg, M. 2019.
\newblock Visualizing and Measuring the Geometry of BERT.
\newblock \emph{arXiv preprint arXiv:1906.02715} .

\bibitem[{De~Deyne et~al.(2019)De~Deyne, Navarro, Perfors, Brysbaert, and
  Storms}]{de2019small}
De~Deyne, S.; Navarro, D.~J.; Perfors, A.; Brysbaert, M.; and Storms, G. 2019.
\newblock The “Small World of Words” English word association norms for
  over 12,000 cue words.
\newblock \emph{Behavior research methods} 51(3): 987--1006.

\bibitem[{Devlin et~al.(2018)Devlin, Chang, Lee, and
  Toutanova}]{devlin2018bert}
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805} .

\bibitem[{Ethayarajh(2019)}]{Ethayarajh2019HowCA}
Ethayarajh, K. 2019.
\newblock How Contextual are Contextualized Word Representations? Comparing the
  Geometry of BERT, ELMo, and GPT-2 Embeddings.
\newblock \emph{ArXiv} abs/1909.00512.

\bibitem[{Finkelstein et~al.(2002)Finkelstein, Gabrilovich, Matias, Rivlin,
  Solan, Wolfman, and Ruppin}]{finkelstein2002placing}
Finkelstein, L.; Gabrilovich, E.; Matias, Y.; Rivlin, E.; Solan, Z.; Wolfman,
  G.; and Ruppin, E. 2002.
\newblock Placing search in context: The concept revisited.
\newblock \emph{ACM Transactions on information systems} 20(1): 116--131.

\bibitem[{Griffiths, Steyvers, and Tenenbaum(2007)}]{griffiths2007topics}
Griffiths, T.~L.; Steyvers, M.; and Tenenbaum, J.~B. 2007.
\newblock Topics in semantic representation.
\newblock \emph{Psychological review} 114(2): 211.

\bibitem[{Hewitt and Manning(2019)}]{hewitt2019structural}
Hewitt, J.; and Manning, C.~D. 2019.
\newblock A structural probe for finding syntax in word representations.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, 4129--4138.

\bibitem[{Hill, Reichart, and Korhonen(2015)}]{hill2015simlex}
Hill, F.; Reichart, R.; and Korhonen, A. 2015.
\newblock SimLex-999: Evaluating Semantic Models With (Genuine) Similarity
  Estimation.
\newblock \emph{Computational Linguistics} 41(4): 665--695.

\bibitem[{Jawahar, Sagot, and Seddah(2019)}]{jawahar2019does}
Jawahar, G.; Sagot, B.; and Seddah, D. 2019.
\newblock What Does BERT Learn about the Structure of Language?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, 3651--3657.

\bibitem[{Joulin et~al.(2016)Joulin, Grave, Bojanowski, Douze, J{\'e}gou, and
  Mikolov}]{joulin2016fasttext}
Joulin, A.; Grave, E.; Bojanowski, P.; Douze, M.; J{\'e}gou, H.; and Mikolov,
  T. 2016.
\newblock Fasttext. zip: Compressing text classification models.
\newblock \emph{arXiv preprint arXiv:1612.03651} .

\bibitem[{Kiss et~al.(1973)Kiss, Armstrong, Milroy, and
  Piper}]{kiss1973associative}
Kiss, G.~R.; Armstrong, C.; Milroy, R.; and Piper, J. 1973.
\newblock An associative thesaurus of English and its computer analysis.
\newblock \emph{The computer and literary studies} 153--165.

\bibitem[{Lan et~al.(2019)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut}]{lan2019albert}
Lan, Z.; Chen, M.; Goodman, S.; Gimpel, K.; Sharma, P.; and Soricut, R. 2019.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock \emph{arXiv preprint arXiv:1909.11942} .

\bibitem[{Levy and Goldberg(2014)}]{Levy2014NeuralWE}
Levy, O.; and Goldberg, Y. 2014.
\newblock Neural Word Embedding as Implicit Matrix Factorization.
\newblock In \emph{NIPS}.

\bibitem[{Liu et~al.(2020)Liu, Zhou, Zhao, Wang, Ju, Deng, and Wang}]{liu2019k}
Liu, W.; Zhou, P.; Zhao, Z.; Wang, Z.; Ju, Q.; Deng, H.; and Wang, P. 2020.
\newblock K-bert: Enabling language representation with knowledge graph.
\newblock \emph{AAAI} .

\bibitem[{Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov}]{liu2019roberta}
Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.;
  Zettlemoyer, L.; and Stoyanov, V. 2019.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692} .

\bibitem[{Mickus et~al.(2019)Mickus, Paperno, Constant, and van
  Deemeter}]{mickus2019mean}
Mickus, T.; Paperno, D.; Constant, M.; and van Deemeter, K. 2019.
\newblock What do you mean, BERT? Assessing BERT as a Distributional Semantics
  Model.

\bibitem[{Mikolov et~al.(2018)Mikolov, Grave, Bojanowski, Puhrsch, and
  Joulin}]{mikolov2018advances}
Mikolov, T.; Grave, E.; Bojanowski, P.; Puhrsch, C.; and Joulin, A. 2018.
\newblock Advances in Pre-Training Distributed Word Representations.
\newblock In \emph{Proceedings of the International Conference on Language
  Resources and Evaluation (LREC 2018)}.

\bibitem[{Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean}]{mikolov2013distributed}
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G.~S.; and Dean, J. 2013.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems},
  3111--3119.

\bibitem[{Miller and Charles(1991)}]{miller1991contextual}
Miller, G.~A.; and Charles, W.~G. 1991.
\newblock Contextual correlates of semantic similarity.
\newblock \emph{Language and cognitive processes} 6(1): 1--28.

\bibitem[{Nelson, McEvoy, and Schreiber(2004)}]{nelson2004university}
Nelson, D.~L.; McEvoy, C.~L.; and Schreiber, T.~A. 2004.
\newblock The University of South Florida free association, rhyme, and word
  fragment norms.
\newblock \emph{Behavior Research Methods, Instruments, \& Computers} 36(3):
  402--407.

\bibitem[{Nematzadeh, Meylan, and Griffiths(2017)}]{nematzadeh2017evaluating}
Nematzadeh, A.; Meylan, S.~C.; and Griffiths, T.~L. 2017.
\newblock Evaluating Vector-Space Models of Word Representation, or, The
  Unreasonable Effectiveness of Counting Words Near Other Words.

\bibitem[{Pennington, Socher, and Manning(2014)}]{pennington2014glove}
Pennington, J.; Socher, R.; and Manning, C. 2014.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, 1532--1543.

\bibitem[{Petroni et~al.(2019)Petroni, Rockt{\"a}schel, Riedel, Lewis, Bakhtin,
  Wu, and Miller}]{petroni2019language}
Petroni, F.; Rockt{\"a}schel, T.; Riedel, S.; Lewis, P.; Bakhtin, A.; Wu, Y.;
  and Miller, A. 2019.
\newblock Language Models as Knowledge Bases?
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, 2463--2473.

\bibitem[{Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and
  Liang}]{rajpurkar-etal-2016-squad}
Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016.
\newblock {SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, 2383--2392. Austin, Texas: Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/D16-1264}.
\newblock \urlprefix\url{https://www.aclweb.org/anthology/D16-1264}.

\bibitem[{Reif et~al.(2019)Reif, Yuan, Wattenberg, Viegas, Coenen, Pearce, and
  Kim}]{reif2019visualizing}
Reif, E.; Yuan, A.; Wattenberg, M.; Viegas, F.~B.; Coenen, A.; Pearce, A.; and
  Kim, B. 2019.
\newblock Visualizing and Measuring the Geometry of BERT.
\newblock In Wallach, H.; Larochelle, H.; Beygelzimer, A.; d\textquotesingle
  Alch\'{e}-Buc, F.; Fox, E.; and Garnett, R., eds., \emph{Advances in Neural
  Information Processing Systems 32}, 8592--8600. Curran Associates, Inc.
\newblock
  \urlprefix\url{http://papers.nips.cc/paper/9065-visualizing-and-measuring-the-geometry-of-bert.pdf}.

\bibitem[{Resnik(1995)}]{Resnik:1995:UIC:1625855.1625914}
Resnik, P. 1995.
\newblock Using Information Content to Evaluate Semantic Similarity in a
  Taxonomy.
\newblock In \emph{Proceedings of the 14th International Joint Conference on
  Artificial Intelligence - Volume 1}, IJCAI'95, 448--453. San Francisco, CA,
  USA: Morgan Kaufmann Publishers Inc.
\newblock ISBN 1-55860-363-8, 978-1-558-60363-9.
\newblock \urlprefix\url{http://dl.acm.org/citation.cfm?id=1625855.1625914}.

\bibitem[{Rubenstein and Goodenough(1965)}]{rubenstein1965contextual}
Rubenstein, H.; and Goodenough, J.~B. 1965.
\newblock Contextual correlates of synonymy.
\newblock \emph{Communications of the ACM} 8(10): 627--633.

\bibitem[{Speer, Chin, and Havasi(2017)}]{speer2017conceptnet}
Speer, R.; Chin, J.; and Havasi, C. 2017.
\newblock Conceptnet 5.5: An open multilingual graph of general knowledge.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence}.

\bibitem[{Tenney, Das, and Pavlick(2019)}]{tenney2019bert}
Tenney, I.; Das, D.; and Pavlick, E. 2019.
\newblock Bert rediscovers the classical nlp pipeline.
\newblock \emph{arXiv preprint arXiv:1905.05950} .

\bibitem[{Tenney et~al.(2019)Tenney, Xia, Chen, Wang, Poliak, McCoy, Kim,
  Van~Durme, Bowman, Das et~al.}]{tenney2019you}
Tenney, I.; Xia, P.; Chen, B.; Wang, A.; Poliak, A.; McCoy, R.~T.; Kim, N.;
  Van~Durme, B.; Bowman, S.~R.; Das, D.; et~al. 2019.
\newblock What do you learn from context? probing for sentence structure in
  contextualized word representations.
\newblock \emph{arXiv preprint arXiv:1905.06316} .

\bibitem[{Torabi~Asr, Zinkov, and Jones(2018)}]{torabi-asr-etal-2018-querying}
Torabi~Asr, F.; Zinkov, R.; and Jones, M. 2018.
\newblock Querying Word Embeddings for Similarity and Relatedness.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, 675--684. New Orleans, Louisiana:
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N18-1062}.
\newblock \urlprefix\url{https://www.aclweb.org/anthology/N18-1062}.

\bibitem[{Tversky(1977)}]{tversky1977features}
Tversky, A. 1977.
\newblock Features of similarity.
\newblock \emph{Psychological review} 84(4): 327.

\bibitem[{Wang et~al.(2019)Wang, Pruksachatkun, Nangia, Singh, Michael, Hill,
  Levy, and Bowman}]{wang2019superglue}
Wang, A.; Pruksachatkun, Y.; Nangia, N.; Singh, A.; Michael, J.; Hill, F.;
  Levy, O.; and Bowman, S.~R. 2019.
\newblock Superglue: A stickier benchmark for general-purpose language
  understanding systems.
\newblock \emph{NIPS} .

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang2018glue}
Wang, A.; Singh, A.; Michael, J.; Hill, F.; Levy, O.; and Bowman, S.~R. 2018.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock \emph{BlackBoxNLP} .

\bibitem[{Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, and Brew}]{Wolf2019HuggingFacesTS}
Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.;
  Rault, T.; Louf, R.; Funtowicz, M.; and Brew, J. 2019.
\newblock HuggingFace's Transformers: State-of-the-art Natural Language
  Processing.
\newblock \emph{ArXiv} abs/1910.03771.

\bibitem[{Yang and Powers(2006)}]{yang2006verb}
Yang, D.; and Powers, D.~M. 2006.
\newblock Verb similarity on the taxonomy of WordNet.
\newblock \emph{Proceedings of GWC-06} 121--128.

\end{thebibliography}
