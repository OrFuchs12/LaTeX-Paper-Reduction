\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Cao et~al.(2023)Cao, Wei, Xu, Geng, Chen, Zhang, Zou, Shen, and
  Jiang}]{cao2023iterative}
Cao, M.; Wei, F.; Xu, C.; Geng, X.; Chen, L.; Zhang, C.; Zou, Y.; Shen, T.; and
  Jiang, D. 2023.
\newblock Iterative Proposal Refinement for Weakly-Supervised Video Grounding.
\newblock In \emph{CVPR}, 6524--6534.

\bibitem[{Carreira and Zisserman(2017)}]{carreira2017quo}
Carreira, J.; and Zisserman, A. 2017.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In \emph{CVPR}, 6299--6308.

\bibitem[{Chen et~al.(2022)Chen, Luo, Zhang, and Ma}]{Chen_Luo_Zhang_Ma_2022}
Chen, J.; Luo, W.; Zhang, W.; and Ma, L. 2022.
\newblock Explore Inter-contrast between Videos via Composition for Weakly
  Supervised Temporal Sentence Grounding.
\newblock In \emph{AAAI}.

\bibitem[{Chen and Jiang(2021)}]{chen2021towards}
Chen, S.; and Jiang, Y.-G. 2021.
\newblock Towards bridging event captioner and sentence localizer for weakly
  supervised dense event captioning.
\newblock In \emph{CVPR}, 8425--8435.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova}]{devlin2018bert}
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{NAACL-HLT}.

\bibitem[{Dong et~al.(2019)Dong, Li, Xu, Ji, He, Yang, and Wang}]{dong2019dual}
Dong, J.; Li, X.; Xu, C.; Ji, S.; He, Y.; Yang, G.; and Wang, X. 2019.
\newblock Dual encoding for zero-example video retrieval.
\newblock In \emph{CVPR}, 9346--9355.

\bibitem[{Duan et~al.(2018)Duan, Huang, Gan, Wang, Zhu, and
  Huang}]{duan2018weakly}
Duan, X.; Huang, W.; Gan, C.; Wang, J.; Zhu, W.; and Huang, J. 2018.
\newblock Weakly supervised dense event captioning in videos.
\newblock In \emph{NeurIPS}, volume~31.

\bibitem[{Gao et~al.(2017)Gao, Sun, Yang, and Nevatia}]{gao2017tall}
Gao, J.; Sun, C.; Yang, Z.; and Nevatia, R. 2017.
\newblock Tall: Temporal activity localization via language query.
\newblock In \emph{ICCV}, 5267--5275.

\bibitem[{Huang et~al.(2021)Huang, Liu, Gong, and Jin}]{huang2021cross}
Huang, J.; Liu, Y.; Gong, S.; and Jin, H. 2021.
\newblock Cross-sentence temporal and semantic relations in video activity
  localisation.
\newblock In \emph{ICCV}, 7199--7208.

\bibitem[{Kim et~al.(2022)Kim, Ha, Yun, and Choi}]{kim2022swag}
Kim, S.; Ha, T.; Yun, K.; and Choi, J.~Y. 2022.
\newblock SWAG-Net: Semantic Word-Aware Graph Network for Temporal Video
  Grounding.
\newblock In \emph{ACM CIKM}, 982â€“992.

\bibitem[{Kim, Yun, and Choi(2021)}]{kim2021plrn}
Kim, S.; Yun, K.; and Choi, J.~Y. 2021.
\newblock Position-aware Location Regression Network for Temporal Video
  Grounding.
\newblock In \emph{AVSS}, 1--8.

\bibitem[{Kingma and Ba(2015)}]{kingma2014adam}
Kingma, D.~P.; and Ba, J. 2015.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR}.

\bibitem[{Krishna et~al.(2017)Krishna, Hata, Ren, Fei-Fei, and
  Carlos~Niebles}]{krishna2017dense}
Krishna, R.; Hata, K.; Ren, F.; Fei-Fei, L.; and Carlos~Niebles, J. 2017.
\newblock Dense-captioning events in videos.
\newblock In \emph{ICCV}, 706--715.

\bibitem[{Lee et~al.(2018)Lee, Lee, Lee, and Shin}]{lee2018simple}
Lee, K.; Lee, K.; Lee, H.; and Shin, J. 2018.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock \emph{NeurIPS}, 31.

\bibitem[{Lin et~al.(2017)Lin, Feng, Santos, Yu, Xiang, Zhou, and
  Bengio}]{lin2017structured}
Lin, Z.; Feng, M.; Santos, C. N.~d.; Yu, M.; Xiang, B.; Zhou, B.; and Bengio,
  Y. 2017.
\newblock A structured self-attentive sentence embedding.
\newblock \emph{arXiv preprint arXiv:1703.03130}.

\bibitem[{Lin et~al.(2020)Lin, Zhao, Zhang, Wang, and Liu}]{lin2020weakly}
Lin, Z.; Zhao, Z.; Zhang, Z.; Wang, Q.; and Liu, H. 2020.
\newblock Weakly-supervised video moment retrieval via semantic completion
  network.
\newblock In \emph{AAAI}, volume~34, 11539--11546.

\bibitem[{Long et~al.(2019)Long, Yao, Qiu, Tian, Luo, and
  Mei}]{long2019gaussian}
Long, F.; Yao, T.; Qiu, Z.; Tian, X.; Luo, J.; and Mei, T. 2019.
\newblock Gaussian temporal awareness networks for action localization.
\newblock In \emph{CVPR}, 344--353.

\bibitem[{Ma et~al.(2020)Ma, Yoon, Kim, Lee, Kang, and Yoo}]{ma2020vlanet}
Ma, M.; Yoon, S.; Kim, J.; Lee, Y.; Kang, S.; and Yoo, C.~D. 2020.
\newblock Vlanet: Video-language alignment network for weakly-supervised video
  moment retrieval.
\newblock In \emph{ECCV}, 156--171. Springer.

\bibitem[{Ma et~al.(2002)Ma, Lu, Zhang, and Li}]{ma2002user}
Ma, Y.-F.; Lu, L.; Zhang, H.-J.; and Li, M. 2002.
\newblock A user attention model for video summarization.
\newblock In \emph{ACM MM}, 533--542.

\bibitem[{Mithun, Paul, and Roy-Chowdhury(2019)}]{mithun2019weakly}
Mithun, N.~C.; Paul, S.; and Roy-Chowdhury, A.~K. 2019.
\newblock Weakly supervised video moment retrieval from text queries.
\newblock In \emph{CVPR}, 11592--11601.

\bibitem[{Neubeck and Van~Gool(2006)}]{neubeck2006efficient}
Neubeck, A.; and Van~Gool, L. 2006.
\newblock Efficient non-maximum suppression.
\newblock In \emph{ICPR}, volume~3, 850--855. IEEE.

\bibitem[{Pennington, Socher, and Manning(2014)}]{pennington2014glove}
Pennington, J.; Socher, R.; and Manning, C. 2014.
\newblock {G}lo{V}e: Global Vectors for Word Representation.
\newblock In \emph{EMNLP}, 1532--1543.

\bibitem[{Piergiovanni and Ryoo(2019)}]{piergiovanni2019temporal}
Piergiovanni, A.; and Ryoo, M. 2019.
\newblock Temporal gaussian mixture layer for videos.
\newblock In \emph{ICML}, 5152--5161. PMLR.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Radford, A.; Kim, J.~W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry,
  G.; Askell, A.; Mishkin, P.; Clark, J.; et~al. 2021.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{ICML}, 8748--8763. PMLR.

\bibitem[{Sanh et~al.(2019)Sanh, Debut, Chaumond, and
  Wolf}]{sanh2019distilbert}
Sanh, V.; Debut, L.; Chaumond, J.; and Wolf, T. 2019.
\newblock DistilBERT, a distilled version of BERT: smaller, faster, cheaper and
  lighter.
\newblock \emph{arXiv preprint arXiv:1910.01108}.

\bibitem[{Song et~al.(2020)Song, Wang, Ma, Yu, and Yu}]{song2020weakly}
Song, Y.; Wang, J.; Ma, L.; Yu, Z.; and Yu, J. 2020.
\newblock Weakly-supervised multi-level attentional reconstruction network for
  grounding textual queries in videos.
\newblock \emph{arXiv preprint arXiv:2003.07048}.

\bibitem[{Tan et~al.(2021)Tan, Xu, Saenko, and Plummer}]{tan2021logan}
Tan, R.; Xu, H.; Saenko, K.; and Plummer, B.~A. 2021.
\newblock Logan: Latent graph co-attention network for weakly-supervised video
  moment retrieval.
\newblock In \emph{WACV}, 2083--2092.

\bibitem[{Tran et~al.(2015)Tran, Bourdev, Fergus, Torresani, and
  Paluri}]{tran2015learning}
Tran, D.; Bourdev, L.; Fergus, R.; Torresani, L.; and Paluri, M. 2015.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In \emph{ICCV}, 4489--4497.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.;
  Kaiser, {\L}.; and Polosukhin, I. 2017.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, volume~30.

\bibitem[{Wang et~al.(2022)Wang, Ge, Cai, Yan, Lin, Shan, Qie, and
  Shou}]{wang2022object}
Wang, J.; Ge, Y.; Cai, G.; Yan, R.; Lin, X.; Shan, Y.; Qie, X.; and Shou, M.~Z.
  2022.
\newblock Object-aware video-language pre-training for retrieval.
\newblock In \emph{CVPR}, 3313--3322.

\bibitem[{Wang et~al.(2014)Wang, Song, Leung, Rosenberg, Wang, Philbin, Chen,
  and Wu}]{wang2014learning}
Wang, J.; Song, Y.; Leung, T.; Rosenberg, C.; Wang, J.; Philbin, J.; Chen, B.;
  and Wu, Y. 2014.
\newblock Learning fine-grained image similarity with deep ranking.
\newblock In \emph{CVPR}, 1386--1393.

\bibitem[{Wang et~al.(2021)Wang, Deng, Zhou, and Li}]{wang2021weakly}
Wang, Y.; Deng, J.; Zhou, W.; and Li, H. 2021.
\newblock Weakly supervised temporal adjacent network for language grounding.
\newblock \emph{IEEE Transactions on Multimedia}.

\bibitem[{Wang, Zhou, and Li(2021)}]{wang2022fine}
Wang, Y.; Zhou, W.; and Li, H. 2021.
\newblock Fine-grained semantic alignment network for weakly supervised
  temporal language grounding.
\newblock In \emph{EMNLP}.

\bibitem[{Wang, Chen, and Jiang(2021)}]{wang2021visual}
Wang, Z.; Chen, J.; and Jiang, Y.-G. 2021.
\newblock Visual co-occurrence alignment learning for weakly-supervised video
  moment retrieval.
\newblock In \emph{ACM MM}, 1459--1468.

\bibitem[{Wu et~al.(2020)Wu, Li, Han, and Lin}]{wu2020reinforcement}
Wu, J.; Li, G.; Han, X.; and Lin, L. 2020.
\newblock Reinforcement learning for weakly supervised temporal grounding of
  natural language in untrimmed videos.
\newblock In \emph{ACM MM}, 1283--1291.

\bibitem[{Yang et~al.(2021)Yang, Zhang, Zhang, and Wu}]{yang2021local}
Yang, W.; Zhang, T.; Zhang, Y.; and Wu, F. 2021.
\newblock Local correspondence network for weakly supervised temporal sentence
  grounding.
\newblock \emph{IEEE Transactions on Image Processing}, 30: 3252--3262.

\bibitem[{Yuan et~al.(2021)Yuan, Lan, Wang, Chen, Wang, and
  Zhu}]{yuan2021closer}
Yuan, Y.; Lan, X.; Wang, X.; Chen, L.; Wang, Z.; and Zhu, W. 2021.
\newblock A closer look at temporal sentence grounding in videos: Dataset and
  metric.
\newblock In \emph{Proceedings of the 2nd International Workshop on
  Human-centric Multimedia Analysis}, 13--21.

\bibitem[{Zhang et~al.(2020{\natexlab{a}})Zhang, Lin, Zhao, Zhu, and
  He}]{zhang2020regularized}
Zhang, Z.; Lin, Z.; Zhao, Z.; Zhu, J.; and He, X. 2020{\natexlab{a}}.
\newblock Regularized two-branch proposal networks for weakly-supervised moment
  retrieval in videos.
\newblock In \emph{ACM MM}, 4098--4106.

\bibitem[{Zhang et~al.(2020{\natexlab{b}})Zhang, Zhao, Lin, He
  et~al.}]{zhang2020counterfactual}
Zhang, Z.; Zhao, Z.; Lin, Z.; He, X.; et~al. 2020{\natexlab{b}}.
\newblock Counterfactual contrastive learning for weakly-supervised
  vision-language grounding.
\newblock In \emph{NeurIPS}, volume~33, 18123--18134.

\bibitem[{Zheng et~al.(2022{\natexlab{a}})Zheng, Huang, Chen, and
  Liu}]{zheng2022cnm}
Zheng, M.; Huang, Y.; Chen, Q.; and Liu, Y. 2022{\natexlab{a}}.
\newblock Weakly supervised video moment localization with contrastive negative
  sample mining.
\newblock In \emph{AAAI}, volume~1, 3.

\bibitem[{Zheng et~al.(2022{\natexlab{b}})Zheng, Huang, Chen, Peng, and
  Liu}]{zheng2022cpl}
Zheng, M.; Huang, Y.; Chen, Q.; Peng, Y.; and Liu, Y. 2022{\natexlab{b}}.
\newblock Weakly Supervised Temporal Sentence Grounding With Gaussian-Based
  Contrastive Proposal Learning.
\newblock In \emph{CVPR}, 15555--15564.

\bibitem[{Zhou et~al.(2021)Zhou, Zhang, Luo, Chen, and Hu}]{zhou2021embracing}
Zhou, H.; Zhang, C.; Luo, Y.; Chen, Y.; and Hu, C. 2021.
\newblock Embracing uncertainty: Decoupling and de-bias for robust temporal
  grounding.
\newblock In \emph{CVPR}, 8445--8454.

\bibitem[{Zhou(2021)}]{zhou2021ensemble}
Zhou, Z.-H. 2021.
\newblock Ensemble learning.
\newblock In \emph{Machine learning}, 181--210. Springer.

\bibitem[{Zong et~al.(2018)Zong, Song, Min, Cheng, Lumezanu, Cho, and
  Chen}]{zong2018deep}
Zong, B.; Song, Q.; Min, M.~R.; Cheng, W.; Lumezanu, C.; Cho, D.; and Chen, H.
  2018.
\newblock Deep autoencoding gaussian mixture model for unsupervised anomaly
  detection.
\newblock In \emph{ICLR}.

\end{thebibliography}
