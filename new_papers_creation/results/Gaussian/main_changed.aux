\relax 
\bibstyle{aaai24}
\citation{carreira2017quo}
\citation{ma2002user}
\citation{dong2019dual}
\citation{kim2021plrn,kim2022swag,gao2017tall}
\citation{yuan2021closer,zhou2021embracing}
\citation{huang2021cross,lin2020weakly,mithun2019weakly,tan2021logan,wang2021weakly,zhang2020counterfactual}
\citation{zheng2022cnm,zheng2022cpl}
\citation{zong2018deep,lee2018simple}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:concept-art}{{1}{1}{Weakly supervised temporal video grounding. (a) Previous methods use sliding windows (left) or a single Gaussian proposal (right), which has a predetermined shape. (b) The proposed method generates a Gaussian mixture proposal trained to be moderately coupled with a pull-push learning scheme to capture diverse query-relevant events. }{}{}}
\newlabel{fig:concept-art@cref}{{[figure][1][]1}{[1][1][]1}}
\citation{gao2017tall}
\citation{krishna2017dense}
\citation{huang2021cross,tan2021logan,mithun2019weakly,wang2021weakly,zhang2020counterfactual}
\citation{tan2021logan}
\citation{huang2021cross}
\citation{neubeck2006efficient}
\citation{lin2020weakly,zheng2022cnm,zheng2022cpl,song2020weakly,cao2023iterative}
\citation{lin2020weakly,song2020weakly}
\citation{zheng2022cnm,zheng2022cpl}
\citation{cao2023iterative}
\citation{zong2018deep,lee2018simple,piergiovanni2019temporal,long2019gaussian,zheng2022cnm,zheng2022cpl}
\citation{zheng2022cnm,zheng2022cpl}
\citation{zheng2022cnm}
\citation{zheng2022cpl}
\citation{long2019gaussian}
\citation{piergiovanni2019temporal}
\citation{zong2018deep,lee2018simple}
\newlabel{sec:weakly-supervised-temporal-video-grounding}{{2}{2}{}{}{}}
\newlabel{sec:weakly-supervised-temporal-video-grounding@cref}{{[section][2][]2}{[1][2][]2}}
\newlabel{sec:gaussian-proposals-in-video}{{2}{2}{}{}{}}
\newlabel{sec:gaussian-proposals-in-video@cref}{{[section][2][]2}{[1][2][]2}}
\citation{wu2020reinforcement,chen2021towards}
\citation{carreira2017quo,tran2015learning}
\citation{pennington2014glove}
\citation{vaswani2017attention}
\citation{devlin2018bert}
\newlabel{fig:framework}{{2}{3}{ The overall scheme of the proposed method. The Gaussian mixture proposal generator produces multiple Gaussian masks from the features representing both the video and sentence query. For the positive proposals, we define a Gaussian mixture proposal, where multiple Gaussian masks are combined via attentive pooling using the importance weights from the importance-based reconstructor. Further, to generate moderately coupled masks in the mixture proposal, we propose the pull-push learning scheme using $\mathcal  {L}_{pull}$, $\mathcal  {L}^{intra}_{push}$, and $\mathcal  {L}^{inter}_{push}$. The importance-based reconstructor leverages the proposals to produce the reconstructed query from the hidden query. }{}{}}
\newlabel{fig:framework@cref}{{[figure][2][]2}{[1][2][]3}}
\newlabel{sec:encoders}{{3}{3}{}{}{}}
\newlabel{sec:encoders@cref}{{[section][3][]3}{[1][3][]3}}
\newlabel{sec:proposal-generator}{{3}{3}{}{}{}}
\newlabel{sec:proposal-generator@cref}{{[section][3][]3}{[1][3][]3}}
\newlabel{eq:mask-center}{{1}{3}{}{}{}}
\newlabel{eq:mask-center@cref}{{[equation][1][]1}{[1][3][]3}}
\newlabel{eq:mask-width}{{2}{3}{}{}{}}
\newlabel{eq:mask-width@cref}{{[equation][2][]2}{[1][3][]3}}
\newlabel{eq:gaussian}{{3}{3}{}{}{}}
\newlabel{eq:gaussian@cref}{{[equation][3][]3}{[1][3][]3}}
\newlabel{eq:gaussian-mixture-proposal}{{4}{3}{}{}{}}
\newlabel{eq:gaussian-mixture-proposal@cref}{{[equation][4][]4}{[1][3][]3}}
\citation{lin2017structured}
\citation{zheng2022cnm,zheng2022cpl}
\citation{zheng2022cnm,lin2020weakly}
\citation{devlin2018bert}
\citation{lin2020weakly,song2020weakly}
\citation{lin2020weakly}
\citation{zheng2022cnm}
\citation{wang2014learning}
\newlabel{eq:pulling-loss}{{5}{4}{}{}{}}
\newlabel{eq:pulling-loss@cref}{{[equation][5][]5}{[1][4][]4}}
\newlabel{eq:intra-pushing-loss}{{6}{4}{}{}{}}
\newlabel{eq:intra-pushing-loss@cref}{{[equation][6][]6}{[1][4][]4}}
\newlabel{eq:inter-pushing-loss}{{7}{4}{}{}{}}
\newlabel{eq:inter-pushing-loss@cref}{{[equation][7][]7}{[1][4][]4}}
\newlabel{sec:importance-based-reconstructor}{{3}{4}{}{}{}}
\newlabel{sec:importance-based-reconstructor@cref}{{[section][3][]3}{[1][4][]4}}
\newlabel{eq:reconstructive-transformer}{{8}{4}{}{}{}}
\newlabel{eq:reconstructive-transformer@cref}{{[equation][8][]8}{[1][4][]4}}
\newlabel{eq:mask-importance-value}{{9}{4}{}{}{}}
\newlabel{eq:mask-importance-value@cref}{{[equation][9][]9}{[1][4][]4}}
\newlabel{eq:mask-importance-weight}{{10}{4}{}{}{}}
\newlabel{eq:mask-importance-weight@cref}{{[equation][10][]10}{[1][4][]4}}
\citation{zhou2021ensemble,zheng2022cpl}
\citation{gao2017tall}
\citation{krishna2017dense}
\citation{tran2015learning}
\citation{gao2017tall}
\citation{carreira2017quo}
\citation{kingma2014adam}
\citation{duan2018weakly}
\citation{mithun2019weakly}
\citation{lin2020weakly}
\citation{wang2021weakly}
\citation{ma2020vlanet}
\citation{song2020weakly}
\citation{zhang2020counterfactual}
\citation{zhang2020regularized}
\citation{chen2021towards}
\citation{tan2021logan}
\citation{wang2021visual}
\citation{yang2021local}
\citation{wang2022fine}
\citation{Chen_Luo_Zhang_Ma_2022}
\citation{zheng2022cpl}
\citation{huang2021cross}
\citation{zheng2022cnm}
\citation{cao2023iterative}
\citation{zheng2022cpl}
\citation{zheng2022cpl}
\citation{huang2021cross}
\citation{zheng2022cnm}
\citation{radford2021learning}
\citation{cao2023iterative}
\citation{wang2022object}
\citation{sanh2019distilbert}
\newlabel{tab:comparisons-activitynet}{{1}{5}{Performance comparisons on the ActivityNet Captions. The best results and second best results are represented as bold and underlined numbers, respectively. The methods using additional annotations or large-scale pre-trained models are marked with $^*$.}{}{}}
\newlabel{tab:comparisons-activitynet@cref}{{[table][1][]1}{[1][5][]5}}
\newlabel{sec:training-and-inference}{{3}{5}{}{}{}}
\newlabel{sec:training-and-inference@cref}{{[section][3][]3}{[1][4][]5}}
\newlabel{sec:experimental-setup}{{4}{5}{}{}{}}
\newlabel{sec:experimental-setup@cref}{{[section][4][]4}{[1][5][]5}}
\newlabel{fig:ablation-graph-props}{{3}{5}{Ablation studies by varying the number of positive and negative proposals $K$ and the number of Gaussian masks of an easy negative proposal $E_{en}$. }{}{}}
\newlabel{fig:ablation-graph-props@cref}{{[figure][3][]3}{[1][5][]5}}
\newlabel{sec:comparison-with-state-of-the-art-methods}{{4}{5}{}{}{}}
\newlabel{sec:comparison-with-state-of-the-art-methods@cref}{{[section][4][]4}{[1][5][]5}}
\newlabel{tab:ablation-positive-proposals}{{2}{6}{Ablation studies of Gaussian mixture proposals on the ActivityNet Captions dataset.}{}{}}
\newlabel{tab:ablation-positive-proposals@cref}{{[table][2][]2}{[1][5][]6}}
\newlabel{tab:comparisons-charades}{{3}{6}{Performance comparisons on the Charades-STA. The best results and second best results are represented as bold and underlined numbers, respectively. The methods using additional annotations or large-scale pre-trained models are marked with $^*$.}{}{}}
\newlabel{tab:comparisons-charades@cref}{{[table][3][]3}{[1][5][]6}}
\newlabel{sec:ablation-study}{{4}{6}{}{}{}}
\newlabel{sec:ablation-study@cref}{{[section][4][]4}{[1][5][]6}}
\newlabel{tab:ablation-positive-proposals-fixing}{{4a}{6}{The number of masks for a positive proposal.}{}{}}
\newlabel{tab:ablation-positive-proposals-fixing@cref}{{[subtable][1][4]4a}{[1][6][]6}}
\newlabel{sub@tab:ablation-positive-proposals-fixing}{{a}{6}{The number of masks for a positive proposal.}{}{}}
\newlabel{sub@tab:ablation-positive-proposals-fixing@cref}{{[subtable][1][4]4a}{[1][6][]6}}
\newlabel{tab:ablation-pulling-loss}{{4b}{6}{Strategies for the pulling loss}{}{}}
\newlabel{tab:ablation-pulling-loss@cref}{{[subtable][2][4]4b}{[1][6][]6}}
\newlabel{sub@tab:ablation-pulling-loss}{{b}{6}{Strategies for the pulling loss}{}{}}
\newlabel{sub@tab:ablation-pulling-loss@cref}{{[subtable][2][4]4b}{[1][6][]6}}
\newlabel{tab:ablation-others}{{4}{6}{Ablation studies on the ActivityNet Captions dataset.}{}{}}
\newlabel{tab:ablation-others@cref}{{[table][4][]4}{[1][6][]6}}
\newlabel{tab:ablation-loss}{{5}{7}{Ablation studies of different losses for the pull-push learning scheme on the ActivityNet Captions dataset.}{}{}}
\newlabel{tab:ablation-loss@cref}{{[table][5][]5}{[1][6][]7}}
\newlabel{fig:ablation-graph-alpha}{{4}{7}{Ablation studies by varying $\alpha $ values for the pull-push learning scheme on the ActivityNet Captions dataset. }{}{}}
\newlabel{fig:ablation-graph-alpha@cref}{{[figure][4][]4}{[1][7][]7}}
\newlabel{sec:qualitative-results}{{4}{7}{}{}{}}
\newlabel{sec:qualitative-results@cref}{{[section][4][]4}{[1][7][]7}}
\newlabel{fig:qualitative}{{5}{7}{ Qualitative results on the Activity-Net Captions dataset. Given a video and a query, PPS yields a predicted temporal location (red). We also visualize the predictions of variants using a positive proposal of one Gaussian mask without the mixture (yellow) or excluding a pulling loss (green) or excluding pushing losses (purple). }{}{}}
\newlabel{fig:qualitative@cref}{{[figure][5][]5}{[1][7][]7}}
\bibdata{aaai24}
\gdef \@abspage@last{8}
