\relax 
\bibstyle{aaai24}
\citation{fedavg}
\citation{patch4}
\citation{survey}
\citation{fedavg,chaoyang,fedmd}
\citation{split}
\citation{swarm}
\citation{fedvqa}
\citation{mmv,clip,avlnet,dalle,dalle2}
\citation{butd,mmnas}
\citation{zhu20}
\citation{prior2}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:scheme}{{1}{2}{BiCSL for decentralized visual question answering consists of three main components: cross-modal representation learning (multi-head attention), an answer projection network (APN) for semantic understanding of answers, and two adapter networks (LTA and NHA) for contrastive learning of different model component outputs. BiCSL learns refined representations from different clients via inter-client weight sharing, while ensuring privacy protection via inter-module gradient sharing.}{}{}}
\newlabel{table:related}{{1}{2}{Comparison of VQA methods: BiCSL does not require sharing training data or models. Different from previous work on decentralized VQA of the aimNet, BiCSL is a self-supervised method without the need for training labels.}{}{}}
\citation{attention2}
\citation{lstm}
\citation{attention2}
\citation{cnn}
\citation{mlp}
\citation{pennington2014glove}
\citation{mmv}
\citation{infonce}
\newlabel{fig:compare}{{2}{3}{Conventional Split Learning vs. BiCSL: (a) Split Learning utilizes numeric one-hot vectors of answer labels for model training, based on a unidirectional process that requires sequential processing of components resulting in longer waiting time. (b) BiCSL employs lexical semantic notions of answer texts and a bidirectional process that enables concurrent processing of model components.}{}{}}
\newlabel{fig:heat}{{3}{4}{Measured dot product similarity between any two representations in one batch before and after training with BiCSL. The similarity scores are optimized such that the representations of positive pairs have a higher score while that of the negative pairs have a lower score.}{}{}}
\newlabel{BiCSL}{{1}{4}{BiCSL}{}{}}
\citation{vqabase}
\citation{coco}
\citation{mfb}
\citation{butd}
\citation{ban}
\citation{mmnas}
\citation{mcan}
\citation{pennington2014glove}
\citation{patrick2020}
\citation{mcan,mmnas}
\newlabel{fig:arch}{{4}{5}{The model architectures of the nonlinear head adapter (NHA), the linear tail adapter (LTA), and the answer projection network (APN). The number of neurons in each layer is indicated by the numbers within square brackets.}{}{}}
\newlabel{sec:models}{{}{5}{}{}{}}
\newlabel{structure}{{}{5}{}{}{}}
\newlabel{eq:acc}{{4}{5}{}{}{}}
\citation{t-test}
\citation{t-test}
\citation{san}
\citation{patch4,instance}
\citation{patch4}
\newlabel{tab:BiCSL}{{2}{6}{The performance comparison between VQA models based on the contrastive learning (centralized) method and the proposed BiCSL (decentralized) method. In BiCSL, each client trains a contrastive learning-based model on their local datasets. Then, a global model is trained over the entire data distribution via inter-client weight sharing. The results showed that BiCSL could achieve competitive performance to the centralized VQA method while ensuring client privacy.}{}{}}
\newlabel{fig:attention}{{5}{6}{The attention mechanism identifies the important regions that are relevant to answering the given question. These attention maps were generated by computing the weight matrix from the attention mechanism. The top images are associated with a question asking about the color of the sail, and the sail is highlighted. The bottom images are associated with a question asking about the number of dogs the man is walking, and the dogs are highlighted.}{}{}}
\citation{mcan}
\citation{dp}
\bibdata{aaai24}
\newlabel{fig:adv}{{6}{7}{Samples of the generated dual-key Trojans. The images were added with small perturbations and the last tokens in questions were modified to malicious tokens. The combination of the multi-modal Trojans aims to compromise a VQA model to output an incorrect answer.}{}{}}
\newlabel{fig:robustness}{{7}{7}{VQA task performance under the Trojan attack. BiCSL maintained much stronger robustness against such attacks than the single fusion and split learning methods. Compared to the split learning method, BiCSL leverages the self-supervised learning of input data, which increases the difficulty of generating effective Trojans for the attack. Moreover, compared to the single fusion method that exposes the entire model, BiCSL leverages a decentralized learning method with inter-module gradient sharing to avoid sharing the entire VQA model. As a result, the incomplete information on the target model degraded the successability of the attack in generating an effective Trojan to mount the attack.}{}{}}
\gdef \@abspage@last{8}
