\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Bernstein et~al.(2002)Bernstein, Givan, Immerman, and
  Zilberstein}]{bernstein2002complexity}
Bernstein, D.~S.; Givan, R.; Immerman, N.; and Zilberstein, S. 2002.
\newblock The complexity of decentralized control of Markov decision processes.
\newblock \emph{Mathematics of operations research}, 27(4): 819--840.

\bibitem[{Best et~al.(2019)Best, Cliff, Patten, Mettu, and Fitch}]{best2019dec}
Best, G.; Cliff, O.~M.; Patten, T.; Mettu, R.~R.; and Fitch, R. 2019.
\newblock Dec-MCTS: Decentralized planning for multi-robot active perception.
\newblock \emph{The International Journal of Robotics Research}, 38(2-3):
  316--337.

\bibitem[{Browne et~al.(2012)Browne, Powley, Whitehouse, Lucas, Cowling,
  Rohlfshagen, Tavener, Perez, Samothrakis, and Colton}]{browne2012survey}
Browne, C.~B.; Powley, E.; Whitehouse, D.; Lucas, S.~M.; Cowling, P.~I.;
  Rohlfshagen, P.; Tavener, S.; Perez, D.; Samothrakis, S.; and Colton, S.
  2012.
\newblock A survey of monte carlo tree search methods.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  games}, 4(1): 1--43.

\bibitem[{Dam et~al.(2022)Dam, Chalvatzaki, Peters, and
  Pajarinen}]{dam2022monte}
Dam, T.; Chalvatzaki, G.; Peters, J.; and Pajarinen, J. 2022.
\newblock Monte-Carlo robot path planning.
\newblock \emph{IEEE Robotics and Automation Letters}, 7(4): 11213--11220.

\bibitem[{Damani et~al.(2021)Damani, Luo, Wenzel, and
  Sartoretti}]{damani2021primal}
Damani, M.; Luo, Z.; Wenzel, E.; and Sartoretti, G. 2021.
\newblock PRIMAL $ \_2 $: Pathfinding via reinforcement and imitation
  multi-agent learning-lifelong.
\newblock \emph{IEEE Robotics and Automation Letters}, 6(2): 2666--2673.

\bibitem[{Fawzi et~al.(2022)Fawzi, Balog, Huang, Hubert, Romera-Paredes,
  Barekatain, Novikov, R~Ruiz, Schrittwieser, Swirszcz
  et~al.}]{fawzi2022discovering}
Fawzi, A.; Balog, M.; Huang, A.; Hubert, T.; Romera-Paredes, B.; Barekatain,
  M.; Novikov, A.; R~Ruiz, F.~J.; Schrittwieser, J.; Swirszcz, G.; et~al. 2022.
\newblock Discovering faster matrix multiplication algorithms with
  reinforcement learning.
\newblock \emph{Nature}, 610(7930): 47--53.

\bibitem[{H{\"o}nig et~al.(2018)H{\"o}nig, Kiesel, Tinka, Durham, and
  Ayanian}]{honig2018conflict}
H{\"o}nig, W.; Kiesel, S.; Tinka, A.; Durham, J.; and Ayanian, N. 2018.
\newblock Conflict-based search with optimal task assignment.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and Multiagent Systems ({AAMAS} 2018)}, 757--765.

\bibitem[{Kaelbling, Littman, and Cassandra(1998)}]{Pack1998}
Kaelbling, L.~P.; Littman, M.~L.; and Cassandra, A.~R. 1998.
\newblock {Planning and acting in partially observable stochastic domains}.
\newblock \emph{Artificial Intelligence}, 101(1-2): 99--134.

\bibitem[{Lample et~al.(2022)Lample, Lacroix, Lachaux, Rodriguez, Hayat,
  Lavril, Ebner, and Martinet}]{lample2022hypertree}
Lample, G.; Lacroix, T.; Lachaux, M.-A.; Rodriguez, A.; Hayat, A.; Lavril, T.;
  Ebner, G.; and Martinet, X. 2022.
\newblock Hypertree proof search for neural theorem proving.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:
  26337--26349.

\bibitem[{Li et~al.(2021)Li, Tinka, Kiesel, Durham, Kumar, and
  Koenig}]{li2021lifelong}
Li, J.; Tinka, A.; Kiesel, S.; Durham, J.~W.; Kumar, T.~S.; and Koenig, S.
  2021.
\newblock Lifelong multi-agent path finding in large-scale warehouses.
\newblock In \emph{Proceedings of the 35th AAAI Conference on Artificial
  Intelligence ({AAAI} 2021)}, 11272--11281.

\bibitem[{Li et~al.(2020)Li, Gama, Ribeiro, and Prorok}]{li2020graph}
Li, Q.; Gama, F.; Ribeiro, A.; and Prorok, A. 2020.
\newblock Graph neural networks for decentralized multi-robot path planning.
\newblock In \emph{Proceedings of the 2020 IEEE/RSJ International Conference on
  Intelligent Robots and Systems ({IROS} 2020)}, 11785--11792. IEEE.

\bibitem[{Li et~al.(2022)Li, Chen, Jin, Tan, Zha, and
  Wang}]{Li2022MultiAgentPF}
Li, W.; Chen, H.; Jin, B.; Tan, W.; Zha, H.; and Wang, X. 2022.
\newblock Multi-Agent Path Finding with Prioritized Communication Learning.
\newblock \emph{2022 International Conference on Robotics and Automation
  (ICRA)}, 10695--10701.

\bibitem[{Liu et~al.(2020)Liu, Chen, Zhou, Koushik, Hebert, and Zhao}]{9340876}
Liu, Z.; Chen, B.; Zhou, H.; Koushik, G.; Hebert, M.; and Zhao, D. 2020.
\newblock MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement
  Learning in Mixed Dynamic Environments.
\newblock In \emph{2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, 11748--11754.

\bibitem[{Ma et~al.(2019)Ma, Harabor, Stuckey, Li, and
  Koenig}]{ma2019searching}
Ma, H.; Harabor, D.; Stuckey, P.~J.; Li, J.; and Koenig, S. 2019.
\newblock Searching with consistent prioritization for multi-agent path
  finding.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, 7643--7650.

\bibitem[{Ma and Koenig(2016)}]{ma2016optimal}
Ma, H.; and Koenig, S. 2016.
\newblock Optimal Target Assignment and Path Finding for Teams of Agents.
\newblock In \emph{Proceedings of the 15th International Conference on
  Autonomous Agents and Multiagent Systems ({AAMAS} 2016)}, 1144--1152.

\bibitem[{Ma, Luo, and Ma(2021)}]{ma2021distributed}
Ma, Z.; Luo, Y.; and Ma, H. 2021.
\newblock Distributed heuristic multi-agent path finding with communication.
\newblock In \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, 8699--8705. IEEE.

\bibitem[{Peng et~al.(2021)Peng, Rashid, Schroeder~de Witt, Kamienny, Torr,
  B{\"o}hmer, and Whiteson}]{peng2021facmac}
Peng, B.; Rashid, T.; Schroeder~de Witt, C.; Kamienny, P.-A.; Torr, P.;
  B{\"o}hmer, W.; and Whiteson, S. 2021.
\newblock Facmac: Factored multi-agent centralised policy gradients.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:
  12208--12221.

\bibitem[{Riviere et~al.(2020)Riviere, H{\"o}nig, Yue, and
  Chung}]{riviere2020glas}
Riviere, B.; H{\"o}nig, W.; Yue, Y.; and Chung, S.-J. 2020.
\newblock Glas: Global-to-local safe autonomy synthesis for multi-robot motion
  planning with end-to-end learning.
\newblock \emph{IEEE Robotics and Automation Letters}, 5(3): 4249--4256.

\bibitem[{Rosin(2011)}]{rosin_multi-armed_2011}
Rosin, C.~D. 2011.
\newblock Multi-armed bandits with episode context.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 61(3):
  203--230.

\bibitem[{Sartoretti et~al.(2019)Sartoretti, Kerr, Shi, Wagner, Kumar, Koenig,
  and Choset}]{sartoretti2019primal}
Sartoretti, G.; Kerr, J.; Shi, Y.; Wagner, G.; Kumar, T.~S.; Koenig, S.; and
  Choset, H. 2019.
\newblock Primal: Pathfinding via reinforcement and imitation multi-agent
  learning.
\newblock \emph{IEEE Robotics and Automation Letters}, 4(3): 2378--2385.

\bibitem[{Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert,
  Simonyan, Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel
  et~al.}]{schrittwieser2020mastering}
Schrittwieser, J.; Antonoglou, I.; Hubert, T.; Simonyan, K.; Sifre, L.;
  Schmitt, S.; Guez, A.; Lockhart, E.; Hassabis, D.; Graepel, T.; et~al. 2020.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 588(7839): 604--609.

\bibitem[{Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov}]{schulman2017proximal}
Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and Klimov, O. 2017.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}.

\bibitem[{Sharon et~al.(2015)Sharon, Stern, Felner, and
  Sturtevant}]{sharon2015conflict}
Sharon, G.; Stern, R.; Felner, A.; and Sturtevant, N.~R. 2015.
\newblock Conflict-based search for optimal multi-agent pathfinding.
\newblock \emph{Artificial Intelligence}, 219: 40--66.

\bibitem[{Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, van~den
  Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman,
  Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel,
  and Hassabis}]{Silver2016}
Silver, D.; Huang, A.; Maddison, C.~J.; Guez, A.; Sifre, L.; van~den Driessche,
  G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.;
  Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.;
  Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D.
  2016.
\newblock Mastering the game of {Go} with deep neural networks and tree search.
\newblock \emph{Nature}, 529(7587): 484--489.

\bibitem[{Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou,
  Huang, Guez, Hubert, Baker, Lai, Bolton et~al.}]{silver2017mastering}
Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.; Huang, A.; Guez,
  A.; Hubert, T.; Baker, L.; Lai, M.; Bolton, A.; et~al. 2017.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{nature}, 550(7676): 354--359.

\bibitem[{Skrynnik et~al.(2021)Skrynnik, Yakovleva, Davydov, Yakovlev, and
  Panov}]{skrynnik2021hybrid}
Skrynnik, A.; Yakovleva, A.; Davydov, V.; Yakovlev, K.; and Panov, A.~I. 2021.
\newblock Hybrid Policy Learning for Multi-Agent Pathfinding.
\newblock \emph{IEEE Access}, 9: 126034--126047.

\bibitem[{Stern et~al.(2019)Stern, Sturtevant, Felner, Koenig, Ma, Walker, Li,
  Atzmon, Cohen, Kumar et~al.}]{stern2019multi}
Stern, R.; Sturtevant, N.; Felner, A.; Koenig, S.; Ma, H.; Walker, T.; Li, J.;
  Atzmon, D.; Cohen, L.; Kumar, T.; et~al. 2019.
\newblock Multi-agent pathfinding: Definitions, variants, and benchmarks.
\newblock In \emph{Proceedings of the International Symposium on Combinatorial
  Search}, volume~10, 151--158.

\bibitem[{Wagner and Choset(2011)}]{Wagner2011}
Wagner, G.; and Choset, H. 2011.
\newblock M*: {A} complete multirobot path planning algorithm with performance
  bounds.
\newblock In \emph{Proceedings of The 2011 {IEEE/RSJ} International Conference
  on Intelligent Robots and Systems ({IROS} 2011)}, 3260--3267.

\bibitem[{Wang et~al.(2020)Wang, Liu, Li, and Prorok}]{Wang2020}
Wang, B.; Liu, Z.; Li, Q.; and Prorok, A. 2020.
\newblock {Mobile robot path planning in dynamic environments through globally
  guided reinforcement learning}.
\newblock \emph{IEEE Robotics and Automation Letters}, 5(4): 6932--6939.

\bibitem[{Wang et~al.(2023)Wang, Xiang, Huang, and
  Sartoretti}]{wang_scrimp_2023}
Wang, Y.; Xiang, B.; Huang, S.; and Sartoretti, G. 2023.
\newblock {SCRIMP}: {Scalable} {Communication} for {Reinforcement}- and
  {Imitation}-{Learning}-{Based} {Multi}-{Agent} {Pathfinding}.
\newblock In \emph{Proceedings of the 2023 {International} {Conference} on
  {Autonomous} {Agents} and {Multiagent} {Systems}}, 2598--2600.

\bibitem[{Ye et~al.(2021)Ye, Liu, Kurutach, Abbeel, and Gao}]{ye2021mastering}
Ye, W.; Liu, S.; Kurutach, T.; Abbeel, P.; and Gao, Y. 2021.
\newblock Mastering atari games with limited data.
\newblock \emph{Advances in Neural Information Processing Systems}, 34.

\bibitem[{Yu et~al.(2022)Yu, Velu, Vinitsky, Gao, Wang, Bayen, and
  Wu}]{yu2022surprising}
Yu, C.; Velu, A.; Vinitsky, E.; Gao, J.; Wang, Y.; Bayen, A.; and Wu, Y. 2022.
\newblock The surprising effectiveness of ppo in cooperative multi-agent games.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:
  24611--24624.

\bibitem[{Zerbel and Yliniemi(2019)}]{zerbel2019multiagent}
Zerbel, N.; and Yliniemi, L. 2019.
\newblock Multiagent monte carlo tree search.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, 2309--2311.

\end{thebibliography}
