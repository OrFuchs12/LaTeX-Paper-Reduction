\relax 
\bibstyle{aaai24}
\citation{jin2020uncertainty,ye2021deep,zhang2021person}
\citation{jia2022learning,wang2022pedestrian}
\citation{yu2022multi}
\citation{jia2021spatial,niu2022cross,specker2023upar,zheng2022progressive}
\@LN@col{1}
\@LN@col{2}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{subfig:example_a}{{1a}{1}{Retrieval results with limited coarse-grained attributes}{}{}}
\newlabel{sub@subfig:example_a}{{a}{1}{Retrieval results with limited coarse-grained attributes}{}{}}
\newlabel{subfig:example_b}{{1b}{1}{Retrieval results with only implicit attribute prompts}{}{}}
\newlabel{sub@subfig:example_b}{{b}{1}{Retrieval results with only implicit attribute prompts}{}{}}
\newlabel{subfig:example_c}{{1c}{1}{Retrieval results with multiple fine-grained attribute prompts}{}{}}
\newlabel{sub@subfig:example_c}{{c}{1}{Retrieval results with multiple fine-grained attribute prompts}{}{}}
\newlabel{fig:example}{{1}{1}{Comparison of various usages of attributes for person ReID, where red boxes represent negative images, green boxes indicate positive results and key attribute words have been marked in red. We can see that using multiple fine human attributes as prompts in ReID brought advancements.}{}{}}
\citation{fu2022large,jin2022meta,li2023blip2}
\citation{wu2022fast,zhou2022learning}
\citation{zeng2022point,luddecke2022image,liu2022dpt}
\citation{yu2019mcan,Wang2022vqa}
\citation{radford2021learning}
\citation{petroni2019language,song2022v2p,jin2023domain}
\citation{peng2023instruction}
\citation{zhang2023one}
\citation{ju2022prompting,rao2022denseclip}
\citation{li2019attribute}
\citation{zhang2020person}
\citation{jeong2021asmr}
\citation{li2022clip}
\@LN@col{1}
\@LN@col{2}
\citation{he2021dense,zhu2023learning}
\citation{dosovitskiy2020vit}
\citation{sennrich2016neural}
\newlabel{frameangel}{{2}{3}{The graphical representation of MP-ReID for ReID. Under the prompt learning paradigm, the multi-prompts generated by ChatGPT and VQA are regarded as the textual input to the multi-modal Transformer, which can enhance the retrieval of the matching person images. It is built upon three components: 1) Multi-Prompts Generation Learning; 2) Cross-Modal Alignment; 3) Person Retrieval.}{}{}}
\@LN@col{1}
\newlabel{methodology}{{}{3}{}{}{}}
\@LN@col{2}
\newlabel{mpgl}{{}{3}{}{}{}}
\newlabel{eqn1}{{1}{3}{}{}{}}
\newlabel{eqn2}{{2}{3}{}{}{}}
\citation{yu2019mcan}
\citation{zhou2022learning,zhou2022conditional}
\citation{li2022clip}
\citation{chen2022video}
\citation{zhai2022trireid}
\citation{luo2019bag}
\@LN@col{1}
\newlabel{frameprompt}{{\caption@xref {frameprompt}{ on input line 337}}{4}{}{}{}}
\newlabel{frameprompt}{{3}{4}{The process of multi-prompts generation learning in the proposed MP-ReID framework. The top is the question bank and answer bank of VQA model; and the bottom is the concrete multi-prompts generation from the VQA prompt, ChatGPT prompt and learnable prompt, respectively.}{}{}}
\@LN@col{2}
\newlabel{mma}{{}{4}{}{}{}}
\newlabel{eqn3}{{3}{4}{}{}{}}
\citation{hermans2017defense}
\citation{zheng2017person}
\citation{zheng2015scalable}
\citation{zheng2017unlabeled}
\citation{lin2019improving}
\citation{wang2021beyond,farooq2022axm}
\newlabel{tab:sotas}{{\caption@xref {tab:sotas}{ on input line 353}}{5}{}{}{}}
\@LN@col{1}
\newlabel{eqn8}{{6}{5}{}{}{}}
\newlabel{eqn5}{{7}{5}{}{}{}}
\newlabel{eqn6}{{8}{5}{}{}{}}
\newlabel{eqn7}{{9}{5}{}{}{}}
\newlabel{eqn8}{{10}{5}{}{}{}}
\newlabel{pr}{{}{5}{}{}{}}
\@LN@col{2}
\newlabel{eqn8}{{11}{5}{}{}{}}
\newlabel{eqn9}{{12}{5}{}{}{}}
\newlabel{eqn7}{{13}{5}{}{}{}}
\newlabel{eqn7}{{14}{5}{}{}{}}
\newlabel{expd}{{}{5}{}{}{}}
\citation{chen2021explainable}
\citation{chen2021explainable}
\citation{sun2018beyond}
\citation{specker2023upar}
\citation{li2022clip}
\citation{jin2020semantics}
\citation{li2021diverse}
\citation{he2021transreid}
\citation{cheng2022more}
\citation{zhu2022dual}
\newlabel{ablationsm}{{\caption@xref {ablationsm}{ on input line 432}}{6}{}{}{}}
\@LN@col{1}
\newlabel{sec:expcompare}{{}{6}{}{}{}}
\@LN@col{2}
\newlabel{visual1}{{\caption@xref {visual1}{ on input line 498}}{6}{}{}{}}
\newlabel{visual1}{{4}{6}{Ablation study on the effect of reducing various sub-prompts for MP-ReID.}{}{}}
\newlabel{abstudy}{{}{6}{}{}{}}
\@LN@col{1}
\newlabel{visual3}{{5}{7}{Visualization of three examples that illustrate the retrieval results about a) baseline (implicit learnable prompt); b) + coarse and separate attribute words; and c) our MP-ReID. Thereinto, the green box denotes the same ID as the query image, and the red box indicates a different ID from the query image.}{}{}}
\newlabel{visualizations}{{}{7}{}{}{}}
\@LN@col{2}
\@LN@col{1}
\@LN@col{2}
\bibdata{aaai24}
\gdef \@abspage@last{8}
