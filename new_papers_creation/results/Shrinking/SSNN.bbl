\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Amir et~al.(2017)}]{DVS-Gesture}
Amir, A.; et~al. 2017.
\newblock A Low Power, Fully Event-Based Gesture Recognition System.
\newblock In \emph{2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 7388--7397.

\bibitem[{Cavanagh, Hunt, and Kennerley(2020)}]{10.3389/fncir.2020.615626}
Cavanagh, S.~E.; Hunt, L.~T.; and Kennerley, S.~W. 2020.
\newblock A Diversity of Intrinsic Timescales Underlie Neural Computations.
\newblock \emph{Frontiers in Neural Circuits}, 14.

\bibitem[{Deng et~al.(2020)}]{DENG2020294}
Deng, L.; et~al. 2020.
\newblock Rethinking the performance comparison between SNNS and ANNS.
\newblock \emph{Neural Networks}, 121: 294--307.

\bibitem[{Deng et~al.(2022)Deng, Li, Zhang, and Gu}]{TET}
Deng, S.; Li, Y.; Zhang, S.; and Gu, S. 2022.
\newblock Temporal Efficient Training of Spiking Neural Network via Gradient
  Re-weighting.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Ding et~al.(2022)}]{ding2022biologically}
Ding, J.; et~al. 2022.
\newblock Biologically Inspired Dynamic Thresholds for Spiking Neural Networks.
\newblock In Oh, A.~H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds.,
  \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Ding et~al.(2023)Ding, Zuo, Yang, Chen, Hu, and Xiahou}]{PALIF}
Ding, Y.; Zuo, L.; Yang, K.; Chen, Z.; Hu, J.; and Xiahou, T. 2023.
\newblock An improved probabilistic spiking neural network with enhanced
  discriminative ability.
\newblock \emph{Knowledge-Based Systems}, 280: 111024.

\bibitem[{Duan et~al.(2022)Duan, Ding, Chen, Yu, and Huang}]{TEBN}
Duan, C.; Ding, J.; Chen, S.; Yu, Z.; and Huang, T. 2022.
\newblock Temporal Effective Batch Normalization in Spiking Neural Networks.
\newblock In Koyejo, S.; Mohamed, S.; Agarwal, A.; Belgrave, D.; Cho, K.; and
  Oh, A., eds., \emph{Advances in Neural Information Processing Systems},
  volume~35, 34377--34390. Curran Associates, Inc.

\bibitem[{Fang et~al.(2020)Fang, Chen, Ding, Chen, Yu, Zhou, Tian, and other
  contributors}]{SpikingJelly}
Fang, W.; Chen, Y.; Ding, J.; Chen, D.; Yu, Z.; Zhou, H.; Tian, Y.; and other
  contributors. 2020.
\newblock SpikingJelly.
\newblock \url{https://github.com/fangwei123456/spikingjelly}.

\bibitem[{Fang et~al.(2021{\natexlab{a}})Fang, Yu, Chen, Huang, Masquelier, and
  Tian}]{SEWResNet}
Fang, W.; Yu, Z.; Chen, Y.; Huang, T.; Masquelier, T.; and Tian, Y.
  2021{\natexlab{a}}.
\newblock Deep Residual Learning in Spiking Neural Networks.
\newblock In Ranzato, M.; Beygelzimer, A.; Dauphin, Y.; Liang, P.; and Vaughan,
  J.~W., eds., \emph{Advances in Neural Information Processing Systems},
  volume~34, 21056--21069. Curran Associates, Inc.

\bibitem[{Fang et~al.(2021{\natexlab{b}})Fang, Yu, Chen, Masquelier, Huang, and
  Tian}]{PLIF}
Fang, W.; Yu, Z.; Chen, Y.; Masquelier, T.; Huang, T.; and Tian, Y.
  2021{\natexlab{b}}.
\newblock Incorporating Learnable Membrane Time Constant To Enhance Learning of
  Spiking Neural Networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2661--2671.

\bibitem[{Feng et~al.(2022)Feng, Liu, Tang, Ma, and Pan}]{MLF}
Feng, L.; Liu, Q.; Tang, H.; Ma, D.; and Pan, G. 2022.
\newblock Multi-{Level} {Firing} with {Spiking} {DS}-{ResNet}: {Enabling}
  {Better} and {Deeper} {Directly}-{Trained} {Spiking} {Neural} {Networks}.
\newblock In \emph{IJCAI}, 2471--2477. International Joint Conferences on
  Artificial Intelligence Organization.

\bibitem[{Guo et~al.(2022{\natexlab{a}})}]{NEURIPS2022_010c5ba0}
Guo, Y.; et~al. 2022{\natexlab{a}}.
\newblock IM-Loss: Information Maximization Loss for Spiking Neural Networks.
\newblock In Koyejo, S.; Mohamed, S.; Agarwal, A.; Belgrave, D.; Cho, K.; and
  Oh, A., eds., \emph{Advances in Neural Information Processing Systems},
  volume~35, 156--166. Curran Associates, Inc.

\bibitem[{Guo et~al.(2022{\natexlab{b}})}]{Guo_2022_CVPR}
Guo, Y.; et~al. 2022{\natexlab{b}}.
\newblock RecDis-SNN: Rectifying Membrane Potential Distribution for Directly
  Training Spiking Neural Networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 326--335.

\bibitem[{Kim et~al.(2022)Kim, Li, Park, Venkatesha, Hambitzer, and
  Panda}]{kim2022exploring}
Kim, Y.; Li, Y.; Park, H.; Venkatesha, Y.; Hambitzer, A.; and Panda, P. 2022.
\newblock Exploring Temporal Information Dynamics in Spiking Neural Networks.
\newblock arXiv:2211.14406.

\bibitem[{Li, Jones, and Furber(2023)}]{li2023unleashing}
Li, C.; Jones, E.; and Furber, S. 2023.
\newblock Unleashing the Potential of Spiking Neural Networks by Dynamic
  Confidence.
\newblock arXiv:2303.10276.

\bibitem[{Li et~al.(2017)Li, Liu, Ji, Li, and Shi}]{CIFAR10-DVS}
Li, H.; Liu, H.; Ji, X.; Li, G.; and Shi, L. 2017.
\newblock CIFAR10-DVS: An Event-Stream Dataset for Object Classification.
\newblock \emph{Frontiers in Neuroscience}, 11.

\bibitem[{Li et~al.(2023)Li, Geller, Kim, and Panda}]{SEENN}
Li, Y.; Geller, T.; Kim, Y.; and Panda, P. 2023.
\newblock SEENN: Towards Temporal Spiking Early-Exit Neural Networks.
\newblock arXiv:2304.01230.

\bibitem[{Li et~al.(2022)Li, Kim, Park, Geller, and Panda}]{NDA}
Li, Y.; Kim, Y.; Park, H.; Geller, T.; and Panda, P. 2022.
\newblock Neuromorphic Data Augmentation for Training Spiking Neural Networks.
\newblock In Avidan, S.; Brostow, G.; Ciss{\'e}, M.; Farinella, G.~M.; and
  Hassner, T., eds., \emph{Computer Vision -- ECCV 2022}, 631--649. Cham:
  Springer Nature Switzerland.

\bibitem[{Maass(1997)}]{MAASS19971659}
Maass, W. 1997.
\newblock Networks of spiking neurons: The third generation of neural network
  models.
\newblock \emph{Neural Networks}, 10(9): 1659--1671.

\bibitem[{Meng et~al.(2022)Meng, Xiao, Yan, Wang, Lin, and Luo}]{DSR}
Meng, Q.; Xiao, M.; Yan, S.; Wang, Y.; Lin, Z.; and Luo, Z.-Q. 2022.
\newblock Training High-Performance Low-Latency Spiking Neural Networks by
  Differentiation on Spike Representation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 12444--12453.

\bibitem[{Meng et~al.(2023)Meng, Xiao, Yan, Wang, Lin, and Luo}]{SLTT}
Meng, Q.; Xiao, M.; Yan, S.; Wang, Y.; Lin, Z.; and Luo, Z.-Q. 2023.
\newblock Towards Memory- and Time-Efficient Backpropagation for Training
  Spiking Neural Networks.
\newblock arXiv:2302.14311.

\bibitem[{Na et~al.(2022)Na, Mok, Park, Lee, Choe, and Yoon}]{AutoSNN}
Na, B.; Mok, J.; Park, S.; Lee, D.; Choe, H.; and Yoon, S. 2022.
\newblock {A}uto{SNN}: Towards Energy-Efficient Spiking Neural Networks.
\newblock In Chaudhuri, K.; Jegelka, S.; Song, L.; Szepesvari, C.; Niu, G.; and
  Sabato, S., eds., \emph{Proceedings of the 39th International Conference on
  Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning
  Research}, 16253--16269. PMLR.

\bibitem[{Orchard et~al.(2015)Orchard, Jayawant, Cohen, and
  Thakor}]{N-Caltech101}
Orchard, G.; Jayawant, A.; Cohen, G.~K.; and Thakor, N. 2015.
\newblock Converting Static Image Datasets to Spiking Neuromorphic Datasets
  Using Saccades.
\newblock \emph{Frontiers in Neuroscience}, 9.

\bibitem[{Ponghiran and Roy(2022)}]{ponghiran_spiking_2022}
Ponghiran, W.; and Roy, K. 2022.
\newblock Spiking {Neural} {Networks} with {Improved} {Inherent} {Recurrence}
  {Dynamics} for {Sequential} {Learning}.
\newblock In \emph{Proceedings of the {AAAI} {Conference} on {Artificial}
  {Intelligence}}, 8001--8008.

\bibitem[{Shen, Zhao, and Zeng(2022)}]{eventmix}
Shen, G.; Zhao, D.; and Zeng, Y. 2022.
\newblock EventMix: An Efficient Augmentation Strategy for Event-Based Data.
\newblock arXiv:2205.12054.

\bibitem[{Sun et~al.(2023)Sun, Zeng, Zhao, and Zhao}]{sun2023multicompartment}
Sun, Y.; Zeng, Y.; Zhao, F.; and Zhao, Z. 2023.
\newblock Multi-compartment Neuron and Population Encoding improved Spiking
  Neural Network for Deep Distributional Reinforcement Learning.
\newblock arXiv:2301.07275.

\bibitem[{Teerapittayanon, McDanel, and Kung(2016)}]{BranchyNet}
Teerapittayanon, S.; McDanel, B.; and Kung, H. 2016.
\newblock BranchyNet: Fast inference via early exiting from deep neural
  networks.
\newblock In \emph{2016 23rd International Conference on Pattern Recognition
  (ICPR)}, 2464--2469.

\bibitem[{Wu et~al.(2018)Wu, Deng, Li, Zhu, and Shi}]{STBP}
Wu, Y.; Deng, L.; Li, G.; Zhu, J.; and Shi, L. 2018.
\newblock Spatio-Temporal Backpropagation for Training High-Performance Spiking
  Neural Networks.
\newblock \emph{Frontiers in Neuroscience}, 12.

\bibitem[{Xu, Liu, and Yang(2023)}]{SLSSNN}
Xu, C.; Liu, Y.; and Yang, Y. 2023.
\newblock SLSSNN: High energy efficiency spike-train level spiking neural
  networks with spatio-temporal conversion.
\newblock arXiv:2307.07136.

\bibitem[{Xu et~al.(2023)}]{KD}
Xu, Q.; et~al. 2023.
\newblock Biologically inspired structure learning with reverse knowledge
  distillation for spiking neural networks.
\newblock arXiv:2304.09500.

\bibitem[{Yao et~al.(2023)Yao, Zhao, Zhang, Hu, Deng, Tian et~al.}]{10032591}
Yao, M.; Zhao, G.; Zhang, H.; Hu, Y.; Deng, L.; Tian, Y.; et~al. 2023.
\newblock Attention Spiking Neural Networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 1--18.

\bibitem[{Yao et~al.(2022)Yao, Li, Mo, and Cheng}]{GLIF}
Yao, X.; Li, F.; Mo, Z.; and Cheng, J. 2022.
\newblock {GLIF}: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking
  Neural Networks.
\newblock In Oh, A.~H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds.,
  \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Zhao, Zeng, and Li(2022)}]{BackEISNN}
Zhao, D.; Zeng, Y.; and Li, Y. 2022.
\newblock BackEISNN: A deep spiking neural network with adaptive self-feedback
  and balanced excitatory–inhibitory neurons.
\newblock \emph{Neural Networks}, 154: 68--77.

\bibitem[{Zheng et~al.(2021)Zheng, Wu, Deng, Hu, and Li}]{tdBN_2021}
Zheng, H.; Wu, Y.; Deng, L.; Hu, Y.; and Li, G. 2021.
\newblock Going {Deeper} {With} {Directly}-{Trained} {Larger} {Spiking}
  {Neural} {Networks}.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  35(12): 11062--11070.

\bibitem[{Zhou et~al.(2023)}]{Spikformer}
Zhou, Z.; et~al. 2023.
\newblock Spikformer: When Spiking Neural Network Meets Transformer.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}.

\bibitem[{Zuo et~al.(2020)Zuo, Chen, Zhang, and Chen}]{zuo2020spiking}
Zuo, L.; Chen, Y.; Zhang, L.; and Chen, C. 2020.
\newblock A spiking neural network with probability information transmission.
\newblock \emph{Neurocomputing}, 408: 1--12.

\end{thebibliography}
