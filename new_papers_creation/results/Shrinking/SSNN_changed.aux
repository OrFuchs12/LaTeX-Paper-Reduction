\relax 
\bibstyle{aaai24}
\citation{MAASS19971659}
\citation{DENG2020294}
\citation{zuo2020spiking,ponghiran_spiking_2022,PALIF}
\citation{PLIF,GLIF,ding2022biologically}
\citation{BackEISNN,sun2023multicompartment}
\citation{TET,Guo_2022_CVPR}
\citation{CIFAR10-DVS}
\citation{N-Caltech101}
\citation{DVS-Gesture}
\citation{MLF,GLIF}
\citation{li2023unleashing,SEENN}
\citation{li2023unleashing}
\citation{kim2022exploring}
\citation{10.3389/fncir.2020.615626}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{cal1}{{1}{1}{Comparative results of the proposed SSNN and existing SNNs (with an average timestep of 5). Results show that SSNN exceeds existing SNNs by a large margin.}{}{}}
\citation{MLF}
\citation{STBP}
\newlabel{Background}{{}{2}{}{}{}}
\newlabel{eq1}{{1}{2}{}{}{}}
\newlabel{eq2}{{2}{2}{}{}{}}
\newlabel{eq4}{{3}{2}{}{}{}}
\newlabel{eq5}{{4}{2}{}{}{}}
\newlabel{eq6}{{5}{2}{}{}{}}
\newlabel{eq7}{{6}{2}{}{}{}}
\newlabel{Method}{{}{2}{}{}{}}
\newlabel{TSAC}{{2}{3}{Overview of SSNN. The SSNN is divided into $n$ stages with gradually shrinking timesteps $\{T_1,T_2,\cdot \cdot \cdot , T_n\}$, and the temporal transformer transforms the temporal scale of the information. During training, an early classifier is added after each stage of the SSNN except the last one. The predictions generated by each early classifier are used to facilitate the optimization of the parameters by calculating the losses along with the ground truth (green arrows).}{}{}}
\newlabel{eq8}{{7}{3}{}{}{}}
\newlabel{eq9}{{8}{3}{}{}{}}
\newlabel{eq10}{{9}{3}{}{}{}}
\newlabel{eq12}{{10}{3}{}{}{}}
\citation{SEWResNet}
\citation{BranchyNet}
\citation{TET}
\citation{NEURIPS2022_010c5ba0}
\citation{CIFAR10-DVS}
\citation{N-Caltech101}
\citation{DVS-Gesture}
\citation{MLF}
\newlabel{eq14}{{11}{4}{}{}{}}
\newlabel{alg1}{{1}{4}{Training framework for SSNN}{}{}}
\newlabel{Experiments}{{}{4}{}{}{}}
\citation{DSR}
\citation{GLIF}
\citation{TET}
\citation{SLTT}
\citation{SLSSNN}
\citation{AutoSNN}
\citation{tdBN_2021}
\citation{PLIF}
\citation{BackEISNN}
\citation{MLF}
\citation{TEBN}
\citation{Spikformer}
\citation{eventmix}
\citation{NDA}
\citation{tdBN_2021}
\citation{PLIF}
\citation{BackEISNN}
\citation{MLF}
\citation{TEBN}
\citation{Spikformer}
\citation{KD}
\citation{tdBN_2021}
\citation{PLIF}
\citation{BackEISNN}
\citation{MLF}
\citation{TEBN}
\citation{Spikformer}
\newlabel{lambda}{{3}{5}{Influence of $\lambda $ on performance. The accuracy remains at [68.70\%,70.36\%] as long as $\lambda _1$, $\lambda _2$ and $\lambda _3$ are not zero, indicating that our method is not sensitive to $\lambda $.}{}{}}
\newlabel{ablation}{{1}{5}{Average test accuracy (\%) for ablation studies of timestep shrinkage (TS), early classifier (EC), and SSNN.}{}{}}
\newlabel{alm}{{4}{5}{Influence of the temporal transformer (TT). The performance of SNNs is severely degraded and inferior to the baseline without the temporal transformer.}{}{}}
\citation{Spikformer}
\citation{SLTT}
\citation{TET}
\citation{GLIF}
\citation{DSR}
\citation{Spikformer}
\citation{eventmix}
\citation{NDA}
\citation{NDA}
\citation{eventmix}
\citation{MLF}
\citation{MLF}
\citation{KD}
\newlabel{comparative }{{2}{6}{Comparative results with existing methods. * denotes self-implementation results. $\dag  $ indicates using data augmentation.}{}{}}
\citation{10032591}
\newlabel{stage}{{5}{7}{Influence of stage division and stage-wise timesteps, S$n\{t_1,t_2,... ,t_n\}$ denotes division into $n$ stages and stage-wise timestep of $\{t_1,t_2,... ,t_n\}$. Results indicate that our method is not sensitive to different stage divisions and stage-wise timesteps.}{}{}}
\newlabel{timestep}{{6}{7}{Influence of average timestep on performance. SSNN consistently outperforms the baseline and shows significant advantages, especially at low latencies.}{}{}}
\newlabel{firing_rate}{{7}{7}{Visualization of spike firing rate on DVS-Gesture. Compared to the vanilla SNN, SSNN can accurately focus on the hand region, which is crucial for gesture recognition.}{}{}}
\newlabel{Visualization}{{}{7}{}{}{}}
\newlabel{Conclusion}{{}{7}{}{}{}}
\citation{CIFAR10-DVS}
\citation{N-Caltech101}
\citation{SpikingJelly}
\citation{DVS-Gesture}
\citation{MLF,SEWResNet}
\citation{PLIF}
\citation{tdBN_2021}
\citation{BackEISNN}
\citation{MLF}
\citation{TEBN}
\citation{Spikformer}
\newlabel{Supplementary Material}{{}{8}{}{}{}}
\newlabel{model}{{3}{9}{Structures of VGG-9 and ResNet-18, where fc denotes the fully connected layer.}{}{}}
\newlabel{accuracy}{{8}{9}{Accuracy curves during training (left: CIFAR10-DVS, middle: N-Caltech101, right: DVS-Gesture). }{}{}}
\newlabel{timestep setting}{{4}{9}{Stage-wise timestep setting at average timestep range from 3 to 10.}{}{}}
\newlabel{highlatency}{{\caption@xref {highlatency}{ on input line 553}}{9}{}{}{}}
\bibdata{SSNN}
\gdef \@abspage@last{10}
