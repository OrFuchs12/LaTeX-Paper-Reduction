\relax 
\bibstyle{aaai21}
\citation{huang2013learning}
\citation{hu2014convolutional}
\citation{shen2014latent}
\citation{guo2016deep}
\citation{xiong2017end}
\citation{hui2017pacrr,hui2018co}
\citation{guo2016deep}
\citation{pang2016text,pang2017deeprank,hui2017pacrr}
\@LN@col{1}
\@LN@col{2}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1a}{{1(a)}{1}{}{}{}}
\newlabel{sub@fig:1a}{{(a)}{1}}
\newlabel{fig:1b}{{1(b)}{1}{}{}{}}
\newlabel{sub@fig:1b}{{(b)}{1}}
\newlabel{fig:1c}{{1(c)}{1}{}{}{}}
\newlabel{sub@fig:1c}{{(c)}{1}}
\newlabel{fig:1}{{\caption@xref {fig:1}{ on input line 19}}{1}{}{}{}}
\citation{yao2019graph}
\citation{zhang2020every}
\citation{rousseau2015text}
\citation{huang2013learning}
\citation{hu2014convolutional}
\citation{shen2014latent}
\citation{pang2016text}
\citation{guo2016deep}
\citation{hui2017pacrr}
\citation{xiong2017end}
\citation{huang2013learning}
\citation{hu2014convolutional}
\citation{shen2014latent}
\citation{guo2016deep}
\citation{xiong2017end}
\citation{dai2018convolutional}
\citation{pang2016text,pang2017deeprank,hui2017pacrr,hui2018co,fan2018modeling}
\citation{dai2019deeper}
\citation{macavaney2019cedr}
\citation{scarselli2008graph}
\citation{li2016gated,kipf2017semi,hamilton2017inductive,velivckovic2018graph}
\citation{wu2019session,li2019fi}
\citation{yao2019graph,zhang2020every}
\citation{de2019question}
\citation{li2019spam}
\@LN@col{1}
\@LN@col{2}
\citation{mikolov2013distributed}
\citation{kipf2017semi}
\newlabel{fig:2}{{2}{3}{The workflow of the GRMM model. The document is first transformed into the graph-of-word form, where the node feature is the similarity between the word and each query term. Then, graph neural networks are applied to propagate these matching signals on the document graph. Finally, to estimate a relevance score, top-$k$ signals of each query term are chosen to filter out irrelevant noisy information, and their features are fed into a dense neural layer. }{}{}}
\@LN@col{1}
\newlabel{sec:graphconstruct}{{3.2}{3}{}{}{}}
\@LN@col{2}
\citation{li2016gated}
\citation{kipf2017semi}
\citation{guo2016deep}
\citation{guo2016deep}
\@LN@col{1}
\@LN@col{2}
\citation{zhai2004study}
\citation{robertson1994some}
\citation{pang2016text}
\citation{guo2016deep}
\citation{xiong2017end}
\citation{hui2017pacrr}
\citation{hui2018co}
\citation{dai2019deeper}
\citation{mikolov2013distributed}
\citation{macavaney2019cedr}
\@LN@col{1}
\@LN@col{2}
\newlabel{tab:1}{{1}{5}{Statistics of datasets.}{}{}}
\citation{guo2016deep}
\@LN@col{1}
\newlabel{tab:2}{{2}{6}{Performance comparison of different methods. The best performances on each dataset and metric are highlighted. Significant performance degradation with respect to GRMM is indicated (-) with p-value $\leq $ 0.05.}{}{}}
\newlabel{sec:modelcompare}{{4.2}{6}{}{}{}}
\newlabel{sec:graphstructure}{{4.3}{6}{}{}{}}
\@LN@col{2}
\newlabel{fig:3}{{3}{6}{Ablation study on graph structure of GRMM.}{}{}}
\newlabel{sec:neighbouraggre}{{4.4}{6}{}{}{}}
\citation{kipf2017semi}
\citation{jiang2016learning}
\bibdata{ref.bib}
\@LN@col{1}
\newlabel{fig:4}{{4}{7}{Influence of different graph layer numbers.}{}{}}
\newlabel{sec:featureelect}{{4.5}{7}{}{}{}}
\@LN@col{2}
\newlabel{fig:5}{{5}{7}{Influence of different $k$ values of $k$-max pooling.}{}{}}
\@LN@col{1}
\@LN@col{2}
\gdef \@abspage@last{8}
