\relax 
\bibstyle{aaai24}
\citation{misra2017red,purushwalkam2019task}
\citation{mit}
\citation{resnet}
\citation{mit}
\citation{resnet}
\citation{misra2017red,li2020symmetry,purushwalkam2019task,li2022siamese}
\citation{naeem2021learning,mancini2021open,mancini2022learning}
\citation{menon2020long,tang2020unbiased,kim2020detecting}
\citation{atzmon2020causal}
\citation{saini2022disentangling,wang2023learning}
\citation{menon2020long}
\newlabel{sec:intro}{{}{1}{}{}{}}
\citation{xian2017zero}
\citation{chen2022zero}
\citation{akata2013label,lampert2013attribute,parikh2011relative,frome2013devise,akata2015evaluation}
\citation{atzmon2020causal,yang2022decomposable,nagarajan2018attributes,wang2019task}
\citation{hoffman1984parts}
\citation{misra2017red,chen2014inferring,yang2020learning,lu2016visual,li2022siamese}
\citation{naeem2021learning,mancini2022learning,mancini2021open}
\citation{saini2022disentangling}
\citation{wang2023learning}
\citation{long1,long3,hou2021detecting,menon2020long,focal}
\citation{chen2022zero}
\citation{jiang2022mutual}
\citation{xian2017zero}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{2}{An example of prior and posterior probabilities (predicted by model) of same classes in MIT-States \citep  {mit}. N.S. represents the prior probability calculated from the number of samples in each class. P. denotes the average value of posterior probabilities indicating the likelihood of the sample belonging to its class, which is predicted by a MLP with ResNet-18 \citep  {resnet} as backbone (same settings as $\mathcal  {C}_{o},\mathcal  {C}_{s}$ and $\mathcal  {C}_{y}$ in Implementation Details and trained via vanilla cross-entropy loss). The classes are selected on the basis of the closest sample size, and shows the results for the object (left), state (middle), and composition (right) classes. All data is simply normalized for ease of presentation.}{}{}}
\newlabel{sec.related}{{}{2}{}{}{}}
\newlabel{Sec.methodology}{{}{2}{}{}{}}
\newlabel{subsec.taskdefine}{{}{2}{}{}{}}
\citation{mancini2021open}
\citation{naeem2021learning}
\citation{saini2022disentangling,wang2023learning}
\citation{mancini2021open,naeem2021learning}
\citation{kexuefm-7615}
\citation{kraskov2004estimating}
\newlabel{subsec.empirical_analysis}{{}{3}{}{}{}}
\newlabel{tab.empirical}{{1}{3}{The results of methods that incorporate a composition classifier, along with the addition of two classifiers for states and objects on top of them (\textit  {i.e.}, model ensemble), are presented. I.C. indicates only two independent classifiers are used. M.E. indicates the utilization of model ensemble in the methods, where F denotes false and T denotes true. The metrics in the table are defined in Evaluation Protocol.}{}{}}
\newlabel{eq1}{{1}{3}{}{}{}}
\newlabel{subsec_mutal}{{}{3}{}{}{}}
\newlabel{eq_objective}{{2}{3}{}{}{}}
\newlabel{eq_condition}{{3}{3}{}{}{}}
\newlabel{eq_mutual_information}{{4}{3}{}{}{}}
\newlabel{eq_f_log}{{5}{3}{}{}{}}
\newlabel{eq_f_log_transfer}{{6}{3}{}{}{}}
\citation{menon2020long}
\citation{johnson2019survey,japkowicz2002class}
\citation{chen2022zero}
\citation{importancesampling}
\newlabel{eq_after_softmax}{{7}{4}{}{}{}}
\newlabel{subsec.from_posteri_view}{{}{4}{}{}{}}
\newlabel{eq_estimate}{{8}{4}{}{}{}}
\newlabel{eq_final_sigma_introduce}{{9}{4}{}{}{}}
\newlabel{eq_onehot}{{10}{4}{}{}{}}
\newlabel{eq_final_after_softmax}{{11}{4}{}{}{}}
\newlabel{subsec.inference}{{}{4}{}{}{}}
\newlabel{eq_ah}{{12}{4}{}{}{}}
\newlabel{eq_lowerbound}{{13}{4}{}{}{}}
\newlabel{eq_infer_1}{{14}{4}{}{}{}}
\newlabel{eq_seen}{{15}{4}{}{}{}}
\newlabel{eq_importance}{{16}{4}{}{}{}}
\newlabel{eq_khat}{{17}{4}{}{}{}}
\citation{mit}
\citation{utzappos}
\citation{naeem2021learning}
\citation{naeem2021learning}
\citation{xian2017zero}
\citation{naeem2021learning}
\citation{wang2019task}
\citation{misra2017red}
\citation{nagarajan2018attributes}
\citation{purushwalkam2019task}
\citation{li2020symmetry}
\citation{mancini2021open}
\citation{naeem2021learning}
\citation{li2022siamese}
\citation{mancini2022learning}
\citation{saini2022disentangling}
\citation{yang2022decomposable}
\citation{wang2023learning}
\citation{csp}
\citation{dfsp}
\citation{resnet}
\citation{2009ImageNet}
\citation{glove}
\citation{relu}
\citation{dropout}
\citation{kingma2014adam}
\citation{paszke2019pytorch}
\citation{dfsp,csp}
\citation{clip}
\newlabel{fig_method}{{2}{5}{A brief demonstration of ProLT's training stage (detailed in Method Overview). $\mathcal  {X}^s$ is the set of seen visual features, we obtain the attribute prior according to Eq. \ref {eq_estimate}.}{}{}}
\newlabel{subsec.overview}{{}{5}{}{}{}}
\newlabel{eq_prototype}{{18}{5}{}{}{}}
\newlabel{eq_ce}{{19}{5}{}{}{}}
\newlabel{eq_prototype_common}{{20}{5}{}{}{}}
\newlabel{sec.experiments}{{}{5}{}{}{}}
\newlabel{subsec.datasets}{{}{5}{}{}{}}
\newlabel{subsec.metrics}{{}{5}{}{}{}}
\newlabel{subsec.implementation}{{}{5}{}{}{}}
\newlabel{subsec.compare}{{}{5}{}{}{}}
\citation{naeem2021learning}
\citation{menon2020long}
\newlabel{tab_results}{{2}{6}{The SoTA comparisons on three datasets. We compare ProLT with others on AUC, best HM, best sta (Sta.), best obj (Obj.), best seen (S.) and best unseen (U.). $\dagger {}$ denotes ResNet-based methods and $\ddagger $ denotes CLIP-based methods. The best AUC and HM for ResNet-based methods and CLIP-based methods are shown in bold.}{}{}}
\newlabel{tab.ablation1}{{3}{6}{A comparison of different priors for Eq. \ref {eq_final_after_softmax} and Eq. \ref {eq_infer_1} on UT-Zappos. GCN: GCN is used as the prototype learner, FC: FC layers are used as the prototype learner. N. represents no prior is introduced, using pure ensemble method, C.P. represents class prior from datasets is utilized, and A.P. denotes attribute prior is incorporated.}{}{}}
\newlabel{subsec.ablation}{{}{6}{}{}{}}
\newlabel{tab.ablation2}{{4}{6}{Ablation results for each component on UT-Zappos. $p=0$ deontes we remove the prior in Eq. \ref {eq_infer_1}, $\text  {$\mathsurround \z@ \mathchar "458$}$ indicates setting $p$ or $\eta $ to $0$, and $\times $ indicates the opposite.}{}{}}
\newlabel{fig_qua}{{3}{7}{Qualitative results on MIT-States (first row), UT-Zappos (second row) and C-GQA (third row), where the left part contains the top-3 results contains correct predicts, and the rights contains the top-3 predicts do not contain correct predicts. The label is indicated in black above the image, with correctly predicted results indicated in blue and incorrect ones in red.}{}{}}
\newlabel{fig_hyper}{{4}{7}{Influence of hyper-parameters on UT-Zappos about best seen (S.), best unseen (U.) and AUC.}{}{}}
\newlabel{subsec.hyper_parameters}{{}{7}{}{}{}}
\newlabel{subsec.qualitative}{{}{7}{}{}{}}
\bibdata{aaai24}
\citation{dfsp}
\citation{glove}
\citation{kingma2014adam}
\citation{utzappos}
\citation{naeem2021learning}
\citation{resnet}
\citation{naeem2021learning}
\citation{glove}
\citation{mikolov2013distributed}
\citation{fasttext}
\newlabel{subtab.ablation}{{A.5}{8}{A comparison of different priors for Eq. 11 and Eq. 14 when using CLIP as image and text encoder on UT-Zappos. \textbf  {N.:} no prior is introduced, using pure ensemble method. \textbf  {C.P.:} class prior from datasets is utilized. \textbf  {A.P.:} attribute prior is incorporated.}{}{}}
\newlabel{subtab.ablation2}{{A.6}{8}{Ablation results for each component on UT-Zappos when using CLIP as image and text encoder. $p=0$ deontes we remove the prior in Eq. 14, $\text  {$\mathsurround \z@ \mathchar "458$}$ indicates setting $p$ or $\eta $ to $0$, and $\times $ indicates the opposite.}{}{}}
\newlabel{subtab_wordembedding}{{A.7}{8}{Results on UT-Zappos using different word embedding. }{}{}}
\newlabel{subtab_dimension}{{A.8}{9}{Reults on UT-Zappos using different hidden layer settings.}{}{}}
\newlabel{subfig_hyper}{{A.5}{9}{Influence of $\tau $ on UT-Zappos about best seen (S.), best unseen (U.) and AUC.}{}{}}
\newlabel{subeq_is}{{A.21}{9}{}{}{}}
\newlabel{subtab.ablation3}{{\caption@xref {subtab.ablation3}{ on input line 687}}{9}{}{}{}}
\newlabel{sub_figre_ana}{{A.6}{9}{An example of posterior and prior probabilities for various compositions using our method, where \textbf  {N.S.} denotes the class prior, and the \textbf  {P.} denotes the probabilities of $p(y|\mathbf  {x})$. Our adjusted posterior provides a more balanced distribution compared to Fig. 1.}{}{}}
\gdef \@abspage@last{10}
