\begin{table*}[t]
\small
\centering
    \begin{tabular}{lccccccccccccccc}
        \toprule
        Method & \shortstack{Additional\\Supervision} & \rot{Pets} & \rot{CIFAR-10} & \rot{CIFAR-100} & \rot{SUN397} & \rot{Food-101} & \rot{Flowers} & \rot{Cars} & \rot{Caltech-101} & \rot{Aircraft} & \rot{DTD} & \rot{ImageNet} & \rot{\textbf{Average}} \\\midrule
        % \multicolumn{14}{l}{\textit{Zero-shot classification:}} \\ \\[-9pt]
        % Method & Supervision & PETS & C10 & C100 & S397 & F101 & FLW & CARS & C101 & AIR & DTD & IMN & \textbf{AVG} \\\midrule
        CLIP & - & 19.4 & 62.3 & 33.6 & 40.2 & 33.7 & 6.3 & 2.1 & 55.4 & 1.4 & 16.9 & 31.3 & 27.5\\
        SLIP & S & 28.3 & 72.2 & 45.3 & 45.1 & 44.7 & 6.8 & 2.9 & 65.9 & 1.9 & 21.8 & 38.3 & 33.9\\
        % Pets, CIFAR-10, 100, SUN397, Food-101, Flowers, Cars, Caltech-101, Aircraft, DTD, ImageNet, AVG
        % \multicolumn{14}{l}{\color{lightgray}\textit{Models with extended supervisions:}} \\ \\[-9pt]
        % \color{gray}DeCLIP~\cite{li2022supervision} & \color{gray}S+E+N+L & \color{gray}30.2 & \color{gray}72.1 & \color{gray}39.7 & \color{gray}51.6 & \color{gray}46.9 & \color{gray}7.1 & \color{gray}3.9 & \color{gray}70.1 & \color{gray}2.5 & \color{gray}24.2 & \color{gray}41.2 & \color{gray}35.4\\
        % \color{lightgray}UniCLIP~\cite{lee2022uniclip} & \color{lightgray}C+S+W+T & \color{lightgray}32.5 & \color{lightgray}78.6 & \color{lightgray}47.2 & \color{lightgray}50.4 & \color{lightgray}48.7 & \color{lightgray}8.1 & \color{lightgray}3.4 & \color{lightgray}73.0 & \color{lightgray}2.8 & \color{lightgray}23.3 & \color{lightgray}42.8 & 37.3\\
        % \textbf{E-CLIP-SE} & ViT-B/32 & \textbf{31.3} & \textbf{79.5} & \textbf{46.0} & 46.4 & 42.0 & \textbf{7.2} & 3.3 & 65.8 & \textbf{2.5} & 22.5 & 38.4 & - \\
        \textbf{ECLIPSE} & - & \textbf{24.7} & \textbf{67.8} & \textbf{38.8} & \textbf{44.4} & \textbf{34.0} & \textbf{6.2} & \textbf{2.8} & \textbf{56.7} & \textbf{2.1} & \textbf{19.6} & \textbf{32.7} & \textbf{30.0} \\
        \textbf{ECLIPSE} & S & \textbf{31.3} & \textbf{79.5} & \textbf{46.0} & \textbf{46.4} & 42.0 & \textbf{7.2} & \textbf{3.3} & 65.8 & \textbf{2.5} & \textbf{22.5} & \textbf{39.5} & \textbf{35.1} \\
        % \midrule
        % \multicolumn{14}{l}{\textit{Linear Probing:}} \\ \\[-9pt]
        % CLIP~\cite{radford2021learning} & C & 71.2 & 89.2 & 72.1 & 70.1 & 71.4 & 93.2 & 34.9 & 84.3 & 29.7 & 60.9 & 61.1 & 67.1 \\
        % % % \textbf{E-CLIP-SE} & ViT-B/32 & \textbf{31.3} & \textbf{79.5} & \textbf{46.0} & 46.4 & 42.0 & \textbf{7.2} & 3.3 & 65.8 & \textbf{2.5} & 22.5 & 38.4 & - \\
        % SLIP~\cite{mu2021slip} & C+S  & 75.4 & 90.5 & 75.3 & 73.5 & 77.1 & 96.1 & 43.0 & 87.2 & 34.1 & 71.1 & 68.1 & 71.9 \\
        % \color{lightgray}DeCLIP$^\dagger$~\cite{li2022supervision} & \color{lightgray}C+S+E+N+L  & \color{lightgray}76.5 & \color{lightgray}88.6 & \color{lightgray}71.6 & \color{lightgray}75.9 & \color{lightgray}79.3 & \color{lightgray}96.7 & \color{lightgray}42.6 & \color{lightgray}88.0 & \color{lightgray}32.6 & \color{lightgray}69.1& \color{lightgray}69.2 & \color{lightgray}71.8\\
        % % % \color{lightgray}UniCLIP~\cite{lee2022uniclip} & \color{lightgray}C+S+W+T & \color{lightgray}83.1 & \color{lightgray}92.5 & \color{lightgray}78.2 & \color{lightgray}77.0 & \color{lightgray}81.3 & \color{lightgray}97.1 & \color{lightgray}49.8 & \color{lightgray}88.9 & \color{lightgray}36.2 & \color{lightgray}72.8 & \color{lightgray}70.8 & \color{lightgray}75.2 \\
        % \rowcolor[gray]{0.95}\textbf{ECLIPSE} & C & - & - & - & - & - & - & - & - & - & - & - & - \\
        % % \rowcolor[gray]{0.95}\textbf{ECLIPSE} & C+S & - & - & - & - & - & - & - & - & - & - & - & - \\
        \bottomrule
        \toprule
            & & \multicolumn{6}{c}{Image-to-text retrieval} & \multicolumn{6}{c}{Text-to-image retrieval} \\
            & & \multicolumn{3}{c}{Flickr30k} & \multicolumn{3}{c}{COCO Captions} & \multicolumn{3}{c}{Flickr30k} & \multicolumn{3}{c}{COCO Captions} \\
            Method & \shortstack{Additional\\Supervision} & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 \\
            \midrule
            CLIP & - & 34.9	& 63.9 & 75.9 & 20.8 & 43.9 & 55.7 & 23.4 & 47.2 & 58.9 & 13.0 & 31.7 & 42.7\\
            SLIP & S & 47.8	& 76.5 & 85.9 & 27.7 & 52.6 & 63.9 & 32.3 & 58.7 & 68.8 & 18.2 & 39.2 & 51.0\\
            % \color{gray}DeCLIP~\cite{li2022supervision} & \color{gray}S+E+N+L & \color{gray}51.4 & \color{gray}80.2 & \color{gray}88.9 & \color{gray}28.3 & \color{gray}53.2 & \color{gray}64.5 & \color{gray}34.3 & \color{gray}60.3 & \color{gray}70.7 & \color{gray}18.4 & \color{gray}39.6 & \color{gray}51.4\\
            \textbf{ECLIPSE} & - & \textbf{42.6} & \textbf{71.4} & \textbf{83.8} & \textbf{24.9} & \textbf{50.6} & \textbf{62.4} & \textbf{28.9} & \textbf{53.0} & \textbf{64.2} & \textbf{15.1} & \textbf{35.4} & \textbf{47.0} \\ 
            \textbf{ECLIPSE} & S & \textbf{50.2} & \textbf{77.4} & \textbf{87.5} & \textbf{27.9} & \textbf{53.9} & \textbf{65.9} & \textbf{33.6} & \textbf{59.6} & \textbf{70.9} & 17.5 & \textbf{39.6} & 50.7 \\ 
        \bottomrule
    \end{tabular}
    \caption{Zero-shot image classification performance (single-modal) on 11 downstream datasets and image--text retrieval (multi-modal) on the test splits of Flickr30k and COCO Captions with models pre-trained on YFCC15M.
    Our ECLIPSE achieves competitive performance with other state-of-the-art works while resulting in 54\% acceleration.
    Additional Supervisions other than Contrastive loss for image-text pairs are abbreviated as S: SSL between Augmentations.}
    \label{result:cls}
\end{table*}