\begin{table}[t]
  \centering
  \small
  \begin{tabular}{l c c c c c c c}
    \toprule
    Method & Supervision & 3M   & 15M    & 88M \\ \midrule
    CLIP                 & C   & 17.1 & 31.3   & 57.4 \\ % & 57.4 44.2 \\
    \textbf{ECLIPSE}     & C &\textbf{19.7} & \textbf{32.7} & \textbf{60.2} \\
    % SLIP & 22.9 & 38.3   & -     & -     & - \\
    % DeCLIP$^\dagger$ & 25.4 & 41.9   & 49.3  & 66.2  & -\\
    % UniCLIP & 25.5 & 42.8   & 54.2  & -     & - \\
    \bottomrule
  \end{tabular}
  \vspace{0.5em}
  \caption{
  ImageNet-1k Top 1 zero shot accuracy for vision-language pretraining on different dataset scales. Both models were pretrained with a ViT-B/16 backbone for 3M and ViT-B/32 backbone for others.
  ECLIPSE shows a consistent tendency across various scales of pretrain datasets.
  }
  \label{tab:scale}
\end{table}