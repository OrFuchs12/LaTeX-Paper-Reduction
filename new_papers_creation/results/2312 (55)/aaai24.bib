@String(ICML  = {International Conference on Machine Learning})
@String(NIPS  = {Advances in Neural Information Processing Systems})
@String(ICCV  = {Proceedings of the IEEE/CVF International Conference on Computer Vision})
@String(ECCV  = {European Conference on Computer Vision})
@String(CVPR  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition})
@String(ICLR  = {International Conference on Learning Representations})

%%%%%%% Contrastive VL %%%%%%%
% ALIGN
@inproceedings{jia2021scaling,
    title={Scaling up visual and vision-language representation learning with noisy text supervision},
    author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
    booktitle=ICML,
    year={2021},
}

% CLIP
@inproceedings{radford2021learning,
    title={Learning transferable visual models from natural language supervision},
    author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
    booktitle=ICML,
    year={2021},
}

% ALBEF
@inproceedings{li2021align,
title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},
author={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},
booktitle=NIPS,
year={2021},
}

% COTS
@inproceedings{Lu2022COTS,
  author={Haoyu Lu and Nanyi Fei and Yuqi Huo and Yizhao Gao and Zhiwu Lu and Ji-Rong Wen},
  title={COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval},
  year={2022},
  booktitle=CVPR,
}

% FLIP
@inproceedings{li2022scaling,
  title={Scaling Language-Image Pre-training via Masking},
  author={Li, Yanghao and Fan, Haoqi and Hu, Ronghang and Feichtenhofer, Christoph and He, Kaiming},
  booktitle=CVPR,
  year={2023}
}

% DeCLIP
@inproceedings{li2022supervision,
    title={Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm},
    author={Yangguang Li and Feng Liang and Lichen Zhao and Yufeng Cui and Wanli Ouyang and Jing Shao and Fengwei Yu and Junjie Yan},
    booktitle=ICLR,
    year={2022},
}

% SLIP
@article{mu2021slip,
    title={SLIP: Self-supervision meets Language-Image Pre-training},
    author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
    journal={arXiv preprint arXiv:2112.12750},
    year={2021}
}

% HIT
@inproceedings{Liu2021HiT,
  title={HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval},
  author={Song Liu and Haoqi Fan and Shengsheng Qian and Yiru Chen and Wenkui Ding and Zhongyuan Wang},
  booktitle=ICCV,
  year={2021},
}

% Progressive self distill
@Inproceedings{Andonian2022robust,
 author = {Alex Andonian and Shixing Chen and Raffay Hamid},
 title = {Robust cross-modal representation learning with progressive self-distillation},
 year = {2022},
 booktitle = CVPR,
}

%%%%%%% Sparse ViT %%%%%%%
% EViT
@inproceedings{liang2022evit,
title={{EV}iT: Expediting Vision Transformers via Token Reorganizations},
    author={Youwei Liang and Chongjian GE and Zhan Tong and Yibing Song and Jue Wang and Pengtao Xie},
    booktitle={International Conference on Learning Representations},
    year={2022}
}

% Dynamic ViT
@article{rao2021dynamicvit,
    title={Dynamicvit: Efficient vision transformers with dynamic token sparsification},
    author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
    journal=NIPS,
    year={2021}
}

% Dense
@article{liang2022expediting,
  title={Expediting large-scale vision transformer for dense prediction without fine-tuning},
  author={Liang, Weicong and Yuan, Yuhui and Ding, Henghui and Luo, Xiao and Lin, Weihong and Jia, Ding and Zhang, Zheng and Zhang, Chao and Hu, Han},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}


%%%%%%% Image SSL %%%%%%%
% SimSiam
@inproceedings{chen2021exploring,
    title={Exploring simple siamese representation learning},
    author={Chen, Xinlei and He, Kaiming},
    booktitle=CVPR,
    year={2021}
}

% InfoNCE
@article{oord2018representation,
    title={Representation learning with contrastive predictive coding},
    author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
    journal={arXiv preprint arXiv:1807.03748},
    year={2018}
}

% SimCLR
@inproceedings{chen2020simple,
    title={A simple framework for contrastive learning of visual representations},
    author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
    booktitle=ICLR,
    year={2020},
}

% MoCo
@inproceedings{he2020moco,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle=CVPR,
  year={2020}
}

% MAE
@inproceedings{he2022masked,
    title={Masked autoencoders are scalable vision learners},
    author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
    booktitle=CVPR,
    year={2022}
}

% BYOL
@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal=NIPS,
  year={2020}
}

% DINO
@inproceedings{caron2021emerging,
    title={Emerging properties in self-supervised vision transformers},
    author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
    booktitle=ICCV,
    year={2021}
}

% MoCov2
@article{Chen2020mocov2,
  title={Improved Baselines with Momentum Contrastive Learning},
  author={Xinlei Chen and
               Haoqi Fan and
               Ross B. Girshick and
               Kaiming He},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

%%%%%%% ViT %%%%%%%
% Transformer
@article{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    journal=NIPS,
    year={2017}
}

% ViT
@inproceedings{dosovitskiy2021an,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    booktitle=ICLR,
    year={2021},
}

% DeiT
@inproceedings{touvron2021training,
    title={Training data-efficient image transformers \& distillation through attention},
    author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
    booktitle=ICML,
    year={2021},
}

% LV-ViT
@article{jiang2021all,
    title={All tokens matter: Token labeling for training better vision transformers},
    author={Jiang, Zi-Hang and Hou, Qibin and Yuan, Li and Zhou, Daquan and Shi, Yujun and Jin, Xiaojie and Wang, Anran and Feng, Jiashi},
    journal=NIPS,
    year={2021}
}

% LeViT
@inproceedings{graham2021levit,
    title={Levit: a vision transformer in convnet's clothing for faster inference},
    author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
    booktitle=ICCV,
    year={2021}
}

% DETR
@inproceedings{carion2020end,
    title={End-to-end object detection with transformers},
    author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
    booktitle=ECCV,
    year={2020},
}

% Segformer
@article{xie2021segformer,
    title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
    author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
    journal=NIPS,
    year={2021}
}

% SwinTransformer
@inproceedings{liu2021swin,
    title={Swin transformer: Hierarchical vision transformer using shifted windows},
    author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
    booktitle=ICCV,
    year={2021}
}

% PyarmidViT
@inproceedings{wang2021pyramid,
    title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
    author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
    booktitle=ICCV,
    year={2021}
}


%%%%%%% VLP Related works %%%%%%%
% VisualBERT
@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{chen2019uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle=ECCV,
  year={2020}
}

@inproceedings{huang2019unicoder,
  title = "{U}nicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks",
    author = "Huang, Haoyang  and
      Liang, Yaobo  and
      Duan, Nan  and
      Gong, Ming  and
      Shou, Linjun  and
      Jiang, Daxin  and
      Zhou, Ming",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle=ECCV,
  year={2020},
}

@inproceedings{li2020unimo,
  title = "{UNIMO}: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning",
    author = "Li, Wei  and
      Gao, Can  and
      Niu, Guocheng  and
      Xiao, Xinyan  and
      Liu, Hao  and
      Liu, Jiachen  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    year = "2021",
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal=NIPS,
  year={2019}
}

@inproceedings{tan2019lxmert,
  title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
}

%%%%%%% Knowledge Distillation %%%%%%%
% knowledge distillation
@article{hinton2015distilling,
    title={Distilling the knowledge in a neural network},
    author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
    journal={arXiv preprint arXiv:1503.02531},
    year={2015}
}

@InProceedings{Park2019RelKD,
    author = {Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
    title = {Relational Knowledge Distillation},
    booktitle = CVPR,
    year = {2019}
}

@inproceedings{Romero2015FitNet,
    author = {Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Y.},
    year = {2015},
    title = {FitNets: Hints for Thin Deep Nets},
    booktitle = ICLR
}

@InProceedings{Furlanello2018BornAgain,
  title = {Born Again Neural Networks},
  author = {Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle = ICML,
  year = 	 {2018},
}

@article{Bagherinezhad2018LabelRefinery,
    title={Label Refinery: Improving ImageNet Classification through Label Progression},
    author={Hessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari and Ali Farhadi},
    journal={arXiv preprint arXiv:1807.03748},
    year={2018}
}

@inproceedings{Tarvainen2017meanteacher,
 author = {Tarvainen, Antti and Valpola, Harri},
 booktitle = NIPS,
 title = {Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
 year = {2017}
}



%%%%%%% NLP %%%%%%%
% EDA
@inproceedings{wei2019eda,
    title={EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks},
    author={Wei, Jason and Zou, Kai},
    booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
    year={2019}
}

@inproceedings{devlin2018bert,
  title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    year = "2019",
}

%%%%%%% Dataset %%%%%%%
@inproceedings{sharma2018cc3m,
    title = "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning",
    author = "Sharma, Piyush  and
      Ding, Nan  and
      Goodman, Sebastian  and
      Soricut, Radu",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2018",
}

@article{thomee2016yfcc100m,
    title={YFCC100M: The new data in multimedia research},
    author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
    journal={Communications of the ACM},
    year={2016},
}

% Visual Relationship with Transformers
@inproceedings{kim2021hotr,
  title={Hotr: End-to-end human-object interaction detection with transformers},
  author={Kim, Bumsoo and Lee, Junhyun and Kang, Jaewoo and Kim, Eun-Sol and Kim, Hyunwoo J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={74--83},
  year={2021}
}

@inproceedings{kim2022mstr,
  title={Mstr: Multi-scale transformer for end-to-end human-object interaction detection},
  author={Kim, Bumsoo and Mun, Jonghwan and On, Kyoung-Woon and Shin, Minchul and Lee, Junhyun and Kim, Eun-Sol},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19578--19587},
  year={2022}
}

% MCD
@inproceedings{kim2023misalign,
  title={Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-training},
  author={Kim, Bumsoo and Jo, Yeonsik and Kim, Jinhyung and Kim, Seunghwan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2563--2572},
  year={2023}
}
