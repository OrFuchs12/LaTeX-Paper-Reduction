\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Andonian, Chen, and Hamid(2022)}]{Andonian2022robust}
Andonian, A.; Chen, S.; and Hamid, R. 2022.
\newblock Robust cross-modal representation learning with progressive self-distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and Zagoruyko}]{carion2020end}
Carion, N.; Massa, F.; Synnaeve, G.; Usunier, N.; Kirillov, A.; and Zagoruyko, S. 2020.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}.

\bibitem[{Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal, Bojanowski, and Joulin}]{caron2021emerging}
Caron, M.; Touvron, H.; Misra, I.; J{\'e}gou, H.; Mairal, J.; Bojanowski, P.; and Joulin, A. 2021.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}.

\bibitem[{Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and Hinton}]{chen2020simple}
Chen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020{\natexlab{a}}.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Chen et~al.(2020{\natexlab{b}})Chen, Fan, Girshick, and He}]{Chen2020mocov2}
Chen, X.; Fan, H.; Girshick, R.~B.; and He, K. 2020{\natexlab{b}}.
\newblock Improved Baselines with Momentum Contrastive Learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}.

\bibitem[{Chen and He(2021)}]{chen2021exploring}
Chen, X.; and He, K. 2021.
\newblock Exploring simple siamese representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Chen et~al.(2020{\natexlab{c}})Chen, Li, Yu, Kholy, Ahmed, Gan, Cheng, and Liu}]{chen2019uniter}
Chen, Y.-C.; Li, L.; Yu, L.; Kholy, A.~E.; Ahmed, F.; Gan, Z.; Cheng, Y.; and Liu, J. 2020{\natexlab{c}}.
\newblock Uniter: Universal image-text representation learning.
\newblock In \emph{European Conference on Computer Vision}.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova}]{devlin2018bert}
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.
\newblock {BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}.

\bibitem[{Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby}]{dosovitskiy2021an}
Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.; Gelly, S.; Uszkoreit, J.; and Houlsby, N. 2021.
\newblock An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Furlanello et~al.(2018)Furlanello, Lipton, Tschannen, Itti, and Anandkumar}]{Furlanello2018BornAgain}
Furlanello, T.; Lipton, Z.; Tschannen, M.; Itti, L.; and Anandkumar, A. 2018.
\newblock Born Again Neural Networks.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[{Graham et~al.(2021)Graham, El-Nouby, Touvron, Stock, Joulin, J{\'e}gou, and Douze}]{graham2021levit}
Graham, B.; El-Nouby, A.; Touvron, H.; Stock, P.; Joulin, A.; J{\'e}gou, H.; and Douze, M. 2021.
\newblock Levit: a vision transformer in convnet's clothing for faster inference.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}.

\bibitem[{Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond, Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar et~al.}]{grill2020bootstrap}
Grill, J.-B.; Strub, F.; Altch{\'e}, F.; Tallec, C.; Richemond, P.; Buchatskaya, E.; Doersch, C.; Avila~Pires, B.; Guo, Z.; Gheshlaghi~Azar, M.; et~al. 2020.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick}]{he2022masked}
He, K.; Chen, X.; Xie, S.; Li, Y.; Doll{\'a}r, P.; and Girshick, R. 2022.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{He et~al.(2020)He, Fan, Wu, Xie, and Girshick}]{he2020moco}
He, K.; Fan, H.; Wu, Y.; Xie, S.; and Girshick, R. 2020.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Hessam~Bagherinezhad and Farhadi(2018)}]{Bagherinezhad2018LabelRefinery}
Hessam~Bagherinezhad, M.~R., Maxwell~Horton; and Farhadi, A. 2018.
\newblock Label Refinery: Improving ImageNet Classification through Label Progression.
\newblock \emph{arXiv preprint arXiv:1807.03748}.

\bibitem[{Hinton et~al.(2015)Hinton, Vinyals, Dean et~al.}]{hinton2015distilling}
Hinton, G.; Vinyals, O.; Dean, J.; et~al. 2015.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}.

\bibitem[{Huang et~al.(2019)Huang, Liang, Duan, Gong, Shou, Jiang, and Zhou}]{huang2019unicoder}
Huang, H.; Liang, Y.; Duan, N.; Gong, M.; Shou, L.; Jiang, D.; and Zhou, M. 2019.
\newblock {U}nicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}.

\bibitem[{Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig}]{jia2021scaling}
Jia, C.; Yang, Y.; Xia, Y.; Chen, Y.-T.; Parekh, Z.; Pham, H.; Le, Q.; Sung, Y.-H.; Li, Z.; and Duerig, T. 2021.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[{Jiang et~al.(2021)Jiang, Hou, Yuan, Zhou, Shi, Jin, Wang, and Feng}]{jiang2021all}
Jiang, Z.-H.; Hou, Q.; Yuan, L.; Zhou, D.; Shi, Y.; Jin, X.; Wang, A.; and Feng, J. 2021.
\newblock All tokens matter: Token labeling for training better vision transformers.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Kim et~al.(2023)Kim, Jo, Kim, and Kim}]{kim2023misalign}
Kim, B.; Jo, Y.; Kim, J.; and Kim, S. 2023.
\newblock Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2563--2572.

\bibitem[{Kim et~al.(2021)Kim, Lee, Kang, Kim, and Kim}]{kim2021hotr}
Kim, B.; Lee, J.; Kang, J.; Kim, E.-S.; and Kim, H.~J. 2021.
\newblock Hotr: End-to-end human-object interaction detection with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 74--83.

\bibitem[{Kim et~al.(2022)Kim, Mun, On, Shin, Lee, and Kim}]{kim2022mstr}
Kim, B.; Mun, J.; On, K.-W.; Shin, M.; Lee, J.; and Kim, E.-S. 2022.
\newblock Mstr: Multi-scale transformer for end-to-end human-object interaction detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 19578--19587.

\bibitem[{Li et~al.(2021{\natexlab{a}})Li, Selvaraju, Gotmare, Joty, Xiong, and Hoi}]{li2021align}
Li, J.; Selvaraju, R.~R.; Gotmare, A.~D.; Joty, S.; Xiong, C.; and Hoi, S. 2021{\natexlab{a}}.
\newblock Align before Fuse: Vision and Language Representation Learning with Momentum Distillation.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Li et~al.(2019)Li, Yatskar, Yin, Hsieh, and Chang}]{li2019visualbert}
Li, L.~H.; Yatskar, M.; Yin, D.; Hsieh, C.-J.; and Chang, K.-W. 2019.
\newblock Visualbert: A simple and performant baseline for vision and language.
\newblock \emph{arXiv preprint arXiv:1908.03557}.

\bibitem[{Li et~al.(2021{\natexlab{b}})Li, Gao, Niu, Xiao, Liu, Liu, Wu, and Wang}]{li2020unimo}
Li, W.; Gao, C.; Niu, G.; Xiao, X.; Liu, H.; Liu, J.; Wu, H.; and Wang, H. 2021{\natexlab{b}}.
\newblock {UNIMO}: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}.

\bibitem[{Li et~al.(2020)Li, Yin, Li, Zhang, Hu, Zhang, Wang, Hu, Dong, Wei et~al.}]{li2020oscar}
Li, X.; Yin, X.; Li, C.; Zhang, P.; Hu, X.; Zhang, L.; Wang, L.; Hu, H.; Dong, L.; Wei, F.; et~al. 2020.
\newblock Oscar: Object-semantics aligned pre-training for vision-language tasks.
\newblock In \emph{European Conference on Computer Vision}.

\bibitem[{Li et~al.(2023)Li, Fan, Hu, Feichtenhofer, and He}]{li2022scaling}
Li, Y.; Fan, H.; Hu, R.; Feichtenhofer, C.; and He, K. 2023.
\newblock Scaling Language-Image Pre-training via Masking.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Li et~al.(2022)Li, Liang, Zhao, Cui, Ouyang, Shao, Yu, and Yan}]{li2022supervision}
Li, Y.; Liang, F.; Zhao, L.; Cui, Y.; Ouyang, W.; Shao, J.; Yu, F.; and Yan, J. 2022.
\newblock Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Liang et~al.(2022{\natexlab{a}})Liang, Yuan, Ding, Luo, Lin, Jia, Zhang, Zhang, and Hu}]{liang2022expediting}
Liang, W.; Yuan, Y.; Ding, H.; Luo, X.; Lin, W.; Jia, D.; Zhang, Z.; Zhang, C.; and Hu, H. 2022{\natexlab{a}}.
\newblock Expediting large-scale vision transformer for dense prediction without fine-tuning.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Liang et~al.(2022{\natexlab{b}})Liang, GE, Tong, Song, Wang, and Xie}]{liang2022evit}
Liang, Y.; GE, C.; Tong, Z.; Song, Y.; Wang, J.; and Xie, P. 2022{\natexlab{b}}.
\newblock {EV}iT: Expediting Vision Transformers via Token Reorganizations.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Liu et~al.(2021{\natexlab{a}})Liu, Fan, Qian, Chen, Ding, and Wang}]{Liu2021HiT}
Liu, S.; Fan, H.; Qian, S.; Chen, Y.; Ding, W.; and Wang, Z. 2021{\natexlab{a}}.
\newblock HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}.

\bibitem[{Liu et~al.(2021{\natexlab{b}})Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo}]{liu2021swin}
Liu, Z.; Lin, Y.; Cao, Y.; Hu, H.; Wei, Y.; Zhang, Z.; Lin, S.; and Guo, B. 2021{\natexlab{b}}.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}.

\bibitem[{Lu et~al.(2022)Lu, Fei, Huo, Gao, Lu, and Wen}]{Lu2022COTS}
Lu, H.; Fei, N.; Huo, Y.; Gao, Y.; Lu, Z.; and Wen, J.-R. 2022.
\newblock COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Lu et~al.(2019)Lu, Batra, Parikh, and Lee}]{lu2019vilbert}
Lu, J.; Batra, D.; Parikh, D.; and Lee, S. 2019.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Mu et~al.(2021)Mu, Kirillov, Wagner, and Xie}]{mu2021slip}
Mu, N.; Kirillov, A.; Wagner, D.; and Xie, S. 2021.
\newblock SLIP: Self-supervision meets Language-Image Pre-training.
\newblock \emph{arXiv preprint arXiv:2112.12750}.

\bibitem[{Oord, Li, and Vinyals(2018)}]{oord2018representation}
Oord, A. v.~d.; Li, Y.; and Vinyals, O. 2018.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}.

\bibitem[{Park et~al.(2019)Park, Kim, Lu, and Cho}]{Park2019RelKD}
Park, W.; Kim, D.; Lu, Y.; and Cho, M. 2019.
\newblock Relational Knowledge Distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Radford, A.; Kim, J.~W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et~al. 2021.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[{Rao et~al.(2021)Rao, Zhao, Liu, Lu, Zhou, and Hsieh}]{rao2021dynamicvit}
Rao, Y.; Zhao, W.; Liu, B.; Lu, J.; Zhou, J.; and Hsieh, C.-J. 2021.
\newblock Dynamicvit: Efficient vision transformers with dynamic token sparsification.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Romero et~al.(2015)Romero, Ballas, Kahou, Chassang, Gatta, and Bengio}]{Romero2015FitNet}
Romero, A.; Ballas, N.; Kahou, S.~E.; Chassang, A.; Gatta, C.; and Bengio, Y. 2015.
\newblock FitNets: Hints for Thin Deep Nets.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Sharma et~al.(2018)Sharma, Ding, Goodman, and Soricut}]{sharma2018cc3m}
Sharma, P.; Ding, N.; Goodman, S.; and Soricut, R. 2018.
\newblock Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}.

\bibitem[{Tan and Bansal(2019)}]{tan2019lxmert}
Tan, H.; and Bansal, M. 2019.
\newblock {LXMERT}: Learning Cross-Modality Encoder Representations from Transformers.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}.

\bibitem[{Tarvainen and Valpola(2017)}]{Tarvainen2017meanteacher}
Tarvainen, A.; and Valpola, H. 2017.
\newblock Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland, Borth, and Li}]{Thomee2016YFCC100M}
Thomee, B.; Shamma, D.~A.; Friedland, G.; Elizalde, B.; Ni, K.; Poland, D.; Borth, D.; and Li, L.-J. 2016.
\newblock YFCC100M: The new data in multimedia research.
\newblock \emph{Communications of the ACM}.

\bibitem[{Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and J{\'e}gou}]{touvron2021training}
Touvron, H.; Cord, M.; Douze, M.; Massa, F.; Sablayrolles, A.; and J{\'e}gou, H. 2021.
\newblock Training data-efficient image transformers \& distillation through attention.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.; Kaiser, {\L}.; and Polosukhin, I. 2017.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Wang et~al.(2021)Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and Shao}]{wang2021pyramid}
Wang, W.; Xie, E.; Li, X.; Fan, D.-P.; Song, K.; Liang, D.; Lu, T.; Luo, P.; and Shao, L. 2021.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction without convolutions.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}.

\bibitem[{Wei and Zou(2019)}]{wei2019eda}
Wei, J.; and Zou, K. 2019.
\newblock EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}.

\bibitem[{Xie et~al.(2021)Xie, Wang, Yu, Anandkumar, Alvarez, and Luo}]{xie2021segformer}
Xie, E.; Wang, W.; Yu, Z.; Anandkumar, A.; Alvarez, J.~M.; and Luo, P. 2021.
\newblock SegFormer: Simple and efficient design for semantic segmentation with transformers.
\newblock \emph{Advances in Neural Information Processing Systems}.

\end{thebibliography}
