\section{Conclusion}
\label{sec:conclusion}
We propose ECLIPSE, a meta-architecture for streamlining vision transformers under visual--language pretraining.
Our novel distillation formulation enables data-efficient training with accelerated ViTs under Contrastive Language-Image Pretraining.
ECLIPSE can be trained with or without model acceleration, thus offering a model choice between efficiency and performance.
Future works will include extending ECLIPSE frameworks to other modalities.