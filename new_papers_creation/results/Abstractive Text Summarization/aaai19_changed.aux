\relax 
\citation{Sutskever2014SequenceTS}
\citation{Chopra2016AbstractiveSS}
\citation{see2017get}
\citation{Tao2018GetTP}
\citation{Gao2019Product}
\citation{Sun2018AUM}
\citation{Zhou2017SelectiveEF}
\citation{Bansal2018FastAS}
\citation{Hu2008CommentsorientedDS}
\citation{Yang2011SocialCS}
\citation{Li2015ReaderAwareMS}
\citation{li2017reader}
\citation{Hu2008CommentsorientedDS}
\citation{Yang2011SocialCS}
\citation{Li2015ReaderAwareMS}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:intro-case}{{1}{1}{Examples of the text summarization. The text in red denotes the focused aspect by the good summary, while the text in blue is described by the bad summary. The text with underline is the focused aspect by reader comments.}{}{}}
\citation{Jadhav2018ExtractiveSW}
\citation{Narayan2018RankingSF}
\citation{Bansal2018FastAS}
\citation{Ma2018AutoencoderAA}
\citation{Zhou2018SequentialCN}
\citation{Sutskever2014SequenceTS}
\citation{Gu2016IncorporatingCM}
\citation{see2017get}
\citation{Bansal2018FastAS}
\citation{Hu2015LCSTSAL}
\citation{Lin2018GlobalEF}
\citation{Wang2018ART}
\citation{Hu2007CommentsorientedBS}
\citation{Hu2008CommentsorientedDS}
\citation{Nguyen2016SoLSCSumAL}
\citation{Li2015ReaderAwareMS}
\citation{li2017reader}
\citation{Li2017SalienceEV}
\newlabel{sec:formulation}{{}{2}{}{}{}}
\citation{see2017get}
\citation{Ma2018AHE}
\citation{Bahdanau2014NeuralMT}
\citation{Gu2016IncorporatingCM}
\citation{vinyals2015pointer}
\citation{see2017get}
\citation{see2017get}
\newlabel{equ:dec-init}{{2}{3}{}{}{}}
\newlabel{equ:dec-step}{{3}{3}{}{}{}}
\newlabel{equ:attention-sm}{{5}{3}{}{}{}}
\newlabel{equ:out-proj}{{7}{3}{}{}{}}
\newlabel{equ:comment-avg}{{10}{3}{}{}{}}
\newlabel{equ:slience-score}{{11}{3}{}{}{}}
\newlabel{fig:overview}{{1}{4}{Overview of RASG. We divide our model into four parts: (1) \textit  {Summary generator} generates a summary to describe the main aspect of document. (2) \textit  {Reader attention} module models the readers attention of document. (3) \textit  {Supervisor} models the gap of focused document aspect between generated summary and reader comments. (4) \textit  {Goal tracker} sets a goal of summary generator according to gap given by supervisor. }{}{}}
\newlabel{equ:denoising-loss}{{12}{4}{}{}{}}
\newlabel{equ:word-sim}{{13}{4}{}{}{}}
\newlabel{equ:word-sim-max}{{14}{4}{}{}{}}
\newlabel{equ:word-sim-weight}{{15}{4}{}{}{}}
\newlabel{equ:word-sim-sm}{{16}{4}{}{}{}}
\newlabel{sec:supervisor}{{}{4}{}{}{}}
\newlabel{equ:current_attention}{{17}{4}{}{}{}}
\newlabel{equ:reader-attention-weighted-doc}{{19}{4}{}{}{}}
\citation{Guo2018LongTG}
\citation{lin2004rouge}
\citation{Sun2018AUM}
\citation{chen2018iterative}
\citation{Sutskever2014SequenceTS}
\citation{Lin2018GlobalEF}
\citation{Nallapati2017SummaRuNNerAR}
\citation{see2017get}
\citation{Mihalcea2004TextRankBO}
\newlabel{equ:feature-extractor}{{20}{5}{}{}{}}
\newlabel{equ:discriminator-sigmoid-m}{{21}{5}{}{}{}}
\newlabel{equ:discriminator-sigmoid-u}{{22}{5}{}{}{}}
\newlabel{equ:dis-d}{{23}{5}{}{}{}}
\newlabel{equ:dis-c}{{24}{5}{}{}{}}
\newlabel{equ:attention-gap}{{25}{5}{}{}{}}
\newlabel{sec:goal-tracker}{{}{5}{}{}{}}
\newlabel{equ:loss-generator}{{27}{5}{}{}{}}
\citation{abadi2016tensorflow}
\citation{Duchi2010AdaptiveSM}
\newlabel{tab:ablations}{{2}{6}{Ablation models for comparison.}{}{}}
\newlabel{tab:comp_rouge_baselines}{{3}{6}{ROUGE scores comparison between baselines.}{}{}}
\newlabel{tab:comp_rouge_ablation}{{4}{6}{ROUGE scores of different ablation models.}{}{}}
\newlabel{fig:subfig}{{2}{7}{(a) Cosine distance between decoding attention and reader attention. (b) Recall score of denoising module.}{}{}}
\newlabel{tab:comp_human_baslines}{{5}{7}{Consistency and fluency comparison by human evaluation.}{}{}}
\newlabel{tab:case}{{3}{7}{Examples of the generated summary by RASG and other models.}{}{}}
\bibdata{aaai19}
\bibstyle{aaai}
\gdef \@abspage@last{8}
