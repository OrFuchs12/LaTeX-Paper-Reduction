\relax 
\bibstyle{aaai24}
\citation{hendrycks2021measuring}
\citation{openai2023gpt4,anil2023palm}
\citation{marie2023,narayanan_kapoor2023}
\citation{dickson2023}
\citation{kreutzer-etal-2022-quality}
\citation{liu2023evaluating,jacovi2023stop}
\citation{dodge2021documenting}
\citation{dodge2021documenting}
\citation{brown2020language}
\citation{wei2021finetuned}
\citation{touvron2023llama}
\citation{openai2023gpt4}
\citation{li2023open}
\citation{dodge2021documenting}
\citation{brown2020language}
\citation{chowdhery2022palm}
\citation{carlini2021extracting,carlini2022quantifying,li2023estimating}
\citation{li2023open}
\citation{brown2020language}
\citation{touvron2023llama}
\citation{clark2019boolq}
\citation{brown2020language}
\citation{jacovi2023stop}
\newlabel{scope}{{}{2}{}{}{}}
\citation{rajpurkar2018know}
\citation{grootendorst2020keybert}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:scope}{{1}{3}{Six most frequent categories of user query to comprehend papers.}{}{}}
\newlabel{fig:pipeline}{{1}{4}{The overall pipeline of LatestEval. Step \textsc  {1} is for collecting the latest texts; \textsc  {2,3} are to construct the answers; \textsc  {4} is to construct corresponding queries; and \textsc  {5} is to prepare the passages.}{}{}}
\citation{carlini2021extracting,carlini2022quantifying}
\citation{merity2016pointer}
\citation{rajpurkar2018know}
\citation{clark2019boolq}
\citation{choi2018quac}
\citation{zhang2022opt}
\citation{touvron2023llama}
\newlabel{fig:contamination}{{2}{5}{The comparison of datasets' perplexities indicates the contamination extent on various language models.}{}{}}
\newlabel{tab:statistics}{{2}{5}{Statistics of LatestEval, July week 1 2023.}{}{}}
\citation{carlini2022quantifying}
\citation{vicuna2023}
\citation{zheng2023judging}
\citation{ouyang2022training}
\newlabel{fig:visualisation}{{3}{6}{Memorisation test of \texttt  {GPT-4} model on four benchmarks. Coloured text refers to the text generated by \texttt  {GPT-4} that matches the original test text. The four examples shown are just the first instance of each benchmark, so no cherry picking.}{}{}}
\citation{li2023compressing}
\citation{li2023unlocking}
\newlabel{fig:performance}{{4}{7}{\texttt  {(a)}: single answer scores across five types of queries; \texttt  {(b)}: pair-wise win rate, y-axis indicates the winner. }{}{}}
\newlabel{tab:human_eval}{{3}{7}{Human evaluation on the faithfulness, answerability, and copyability of LatestEval.}{}{}}
\bibdata{aaai24}
\gdef \@abspage@last{8}
