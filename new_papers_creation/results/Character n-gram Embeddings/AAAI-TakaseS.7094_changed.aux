\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{Sutskever:2014:SSL:2969033.2969173}
\citation{rush-chopra-weston:2015:EMNLP}
\citation{wen-EtAl:2015:EMNLP}
\citation{Vinyals_2015_CVPR}
\citation{chime4asr}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{verwimp-EtAl:2017:EACLlong}
\citation{verwimp-EtAl:2017:EACLlong}
\citation{Kim:2016:CNL:3016100.3016285}
\citation{45446}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{TACL999}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{shen2018disan}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}RNN Language Model}{1}{section.2}\protected@file@percent }
\newlabel{eq:def_lm}{{1}{1}{RNN Language Model}{equation.2.1}{}}
\citation{DBLP:journals/corr/BradburyMXS16}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{TACL999}
\citation{takase-okazaki-inui:2016:P16-1}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{shen2018disan}
\citation{shen2018disan}
\newlabel{eq:softmax}{{2}{2}{RNN Language Model}{equation.2.2}{}}
\newlabel{eq:rnn}{{3}{2}{RNN Language Model}{equation.2.3}{}}
\newlabel{eq:embed}{{4}{2}{RNN Language Model}{equation.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Incorporating Character $n$-gram Embeddings}{2}{section.3}\protected@file@percent }
\newlabel{eq:embed4proposed}{{5}{2}{Incorporating Character \texorpdfstring {$n$}{n}-gram Embeddings}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Multi-dimensional Self-attention}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the proposed method. The proposed method computes char$n$-MS-vec from character $n$-gram (3-gram in this figure) embeddings and inputs the sum of it and the standard word embedding into an RNN.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:overview}{{1}{2}{Overview of the proposed method. The proposed method computes char$n$-MS-vec from character $n$-gram (3-gram in this figure) embeddings and inputs the sum of it and the standard word embedding into an RNN}{figure.1}{}}
\newlabel{eq:weightedsum}{{6}{2}{Multi-dimensional Self-attention}{equation.3.6}{}}
\newlabel{eq:multi_attention}{{7}{2}{Multi-dimensional Self-attention}{equation.3.7}{}}
\citation{DBLP:journals/corr/InanKS16}
\citation{press-wolf:2017:EACLshort}
\citation{Marcus:1993:BLA:972470.972475}
\citation{DBLP:journals/corr/MerityXBS16}
\citation{DBLP:conf/interspeech/MikolovKBCK10}
\citation{DBLP:journals/corr/MerityXBS16}
\citation{merityRegOpt}
\citation{DBLP:journals/corr/BradburyMXS16}
\citation{DBLP:journals/corr/MelisDB17}
\citation{zilly2016recurrent}
\citation{merityRegOpt}
\citation{polyak1992acceleration}
\citation{merityAnalysis}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{verwimp-EtAl:2017:EACLlong}
\citation{Kim:2016:CNL:3016100.3016285}
\citation{Gal2016Theoretically}
\citation{Gal2016Theoretically}
\citation{zilly2016recurrent}
\citation{zilly2016recurrent}
\citation{takase-suzuki-nagata:2017:I17-2}
\citation{45826}
\citation{DBLP:journals/corr/MelisDB17}
\citation{merityRegOpt}
\citation{fraternal}
\citation{DBLP:journals/corr/abs-1711-03953}
\citation{D18-1489}
\citation{DBLP:journals/corr/GraveJU16}
\citation{takase-suzuki-nagata:2017:I17-2}
\citation{DBLP:journals/corr/InanKS16}
\citation{DBLP:journals/corr/MelisDB17}
\citation{merityRegOpt}
\citation{fraternal}
\citation{DBLP:journals/corr/abs-1711-03953}
\citation{D18-1489}
\citation{DBLP:journals/corr/GraveJU16}
\citation{DBLP:journals/corr/DauphinFAG16}
\citation{DBLP:journals/corr/DauphinFAG16}
\citation{merityAnalysis}
\citation{Kim:2016:CNL:3016100.3016285}
\citation{Kim:2016:CNL:3016100.3016285}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Statistics of PTB, WT2, and WT103.}}{3}{table.1}\protected@file@percent }
\newlabel{tab:dataset}{{1}{3}{Statistics of PTB, WT2, and WT103}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Word Tying}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments on Language Modeling}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Datasets}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Baseline RNN Language Model}{3}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results}{3}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Perplexities on each dataset. We varied the $n$ for char$n$-MS-vec from 2 to 4.}}{4}{table.2}\protected@file@percent }
\newlabel{tab:perplexities4charn}{{2}{4}{Perplexities on each dataset. We varied the $n$ for char$n$-MS-vec from 2 to 4}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Computational speed of the baseline and proposed method on NVIDIA Tesla P100.}}{4}{table.3}\protected@file@percent }
\newlabel{tab:calc_speed}{{3}{4}{Computational speed of the baseline and proposed method on NVIDIA Tesla P100}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Perplexities on the PTB dataset where an input word is infrequent in the training data, which means its frequency is lower than 2,000.}}{4}{table.4}\protected@file@percent }
\newlabel{tab:perplexities4freq}{{4}{4}{Perplexities on the PTB dataset where an input word is infrequent in the training data, which means its frequency is lower than 2,000}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Perplexities of each structure on PTB dataset.}}{4}{table.5}\protected@file@percent }
\newlabel{tab:ablation}{{5}{4}{Perplexities of each structure on PTB dataset}{table.5}{}}
\citation{DBLP:journals/corr/GraveJU16}
\citation{DBLP:journals/corr/abs-1709-07432}
\citation{DBLP:journals/corr/abs-1711-03953}
\citation{D18-1489}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Perplexities of the proposed method and as reported in previous studies on the PTB dataset.}}{5}{table.6}\protected@file@percent }
\newlabel{tb:perplexity}{{6}{5}{Perplexities of the proposed method and as reported in previous studies on the PTB dataset}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Perplexities of the proposed method and as reported in previous studies on the WT2 dataset.}}{5}{table.7}\protected@file@percent }
\newlabel{tb:perplexityOnWikitext2}{{7}{5}{Perplexities of the proposed method and as reported in previous studies on the WT2 dataset}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Perplexities of the proposed method and as reported in previous studies on the WT103 dataset.}}{5}{table.8}\protected@file@percent }
\newlabel{tb:perplexityOnWikitext103}{{8}{5}{Perplexities of the proposed method and as reported in previous studies on the WT103 dataset}{table.8}{}}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{rush-chopra-weston:2015:EMNLP}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{Napoles:2012:AG:2391200.2391218}
\citation{rush-chopra-weston:2015:EMNLP}
\citation{rush-chopra-weston:2015:EMNLP}
\citation{zhou-EtAl:2017:Long}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{kiyono}
\citation{luong-pham-manning:2015:EMNLP}
\citation{kiyono}
\citation{sennrich-haddow-birch:2016:P16-11}
\citation{zhou-EtAl:2017:Long}
\citation{kiyono}
\citation{zhou-EtAl:2017:Long}
\citation{C18-1052}
\citation{DBLP:conf/interspeech/MikolovKBCK10}
\citation{Chen:1996:ESS:981863.981904}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{Srivastava:2014:DSW:2627435.2670313}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{Gal2016Theoretically}
\citation{DBLP:journals/corr/MelisDB17}
\citation{merityRegOpt}
\citation{wan2013regularization}
\citation{polyak1992acceleration}
\citation{merityAnalysis}
\citation{DBLP:journals/corr/BradburyMXS16}
\citation{DBLP:journals/corr/abs-1711-03953}
\citation{D18-1489}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments on Applications}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Datasets}{6}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experimental Settings}{6}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Results}{6}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Related Work}{6}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RNN Language Model}{6}{section*.1}\protected@file@percent }
\citation{Kim:2016:CNL:3016100.3016285}
\citation{DBLP:journals/corr/ZarembaSV14}
\citation{45446}
\citation{verwimp-EtAl:2017:EACLlong}
\citation{Kim:2016:CNL:3016100.3016285}
\citation{merityRegOpt}
\citation{DBLP:journals/corr/GraveJU16}
\citation{DBLP:journals/corr/abs-1709-07432}
\citation{DBLP:journals/corr/abs-1709-07432}
\citation{luong-socher-manning:2013:CoNLL-2013}
\citation{ling-EtAl:2015:EMNLP2}
\citation{TACL999}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{rantian:additive}
\citation{Muraoka-EtAl:2014:PACLIC}
\citation{takase-okazaki-inui:2016:P16-1}
\citation{wieting-EtAl:2016:EMNLP2016}
\citation{shen2018disan}
\bibdata{AAAI-TakaseS.7094.bbl}
\bibstyle{aaai}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces BLEU scores on the IWSLT16 dataset. We report the average score of 3 runs.}}{7}{table.9}\protected@file@percent }
\newlabel{tb:nmt}{{9}{7}{BLEU scores on the IWSLT16 dataset. We report the average score of 3 runs}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces ROUGE F1 scores on the headline generation test sets provided by \cite {zhou-EtAl:2017:Long} and \cite {kiyono}. The upper part is the results of our implementation and the lower part shows the scores reported in previous studies. In the upper part, we report the average score of 3 runs.}}{7}{table.10}\protected@file@percent }
\newlabel{tb:headline}{{10}{7}{ROUGE F1 scores on the headline generation test sets provided by \protect \cite {zhou-EtAl:2017:Long} and \protect \cite {kiyono}. The upper part is the results of our implementation and the lower part shows the scores reported in previous studies. In the upper part, we report the average score of 3 runs}{table.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Embedding Construction}{7}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{7}{section.7}\protected@file@percent }
\gdef \@abspage@last{8}
