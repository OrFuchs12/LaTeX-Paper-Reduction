\section{Related Work}
As one of the early works, \cite{liu2001neural} attempted a shallow neural network on corn yield prediction. It was shown that neural networks could beat conventional regression algorithms \cite{drummond2003statistical}. In recent years, owing to the development of deep learning, neural network-based models have become more prevalent in the crop yield prediction field \cite{dahikar2014agricultural,gandhi2016rice}. As we mentioned in the introduction, 48 out of 70 recent works we surveyed employed neural nets. More than half of the NN-based works adopted CNN and one fourth of them employed RNN. 

There are two groups of research directions according to different input sources. The first group of methods read remote sensing data such as satellite images or normalized difference vegetation index (NDVI), and used that to estimate the yields. \cite{you2017deep} applied a deep Gaussian process to predict crop yields from a series of the multi-spectral satellite images. \cite{nevavuori2019crop} employed deep CNNs to reduce the prediction uncertainty on RGB images. \cite{kim2019comparison} did a case study in the Midwest and compared various AI models on satellite product datasets. 20 out of all the 70 papers primarily or only dealt with remote sensing data.
These methods illuminate the use of the widely available remote sensing data, but it is hard to directly model the relations between crop yields and environmental factors that actually affect the yields.
Therefore, another line of research aims at collecting environmental factors and directly training models with these factors as inputs. \cite{ccakir2014yield} used temperature, rainfall and other meterological parameters to predict wheat production.  \cite{khaki2019crop} collected crop genotypes and environments to predict the performance of corn hybrids. More recently, CNN-RNN \cite{khaki2020cnn} incorporated historical environment knowledge and proved benefits. Our GNN-RNN takes one more step by further adding neighborhood information. 

Dataset-wise, most papers have their own small-scale datasets, which vary largely in different dimensions. Scale-wise, \cite{gonzalez2014predictive} only studied a single zone in Mexico, while \cite{wang2018deep} studied the whole country of Argentina. Time-wise, \cite{wang2018deep} spanned over 5 years, while \cite{you2017deep} investigated 13 years. It is thus hard to fairly compare models or validate the performance. There have been several efforts to evaluate models on a large and consistent dataset. The closest one to ours is the one from the CNN-RNN paper \cite{khaki2020cnn}. However, they only used 13 states from the Corn Belt and used fewer features than us (for example, they did not use land surface data such as soil moisture). By contrast, we evaluate our models at a nationwide scale, using data from 41 states and 39 years. This forces our models to generalize to a diverse range of locations that have very different climatic and geographic conditions, instead of overfitting to a single region.



%\junwen{this paragraph can be removed if the dataset comparison has been addressed in the dataset section.}
