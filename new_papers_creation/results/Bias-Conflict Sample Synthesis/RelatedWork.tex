\section{Related Work}

\subsection{Temporal Sentence Grounding in Video}

TSGV methods are generally divided into proposal-based and proposal-free models.
Proposal-based methods first generate a large number of candidate proposals, and then score all proposals with the language queries. 
% Early methods~\cite{RN1} used sliding windows on the video to generate proposals, which consumed a lot of time.
Anchor-based proposal generation methods~\cite{RN8, RN9, RN10, RN11, RN5} pre-define some boxes of specific proportions and directly generate proposals on the multi-modal features. 2D-based proposal generation methods~\cite{RN2, RN13, RN14, RN15, RN16, RN17} extend anchors to 2D to more finely model the positional relationships between proposals.
Proposal-free methods are divided into regression-based and span-based methods. Regression-based methods~\cite{RN18, RN19, RN20, RN21, RN3, zheng2023generating, wang2023scene} directly regress start and end timestamps. Such methods mainly focus on designing various feature encoding and cross-modal reasoning strategies to achieve precise localization. Span-based methods~\cite{RN22, RN23, RN25, RN26, RN4, zheng2023phrase} directly predict the probability of each video segment as the start and end position of the target moment. 


\subsection{Model Debiasing}

%Poor generalization caused by dataset bias is a common issue in machine learning. 
Solutions for mitigating dataset bias are divided into two categories: ensemble-based methods and additional constraint-based methods.
Ensemble-based methods~\cite{RN34, RN36, RN28} involve using weak models to learn the bias and then assessing the bias of samples based on the weak models. Biased samples are then given lower weights in the main model to achieve debias. 
Constraint-based methods~\cite{RN30, RN35, RN29, lan2023curriculum, qi2023self, lan2022closer, yoon2023counterfactual} usually entail designing special structures and adding extra tasks to the model. This approach can separate bias from true rules, forcing the model to learn the true rules to complete the task. 
In contrast to the above methods, we propose to synthesize bias-conflict samples and disrupt the uneven distribution of the target moments for samples with similar semantic components, which forces models to learn useful alignment visual-language information for grounding.

% Model bias is a common issue in machine learning.
% Dagaev {\it et al.}~\cite{RN34} proposed a debiasing method based on ensemble models for image classification tasks. They trained low-capacity models to learn the bias and used sample weighting to guide the training of the main model. 
% Darlow {\it et al.}~\cite{RN35} modified the latent representation of images to a high-entropy distribution and used adversarial training~\cite{GAN} to decouple easy-to-learn mixed signals from causal signals. Inspired by this, we propose an adversarial training-based method for debiasing models. 
% Han {\it et al.}~\cite{RN36} introduced a greedy gradient ensemble method for debiasing in the VQA task, where biased models learn the bias and the ensemble model gradient descent is used to re-label samples to reduce the influence of biased samples. 
% Yang {\it et al.}~\cite{RN29} separated time and location information from each proposal feature using constraint loss and used causal intervention to fairly consider all candidate proposals in the TSGV task.
% Hao {\it et al.}~\cite{RN30} disrupted the input video and introduced two auxiliary tasks to facilitate visual-textual feature mining for matching. 
% Liu {\it et al.}~\cite{RN28} solved the bias problem through feature distillation and negative sample generation. Inspired by these works, we propose an automatic bias-adversarial sample generation method based on adversarial training in this paper to address model bias.


