@inproceedings{wang2023scene,
	title={Scene-robust Natural Language Video Localization via Learning Domain-invariant Representations},
	author={Wang, Zehan and Zhao, Yang and Huang, Haifeng and Xia, Yan and Zhao, Zhou},
	booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
	pages={144--160},
	year={2023}
}
@inproceedings{zheng2023generating,
	title={Generating Structured Pseudo Labels for Noise-resistant Zero-shot Video Sentence Localization},
	author={Zheng, Minghang and Gong, Shaogang and Jin, Hailin and Peng, Yuxin and Liu, Yang},
	booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics},
	pages={14197--14209},
	year={2023}
}
@inproceedings{zheng2023phrase,
	title={Phrase-level Temporal Relationship Mining for Temporal Sentence Localization},
	author={Zheng, Minghang and Li, Sizhe and Chen, Qingchao and Peng, Yuxin and Liu, Yang},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	year={2023}
}
@article{qi2023self,
	title={Self-Regulated Learning for Egocentric Video Activity Anticipation},
	author={Qi, Zhaobo and Wang, Shuhui and Su, Chi and Su, Li and Huang, Qingming and Tian, Qi},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={45},
	number={6},
	pages={6715--6730},
	year={2023}
}

@inproceedings{lan2023curriculum,
	title={Curriculum multi-negative augmentation for debiased video grounding},
	author={Lan, Xiaohan and Yuan, Yitian and Chen, Hong and Wang, Xin and Jie, Zequn and Ma, Lin and Wang, Zhi and Zhu, Wenwu},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	year={2023}
}
@article{lan2022closer,
	title={A closer look at debiased temporal sentence grounding in videos: Dataset, metric, and approach},
	author={Lan, Xiaohan and Yuan, Yitian and Wang, Xin and Chen, Long and Wang, Zhi and Ma, Lin and Zhu, Wenwu},
	journal={ACM Transactions on Multimedia Computing, Communications, and Applications},
	year={2022},
	publisher={ACM New York, NY}
}
@inproceedings{yoon2023counterfactual,
	title={Counterfactual Two-Stage Debiasing For Video Corpus Moment Retrieval},
	author={Yoon, Sunjae and Hong, Ji Woo and Eom, Soohwan and Yoon, Hee Suk and Yoon, Eunseop and Kim, Daehyeok and Kim, Junyeong and Kim, Chanwoo and Yoo, Chang D},
	booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
	pages={1--5},
	year={2023},
	organization={IEEE}
}
@article{hao2022query,
	title={Query-aware video encoder for video moment retrieval},
	author={Hao, Jiachang and Sun, Haifeng and Ren, Pengfei and Wang, Jingyu and Qi, Qi and Liao, Jianxin},
	journal={Neurocomputing},
	volume={483},
	pages={72--86},
	year={2022},
	publisher={Elsevier}
}

@inproceedings{RN1,
   author = {Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
   title = {Tall: Temporal activity localization via language query},
   booktitle = {Proceedings of the IEEE international conference on computer vision},
   pages = {5267-5275},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{RN2,
   author = {Zhang, Songyang and Peng, Houwen and Fu, Jianlong and Luo, Jiebo},
   title = {Learning 2d temporal adjacent networks for moment localization with natural language},
   booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {34},
   year = {2020},
   pages = {12870-12877},
   ISBN = {2374-3468},
   type = {Conference Proceedings}
}

@article{RN3,
   author = {Ghosh, Soham and Agarwal, Anuva and Parekh, Zarana and Hauptmann, Alexander},
   title = {Excl: Extractive clip localization using natural language descriptions},
   journal = {arXiv preprint arXiv:1904.02755},
   year = {2019},
   type = {Journal Article}
}

@article{RN4,
   author = {Zhang, Hao and Sun, Aixin and Jing, Wei and Zhou, Joey Tianyi},
   title = {Span-based localizing network for natural language video localization},
   journal = {arXiv preprint arXiv:2004.13931},
   year = {2020},
   type = {Journal Article}
}

@article{RN5,
   author = {Yuan, Yitian and Ma, Lin and Wang, Jingwen and Liu, Wei and Zhu, Wenwu},
   title = {Semantic conditioned dynamic modulation for temporal sentence grounding in videos},
   journal = {Advances in Neural Information Processing Systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}

@inproceedings{RN6,
   author = {Xu, Huijuan and He, Kun and Plummer, Bryan A and Sigal, Leonid and Sclaroff, Stan and Saenko, Kate},
   title = {Multilevel language and vision integration for text-to-clip retrieval},
   booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {33},
   year = {2019},
   pages = {9062-9069},
   ISBN = {2374-3468},
   type = {Conference Proceedings}
}
% Bias Problem
@article{RN7,
   author = {Otani, Mayu and Nakashima, Yuta and Rahtu, Esa and Heikkil√§, Janne},
   title = {Uncovering hidden challenges in query-based video moment retrieval},
   journal = {arXiv preprint arXiv:2009.00325},
   year = {2020},
   type = {Journal Article}
}
% anchor-based methods
@inproceedings{RN8,
   author = {Yu, Xinli and Malmir, Mohsen and He, Xin and Chen, Jiangning and Wang, Tong and Wu, Yue and Liu, Yue and Liu, Yang},
   title = {Cross interaction network for natural language guided video moment retrieval},
   booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   year = {2021},
   pages = {1860-1864},
   type = {Conference Proceedings}
}

@inproceedings{RN9,
   author = {Wang, Jingwen and Ma, Lin and Jiang, Wenhao},
   title = {Temporally grounding language queries in videos by contextual boundary-aware prediction},
   booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {34},
   pages = {12168-12175},
   ISBN = {2374-3468},
   year = {2020},
   type = {Conference Proceedings}
}
@inproceedings{RN10,
   author = {Qu, Xiaoye and Tang, Pengwei and Zou, Zhikang and Cheng, Yu and Dong, Jianfeng and Zhou, Pan and Xu, Zichuan},
   title = {Fine-grained iterative attention network for temporal language localization in videos},
   booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
   pages = {4280-4288},
   year = {2020},
   type = {Conference Proceedings}
}
@inproceedings{RN11,
   author = {Zhang, Zhu and Lin, Zhijie and Zhao, Zhou and Xiao, Zhenxin},
   title = {Cross-modal interaction networks for query-based moment retrieval in videos},
   booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
   pages = {655-664},
   year = {2019},
   type = {Conference Proceedings}
}
@article{RN12,
   author = {Yuan, Yitian and Ma, Lin and Wang, Jingwen and Liu, Wei and Zhu, Wenwu},
   title = {Semantic conditioned dynamic modulation for temporal sentence grounding in videos},
   journal = {Advances in Neural Information Processing Systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}

% 2D-based methods
@inproceedings{RN13,
   author = {Zhang, Mingxing and Yang, Yang and Chen, Xinghan and Ji, Yanli and Xu, Xing and Li, Jingjing and Shen, Heng Tao},
   title = {Multi-stage aggregated transformer network for temporal language localization in videos},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {12669-12678},
   year = {2021},
   type = {Conference Proceedings}
}

@inproceedings{RN14,
   author = {Wang, Hao and Zha, Zheng-Jun and Li, Liang and Liu, Dong and Luo, Jiebo},
   title = {Structured multi-level interaction network for video moment localization via language query},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {7026-7035},
   year = {2021},
   type = {Conference Proceedings}
}
@article{RN15,
   author = {Gao, Jialin and Sun, Xin and Xu, Mengmeng and Zhou, Xi and Ghanem, Bernard},
   title = {Relation-aware video reading comprehension for temporal language grounding},
   journal = {arXiv preprint arXiv:2110.05717},
   year = {2021},
   type = {Journal Article}
}
@inproceedings{RN16,
   author = {Gao, Junyu and Xu, Changsheng},
   title = {Fast video moment retrieval},
   booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
   pages = {1523-1532},
    year = {2021},
   type = {Conference Proceedings}
}
@article{RN17,
   author = {Hu, Yupeng and Nie, Liqiang and Liu, Meng and Wang, Kun and Wang, Yinglong and Hua, Xian-Sheng},
   title = {Coarse-to-fine semantic alignment for cross-modal moment localization},
   journal = {IEEE Transactions on Image Processing},
   volume = {30},
   pages = {5933-5943},
   ISSN = {1057-7149},
   year = {2021},
   type = {Journal Article}
}
% Regression-based models
@inproceedings{RN18,
   author = {Yuan, Yitian and Mei, Tao and Zhu, Wenwu},
   title = {To find where you talk: Temporal sentence localization in video with attention based location regression},
   booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {33},
   pages = {9159-9166},
   year = {2019},
   ISBN = {2374-3468},
   type = {Conference Proceedings}
}


@inproceedings{RN19,
   author = {Lu, Chujie and Chen, Long and Tan, Chilie and Li, Xiaolin and Xiao, Jun},
   title = {Debug: A dense bottom-up grounding approach for natural language video localization},
   booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
   pages = {5144-5153},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{RN20,
   author = {Zeng, Runhao and Xu, Haoming and Huang, Wenbing and Chen, Peihao and Tan, Mingkui and Gan, Chuang},
   title = {Dense regression network for video grounding},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {10287-10296},
   year = {2020},
   type = {Conference Proceedings}
}

@inproceedings{RN21,
  title={Local-global video-text interactions for temporal grounding},
  author={Mun, Jonghwan and Cho, Minsu and Han, Bohyung},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10810--10819},
  year={2020}
}
% Span-based methods
@article{RN22,
   author = {Tang, Haoyu and Zhu, Jihua and Liu, Meng and Gao, Zan and Cheng, Zhiyong},
   title = {Frame-wise cross-modal matching for video moment retrieval},
   journal = {IEEE Transactions on Multimedia},
   volume = {24},
   pages = {1338-1349},
   ISSN = {1520-9210},
   year = {2021},
   type = {Journal Article}
}

@inproceedings{RN23,
   author = {Zhao, Yang and Zhao, Zhou and Zhang, Zhu and Lin, Zhijie},
   title = {Cascaded prediction network via segment tree for temporal video grounding},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {4197-4206},
   year = {2021},
   type = {Conference Proceedings}
}
@inproceedings{RN24,
   author = {Yu, Xinli and Malmir, Mohsen and He, Xin and Chen, Jiangning and Wang, Tong and Wu, Yue and Liu, Yue and Liu, Yang},
   title = {Cross interaction network for natural language guided video moment retrieval},
   booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   pages = {1860-1864},
   year = {2021},
   type = {Conference Proceedings}
}

@article{RN25,
   author = {Zhang, Hao and Sun, Aixin and Jing, Wei and Zhen, Liangli and Zhou, Joey Tianyi and Goh, Rick Siow Mong},
   title = {Parallel attention network with sequence matching for video grounding},
   journal = {arXiv preprint arXiv:2105.08481},
   year = {2021},
   type = {Journal Article}
}

@article{RN26,
   author = {Zhang, Hao and Sun, Aixin and Jing, Wei and Zhen, Liangli and Zhou, Joey Tianyi and Goh, Rick Siow Mong},
   title = {Natural language video localization: A revisit in span-based question answering framework},
   journal = {IEEE transactions on pattern analysis and machine intelligence},
   ISSN = {0162-8828},
   year = {2021},
   type = {Journal Article}
}



% DeBias Method

@article{RN27,
   author = {Lan, Xiaohan and Yuan, Yitian and Wang, Xin and Chen, Long and Wang, Zhi and Ma, Lin and Zhu, Wenwu},
   title = {A Closer Look at Debiased Temporal Sentence Grounding in Videos: Dataset, Metric, and Approach},
   journal = {arXiv preprint arXiv:2203.05243},
   year = {2022},
   type = {Journal Article}
}

@inproceedings{RN28,
   author = {Liu, Daizong and Qu, Xiaoye and Hu, Wei},
   title = {Reducing the vision and language bias for temporal sentence grounding},
   booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
   pages = {4092-4101},
   year = {2022},
   type = {Conference Proceedings}
}

@inproceedings{RN29,
   author = {Yang, Xun and Feng, Fuli and Ji, Wei and Wang, Meng and Chua, Tat-Seng},
   title = {Deconfounded video moment retrieval with causal intervention},
   booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   pages = {1-10},
   year = {2021},
   type = {Conference Proceedings}
}

@inproceedings{RN30,
   author = {Hao, Jiachang and Sun, Haifeng and Ren, Pengfei and Wang, Jingyu and Qi, Qi and Liao, Jianxin},
   title = {Can Shuffling Video Benefit Temporal Bias Problem: A Novel Training Framework for Temporal Grounding},
   booktitle={Proceedings of the European Conference on Computer Vision},
   pages = {130-147},
   year = {2022},
   type = {Conference Proceedings}
}

@article{RN31,
   author = {Zhang, Hao and Sun, Aixin and Jing, Wei and Zhou, Joey Tianyi},
   title = {Towards debiasing temporal sentence grounding in video},
   journal = {arXiv preprint arXiv:2111.04321},
   year = {2021},
   type = {Journal Article}
}

@article{RN32,
   author = {Bao, Peijun and Mu, Yadong},
   title = {Learning Sample Importance for Cross-Scenario Video Temporal Grounding},
   journal = {arXiv preprint arXiv:2201.02848},
   year = {2022},
   type = {Journal Article}
}

% Other Domain Debias

@article{RN33,
   author = {Nam, Junhyun and Cha, Hyuntak and Ahn, Sungsoo and Lee, Jaeho and Shin, Jinwoo},
   title = {Learning from failure: De-biasing classifier from biased classifier},
   journal = {Advances in Neural Information Processing Systems},
   volume = {33},
   pages = {20673-20684},
   year = {2020},
   type = {Journal Article}
}

@article{RN34,
   author = {Dagaev, Nikolay and Roads, Brett D and Luo, Xiaoliang and Barry, Daniel N and Patil, Kaustubh R and Love, Bradley C},
   title = {A too-good-to-be-true prior to reduce shortcut reliance},
   journal = {arXiv preprint arXiv:2102.06406},
   year = {2021},
   type = {Journal Article}
}

@article{RN35,
	title={Latent adversarial debiasing: Mitigating collider bias in deep neural networks},
	author={Darlow, Luke and Jastrz{\k{e}}bski, Stanis{\l}aw and Storkey, Amos},
	journal={arXiv preprint arXiv:2011.11486},
	year={2020},
	type = {Journal Article}
}

@inproceedings{RN36,
   author = {Han, Xinzhe and Wang, Shuhui and Su, Chi and Huang, Qingming and Tian, Qi},
   title = {Greedy gradient ensemble for robust visual question answering},
   booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
   pages = {1584-1593},
   year={2021},
   type = {Conference Proceedings}
}

% Dataset
@inproceedings{RN37,
   author = {Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
   title = {Dense-captioning events in videos},
   booktitle = {Proceedings of the IEEE international conference on computer vision},
   pages = {706-715},
   year={2017},
   type = {Conference Proceedings}
}



@inproceedings{G3AN,
   author = {Wang, Yaohui and Bilinski, Piotr and Bremond, Francois and Dantcheva, Antitza},
   title = {G3AN: Disentangling appearance and motion for video generation},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {5264-5273},
   year={2020},
   type = {Conference Proceedings}
}



@misc{GAN,
  doi = {10.48550/ARXIV.1406.2661},
  
  url = {https://arxiv.org/abs/1406.2661},
  
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Generative Adversarial Networks},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{image2image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

@inproceedings{C3D,
   author = {Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
   title = {Learning spatiotemporal features with 3d convolutional networks},
   booktitle = {Proceedings of the IEEE international conference on computer vision},
   pages = {4489-4497},
   year={2015},
   type = {Conference Proceedings}
}

@inproceedings{I3D,
   author = {Carreira, Joao and Zisserman, Andrew},
   title = {Quo vadis, action recognition? a new model and the kinetics dataset},
   booktitle = {proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
   pages = {6299-6308},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{Glove,
   author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
   title = {Glove: Global vectors for word representation},
   booktitle = {Proceedings of the conference on empirical methods in natural language processing},
   pages = {1532-1543},
   year = {2014},
   type = {Conference Proceedings}
}

@article{AdamW,
  title={Fixing weight decay regularization in adam},
  author={Loshchilov, Ilya and Hutter, Frank},
  year={2017}
}