\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Carreira and Zisserman(2017)}]{I3D}
Carreira, J.; and Zisserman, A. 2017.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In \emph{proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 6299--6308.

\bibitem[{Dagaev et~al.(2021)Dagaev, Roads, Luo, Barry, Patil, and Love}]{RN34}
Dagaev, N.; Roads, B.~D.; Luo, X.; Barry, D.~N.; Patil, K.~R.; and Love, B.~C.
  2021.
\newblock A too-good-to-be-true prior to reduce shortcut reliance.
\newblock \emph{arXiv preprint arXiv:2102.06406}.

\bibitem[{Darlow, Jastrz{\k{e}}bski, and Storkey(2020)}]{RN35}
Darlow, L.; Jastrz{\k{e}}bski, S.; and Storkey, A. 2020.
\newblock Latent adversarial debiasing: Mitigating collider bias in deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:2011.11486}.

\bibitem[{Gao et~al.(2021)Gao, Sun, Xu, Zhou, and Ghanem}]{RN15}
Gao, J.; Sun, X.; Xu, M.; Zhou, X.; and Ghanem, B. 2021.
\newblock Relation-aware video reading comprehension for temporal language
  grounding.
\newblock \emph{arXiv preprint arXiv:2110.05717}.

\bibitem[{Gao and Xu(2021)}]{RN16}
Gao, J.; and Xu, C. 2021.
\newblock Fast video moment retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 1523--1532.

\bibitem[{Ghosh et~al.(2019)Ghosh, Agarwal, Parekh, and Hauptmann}]{RN3}
Ghosh, S.; Agarwal, A.; Parekh, Z.; and Hauptmann, A. 2019.
\newblock Excl: Extractive clip localization using natural language
  descriptions.
\newblock \emph{arXiv preprint arXiv:1904.02755}.

\bibitem[{Han et~al.(2021)Han, Wang, Su, Huang, and Tian}]{RN36}
Han, X.; Wang, S.; Su, C.; Huang, Q.; and Tian, Q. 2021.
\newblock Greedy gradient ensemble for robust visual question answering.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 1584--1593.

\bibitem[{Hao et~al.(2022{\natexlab{a}})Hao, Sun, Ren, Wang, Qi, and
  Liao}]{RN30}
Hao, J.; Sun, H.; Ren, P.; Wang, J.; Qi, Q.; and Liao, J. 2022{\natexlab{a}}.
\newblock Can Shuffling Video Benefit Temporal Bias Problem: A Novel Training
  Framework for Temporal Grounding.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  130--147.

\bibitem[{Hao et~al.(2022{\natexlab{b}})Hao, Sun, Ren, Wang, Qi, and
  Liao}]{hao2022query}
Hao, J.; Sun, H.; Ren, P.; Wang, J.; Qi, Q.; and Liao, J. 2022{\natexlab{b}}.
\newblock Query-aware video encoder for video moment retrieval.
\newblock \emph{Neurocomputing}, 483: 72--86.

\bibitem[{Hu et~al.(2021)Hu, Nie, Liu, Wang, Wang, and Hua}]{RN17}
Hu, Y.; Nie, L.; Liu, M.; Wang, K.; Wang, Y.; and Hua, X.-S. 2021.
\newblock Coarse-to-fine semantic alignment for cross-modal moment
  localization.
\newblock \emph{IEEE Transactions on Image Processing}, 30: 5933--5943.

\bibitem[{Lan et~al.(2023)Lan, Yuan, Chen, Wang, Jie, Ma, Wang, and
  Zhu}]{lan2023curriculum}
Lan, X.; Yuan, Y.; Chen, H.; Wang, X.; Jie, Z.; Ma, L.; Wang, Z.; and Zhu, W.
  2023.
\newblock Curriculum multi-negative augmentation for debiased video grounding.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}.

\bibitem[{Lan et~al.(2022)Lan, Yuan, Wang, Chen, Wang, Ma, and
  Zhu}]{lan2022closer}
Lan, X.; Yuan, Y.; Wang, X.; Chen, L.; Wang, Z.; Ma, L.; and Zhu, W. 2022.
\newblock A closer look at debiased temporal sentence grounding in videos:
  Dataset, metric, and approach.
\newblock \emph{ACM Transactions on Multimedia Computing, Communications, and
  Applications}.

\bibitem[{Liu, Qu, and Hu(2022)}]{RN28}
Liu, D.; Qu, X.; and Hu, W. 2022.
\newblock Reducing the vision and language bias for temporal sentence
  grounding.
\newblock In \emph{Proceedings of the 30th ACM International Conference on
  Multimedia}, 4092--4101.

\bibitem[{Loshchilov and Hutter(2017)}]{AdamW}
Loshchilov, I.; and Hutter, F. 2017.
\newblock Fixing weight decay regularization in adam.

\bibitem[{Lu et~al.(2019)Lu, Chen, Tan, Li, and Xiao}]{RN19}
Lu, C.; Chen, L.; Tan, C.; Li, X.; and Xiao, J. 2019.
\newblock Debug: A dense bottom-up grounding approach for natural language
  video localization.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing}, 5144--5153.

\bibitem[{Mun, Cho, and Han(2020)}]{RN21}
Mun, J.; Cho, M.; and Han, B. 2020.
\newblock Local-global video-text interactions for temporal grounding.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10810--10819.

\bibitem[{Otani et~al.(2020)Otani, Nakashima, Rahtu, and Heikkilä}]{RN7}
Otani, M.; Nakashima, Y.; Rahtu, E.; and Heikkilä, J. 2020.
\newblock Uncovering hidden challenges in query-based video moment retrieval.
\newblock \emph{arXiv preprint arXiv:2009.00325}.

\bibitem[{Pennington, Socher, and Manning(2014)}]{Glove}
Pennington, J.; Socher, R.; and Manning, C.~D. 2014.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the conference on empirical methods in
  natural language processing}, 1532--1543.

\bibitem[{Qi et~al.(2023)Qi, Wang, Su, Su, Huang, and Tian}]{qi2023self}
Qi, Z.; Wang, S.; Su, C.; Su, L.; Huang, Q.; and Tian, Q. 2023.
\newblock Self-Regulated Learning for Egocentric Video Activity Anticipation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 45(6): 6715--6730.

\bibitem[{Qu et~al.(2020)Qu, Tang, Zou, Cheng, Dong, Zhou, and Xu}]{RN10}
Qu, X.; Tang, P.; Zou, Z.; Cheng, Y.; Dong, J.; Zhou, P.; and Xu, Z. 2020.
\newblock Fine-grained iterative attention network for temporal language
  localization in videos.
\newblock In \emph{Proceedings of the 28th ACM International Conference on
  Multimedia}, 4280--4288.

\bibitem[{Tang et~al.(2021)Tang, Zhu, Liu, Gao, and Cheng}]{RN22}
Tang, H.; Zhu, J.; Liu, M.; Gao, Z.; and Cheng, Z. 2021.
\newblock Frame-wise cross-modal matching for video moment retrieval.
\newblock \emph{IEEE Transactions on Multimedia}, 24: 1338--1349.

\bibitem[{Tran et~al.(2015)Tran, Bourdev, Fergus, Torresani, and Paluri}]{C3D}
Tran, D.; Bourdev, L.; Fergus, R.; Torresani, L.; and Paluri, M. 2015.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 4489--4497.

\bibitem[{Wang et~al.(2021)Wang, Zha, Li, Liu, and Luo}]{RN14}
Wang, H.; Zha, Z.-J.; Li, L.; Liu, D.; and Luo, J. 2021.
\newblock Structured multi-level interaction network for video moment
  localization via language query.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 7026--7035.

\bibitem[{Wang, Ma, and Jiang(2020)}]{RN9}
Wang, J.; Ma, L.; and Jiang, W. 2020.
\newblock Temporally grounding language queries in videos by contextual
  boundary-aware prediction.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, 12168--12175.
\newblock ISBN 2374-3468.

\bibitem[{Wang et~al.(2020)Wang, Bilinski, Bremond, and Dantcheva}]{G3AN}
Wang, Y.; Bilinski, P.; Bremond, F.; and Dantcheva, A. 2020.
\newblock G3AN: Disentangling appearance and motion for video generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 5264--5273.

\bibitem[{Wang et~al.(2023)Wang, Zhao, Huang, Xia, and Zhao}]{wang2023scene}
Wang, Z.; Zhao, Y.; Huang, H.; Xia, Y.; and Zhao, Z. 2023.
\newblock Scene-robust Natural Language Video Localization via Learning
  Domain-invariant Representations.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2023}, 144--160.

\bibitem[{Yang et~al.(2021)Yang, Feng, Ji, Wang, and Chua}]{RN29}
Yang, X.; Feng, F.; Ji, W.; Wang, M.; and Chua, T.-S. 2021.
\newblock Deconfounded video moment retrieval with causal intervention.
\newblock In \emph{Proceedings of the 44th International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, 1--10.

\bibitem[{Yoon et~al.(2023)Yoon, Hong, Eom, Yoon, Yoon, Kim, Kim, Kim, and
  Yoo}]{yoon2023counterfactual}
Yoon, S.; Hong, J.~W.; Eom, S.; Yoon, H.~S.; Yoon, E.; Kim, D.; Kim, J.; Kim,
  C.; and Yoo, C.~D. 2023.
\newblock Counterfactual Two-Stage Debiasing For Video Corpus Moment Retrieval.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing}, 1--5. IEEE.

\bibitem[{Yu et~al.(2021)Yu, Malmir, He, Chen, Wang, Wu, Liu, and Liu}]{RN8}
Yu, X.; Malmir, M.; He, X.; Chen, J.; Wang, T.; Wu, Y.; Liu, Y.; and Liu, Y.
  2021.
\newblock Cross interaction network for natural language guided video moment
  retrieval.
\newblock In \emph{Proceedings of the 44th International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, 1860--1864.

\bibitem[{Yuan et~al.(2019)Yuan, Ma, Wang, Liu, and Zhu}]{RN5}
Yuan, Y.; Ma, L.; Wang, J.; Liu, W.; and Zhu, W. 2019.
\newblock Semantic conditioned dynamic modulation for temporal sentence
  grounding in videos.
\newblock \emph{Advances in Neural Information Processing Systems}, 32.

\bibitem[{Yuan, Mei, and Zhu(2019)}]{RN18}
Yuan, Y.; Mei, T.; and Zhu, W. 2019.
\newblock To find where you talk: Temporal sentence localization in video with
  attention based location regression.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, 9159--9166.
\newblock ISBN 2374-3468.

\bibitem[{Zeng et~al.(2020)Zeng, Xu, Huang, Chen, Tan, and Gan}]{RN20}
Zeng, R.; Xu, H.; Huang, W.; Chen, P.; Tan, M.; and Gan, C. 2020.
\newblock Dense regression network for video grounding.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 10287--10296.

\bibitem[{Zhang et~al.(2021{\natexlab{a}})Zhang, Sun, Jing, Zhen, Zhou, and
  Goh}]{RN26}
Zhang, H.; Sun, A.; Jing, W.; Zhen, L.; Zhou, J.~T.; and Goh, R. S.~M.
  2021{\natexlab{a}}.
\newblock Natural language video localization: A revisit in span-based question
  answering framework.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}.

\bibitem[{Zhang et~al.(2021{\natexlab{b}})Zhang, Sun, Jing, Zhen, Zhou, and
  Goh}]{RN25}
Zhang, H.; Sun, A.; Jing, W.; Zhen, L.; Zhou, J.~T.; and Goh, R. S.~M.
  2021{\natexlab{b}}.
\newblock Parallel attention network with sequence matching for video
  grounding.
\newblock \emph{arXiv preprint arXiv:2105.08481}.

\bibitem[{Zhang et~al.(2020{\natexlab{a}})Zhang, Sun, Jing, and Zhou}]{RN4}
Zhang, H.; Sun, A.; Jing, W.; and Zhou, J.~T. 2020{\natexlab{a}}.
\newblock Span-based localizing network for natural language video
  localization.
\newblock \emph{arXiv preprint arXiv:2004.13931}.

\bibitem[{Zhang et~al.(2021{\natexlab{c}})Zhang, Sun, Jing, and Zhou}]{RN31}
Zhang, H.; Sun, A.; Jing, W.; and Zhou, J.~T. 2021{\natexlab{c}}.
\newblock Towards debiasing temporal sentence grounding in video.
\newblock \emph{arXiv preprint arXiv:2111.04321}.

\bibitem[{Zhang et~al.(2021{\natexlab{d}})Zhang, Yang, Chen, Ji, Xu, Li, and
  Shen}]{RN13}
Zhang, M.; Yang, Y.; Chen, X.; Ji, Y.; Xu, X.; Li, J.; and Shen, H.~T.
  2021{\natexlab{d}}.
\newblock Multi-stage aggregated transformer network for temporal language
  localization in videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 12669--12678.

\bibitem[{Zhang et~al.(2020{\natexlab{b}})Zhang, Peng, Fu, and Luo}]{RN2}
Zhang, S.; Peng, H.; Fu, J.; and Luo, J. 2020{\natexlab{b}}.
\newblock Learning 2d temporal adjacent networks for moment localization with
  natural language.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, 12870--12877.
\newblock ISBN 2374-3468.

\bibitem[{Zhang et~al.(2019)Zhang, Lin, Zhao, and Xiao}]{RN11}
Zhang, Z.; Lin, Z.; Zhao, Z.; and Xiao, Z. 2019.
\newblock Cross-modal interaction networks for query-based moment retrieval in
  videos.
\newblock In \emph{Proceedings of the 42nd International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, 655--664.

\bibitem[{Zhao et~al.(2021)Zhao, Zhao, Zhang, and Lin}]{RN23}
Zhao, Y.; Zhao, Z.; Zhang, Z.; and Lin, Z. 2021.
\newblock Cascaded prediction network via segment tree for temporal video
  grounding.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 4197--4206.

\bibitem[{Zheng et~al.(2023{\natexlab{a}})Zheng, Gong, Jin, Peng, and
  Liu}]{zheng2023generating}
Zheng, M.; Gong, S.; Jin, H.; Peng, Y.; and Liu, Y. 2023{\natexlab{a}}.
\newblock Generating Structured Pseudo Labels for Noise-resistant Zero-shot
  Video Sentence Localization.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics}, 14197--14209.

\bibitem[{Zheng et~al.(2023{\natexlab{b}})Zheng, Li, Chen, Peng, and
  Liu}]{zheng2023phrase}
Zheng, M.; Li, S.; Chen, Q.; Peng, Y.; and Liu, Y. 2023{\natexlab{b}}.
\newblock Phrase-level Temporal Relationship Mining for Temporal Sentence
  Localization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}.

\end{thebibliography}
