\relax 
\bibstyle{aaai24}
\citation{antol2015vqa}
\citation{patro2019u,chen2022rex}
\citation{lu2016hierarchical,selvaraju2017grad}
\citation{camburu2018snli,park2018multimodal}
\citation{wei2022chain}
\citation{park2018multimodal,kayser2021vil,wu2019faithful}
\citation{sammani2022nlx}
\citation{sammani2022nlx}
\citation{sammani2022nlx,suo2023s3c}
\citation{wei2022chain}
\citation{malinowski2014multi}
\citation{dong2018predicting,yao2019hierarchy}
\citation{anderson2018bottom,lu2016hierarchical}
\citation{ma2018visual,xiong2016dynamic}
\citation{kipf2016semi,velickovic2017graph}
\citation{selvaraju2017grad,patro2019u}
\citation{wu2019self}
\citation{park2018multimodal}
\citation{kayser2021vil}
\citation{yang2022chunk}
\citation{li2020oscar}
\citation{radford2019language}
\citation{sammani2022nlx}
\citation{suo2023s3c}
\citation{hadsell2006dimensionality}
\citation{dosovitskiy2014discriminative}
\citation{khosla2020supervised,tian2020makes}
\citation{kim2021self,liang2020learning}
\citation{dai2017contrastive,li2020context}
\citation{zhang2020counterfactual}
\citation{zhang2021multi}
\citation{liang2020learning}
\citation{sammani2022nlx}
\citation{radford2019language}
\citation{radford2021learning}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{example}{{1}{2}{Three types of logical errors in VQA-NLE: (a) The generated explanation does not logically lead to the answer; (b) The model falsifies its counterfactual explanation for the answer without considering the facts in image; and (c) The model infers the same explanation and answer for a statement and its opposite semantics.}{}{}}
\newlabel{vl}{{}{2}{}{}{}}
\newlabel{frame}{{2}{3}{The overall architecture of MCLE. It consists of a vision-language model with chain-of-thought generation strategy and a multi-level contrastive learning network (semantic-level, image-level, and instance-level).}{}{}}
\newlabel{COT_loss}{{1}{3}{}{}{}}
\newlabel{hidden_e}{{}{3}{}{}{}}
\newlabel{hidden_a}{{}{3}{}{}{}}
\citation{lee2020contrastive}
\citation{selvaraju2017grad}
\newlabel{score}{{}{4}{}{}{}}
\citation{suo2023s3c}
\citation{park2018multimodal}
\citation{antol2015vqa}
\citation{schwenk2022okvqa}
\citation{lin2014microsoft}
\citation{suo2023s3c}
\citation{papineni2002bleu}
\citation{denkowski2014meteor}
\citation{lin2004rouge}
\citation{anderson2016spice}
\citation{vedantam2015cider}
\citation{suo2023s3c}
\citation{kayser2021vil}
\citation{park2018multimodal}
\citation{wu2019faithful}
\citation{selvaraju2017grad}
\citation{kayser2021vil}
\citation{chen2020uniter}
\citation{sammani2022nlx}
\citation{suo2023s3c}
\citation{sammani2022nlx}
\citation{kayser2021vil}
\citation{sammani2022nlx}
\newlabel{tb:unfiltered}{{1}{6}{Comparison with the state-of-the-art methods on the VQA-X and A-OKVQA datasets in the scenario of ``unfiltered'' scores. (``unfiltered'' indicates that the explanations are evaluated regardless of whether the answer is true or false, while ``filtered'' is to only consider the explanations that have correct answers.) The B4, M, R, C, S, Acc, and Human are short for BLEU-4, METEOR, ROUGE-L, CIDEr, SPICE, Answer Accuracy, and Human Evaluation, respectively.}{}{}}
\newlabel{tb:filtered}{{2}{6}{Comparison with the state-of-the-art methods on the VQA-X dataset in the scenario of ``filtered'' scores. (``unfiltered'' indicates that the explanations are evaluated regardless of whether the answer is true or false, while ``filtered'' is to only consider the explanations that have correct answers.) }{}{}}
\newlabel{tb:shortcoming}{{3}{6}{The main reason of unqualified explanations on the VQA-X dataset. Three types of logical errors: (a) Type I: Deductive unsatisfiability, (b) Type II: Factual inconsistency, and (c) Type III: Semantic perturbation insensitivity (see Figure\nobreakspace  {}\ref {example}).}{}{}}
\newlabel{tb:ablation}{{4}{7}{Ablated results of our MCLE and its key components, chain-of-thought (COT) generation strategy and the multi-level contrastive learning network (semantic-level, image-level, and instance-level).}{}{}}
\newlabel{case}{{3}{7}{Case study on the generated explanations on the VQA-X dataset. The $[\cdot ]$ and $<\cdot >$ indicate answers and explanations respectively. We show the results of our full MCLE model and its three variants. GT denotes by the ground truth.}{}{}}
\bibdata{aaai24}
\gdef \@abspage@last{8}
