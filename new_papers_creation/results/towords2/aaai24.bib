@book{em:86,
	editor  = "Engelmore, Robert and Morgan, Anthony",
	title   = "Blackboard Systems",
	year    = 1986,
	address = "Reading, Mass.",
	publisher = "Addison-Wesley",
}

@inproceedings{c:83,
	author  = "Clancey, William J.",
	year    = 1983,
	title   = "{Communication, Simulation, and Intelligent
	Agents: Implications of Personal Intelligent Machines
	for Medical Education}",
	booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
	pages   = "556-560",
	address = "Menlo Park, Calif",
	publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
	author  = "Clancey, William J.",
	year    = 1984,
	title   = "{Classification Problem Solving}",
	booktitle = "Proceedings of the Fourth National 
	Conference on Artificial Intelligence",
	pages   = "45-54",
	address = "Menlo Park, Calif.",
	publisher="AAAI Press",
}
@article{r:80,
	author = {Robinson, Arthur L.},
	title = {New Ways to Make Microcircuits Smaller},
	volume = {208},
	number = {4447},
	pages = {1019--1022},
	year = {1980},
	doi = {10.1126/science.208.4447.1019},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/208/4447/1019},
	eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
	journal = {Science},
}
@article{r:80x,
	author  = "Robinson, Arthur L.",
	year    = 1980,
	title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
	journal = "Science",
	volume  =  208,
	pages   = "1019-1026",
}
@article{hcr:83,
	title = {Strategic explanations for a diagnostic consultation system},
	journal = {International Journal of Man-Machine Studies},
	volume = {20},
	number = {1},
	pages = {3-19},
	year = {1984},
	issn = {0020-7373},
	doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
	url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
	author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
	abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possible—the representation of strategic knowledge explicitly and separately from domain knowledge— and demonstrate how this representation can be used to generate explanations.}
}
@article{hcrt:83,
	author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
	year    = 1983,
	title   = "{Strategic Explanations in Consultation---Duplicate}",
	journal = "The International Journal of Man-Machine Studies",
	volume  = 20,
	number  = 1,
	pages   = "3-19",
}
@techreport{r:86,
	author  = "Rice, James",
	year    = 1986,
	title   = "{Poligon: A System for Parallel Problem Solving}",
	type    = "Technical Report", 
	number  = "KSL-86-19", 
	institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
	author  = "Clancey, William J.",
	year    = 1979,
	title   = "{Transfer of Rule-Based Expertise
	through a Tutorial Dialogue}",
	type    = "{Ph.D.} diss.",
	school  = "Dept.\ of Computer Science, Stanford Univ.",
	address = "Stanford, Calif.",
}
@unpublished{c:21,
	author  = "Clancey, William J.",
	title   = "{The Engineering of Qualitative Models}",
	year    = 2021,
	note    = "Forthcoming",
}
@misc{c:22,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
@misc{c:23,
	title        = "Pluto: The 'Other' Red Planet",
	author       = "{NASA}",
	howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
	year         = 2015,
	note         = "Accessed: 2018-12-06"
}
@inproceedings{antol2015vqa,
	title={Vqa: Visual question answering},
	author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2425--2433},
	year={2015}
}
@article{lu2016hierarchical,
	title={Hierarchical question-image co-attention for visual question answering},
	author={Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
	journal={Advances in neural information processing systems},
	volume={29},
	year={2016}
}
@inproceedings{selvaraju2017grad,
	title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
	author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={618--626},
	year={2017}
}
@article{camburu2018snli,
	title={e-snli: Natural language inference with natural language explanations},
	author={Camburu, Oana-Maria and Rockt{\"a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
	journal={Advances in Neural Information Processing Systems},
	volume={31},
	year={2018}
}
@inproceedings{park2018multimodal,
	title={Multimodal explanations: Justifying decisions and pointing to the evidence},
	author={Park, Dong Huk and Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Rohrbach, Marcus},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={8779--8788},
	year={2018}
}
@inproceedings{patro2019u,
	title={U-cam: Visual explanation using uncertainty based class activation maps},
	author={Patro, Badri N and Lunayach, Mayank and Patel, Shivansh and Namboodiri, Vinay P},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={7444--7453},
	year={2019}
}
@inproceedings{marasovic2020natural,
	title={Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs},
	author={Marasovi{\'c}, Ana and Bhagavatula, Chandra and Park, Jae Sung and Le Bras, Ronan and Smith, Noah A and Choi, Yejin},
	booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
	pages={2810--2829},
	year={2020}
}
@inproceedings{kayser2021vil,
	title={e-vil: A dataset and benchmark for natural language explanations in vision-language tasks},
	author={Kayser, Maxime and Camburu, Oana-Maria and Salewski, Leonard and Emde, Cornelius and Do, Virginie and Akata, Zeynep and Lukasiewicz, Thomas},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={1244--1254},
	year={2021}
}
@inproceedings{wu2019faithful,
	title={Faithful Multimodal Explanation for Visual Question Answering},
	author={Wu, Jialin and Mooney, Raymond},
	booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	pages={103--112},
	year={2019}
}
@inproceedings{sammani2022nlx,
	title={NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks},
	author={Sammani, Fawaz and Mukherjee, Tanmoy and Deligiannis, Nikos},
	booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={8312--8322},
	year={2022},
	organization={IEEE}
}
@inproceedings{suo2023s3c,
	title={S3C: Semi-Supervised VQA Natural Language Explanation via Self-Critical Learning},
	author={Suo, Wei and Sun, Mengyang and Liu, Weisong and Gao, Yiqi and Wang, Peng and Zhang, Yanning and Wu, Qi},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={2646--2656},
	year={2023}
}
@inproceedings{antol2015vqa,
	title={Vqa: Visual question answering},
	author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2425--2433},
	year={2015}
}
@inproceedings{radford2021learning,
	title={Learning transferable visual models from natural language supervision},
	author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	booktitle={International conference on machine learning},
	pages={8748--8763},
	year={2021},
	organization={PMLR}
}
@article{wei2022chain,
	title={Chain-of-thought prompting elicits reasoning in large language models},
	author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={24824--24837},
	year={2022}
}
@inproceedings{pillai2022consistent,
	title={Consistent explanations by contrastive learning},
	author={Pillai, Vipin and Koohpayegani, Soroush Abbasi and Ouligian, Ashley and Fong, Dennis and Pirsiavash, Hamed},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={10213--10222},
	year={2022}
}
@inproceedings{chen2022rex,
	title={Rex: Reasoning-aware and grounded explanation},
	author={Chen, Shi and Zhao, Qi},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={15586--15595},
	year={2022}
}
@article{radford2019language,
	title={Language models are unsupervised multitask learners},
	author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	journal={OpenAI blog},
	volume={1},
	number={8},
	pages={9},
	year={2019}
}
@inproceedings{lee2020contrastive,
	title={Contrastive Learning with Adversarial Perturbations for Conditional Text Generation},
	author={Lee, Seanie and Lee, Dong Bok and Hwang, Sung Ju},
	booktitle={International Conference on Learning Representations},
	year={2020}
}
@inproceedings{lin2014microsoft,
	title={Microsoft COCO: Common Objects in Context},
	author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	booktitle={European Conference on Computer Vision},
	pages={740--755},
	year={2014},
	organization={Springer}
}
@inproceedings{schwenk2022okvqa,
	title={A-okvqa: A benchmark for visual question answering using world knowledge},
	author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
	booktitle={European Conference on Computer Vision},
	pages={146--162},
	year={2022},
	organization={Springer}
}
@inproceedings{papineni2002bleu,
	title={Bleu: a method for automatic evaluation of machine translation},
	author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
	pages={311--318},
	year={2002}
}
@inproceedings{denkowski2014meteor,
	title={Meteor universal: Language specific translation evaluation for any target language},
	author={Denkowski, Michael and Lavie, Alon},
	booktitle={Proceedings of the ninth workshop on statistical machine translation},
	pages={376--380},
	year={2014}
}
@inproceedings{lin2004rouge,
	title={Rouge: A package for automatic evaluation of summaries},
	author={Lin, Chin-Yew},
	booktitle={Text summarization branches out},
	pages={74--81},
	year={2004}
}
@inproceedings{anderson2016spice,
	title={SPICE: semantic propositional image caption evaluation},
	author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
	booktitle={European Conference on Computer Vision},
	pages={382--398},
	year={2016},
	organization={Springer, Springer Nature}
}
@inproceedings{vedantam2015cider,
	title={Cider: Consensus-based image description evaluation},
	author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4566--4575},
	year={2015}
}
@inproceedings{kayser2021vil,
	title={e-vil: A dataset and benchmark for natural language explanations in vision-language tasks},
	author={Kayser, Maxime and Camburu, Oana-Maria and Salewski, Leonard and Emde, Cornelius and Do, Virginie and Akata, Zeynep and Lukasiewicz, Thomas},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={1244--1254},
	year={2021}
}
@inproceedings{chen2020uniter,
	title={Uniter: Universal image-text representation learning},
	author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
	booktitle={European conference on computer vision},
	pages={104--120},
	year={2020},
	organization={Springer}
}
@inproceedings{wu2019faithful,
	title={Faithful Multimodal Explanation for Visual Question Answering},
	author={Wu, Jialin and Mooney, Raymond},
	booktitle={Proceedings of the 2019 ACL Workshop},
	pages={103--112},
	year={2019}
}
@article{malinowski2014multi,
	title={A multi-world approach to question answering about real-world scenes based on uncertain input},
	author={Malinowski, Mateusz and Fritz, Mario},
	journal={Advances in neural information processing systems},
	volume={27},
	year={2014}
}

@article{dong2018predicting,
	title={Predicting visual features from text for image and video caption retrieval},
	author={Dong, Jianfeng and Li, Xirong and Snoek, Cees GM},
	journal={IEEE Transactions on Multimedia},
	volume={20},
	number={12},
	pages={3377--3388},
	year={2018},
	publisher={IEEE}
}

@inproceedings{yao2019hierarchy,
	title={Hierarchy parsing for image captioning},
	author={Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={2621--2629},
	year={2019}
}

@inproceedings{anderson2018bottom,
	title={Bottom-up and top-down attention for image captioning and visual question answering},
	author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={6077--6086},
	year={2018}
}

@article{lu2016hierarchical,
	title={Hierarchical question-image co-attention for visual question answering},
	author={Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
	journal={Advances in neural information processing systems},
	volume={29},
	year={2016}
}

@inproceedings{ma2018visual,
	title={Visual question answering with memory-augmented networks},
	author={Ma, Chao and Shen, Chunhua and Dick, Anthony and Wu, Qi and Wang, Peng and Van den Hengel, Anton and Reid, Ian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={6975--6984},
	year={2018}
}

@inproceedings{xiong2016dynamic,
	title={Dynamic memory networks for visual and textual question answering},
	author={Xiong, Caiming and Merity, Stephen and Socher, Richard},
	booktitle={International conference on machine learning},
	pages={2397--2406},
	year={2016},
	organization={PMLR}
}

@article{kipf2016semi,
	title={Semi-supervised classification with graph convolutional networks},
	author={Kipf, Thomas N and Welling, Max},
	journal={arXiv preprint arXiv:1609.02907},
	year={2016}
}

@article{velickovic2017graph,
	title={Graph attention networks},
	author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua and others},
	journal={stat},
	volume={1050},
	number={20},
	pages={10--48550},
	year={2017}
}

@inproceedings{selvaraju2017grad,
	title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
	author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={618--626},
	year={2017}
}

@inproceedings{patro2019u,
	title={U-cam: Visual explanation using uncertainty based class activation maps},
	author={Patro, Badri N and Lunayach, Mayank and Patel, Shivansh and Namboodiri, Vinay P},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={7444--7453},
	year={2019}
}

@article{wu2019self,
	title={Self-critical reasoning for robust visual question answering},
	author={Wu, Jialin and Mooney, Raymond},
	journal={Advances in Neural Information Processing Systems},
	volume={32},
	year={2019}
}

@inproceedings{park2018multimodal,
	title={Multimodal explanations: Justifying decisions and pointing to the evidence},
	author={Park, Dong Huk and Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Rohrbach, Marcus},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={8779--8788},
	year={2018}
}

@inproceedings{kayser2021vil,
	title={e-vil: A dataset and benchmark for natural language explanations in vision-language tasks},
	author={Kayser, Maxime and Camburu, Oana-Maria and Salewski, Leonard and Emde, Cornelius and Do, Virginie and Akata, Zeynep and Lukasiewicz, Thomas},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={1244--1254},
	year={2021}
}

@inproceedings{yang2022chunk,
	title={Chunk-aware alignment and lexical constraint for visual entailment with natural language explanations},
	author={Yang, Qian and Li, Yunxin and Hu, Baotian and Ma, Lin and Ding, Yuxin and Zhang, Min},
	booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
	pages={3587--3597},
	year={2022}
}

@inproceedings{li2020oscar,
	title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
	author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
	booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
	pages={121--137},
	year={2020},
	organization={Springer}
}

@article{radford2019language,
	title={Language models are unsupervised multitask learners},
	author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	journal={OpenAI blog},
	volume={1},
	number={8},
	pages={9},
	year={2019}
}

@inproceedings{sammani2022nlx,
	title={Nlx-gpt: A model for natural language explanations in vision and vision-language tasks},
	author={Sammani, Fawaz and Mukherjee, Tanmoy and Deligiannis, Nikos},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={8322--8332},
	year={2022}
}

@inproceedings{hadsell2006dimensionality,
	title={Dimensionality reduction by learning an invariant mapping},
	author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
	booktitle={2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06)},
	volume={2},
	pages={1735--1742},
	year={2006},
	organization={IEEE}
}

@article{oord2018representation,
	title={Representation learning with contrastive predictive coding},
	author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	journal={arXiv preprint arXiv:1807.03748},
	year={2018}
}

@article{dosovitskiy2014discriminative,
	title={Discriminative unsupervised feature learning with convolutional neural networks},
	author={Dosovitskiy, Alexey and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
	journal={Advances in neural information processing systems},
	volume={27},
	year={2014}
}

@article{khosla2020supervised,
	title={Supervised contrastive learning},
	author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={18661--18673},
	year={2020}
}

@article{tian2020makes,
	title={What makes for good views for contrastive learning?},
	author={Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={6827--6839},
	year={2020}
}

@inproceedings{kim2021self,
	title={Self-supervised pre-training and contrastive representation learning for multiple-choice video qa},
	author={Kim, Seonhoon and Jeong, Seohyeong and Kim, Eunbyul and Kang, Inho and Kwak, Nojun},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={35},
	number={14},
	pages={13171--13179},
	year={2021}
}

@inproceedings{liang2020learning,
	title={Learning to contrast the counterfactual samples for robust visual question answering},
	author={Liang, Zujie and Jiang, Weitao and Hu, Haifeng and Zhu, Jiaying},
	booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP)},
	pages={3285--3292},
	year={2020}
}

@article{dai2017contrastive,
	title={Contrastive learning for image captioning},
	author={Dai, Bo and Lin, Dahua},
	journal={Advances in Neural Information Processing Systems},
	volume={30},
	year={2017}
}

@inproceedings{li2020context,
	title={Context-aware group captioning via self-attention and contrastive features},
	author={Li, Zhuowan and Tran, Quan and Mai, Long and Lin, Zhe and Yuille, Alan L},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={3440--3450},
	year={2020}
}

@article{zhang2020counterfactual,
	title={Counterfactual contrastive learning for weakly-supervised vision-language grounding},
	author={Zhang, Zhu and Zhao, Zhou and Lin, Zhijie and He, Xiuqiang and others},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={18123--18134},
	year={2020}
}
@inproceedings{patro2019u,
	title={U-cam: Visual explanation using uncertainty based class activation maps},
	author={Patro, Badri N and Lunayach, Mayank and Patel, Shivansh and Namboodiri, Vinay P},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={7444--7453},
	year={2019}
}
@inproceedings{marasovic2020natural,
	title={Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs},
	author={Marasovi{\'c}, Ana and Bhagavatula, Chandra and Park, Jae Sung and Le Bras, Ronan and Smith, Noah A and Choi, Yejin},
	booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
	pages={2810--2829},
	year={2020}
}
@inproceedings{zhang2021multi,
	title={Multi-level counterfactual contrast for visual commonsense reasoning},
	author={Zhang, Xi and Zhang, Feifei and Xu, Changsheng},
	booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
	pages={1793--1802},
	year={2021}
}
@inproceedings{kayser2021vil,
	title={e-vil: A dataset and benchmark for natural language explanations in vision-language tasks},
	author={Kayser, Maxime and Camburu, Oana-Maria and Salewski, Leonard and Emde, Cornelius and Do, Virginie and Akata, Zeynep and Lukasiewicz, Thomas},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={1244--1254},
	year={2021}
}
@inproceedings{wu2019faithful,
	title={Faithful Multimodal Explanation for Visual Question Answering},
	author={Wu, Jialin and Mooney, Raymond},
	booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	pages={103--112},
	year={2019}
}