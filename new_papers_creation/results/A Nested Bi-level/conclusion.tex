%To tackle the issue that MAML does not perform well in the scenario where outliers (tasks, or instances) exist in the meta-training tasks. In this work, we propose a novel and robust re-weighting meta-learning algorithm, \sysname{}, which learns to assign weights to training instances or tasks. We consider these weights to be hyperparameters, and optimize them based on a small set of validation tasks using an online approximation in a ``\biopt{}" optimization framework. Extensive experiments on synthetic and real-world datasets demonstrate that our framework efficiently mitigates affects of ``unwanted" instances, showing that our proposed technique outperforms state-of-the-art meta-learning methods.
\vspace{-1mm}
We propose a novel robust meta-learning algorithm for reweighting tasks/instances of corrupted data in the meta-training phase. Our method is model-agnostic, can be directly applied to any deep learning architecture in an end-to-end manner. To the best of our knowledge, \sysname{} is the first algorithm to solve a \textit{\biopt{}} optimization problem in an online manner with a convergence result. Finally, 
% we empirically evaluate the \sysname{} algorithm's performance in OOD task and noisy label scenarios. 
empirical evaluation results in OOD task and noisy label scenarios show that \sysname{} outperforms state-of-the-art meta-learning methods by efficiently mitigating the effects of unwanted instances or tasks. 
% We strive to test \sysname{} in distribution shift, task, and class imbalance settings for future work.
%Validating on every training step is a novel setting and we show that it has links with model regularization, which can be a fruitful future research direction.