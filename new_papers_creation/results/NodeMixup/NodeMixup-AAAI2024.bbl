\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Alon and Yahav(2020)}]{bottleneck}
Alon, U.; and Yahav, E. 2020.
\newblock On the bottleneck of graph neural networks and its practical implications.
\newblock \emph{arXiv preprint arXiv:2006.05205}.

\bibitem[{Barcel{\'o} et~al.(2020)Barcel{\'o}, Kostylev, Monet, P{\'e}rez, Reutter, and Silva}]{under_reaching}
Barcel{\'o}, P.; Kostylev, E.~V.; Monet, M.; P{\'e}rez, J.; Reutter, J.; and Silva, J.-P. 2020.
\newblock The logical expressiveness of graph neural networks.
\newblock In \emph{8th International Conference on Learning Representations (ICLR 2020)}.

\bibitem[{Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot, Oliver, and Raffel}]{sharp}
Berthelot, D.; Carlini, N.; Goodfellow, I.; Papernot, N.; Oliver, A.; and Raffel, C.~A. 2019.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock \emph{Advances in neural information processing systems}, 32.

\bibitem[{Bishop and Nasrabadi(2006)}]{cross_entropy}
Bishop, C.~M.; and Nasrabadi, N.~M. 2006.
\newblock \emph{Pattern recognition and machine learning}, volume~4.
\newblock Springer.

\bibitem[{Br{\"u}el-Gabrielsson, Yurochkin, and Solomon(2022)}]{rewiring}
Br{\"u}el-Gabrielsson, R.; Yurochkin, M.; and Solomon, J. 2022.
\newblock Rewiring with positional encodings for graph neural networks.
\newblock \emph{arXiv preprint arXiv:2201.12674}.

\bibitem[{Buchnik and Cohen(2018)}]{influence_decay}
Buchnik, E.; and Cohen, E. 2018.
\newblock Bootstrapped graph diffusions: Exposing the power of nonlinearity.
\newblock In \emph{Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems}, 8--10.

\bibitem[{Chen et~al.(2021)Chen, Lin, Zhao, Ren, Li, Zhou, and Sun}]{renode}
Chen, D.; Lin, Y.; Zhao, G.; Ren, X.; Li, P.; Zhou, J.; and Sun, X. 2021.
\newblock Topology-imbalance learning for semi-supervised node classification.
\newblock \emph{Advances in Neural Information Processing Systems}, 34: 29885--29897.

\bibitem[{Chen et~al.(2020)Chen, Wei, Huang, Ding, and Li}]{gcnii}
Chen, M.; Wei, Z.; Huang, Z.; Ding, B.; and Li, Y. 2020.
\newblock Simple and deep graph convolutional networks.
\newblock In \emph{International Conference on Machine Learning}, 1725--1735. PMLR.

\bibitem[{Chien et~al.(2021)Chien, Peng, Li, and Milenkovic}]{gprgnn}
Chien, E.; Peng, J.; Li, P.; and Milenkovic, O. 2021.
\newblock Adaptive Universal Generalized PageRank Graph Neural Network.
\newblock \emph{ICLR}.

\bibitem[{Crisostomi et~al.(2022)Crisostomi, Antonelli, Maiorca, Moschella, Marin, and Rodol{\`a}}]{mixup_metric_g}
Crisostomi, D.; Antonelli, S.; Maiorca, V.; Moschella, L.; Marin, R.; and Rodol{\`a}, E. 2022.
\newblock Metric Based Few-Shot Graph Classification.
\newblock \emph{arXiv preprint arXiv:2206.03695}.

\bibitem[{Defferrard, Bresson, and Vandergheynst(2016)}]{chebnet}
Defferrard, M.; Bresson, X.; and Vandergheynst, P. 2016.
\newblock Convolutional neural networks on graphs with fast localized spectral filtering.
\newblock \emph{Advances in neural information processing systems}, 29.

\bibitem[{Di~Giovanni et~al.(2023)Di~Giovanni, Giusti, Barbero, Luise, Lio, and Bronstein}]{over}
Di~Giovanni, F.; Giusti, L.; Barbero, F.; Luise, G.; Lio, P.; and Bronstein, M. 2023.
\newblock On Over-Squashing in Message Passing Neural Networks: The Impact of Width, Depth, and Topology.
\newblock \emph{arXiv preprint arXiv:2302.02941}.

\bibitem[{Fey and Lenssen(2019)}]{torch_geo}
Fey, M.; and Lenssen, J.~E. 2019.
\newblock Fast Graph Representation Learning with {PyTorch Geometric}.
\newblock In \emph{ICLR Workshop on Representation Learning on Graphs and Manifolds}.

\bibitem[{Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and Dahl}]{mpnn}
Gilmer, J.; Schoenholz, S.~S.; Riley, P.~F.; Vinyals, O.; and Dahl, G.~E. 2017.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{ICML}, 1263--1272. PMLR.

\bibitem[{Guo and Mao(2021)}]{ifmixup_g}
Guo, H.; and Mao, Y. 2021.
\newblock ifmixup: Towards intrusion-free graph mixup for graph classification.
\newblock \emph{arXiv e-prints}, arXiv--2110.

\bibitem[{Hamilton, Ying, and Leskovec(2017)}]{sage}
Hamilton, W.; Ying, Z.; and Leskovec, J. 2017.
\newblock Inductive representation learning on large graphs.
\newblock \emph{Advances in neural information processing systems}, 30.

\bibitem[{Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and Leskovec}]{ogb}
Hu, W.; Fey, M.; Zitnik, M.; Dong, Y.; Ren, H.; Liu, B.; Catasta, M.; and Leskovec, J. 2020.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock \emph{Advances in neural information processing systems}, 33: 22118--22133.

\bibitem[{Kingma and Ba(2015)}]{adam}
Kingma, D.; and Ba, J. 2015.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR}.

\bibitem[{Kipf and Welling(2017)}]{gcn}
Kipf, N.~T.; and Welling, M. 2017.
\newblock Semi-Supervised Classification with Graph Convolutional Networks.
\newblock \emph{international conference on learning representations}.

\bibitem[{Klicpera, Bojchevski, and Günnemann(2019)}]{appnp}
Klicpera, J.; Bojchevski, A.; and Günnemann, S. 2019.
\newblock Predict then Propagate: Graph Neural Networks meet Personalized PageRank.
\newblock \emph{ICLR}.

\bibitem[{Kornblith et~al.(2019)Kornblith, Norouzi, Lee, and Hinton}]{cka}
Kornblith, S.; Norouzi, M.; Lee, H.; and Hinton, G. 2019.
\newblock Similarity of neural network representations revisited.
\newblock In \emph{International Conference on Machine Learning}, 3519--3529. PMLR.

\bibitem[{Lee et~al.(2013)}]{pl}
Lee, D.-H.; et~al. 2013.
\newblock Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks.
\newblock In \emph{Workshop on challenges in representation learning, ICML}, volume~3, 896.

\bibitem[{Li, Han, and Wu(2018)}]{li2018deeper}
Li, Q.; Han, Z.; and Wu, X.-M. 2018.
\newblock Deeper insights into graph convolutional networks for semi-supervised learning.
\newblock In \emph{Thirty-Second AAAI conference on artificial intelligence}.

\bibitem[{Lu et~al.(2021)Lu, Zhan, Guan, Liu, Yu, Zhao, Yang, and Tao}]{skipnode}
Lu, W.; Zhan, Y.; Guan, Z.; Liu, L.; Yu, B.; Zhao, W.; Yang, Y.; and Tao, D. 2021.
\newblock SkipNode: On Alleviating Over-smoothing for Deep Graph Convolutional Networks.
\newblock \emph{arXiv preprint arXiv:2112.11628}.

\bibitem[{Navarro and Segarra(2022)}]{graphmad_g}
Navarro, M.; and Segarra, S. 2022.
\newblock GraphMAD: Graph Mixup for Data Augmentation using Data-Driven Convex Clustering.
\newblock \emph{arXiv preprint arXiv:2210.15721}.

\bibitem[{Oono and Suzuki(2020)}]{oono2020graph}
Oono, K.; and Suzuki, T. 2020.
\newblock Graph Neural Networks Exponentially Lose Expressive Power for Node Classification.
\newblock \emph{ICLR}.

\bibitem[{Park, Shim, and Yang(2022)}]{mixup_transplant_g}
Park, J.; Shim, H.; and Yang, E. 2022.
\newblock Graph transplant: Node saliency-guided graph mixup with local structure preservation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, 7966--7974.

\bibitem[{Rizve et~al.(2021)Rizve, Duarte, Rawat, and Shah}]{ups}
Rizve, M.~N.; Duarte, K.; Rawat, Y.~S.; and Shah, M. 2021.
\newblock In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning.
\newblock \emph{arXiv preprint arXiv:2101.06329}.

\bibitem[{Shchur et~al.(2018)Shchur, Mumme, Bojchevski, and G{\"u}nnemann}]{coauthor}
Shchur, O.; Mumme, M.; Bojchevski, A.; and G{\"u}nnemann, S. 2018.
\newblock Pitfalls of graph neural network evaluation.
\newblock \emph{arXiv preprint arXiv:1811.05868}.

\bibitem[{Shimodaira(2000)}]{distribution_shift}
Shimodaira, H. 2000.
\newblock Improving predictive inference under covariate shift by weighting the log-likelihood function.
\newblock \emph{Journal of statistical planning and inference}, 90(2): 227--244.

\bibitem[{Sun et~al.(2022)Sun, Li, Yuan, Fu, Peng, Ji, Li, and Yu}]{pastel}
Sun, Q.; Li, J.; Yuan, H.; Fu, X.; Peng, H.; Ji, C.; Li, Q.; and Yu, P.~S. 2022.
\newblock Position-aware structure learning for graph topology-imbalance by relieving under-reaching and over-squashing.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Information \& Knowledge Management}, 1848--1857.

\bibitem[{Topping et~al.(2021)Topping, Giovanni, Chamberlain, Dong, and Bronstein}]{understanding-os}
Topping, J.; Giovanni, D.~F.; Chamberlain, P.~B.; Dong, X.; and Bronstein, M.~M. 2021.
\newblock Understanding over-squashing and bottlenecks on graphs via curvature.
\newblock \emph{ICLR 2022}.

\bibitem[{Velickovic et~al.(2018)Velickovic, Cucurull, Casanova, Romero, Liò, and Bengio}]{gat}
Velickovic, P.; Cucurull, G.; Casanova, A.; Romero, A.; Liò, P.; and Bengio, Y. 2018.
\newblock Graph Attention Networks.
\newblock \emph{ICLR}.

\bibitem[{Verma et~al.(2021)Verma, Qu, Kawaguchi, Lamb, Bengio, Kannala, and Tang}]{graphmix}
Verma, V.; Qu, M.; Kawaguchi, K.; Lamb, A.; Bengio, Y.; Kannala, J.; and Tang, J. 2021.
\newblock Graphmix: Improved training of gnns for semi-supervised learning.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~35, 10024--10032.

\bibitem[{Wang et~al.(2021)Wang, Wang, Liang, Cai, and Hooi}]{mixup_for_node}
Wang, Y.; Wang, W.; Liang, Y.; Cai, Y.; and Hooi, B. 2021.
\newblock Mixup for node and graph classification.
\newblock In \emph{Proceedings of the Web Conference 2021}, 3663--3674.

\bibitem[{Wu et~al.(2019)Wu, Souza, Zhang, Fifty, Yu, and Weinberger}]{sgc}
Wu, F.; Souza, A.; Zhang, T.; Fifty, C.; Yu, T.; and Weinberger, K. 2019.
\newblock Simplifying graph convolutional networks.
\newblock In \emph{International conference on machine learning}, 6861--6871. PMLR.

\bibitem[{Wu et~al.(2021)Wu, Lin, Gao, Tan, Li et~al.}]{graphmixup}
Wu, L.; Lin, H.; Gao, Z.; Tan, C.; Li, S.; et~al. 2021.
\newblock Graphmixup: Improving class-imbalanced node classification on graphs by self-supervised context prediction.
\newblock \emph{arXiv preprint arXiv:2106.11133}.

\bibitem[{Xu et~al.(2019)Xu, Hu, Leskovec, and Jegelka}]{gin}
Xu, K.; Hu, W.; Leskovec, J.; and Jegelka, S. 2019.
\newblock How Powerful are Graph Neural Networks?
\newblock \emph{international conference on learning representations}.

\bibitem[{Xu et~al.(2018)Xu, Li, Tian, Sonobe, Kawarabayashi, and Jegelka}]{jknet}
Xu, K.; Li, C.; Tian, Y.; Sonobe, T.; Kawarabayashi, K.-i.; and Jegelka, S. 2018.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In \emph{International Conference on Machine Learning}, 5453--5462. PMLR.

\bibitem[{Yang, Cohen, and Salakhudinov(2016)}]{cora}
Yang, Z.; Cohen, W.; and Salakhudinov, R. 2016.
\newblock Revisiting semi-supervised learning with graph embeddings.
\newblock In \emph{International conference on machine learning}, 40--48. PMLR.

\bibitem[{Zhang et~al.(2017)Zhang, Cisse, Dauphin, and Lopez-Paz}]{mixup}
Zhang, H.; Cisse, M.; Dauphin, Y.~N.; and Lopez-Paz, D. 2017.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}.

\bibitem[{Zheng et~al.(2022)Zheng, Xia, Zhang, Kharlamov, and Dong}]{distribution}
Zheng, Q.; Xia, X.; Zhang, K.; Kharlamov, E.; and Dong, Y. 2022.
\newblock On the distribution alignment of propagation in graph neural networks.
\newblock \emph{AI Open}, 3: 218--228.

\bibitem[{Zhu et~al.()Zhu, Yan, Heimann, Zhao, Akoglu, and Koutra}]{NLD}
Zhu, J.; Yan, Y.; Heimann, M.; Zhao, L.; Akoglu, L.; and Koutra, D. ????
\newblock Heterophily and Graph Neural Networks: Past, Present and Future.
\newblock \emph{Data Engineering}, 10.

\end{thebibliography}
