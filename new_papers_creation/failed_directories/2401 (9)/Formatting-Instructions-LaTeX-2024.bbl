\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Alderfer(1972)}]{alderfer1972existence}
Alderfer, C.~P. 1972.
\newblock Existence, relatedness, and growth: Human needs in organizational settings.

\bibitem[{Baldassarre and Mirolli(2013)}]{baldassarre2013intrinsically}
Baldassarre, G.; and Mirolli, M. 2013.
\newblock Intrinsically motivated learning systems: an overview.
\newblock \emph{Intrinsically motivated learning in natural and artificial systems}, 1--14.

\bibitem[{Barto et~al.(2004)Barto, Singh, Chentanez et~al.}]{barto2004intrinsically}
Barto, A.~G.; Singh, S.; Chentanez, N.; et~al. 2004.
\newblock Intrinsically motivated learning of hierarchical collections of skills.
\newblock In \emph{Proceedings of the 3rd International Conference on Development and Learning}, volume 112, 19. Citeseer.

\bibitem[{Busoniu, Babuska, and De~Schutter(2008)}]{busoniu2008comprehensive}
Busoniu, L.; Babuska, R.; and De~Schutter, B. 2008.
\newblock A comprehensive survey of multiagent reinforcement learning.
\newblock \emph{IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 38(2): 156--172.

\bibitem[{Heckhausen and Heckhausen(2018)}]{heckhausen2018motivation}
Heckhausen, J.; and Heckhausen, H. 2018.
\newblock \emph{Motivation and action}.
\newblock Springer.

\bibitem[{Hernandez-Leal, Kartal, and Taylor(2019)}]{hernandez2019survey}
Hernandez-Leal, P.; Kartal, B.; and Taylor, M.~E. 2019.
\newblock A survey and critique of multiagent deep reinforcement learning.
\newblock \emph{Autonomous Agents and Multi-Agent Systems}, 33(6): 750--797.

\bibitem[{Littman(1994)}]{littman1994markov}
Littman, M.~L. 1994.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Machine learning proceedings 1994}, 157--163. Elsevier.

\bibitem[{Marsland, Nehmzow, and Shapiro(2000)}]{marsland2000real}
Marsland, S.; Nehmzow, U.; and Shapiro, J. 2000.
\newblock A real-time novelty detector for a mobile robot.
\newblock \emph{EUREL European Advanced Robotics Systems Masterclass and Conference}.

\bibitem[{Maslow(1958)}]{maslow1958dynamic}
Maslow, A.~H. 1958.
\newblock A Dynamic Theory of Human Motivation.

\bibitem[{Merrick(2013)}]{merrick2013novelty}
Merrick, K.~E. 2013.
\newblock Novelty and beyond: Towards combined motivation models and integrated learning architectures.
\newblock \emph{Intrinsically motivated learning in natural and artificial systems}, 209--233.

\bibitem[{Merrick and Maher(2009)}]{merrick2009motivated}
Merrick, K.~E.; and Maher, M.~L. 2009.
\newblock \emph{Motivated reinforcement learning: curious characters for multiuser games}.
\newblock Springer Science \& Business Media.

\bibitem[{Puterman(2014)}]{puterman2014markov}
Puterman, M.~L. 2014.
\newblock \emph{Markov decision processes: discrete stochastic dynamic programming}.
\newblock John Wiley \& Sons.

\bibitem[{R{\u{a}}dulescu et~al.(2020)R{\u{a}}dulescu, Mannion, Roijers, and Now{\'e}}]{ruadulescu2020multi}
R{\u{a}}dulescu, R.; Mannion, P.; Roijers, D.~M.; and Now{\'e}, A. 2020.
\newblock Multi-objective multi-agent decision making: a utility-based analysis and survey.
\newblock \emph{Autonomous Agents and Multi-Agent Systems}, 34(1): 10.

\bibitem[{Rashid et~al.(2020)Rashid, Samvelyan, De~Witt, Farquhar, Foerster, and Whiteson}]{rashid2020monotonic}
Rashid, T.; Samvelyan, M.; De~Witt, C.~S.; Farquhar, G.; Foerster, J.; and Whiteson, S. 2020.
\newblock Monotonic value function factorisation for deep multi-agent reinforcement learning.
\newblock \emph{The Journal of Machine Learning Research}, 21(1): 7234--7284.

\bibitem[{Samvelyan et~al.(2019)Samvelyan, Rashid, de~Witt, Farquhar, Nardelli, Rudner, Hung, Torr, Foerster, and Whiteson}]{samvelyan19smac}
Samvelyan, M.; Rashid, T.; de~Witt, C.~S.; Farquhar, G.; Nardelli, N.; Rudner, T. G.~J.; Hung, C.-M.; Torr, P. H.~S.; Foerster, J.; and Whiteson, S. 2019.
\newblock {The} {StarCraft} {Multi}-{Agent} {Challenge}.
\newblock \emph{CoRR}, abs/1902.04043.

\bibitem[{Schembri, Mirolli, and Baldassarre(2007)}]{schembri2007evolution}
Schembri, M.; Mirolli, M.; and Baldassarre, G. 2007.
\newblock Evolution and learning in an intrinsically motivated reinforcement learning robot.
\newblock In \emph{Advances in Artificial Life: 9th European Conference, ECAL 2007, Lisbon, Portugal, September 10-14, 2007. Proceedings 9}, 294--303. Springer.

\bibitem[{Schiefele(1996)}]{schiefele1996motivation}
Schiefele, U. 1996.
\newblock \emph{Motivation und Lernen mit Texten}.
\newblock Hogrefe G{\"o}ttingen.

\bibitem[{Schmidhuber(1991)}]{schmidhuber1991curious}
Schmidhuber, J. 1991.
\newblock Curious model-building control systems.
\newblock In \emph{Proc. international joint conference on neural networks}, 1458--1463.

\bibitem[{Schmidhuber(2010)}]{schmidhuber2010formal}
Schmidhuber, J. 2010.
\newblock Formal theory of creativity, fun, and intrinsic motivation (1990--2010).
\newblock \emph{IEEE transactions on autonomous mental development}, 2(3): 230--247.

\bibitem[{Shapley(1953)}]{shapley1953stochastic}
Shapley, L.~S. 1953.
\newblock Stochastic games.
\newblock \emph{Proceedings of the national academy of sciences}, 39(10): 1095--1100.

\bibitem[{Son et~al.(2019)Son, Kim, Kang, Hostallero, and Yi}]{son2019qtran}
Son, K.; Kim, D.; Kang, W.~J.; Hostallero, D.~E.; and Yi, Y. 2019.
\newblock Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning.
\newblock In \emph{International conference on machine learning}, 5887--5896. PMLR.

\bibitem[{Tampuu et~al.(2017)Tampuu, Matiisen, Kodelja, Kuzovkin, Korjus, Aru, Aru, and Vicente}]{tampuu2017multiagent}
Tampuu, A.; Matiisen, T.; Kodelja, D.; Kuzovkin, I.; Korjus, K.; Aru, J.; Aru, J.; and Vicente, R. 2017.
\newblock Multiagent cooperation and competition with deep reinforcement learning.
\newblock \emph{PloS one}, 12(4): e0172395.

\bibitem[{Yang(2023)}]{yang2023hierarchical}
Yang, Q. 2023.
\newblock Hierarchical Needs-driven Agent Learning Systems: From Deep Reinforcement Learning To Diverse Strategies.
\newblock \emph{The 37th AAAI 2023 Conference on Artificial Intelligence and Robotics Bridge Program}.

\bibitem[{Yang and Liu(2023)}]{yang2023understanding}
Yang, Q.; and Liu, R. 2023.
\newblock Understanding the Application of Utility Theory in Robotics and Artificial Intelligence: A Survey.
\newblock \emph{arXiv preprint arXiv:2306.09445}.

\bibitem[{Yang et~al.(2019)Yang, Luo, Song, and Parasuraman}]{yang2019self}
Yang, Q.; Luo, Z.; Song, W.; and Parasuraman, R. 2019.
\newblock Self-reactive planning of multi-robots with dynamic task assignments.
\newblock In \emph{2019 International Symposium on Multi-Robot and Multi-Agent Systems (MRS)}, 89--91. IEEE.

\bibitem[{Yang and Parasuraman(2020{\natexlab{a}})}]{yang2020hierarchical}
Yang, Q.; and Parasuraman, R. 2020{\natexlab{a}}.
\newblock Hierarchical needs based self-adaptive framework for cooperative multi-robot system.
\newblock In \emph{2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 2991--2998. IEEE.

\bibitem[{Yang and Parasuraman(2020{\natexlab{b}})}]{yang2020needs}
Yang, Q.; and Parasuraman, R. 2020{\natexlab{b}}.
\newblock Needs-driven heterogeneous multi-robot cooperation in rescue missions.
\newblock In \emph{2020 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, 252--259. IEEE.

\bibitem[{Yang and Parasuraman(2021)}]{yang2021can}
Yang, Q.; and Parasuraman, R. 2021.
\newblock How can robots trust each other for better cooperation? a relative needs entropy based robot-robot trust assessment model.
\newblock In \emph{2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 2656--2663. IEEE.

\bibitem[{Yang and Parasuraman(2022)}]{yang2022game}
Yang, Q.; and Parasuraman, R. 2022.
\newblock Game-theoretic utility tree for multi-robot cooperative pursuit strategy.
\newblock In \emph{ISR Europe 2022; 54th International Symposium on Robotics}, 1--7. VDE.

\bibitem[{Yang and Parasuraman(2023{\natexlab{a}})}]{10.1145/3555776.3577642}
Yang, Q.; and Parasuraman, R. 2023{\natexlab{a}}.
\newblock A Hierarchical Game-Theoretic Decision-Making for Cooperative Multiagent Systems Under the Presence of Adversarial Agents.
\newblock In \emph{Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing}, SAC '23, 773–782. New York, NY, USA: Association for Computing Machinery.
\newblock ISBN 9781450395175.

\bibitem[{Yang and Parasuraman(2023{\natexlab{b}})}]{yang2023strategy}
Yang, Q.; and Parasuraman, R. 2023{\natexlab{b}}.
\newblock A Strategy-Oriented Bayesian Soft Actor-Critic Model.
\newblock \emph{Procedia Computer Science}, 220: 561--566.

\bibitem[{Yang and Parasuraman(2024)}]{yang2022bsac}
Yang, Q.; and Parasuraman, R. 2024.
\newblock Bayesian Soft Actor-Critic: A Directed Acyclic Strategy Graph Based Deep Reinforcement Learning.
\newblock \emph{the 39th ACM/SIGAPP Symposium on Applied Computing, SAC ’24}.

\bibitem[{Zintgraf et~al.(2015)Zintgraf, Kanters, Roijers, Oliehoek, and Beau}]{zintgraf2015quality}
Zintgraf, L.~M.; Kanters, T.~V.; Roijers, D.~M.; Oliehoek, F.; and Beau, P. 2015.
\newblock Quality assessment of MORL algorithms: A utility-based approach.
\newblock In \emph{Benelearn 2015: proceedings of the 24th annual machine learning conference of Belgium and the Netherlands}.

\end{thebibliography}
