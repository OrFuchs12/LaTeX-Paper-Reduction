%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.





% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage[font=small,labelfont=bf]{caption}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else %  \usepackage[caption=false,font=footnotesize]{subfig}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\usepackage{wrapfig}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{hyperref}
%\usepackage{subcaption}
\usepackage{times}
\usepackage[T1]{fontenc}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\newcommand{\learnFixed}{{\textit ZeroR}}
\newcommand{\learnDynamic}{{\textit LearnDynamic}}
\newcommand{\islead}[1]{{\em IsLead(#1)}}
\newcommand{\IsLead}[1]{{\textit IsLead}}
\newcommand{\acquire}[1]{{\em Acquire(#1)}}
\newcommand{\Acquire}{{\textit Acquire}}
\newcommand{\target}{{\textit target}}
\newcommand{\best}{{\textit best}}
\newcommand{\pf}{{\textit pf}}
\newcommand{\newstuff}[1]{#1}

\newtheorem{definition}{Definition}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Target Oriented Network Intelligence Collection: \\
Effective Exploration of Social Networks}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Rami Puzis, Liron Kachko, Barak Hagbi, Roni Stern, and Ariel Felner
\thanks{All authors are from department of Software and Information Systems Engineering at Ben-Gurion University of the Negev}
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
%\markboth{IEEE Intelligent Systems,~Vol.~X, No.~Y, September~2016}%
\markboth{World Wide Web Journal,~Vol.~X, No.~Y, October~2016}%
{TONIC: Target Oriented Network Intelligence Collection}
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Target Oriented Network Intelligence Collection (TONIC) is a crawling process whose goal is to find social network profiles that contain information about a given target. Such profiles are called {\em leads} and the TONIC problem is how to minimize crawling costs incurred while finding them. We model this problem as a search problem in an unknown graph and present a best-first search approach for solving it. 
Three key challenges are (1) which profiles to consider crawling to, (2) how to prioritize the crawling order, and (3) when additional crawling is not worthwhile. For the first challenge, we propose two frameworks: the Restricted TONIC Framework (RTF), that restricts the search to immediate neighbors of previously found leads, and the Extended TONIC Framework (ETF), that extends the scope of the search to a wider neighborhood. Guidelines for when to choose which framework are provided. For the second challenge, we propose a set of effective topology-based heuristics that guide the search towards profiles that are more likely to be leads. For the third challenge, we propose to use data collected in previously executed crawls to learn when additional crawling is expected to be useful.   
%. RTF limits the search to immediate neighbors of previously found leads, and is most suitable for cases where the reward of finding a lead is moderate and the cost of crawling is high. ETF  When the reward of finding a lead is moderate and the cost of crawling is high we propose the Restricted TONIC Framework that limits the search to immediate neighbors of previously found leads. When crawling costs are lower, we propose the Extended TONIC Framework, which extends the scope of the search to a wider neighborhood. For each framework we propose  Experimental analysis on three online social networks shows that acquisition of non-leads significantly speeds up the search process. 
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Artificial Intelligence, Heuristic Search, Online social networks
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}

% 1. OSNs are popular, and people use them to gather intelligence on other people
Web-based {\em online social networks} (OSNs) such as Facebook, Twitter, and Google+ are a part of everyday life for many people around the world. These OSNs are a source of personal information about their users and even contain sensitive commercial or security related information. Commercial companies, government agencies, and even individual people often utilize this abundance of data to extract information about a given person of interest. 
For example, it is common practice for most commercial companies to inspect the Facebook and LinkedIn profiles of candidate employees in order to extract information about past projects, colleagues, and managers. Government agencies may also explore OSNs looking for information on terrorists and organized crime. 

% 2. Information gathering can be automated, but people block this via privacy.
The process of collecting the information available in an OSN 
about a given person or group of interest can be automated using information extraction (IE) techniques \cite{chang2006survey}. 
We refer to such a person or group of interest as the $\target$. 
Awareness to privacy issues and to data leakage causes many users to tighten their OSN privacy settings limiting access to their profiles. 
Consequently, the target's profile is inaccessible to third parties and information about the target cannot be collected from its profile. Furthermore, there might be scenarios where the target does not even have an OSN profile, but information about the target is still available in the OSN.

% 3. If the target is blocked, we get information about it from other profiles. Introducing the notion of a lead. 
In such cases, an alternative way to collect information about the target is through information available in other OSN profiles. 
For example, information about the target can also be collected  from profiles that contain photos of the target, public posts made by the target or posts made by other profiles about the target.
If the target has a profile in the OSN, then a likely source of information about the target is in the profiles of its acquaintances, where acquaintances can be defined using the OSN {\em friendship relationship}.   
It is prohibitively challenging to conceal information about the target that other profiles expose.
A profile that exposes information about the target is called a {\em lead}.



%Information about the target can be collected also from profiles that contain photos of the target, public posts made by the target or posts about the target.

% 4. The TONIC problem. 
In this paper we address the problem of finding as many leads as possible while minimizing the number of inspected profiles. We call this problem the {\em Target Oriented Network Intelligence Collection (TONIC)}. 
In our model, extraction and analysis of relevant information from the OSN is encapsulated in two operators: {\em IsLead} which is a light query that determines whether a profile is a {\em lead} or not, and {\em profile acquisition} which is a heavy operation that fully extracts and observes the information of a given profile.
%We make the assumption that extraction and analysis of relevant information from the OSN is encapsulated in two operators: {\em Islead} which is a light query that determines whether a profile is a {\em lead} or not, and {\em profile acquisition} which is a heavy operation that fully extracts and observes the information of a given profile.
These operators can be carried out by utilizing web scrapping or the OSN application programming interfaces (API) followed by standard IE techniques \cite{chang2006survey,tang2010aCombinationApproach,pawlas2012universal}. 


% This is a search problem, we do BFS and have nice heuristics.
We solve TONIC with Artificial Intelligence techniques, formalizing it as a heuristic search problem.  Profiles and friendship relations form the vertices and edges of a  graph, respectively, and we use a best-first search approach to search this graph~\cite{vempaty1991depthFirst,russell2010artificialIntelligence}. We visit profiles in a best-first order according to heuristic functions that we develop in this paper and apply the {\em IsLead} and {\em profile acquisition} operators on the {\em best} profile in an intelligent manner. 


Two frameworks are proposed for solving TONIC, the Restricted TONIC Framework (RTF) and the Extended TONIC Framework (ETF). RTF restricts the search to known leads and their neighbors. Therefore, in RTF profiles that are found to be non-leads are omitted from deeper exploration. The rationale behind restricting acquisition of non-leads is that the cost of {\em profile acquisition} can be quite high and it may not result in the discovery of new leads. 
By contrast, ETF does not restrict acquisition of non-leads and allows the search to continue through the extended social cycles of a target. As a generic middle ground between RTF and ETF, we proposed ETF($n$), in which non-leads are only explored if they are at most $n$ steps away from a known lead. Thus RTF=ETF(0) and ETF= ETF($\infty$). 

Several intelligent heuristics are proposed for both RTF and ETF. These heuristics guide the search by analyzing the currently known subgraph of the OSN. Importantly, all our investigated heuristics are based solely on the topology of the OSN being crawled, and are thus orthogonal to the details of the {\em IsLead} and {\em profile acquisition} operators. 


In some problem settings, it is possible to reach a stage where performing additional crawling is not worthwhile and even wasteful. This occurs when the expected reward from obtaining new leads is smaller than the expected crawling costs of getting to them. For problem settings when this can occur, we propose two learning-based stopping conditions that use data about past crawls to decide when to stop searching for more leads and halt the current crawling process. 

The proposed heuristics and frameworks are experimentally evaluated on three OSNs: Google+, Pokec~\cite{takac2012data}, and LiveJournal~\cite{backstrom2006groupFormation,leskovec2009community} (an online community that allows member to maintain journals, blogs, and define friendship between profiles). Results show that each framework performs best under different circumstances. We found that in general \(RTF\) and \(ETF(1)\) are worthwhile, while  ETF($n$) for $n>1$ does not contribute significantly to the number of leads found. We further analyze the tradeoff between the cost of searching and the benefit of finding more leads. The results of this analysis show that \(ETF(1)\), with the proposed heuristics, is better than \(RTF\) for short searches and when the reward for finding a lead is high; while \(RTF\), with a proper heuristic, is better suited for a long term search process with moderate and low rewards. 
%\note{Roni}{TODO: Double check this after reading the results}


%Pokec is the most popular on-line social network in Slovakia. The popularity of network has not changed even after the coming of Facebook. Pokec has been provided for more than 10 years and connects more than 1.6 million people. Datasets contains anonymized data of the whole network. Profile data contains gender, age, hobbies, interest, education etc. Profile data are in Slovak language. Friendships in Pokec are oriented

%LiveJournal is a free on-line community with almost 10 million members; a significant fraction of these members are highly active. (For example, roughly 300,000 update their content in any given 24-hour period.) LiveJournal allows members to maintain journals, individual and group blogs, and it allows people to declare which other members are their friends they belong.


%https://snap.stanford.edu/data/soc-pokec.html
% the popular Google+ OSN. 


This paper contains a comprehensive and unifying presentation of material from two previously published conference papers~\cite{stern2013tonic,samama2014extended}. 
This paper also contains several significant improvements and novel contributions over these conference papers, including:
%\begin{enumerate}
%\item Two methods for learning from past experience when to stop crawling in order to maximize gain (Section~\ref{sec:stopping}). 
%\item Results over two additional OSNs (Section~\ref{sec:otherNetworks}), to increase the reliability of our experimental evaluation. 
%\item Modeling TONIC as an Information Retrieval task, and additional analysis of the experimental results based on this modeling (Section~\ref{sec:ir}). 
%\item Comprehensive related work. 
%\item Clean detion of the proposed algorithm, including additional examples and supporting figures. 
%\end{enumerate}
\begin{enumerate}
\item Two algorithms for learning when to stop crawling in order to maximize net gain (Section~\ref{sec:stopping}). 
\item Added reliability to our experimental results through the evaluation on two additional OSNs (Section~\ref{sec:otherNetworks}). 
\item An additional, novel, form of analysis for TONIC, in which TONIC is modeled as an Information Retrieval task and the experimental results are analyzed accordingly (Section~\ref{sec:ir}). 
\item A significantly more comprehensive related work. 
\item Clean description of the proposed algorithm, including additional examples and supporting figures. 
\end{enumerate}

 
%This paper contains material from two previously published conference papers~\cite{stern2013tonic,samama2014extended}. In addition to providing a comprehensive and unified view, this paper also contains additional experiments on the DBLP co-authorship network and deeper analysis of the two frameworks presented.
%\note{Rami: what about Zahy's paper?}


The paper is organized as follows. In Section~\ref{sec:problem} we formally define TONIC and relevant terminology. Section~\ref{sec:relatedWork} contains a review of related works. Section~\ref{sec:TONICAsHeuristic} explains how TONIC can be formalized as a search problem in an unknown graph, and outlines the algorithmic framework we use. Section~\ref{sec:rtf} describes the Restricted TONIC Framework (RTF), RTF heuristics, and presents experimental results to evaluate their performance. Section~\ref{sec:etf} does the same for the Extended TONIC Framework (ETF) -- present it along with ETF heuristics and evaluates them. The trade-off between RTF and ETF is discussed in Section~\ref{sec:costbenefit} in terms of cost and benefit of the respective search processes. In Section~\ref{sec:ir} we present an alternative view of TONIC as an Information Retrieval task. In Section~\ref{sec:otherNetworks} we provide additional support for our conclusions by reporting on additional experimental results performed on other OSNs. Then, we summarize the main findings and outline the next steps in Section~\ref{sec:conclusions}, and discuss ethical aspects of various TONIC applications in Section~\ref{sec:ethics}. 


%\note{Roni: todo: any thoughts what to write here?}.


%Liron: How to address the papers followed the TONIC paper? (Zahy's paper) ??

\section{The TONIC Problem}
\label{sec:problem}
%The goal in TONIC is to extract information on a given target from the OSN (e.g. Google+). The online social web is composed of {\em profiles} of users, that are connected to each other. Each profile contains information on a specific user, and a list of all the profiles that are connected to it. Which profile information is publicly available and which information is blocked depends on the security setting of that profile. The process of downloading the publicly available information of a given profile is called {\em acquisition} (as a verb, this is ``to acquire a profile''). The basic assumption in TONIC is that the profile of the target is completely blocked, i.e., acquiring the profile of the target will not yield any information on the target. Information on the target will only be found by acquiring other profiles. 

%As an input to the problem, we are given the (blocked) profile of the target, as well as a set of prolles that are known to be related to the target. We make a distinction between three states of a profile - {\em acquired}, {\em partial} and {\em unknown}

%\begin{itemize}
%	\item {\bf Acquired profile.} A profile that have been acquired, and all its data have been extracted.
%	\item {\bf Partial profile.} A profile that is connected to an acquired profile, but was not acquired yet.
%	\item {\bf Unknown profile.} A profile that exists in the social web, but is not connected to any acquired profile.  
%\end{itemize}

%At each iteration we decide which profile to explore next based on the heuristics and frameworks presented later in this paper.

%Next, we provide the technical background and terminology required to define the TONIC problem formally.

% Profiles, friends

In this section we formally define the general TONIC problem and its variants as evaluated in our experiments. %While the search algorithms we propose later are evaluated in our experimental model but can easily be generalized to other models as well.


\begin{definition}[profiles]
The basic entity in TONIC is a {\em profile}, which is associated with a specific OSN (e.g., Google+). Profiles are connected to each other via a ``friendship'' relation.  The {\em list of ``friends''} (LOF) of a given profile $p$ is denoted by $LOF(p)$. 
\label{def:profile}
\end{definition}


TONIC is defined with respect to a {\em target} OSN profile. 
The {\em target} profile can be associated, for example, with a particular person, group of people, or legal entity. 


\begin{definition}[Lead and Non-Lead]
A profile $p$ is called a {\em lead} if it has the target in its \(LOF\). Otherwise, it is called a {\em non-lead}.   
\label{def:lead}
\end{definition}


TONIC is motivated by situations in which one wants to find information about the target. 
Since leads are more likely to have such information, the process we envision is to first find profiles that are leads, and then extract valuable information from them if such exists. The information extraction is out of the scope of this paper, since deciding which information about the target is valuable is application dependent and it may require intervention of a human analyst. Thus, in TONIC we focus on finding leads (i.e., friends of the target).


%requires definition of a target.  In certain applications of TONIC, the target is a person, a group of people, or a legal entity.  It may or may not have a profile in the OSN. For example, the target may not have a profile in the OSN but information about it still exists there, e.g., it may be discussed in posts or be tagged in pictures.  In order to simplify the discussion in this paper we will refer to the target as if it has an OSN profile denoted as $\mathit{target}$.  \begin{definition}[Target] The {\em target} is a specific OSN {\em profile} we want to find information about.  \label{def:Target} \end{definition}

% Leads
%Another important entity in TONIC is a {\em lead}.  Ideally, a profile $p$ is  a {\em lead} if it has valuable information about the target. 
% In some applications it is valuable to find out that a profile $p$ is a friend of the target in the OSN (i.e., the target is in its $LOF$), posted a message about the target, or was tagged with the target in the same photo. In other applications a deeper analysis of a profile is needed to decide if it provides valuable information. Thus, deciding which information about the target is valuable is application dependent and may require human intervention (e.g., a human analyst). In this paper, for simplicity, we use a crisp definition of the term {\em lead}, considering as leads those profiles that contain the target in their  \(LOF\).



%The process we envision is therefore to first find profiles that are leads, and then apply a secondary processing phase to extract valuable information from them if such exists. The secondary phase is out of the scope of this paper, and in TONIC we focus on finding leads (i.e., friends of the target). 
%The above definition of a lead is a simple way to capture the notion of a profile that is likely to contain information about target. 
%The methods proposed in this work can also apply for more sophisticated definitions of a ``lead'', e.g.




% R[[1.1]]
Information in general and the LOF in particular can be extracted from an OSN profile in several ways. For example, by scrapping: parsing the web pages that are exposed by the OSN services, such as the time-line in Facebook; or via the OSN APIs. Some OSN APIs provide convenient way to collect information about profiles, including their LOF. A prominent example of OSN API is the Facebook Query Language (FQL). 	
Information extraction from OSN profiles is an active field of research~\cite[inter alia]{tang2010aCombinationApproach,pawlas2012universal,li2016privacy,li2017adaptive}, and plays an important role in web tracking~\cite{ermakova2018web,bujlow2017survey}. 

%While in past web intelligence was largely associated with national agencies, today \cite{arora2017threats,li2017adaptive}


In this work we assume that the information extraction aspects are encapsulated in two possible OSN queries: 
\begin{itemize}
\item {\bf \islead{v}.} This is a binary query which checks whether the given profile \(v\) is a lead or a non-lead. In our implementation \islead{v}  checks whether the target is in the LOF of $v$:
\begin{equation}
IsLead(v)=
\begin{cases} 
      True  & \target \in LOF(v) \\
      False & \text{Otherwise}
\end{cases}
\end{equation}
\item {\bf \acquire{v}.}  This query downloads all publicly available data from the OSN about the given profile \(v\), including its LOF as well as all the information in its profile.
\footnote{Note that the acquire action does not include sophisticated information extraction methods: it simply downloads all data and extracts the LOF. As mentioned above, further analysis of this data may be done by a human analyst.}
\end{itemize}

% Costs of actions
In our model, \islead{} is considered a ``light weight'' operator with relatively small cost, while \acquire{} is considered a heavy operator. 
Consequently, our algorithms below use \islead{} 
quite often and use \acquire{} more conservatively. In particular, in our model, \acquire{} can be applied only to profiles that are known to be either leads or non-leads (i.e., not to potential leads), i.e., to profiles that we already performed an \islead{} query on. 


% Initial Leads
Some profiles are called {\em initial leads}. These profiles are known a-priori to be leads based on previous knowledge about the target.  Initial leads can, for example, be found manually using traditional intelligence techniques. 
% [R 1.11]
For example, consider a scenario where the target is a pedophile and the police is trying to obtain leads to capture him. It is often the case that the police has additional sources of information, e.g., by applying classic detective work that allow them to identify several OSN profiles as related to the target. However, such initial leads are expected to be very hard to obtain, and we assume that there are only few initial leads for each target. 

If a profile $v$ is not an initial lead, then we assume that its LOF is initially unknown.
Consequently, since the target's LOF is also unknown, then it is not known if $v$ is a lead before querying the OSN  (by applying \islead{v} or \acquire{v}). We refer to such profiles as {\em potential leads} as they might later turn into leads or into non-leads. \islead{} is applied only to potential leads.  Applying \islead{} to a potential lead marks it as either a lead or a non-lead. %[R 1.10]
\footnote{In some OSNs, profiles can block their LOF, so that it is not possible to perform the \islead{} query on them. For our purposes, they will be regarded as non-leads, since we cannot verify that they are leads.} 

%We use \(L, NL,\) and \(PL\) to denote the sets of leads, non-leads, and potential leads respectively. 

%\note{Rami:}{change potential leads to undetermined} 
%\note{Roni:}{OK.}
%\note{Rami:}{do you want me to do it?} 
%\note{Roni:}{If you want to. I think this is extra work %for no gain, but I don't object.}



%

Among other things, the heavy \acquire{v} query extracts and examines $LOF(v)$. This results in the discovery of additional, previously unknown, potential leads as well as the discovery of links to previously known profiles (which can be leads, non-leads, or potential leads). A {\em TONIC process} is an OSN exploration process that searches the OSN for leads using the \islead{} and \acquire{} queries.
% [[R 1.7]]
A profile that is not an initial lead has the following life cycle in a TONIC process. First, it is a potential lead. Then, if an isLead() query is applied to it, it is either discovered to be a lead or a non-lead. Later, a profile (either lead or non-lead) may be acquired, revealing all its LOF. 



  

\begin{definition}[TONIC Problem]
The input to TONIC is $target$ and a set of {\em initial leads} (denoted by \(L_0\)). The TONIC problem is to find leads by applying the TONIC process under different problem settings. 
\label{def:btf}
\end{definition}

\subsection{TONIC Problem Settings and Objectives}
Definition~\ref{def:btf} defines the TONIC problem in a general way. 
Informally, all TONIC objectives considered in this work aim at minimizing the number of \islead{} and \acquire{} queries applied while maximizing the number of leads found. Next, we define a number of objectives that will be used in the paper.

%\note{Rami}{The definition below describes the \emph{budget constraint} and not budget objective. I suggest to reformulate it to specific problems vs. the general problem in def~\ref{def:btf}}


\subsubsection{Anytime Objective}

The first objective we consider is to maximize the number of leads found until the algorithm is halted. 


\begin{definition}[Anytime objective]
Given a set of initial leads \(L_0\) the objective is to find as many leads as possible until the TONIC process is stopped, assuming that the TONIC process can be stopped after any number of queries (each of them is either \islead{} or \acquire{}).
\label{def:budget}
\end{definition}

%The objective functions we discuss in this work take into consideration both the {\em cost} of applying the \islead{} and \acquire{} queries as well as the {\em reward} of finding leads. 
Executing the \acquire{} and \islead{} queries requires both computational resources and network activity. 
In addition, most OSN services limit automatic web scrapping attempts as well as massive exploitation of their API. 
These possible limitations on the number of executed queries are the main motivation behind the anytime objective of finding as many leads as soon as possible, i.e., with fewest possible queries.  
%We assume that a query is either fully executed or not executed at all. 

\subsubsection{Max Net-Gain Objective}
Next, we consider 
%The second objective we consider is designed for 
scenarios in which the {\em cost} of \acquire{}, the {\em cost} of \islead{}, and the {\em reward} of finding a lead, can all be quantified, denoted by $C_{Acquire}$, $C_{IsLead}$, and $R_{Lead}$ respectively.\footnote{Sophisticated TONIC applications may assign rewards that decay with time or are dependent on the amount of information about the target that can be extracted from the lead. We focus on a simpler reward model in which the reward of finding a lead is constant.} 
Typically, the reward of finding a lead is larger than the cost of \acquire{}, otherwise there is no point in acquiring any lead. Additionally, it is usually the case that the cost of \acquire{} is much larger than the cost of \islead{} due to the storage requirements, increased interaction with the OSN, and the execution of IE tools. Taking $C_{IsLead}$, $C_{Acquire}$, and $R_{Acquire}$ into consideration, the second objective function we consider is as follows.

%\begin{definition}[Budget objective]
%Given a set of initial leads \(L_0\), cost(\islead{}), cost(\acquire{}) and budget $b$, the objective is to find as many leads as possible while limiting the sum of query costs to be at most $b$. 
%\label{def:budget}
%\end{definition}
%A second objective function we also consider the reward of finding a lead (\(R_{Lead}\)).
\begin{definition}[Max net-gain objective]
Given a set of initial leads \(L_0\), reward \(R_{Lead}\), $C_{IsLead}$, $C_{Acquire}$ the objective is to maximize the total net gain (sum of rewards minus sum of costs) of the TONIC process.  
\label{def:gain}
\end{definition}


%Finally, we acknowledge the fact that in many practical applications TONIC is a real-time process that can be halted at any time. Thus for an efficient TONIC solver it is very important to find most of the leads at the initial stages of the search.  
%\begin{definition}[Real Time Objective]
%Given a set of initial leads \(L_0\), the TONIC problem is to produce an ordered sequence of profiles evaluated for being a lead such that the leads are concentrated in the beginning of the sequence. 
%\label{def:realtime}
%\end{definition}
%\note{Rami}{Should we rename Section~\ref{sec:ir} into Real Time TONIC and reformulate the text respectively?}\note{Roni}{I think there is too much definitions at this stage, and we should get to the algorithms part already. Also, this definition is not accurate enough. How do we measure this objective function? I know we have the DCG later on, but that should be part of the problem definition if we want the problem to be crisply defined. And I don't think mentioning the DCG at this stage is a good thing: too much detailed for now.}

Other problem settings and objectives for TONIC can also be formulated.  For example, finding a fixed number of leads with minimum acquisitions. The algorithm and heuristics proposed in this paper are expected to be effective for all similar objectives. 
In this paper, however, we focus on the two problem settings listed above -- anytime (Definition~\ref{def:budget}) and max net-gain (Definition~\ref{def:gain}). 
The first part of the paper focuses on the anytime objective and Section~\ref{sec:costbenefit} deals with the max net-gain objective. 
%[[Rami: please read and check if you're happy with this]]
%[[Rami: Good]]
%, and we describe it such variants. 



%Assuming that the cost of \islead{} is negligible compared to the cost of \acquire{}, we compute the {\em net gain} %(denoted $NetGain$) of a search as the total reward from finding leads minus the total cost of all \acquire{} %queries. 
%\note{Roni}{Minor: consider replacing $NG$ with $NetGain$. Why not be clear and relax the cognitive burden of the reader?}



 
%\note{Roni}{There is some hiddne assumption in this problem definition that the cost of isLead = the cost of profile acquisition, and is equal to all profiles. That's Ok, just need to explicitly state that. What I guess would be best is to say this assumption, and say that in section X we generalize without these assumptions.}
%\note{Liron}{I said that the cost is equal to all profiles. but it is not equal to isLead(), the acquisition process and the isLead() process have two different costs, the acquisition is assumed to be negligible but i'm not sure we should say it because it sounds more expensive than isLead().}
%\note{Roni}{I do not think we assume that the cost is negligable. Isn't this what we measure in the ETF figures? Also, in the RTF, it is not that we assume the cost is negligable, but we assume that the reward of finding a lead is higher than the cost of acquiring it. That makes sense. 
%I think that an elegant solution to all this is to say that we assume that our exploration model requires to apply an islead query before performing an acquisition action, and their cost is one for simplicity (note that I do not say anything about the outcome of the islead)}
%\note{Liron}{I don't think we should say that because it sounds like isLead() has no cost (which is kind of what we said in the cost section, however if isLead() has no cost- why do bother with all the heuristic? just preform isLead of all the profile and acquire only leads (FIFO or RND) - I think we should talk about this}
%\note{Roni}{See the above writing.}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{sec:relatedWork}
%\note{Liron}{Should we keep the background and the profiles' states?}\note{Roni}{I move the related work to here because most of it is not needed for understanding the paper. the background and profiles' states are now in the problem definition, where it is need.}

%\note{Liron}{Should I mention Zhay's paper ? because it is based of the RTF, maybe it should be mention in the ETF section?}\note{Roni}{Added it here.}


Analyzing and searching the social web was previously addressed in the contexts of intelligent crawling, network completion, and general search in an unknown graph. Next, we briefly review prior efforts in these related problems and discuss their connection to TONIC.


\subsection{Intelligent Crawling}
\label{sec:webCrawling}
% In TONIC we want an intelligent web crawler
In TONIC, we need to explore the social web in an intelligent way in order to extract information about the target. This can be viewed as a special case of {\em intelligent web crawling}~\cite{aggarwal2001intelligent,zareh2007fica,cai2008irobot}. %Broadly speaking we consider  where data collected from web pages is used to decide which page to crawl next.
There is a large body of work on intelligent web crawling, and work in this subject differ in the techniques being used, the data that is available about the crawled web, and, importantly, the purpose for which the crawling is performed. 


\subsubsection{Focused Crawling}
% In most cases, we want to crawl a large part of the web, to index it answer some query
A very common task for web crawlers is to uncover large portions of the OSN and index them. This is fundamentally different from our problem -- TONIC -- in which we wish to retrieve information about a specific target and avoid further crawling. However, some prior work also considered the problem of {\em focused crawling}, where one wants to find  all pages relevant to a specific topic~\cite{diligenti2000focused,menczer2001evaluating}, e.g., for online query answering purposes. We provide here a non-comprehensive list of the techniques used in prior work for focused crawling and discuss their applicability to our problem. 



% Content based methods
Many attributes can be taken into consideration while implementing a focused web crawler. Example of such attributes that have shown to be helpful is the URLs of the nodes that were discovered but not visited yet, the different kinds of links encountered (e.g., link on a picture, link on text) and the number of siblings (i.e., links on the same web page) of a node that have already been crawled. Naturally, a combination of such features yields the most effective focused crawling~\cite{aggarwal2001intelligent}.
It was also shown that reusing the learned information (as a starting point for the next crawl) as well as performing an initial sampling of random web pages are also beneficial~\cite{cai2008irobot}.
 
% More content based methods
Most focused crawlers are based on relevance of the webpage content to the topic being searched. Common measures of webpage relevance are TF/IDF, cosine similarity, and others~\cite{diligenti2000focused,menczer2001evaluating}. 
Some works employ machine learning to classify webpages according to their content~\cite{chakrabarti1999focused}. 
Wang et al. proposed a focused search approach that is based on the words surrounding the prioritized hyperlink~\cite{wang2010focused}.  
Topology-wise these focused crawlers prioritize web pages using the HITS algorithm~\cite{kleinberg1999authoritative} and the PageRank centrality measure~\cite{almpanidis2007combining}. 
All approaches agree that URLs (pointers to webpages that were not crawled yet) need to be ordered intelligently in order to increase the relevance of obtained documents~\cite{cho1998efficient}. Importantly, in this work we do not consider the textual content of the visited profiles, and thus the approach we propose does not require preliminary content extraction (neither in form of the webpage snippet nor in form of the text surrounding the hyperlink). 
Content and topology analysis are orthogonal approaches that can complement each other in future developments. Thus, we could not directly use the techniques used in these works. However, several of the works mentioned above employ Bayes rules to aggregate evidence on the relevance of URLs. We use a similar approach in the \(BysP\) heuristic (see Section~\ref{sec:rtf}) to aggregate topological evidence. 


% Multi-agent crawling
Prior work also studied how to perform focused web crawling with several agents in parallel. A dynamic search method that have been proposed in such a setting is called {\em Fish Search}~\cite{de1994searching}. The idea behind Fish Search is to simulate the search to a school of fish: when food (relevant information) is found, fish (search agents) reproduce and continue looking for food (other relevant information), but in case that food is not found (no relevant information) or when the water is polluted (poor bandwidth), they die (stop looking for other relevant information). Shark Search~\cite{hersovici1998shark} and Improved Shark Search~\cite{chen2007improved} are improvements of Fish Search in which additional features were considered, such as topic description, textual relevance, URL and link relevance. 
In this paper we do not consider a multi-agent version of the TONIC problem, and leave it to future work. 


%
%\roni{This is not fitting here, but maybe when talking about heterogenous networks}
%Another topic that has been studied in the context of intelligent web crawling that we leave for future work is how different social networks affect each other. 
%\rami{This work is not in context of web crawling.}
%For example, \citeN{altshuler2011incremental} found that different types of attributes could be predicted using different types of networks, and considering multiple networks allowed better prediction. Bluetooth data, for example, allowed predicting a person's ``significant other'' and ethnicity with accuracy of 65\% and 60\% respectively, while higher accuracy predictions for a range of attributes (e.g., having children and age group) were obtained by considering also internet usage, alarm usage, and usage of location-based services.


\subsubsection{Network Sampling}

% Another important class is to estimate OSN properties
Another similar task for an intelligent crawler is to {\em sample} an OSN in order to estimate its properties. 
For example, Gjoka et al. used variants of random walk to estimate Facebook's degree distribution and average degree\cite{gojka2010walkingInFacebook}, and Kurant et al. used a form of stratified sampling to estimate the percentage of Facebook users that attended college~\cite{kurant2011walkingOn}. 

% Network sampling is different from TONIC
Crawling to obtain a representative sample of an OSN is different from our problem in that we do not aim to estimate a property of the OSN, but to find specific profiles that have a specific property -- are friends of a specific target profile. Moreover, the number of profiles visited in graph sampling methods is often in the order of hundreds of thousand profiles, while in  TONIC we aim at visiting the fewest possible nodes. 


% In general TONIC is a special special case of intelligent crawling. We are the only one that did anything similar. 
In general, TONIC is different from all prior work on intelligent web crawling on OSNs mainly in that we wish to retrieve information about a specific target and avoid further crawling, while only considering network topology. The only exception, to the best of our knowledge, is our prior work in which we proposed general technique for intelligent crawling that is based on a unique variant of the famous Multi-Arm Bandit problem~\cite{bnaya2013social-journal}. The technique was applied to two intelligent crawling tasks: finding communities in an OSN and TONIC. Importantly, the goal of our work there was to propose a general intelligent crawling method that is not specifically designed for TONIC. Indeed, the results there show results that are comparable to the TONIC-specific BysP heuristic we present in this paper. As we show experimentally in Sections~\ref{sec:btf-experimentalResults} and~\ref{sec:etf}, BysP can be further improved by the heuristics and algorithms we proposed. 


\subsection{Network Completion}
% Network completion is also related to TONIC
Network information that was obtained by crawling is often incomplete. 
Two relevant problems that deal with network completion are profile's attributes prediction and link prediction.  
{\em Profile's attributes prediction} aims at predicting demographic properties or other attributes (e.g., college graduation year and major) of profiles in a social network, based on the topological structure of the social network and a limited set of profiles for whom (at least some of) the relevant attributes are known \cite{fire2011linkPrediction,mislove2010youAreWho,altshuler2011incremental}. 
TONIC is reminiscent of profile attribute prediction, in the sense that the attribute that should be predicted in TONIC is whether a profile contains information about (or linked to) the target. But in TONIC we aim to find -- with certainty -- leads while in profile attribute prediction the task is to {\em estimate} the existence of various profile attributes. Nonetheless, the heuristics we propose were inspired by prior work on attribute prediction and specifically the work of Mislove et al.~\cite{mislove2010youAreWho}. Mislove et al. observed that profiles with similar attributes are grouped into {\em communities} -- highly connected subgraphs of the social network. 
Consequently, in order to find all profiles sharing similar attributes one can crawl the {\em communities} that a given profile is a member of. 



% link prediction
%{\em Link prediction} is a special case of profile's attribute prediction, is specifically the problem of identifying links in a partially known social graph. 
{\em Link prediction} is a variant of network completion problem where given a partially known network one should determine whether or not there should be a link between two given nodes. 
Fire et al. used a variety of topological features to learn an accurate link prediction classifier~\cite{fire2011linkPrediction,fire2014computationallyEfficient}. They also ignored non-topological data like posts, pictures, keywords and other content related to the social network profiles. The resulting link prediction classifier was evaluated 
on five social network datasets: Facebook, Flickr, YouTube, Academia.edu, and TheMarker, and was shown to be very accurate. 
Indeed, we have found that one of the features they proposed --  the \emph{Friends Measure} -- is also an effective heuristic for  prioritizing profiles that should be crawled in TONIC. See Section~\ref{sec:friendsMeasure} for additional details on this measure.  


% [R 2.1]
Similar to profile attribute prediction, some works (e.g.~\cite{tang2012inferring}) focused on predicting the properties of links in {\em heterogeneous social networks}, i.e., networks in which there are more than one type of connection between two profiles. 
Unless we need to find specific kinds of leads (e.g. those that have tagged the target in a photo or commented on his posts but are not his friends on Facebook) this type of link prediction is not suitable for TONIC.   
However, information collected in a heterogeneous network can be used to build stronger classifiers for link prediction~\cite{davis2011multi,dong2012link}. 
Since different types of relationships are usually created by different social processes they carry more information than flat networks. 
%This also gives a strong motivation to using machine learning models for guiding the search process in TONIC in future work. 


Li et al.~\cite{li2017adaptive} studied how to collect reconnaissance in a partially observed OSN with multiple crawlers. This means identifying parts of the OSN, where a benefit function associates a reward to the newly found parts of the OSN. 


%While there are similarities between TONIC and profile attribute prediction (and in particular link prediction), we note that TONIC is a conceptually different problem. %yes... 
%First, unlike most work on profile attribute prediction, in TONIC the network topology is not known upfront is only discovered by costly OSN queries. % in many link prediction (a.k.a network completion papers the topology is not fully known upfront -- this is why one needs to complete it. 
%Even in the link prediction problem all the nodes in the OSN and a large part of the network topology is given as input, while in TONIC only a small number of initial leads are known. 
%Second, in TONIC a link between a profile and the target needs to be verified by an OSN query (\islead{}), while attribute prediction algorithms only predict a link, but do not verify it. The scientific question is thus different: in TONIC, we ask how to know which profile to query so as to minimize query costs, while in link prediction the question is how to predict links with high accuracy and recall. 



\subsection{Heuristic Search in an Unknown Graph}
\label{sec:theWebAsAnUnknownGraph}
TONIC can be formalized  as a {\em search problem in an unknown graph} (see Section~\ref{sec:TONICAsHeuristic}). A search problem in an unknown graph is a search problem in which the structure of the searched graph is not known a-priori, and exploring vertices and edges requires a different type of resource, that is, neither CPU nor memory. The main challenge when searching in an unknown graph is to solve the problem while minimizing the exploration cost.
TONIC fits into this category  as we want to acquire profiles such that the most information about the target will be found while minimizing the costs of our {\em IsLead} and {\em profile acquisition} operators.

%TONIC is  When searching the social web, profiles and friendship relations are the vertices and edges of the searched graph, respectively. Accessing a vertex requires acquiring the corresponding profile, which requires sending and receiving network packets (e.g., HTTP request/response). The main challenge when searching in an unknown graph is to solve the problem while minimizing the exploration cost.  TONIC fits into this category  as we want to acquire profiles such that the most information about the target will be found while minimizing the costs of our operators.

% [R 1.5]
There are several previous works on developing algorithms for searching in an unknown graph. Felner et al.~\cite{felner2004pha} proposed the Physical A* algorithm for solving the shortest path problem in an unknown {\em physical} graph. In a physical graph, exploration is done by a physical agent that needs to physically traverse the graph in order to explore new nodes. The exploration cost being minimized is the distance traveled by the agent. 
In contrast, we deal with exploring an OSN and exploration is done by accessing the OSN, which is not related to a physical distance measure. A setting that is more similar to searching an OSN was discussed by Stern et al.~\cite{stern2010searchingForSOCS} that proposed algorithms for finding a $k$-clique in an unknown (but not physical) graph and any other specific pattern~\cite{stern2012findingPatterns}, where the cost of exploration was constant per node. They employed a best-first approach that is similar to the one proposed in this work and in fact we were inspired by their approach.

That being said, the problem we address in this work -- TONIC -- is  fundamentally different. First, we do not search for a specific pattern, but for nodes with a specific property -- profiles that are leads to the target. 
Second, Stern et al.~\cite{stern2012findingPatterns} proposed heuristics to guide the search for the $k$-clique problem, but these heuristics do not transfer to the TONIC problem of finding leads. In this paper we present several very effective heuristics that are specifically designed for TONIC. Indeed, these heuristics exploit the fact that we are searching for leads and that the search is done over an OSN. 

%In addition most heuristic search research deals with finding a path from an initial node to a predefined goal node. In contrast, the goal of TONIC is to find maximum number of leads while applying at most $b$ acquisitions. While less common, such {\em utility} oriented search algorithms have been previously discussed in the literature~\cite{edelkamp2005costAlgebraic,DBLP:conf/aips/SternPF11}.

% Dunbar's
%Another related subject is Dunbar's number~\cite{Dunbar1992neocortex}, a theoretical cognitive limit on the number of stable social relationships (relationships in which an individual knows who each person is, and how each person relates to every other person). Dunbar's prediction was validated in Twitter~\cite{gonclaves2011modelingUsers}, where it has been  found that users can have a maximum of 100 - 200 stable relationships. This suggests that Dunbar's number can provide us with a limit to the number of profiles that we need to consider.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{TONIC as Search in an Unknown Graph} 
\label{sec:TONICAsHeuristic}


%\begin{wrapfigure}{L}{0.5\columnwidth}
%    \begin{minipage}{0.5\columnwidth}
      \begin{algorithm}
\KwIn{\target\, the target}
\KwIn{\(L_0\), the set of initial leads }
\KwOut{$L$, the leads found}
    $L\gets L_0, PL\gets \emptyset, NL\gets \emptyset$, 	
    $CKG\gets $ the subgraph of $G$ induced by $L$ \nllabel{bfs:lists-init}\\
 	\ForEach{l in $L_0$}{
		$LOF\gets$ \acquire{l} \\
		Add $LOF$ to $OPEN$ and to $PL$\\		
	}
    \While{\nllabel{bfs:loop}$OPEN\neq\emptyset$}{
    	$best\gets$ ChooseBest($OPEN$) \nllabel{bfs:choose}\\
			\If{$\best\in PL$}{
				Remove $\best$ from $PL$ \\
				\If{\islead{\best} \nllabel{bfs:is-lead}}{
					Add $\best$ to $L$\\
					$LOF \gets $ \acquire{$\best$} \nllabel{bfs:acquire-lead}\\
					Update $CKG$, $PL$, and OPEN  \nllabel{bfs:add-pl-to-all}\\					
				}
				\Else{
					Add $\best$ to $NL$ \nllabel{XXbfs:add-nl-to-nl}\\
\nlset{E~~~~~}
					Reinsert $\best$ to OPEN \nllabel{bfs:add-nl-to-open-2}\\
				}
			}
\nlset{E~~~~~}
			\Else{%\tcc*[f]{$best$ is a non-lead}
\nlset{E~~~~~}
				$LOF \gets $\acquire{$\best$} \nllabel{bfs:expand-nl}\\								 
\nlset{E~~~~~}
				Update $CKG$, $PL$, and OPEN \nllabel{bfs:add-pl-to-all-2}\\					
			}
	}
	\Return $L$ \nllabel{bfs:return} \\

        \caption{BFS for TONIC}
        \label{alg:bfs}
\end{algorithm}
 %   \end{minipage}
%  \end{wrapfigure}


%Next we preset a general framework for solving the TONIC problem that embodies a best-first search (BFS) approach. The fundamentals of this framework originate from prior work on solving search problems in unknown graphs (described in Section~\ref{sec:relatedWork}). The unknown graph being searched in TONIC is the topology of the OSN, denoted $G=(V,E)$, where $V$ is a set of OSN profiles and $E$ is a set of links such that \((v_1,v_2)\in E\) if $v_1\in LOF(v_2)$. A key data structure used and maintained when searching an unknown graph is the {\em currently known graph (CKG)}~\cite{stern2012findingPatterns}. We define the CKG for TONIC as follows. 
%Following prior work on solving search problems in an unknown graph~\cite{stern2012findingPatterns} we proposed a best-first search (BFS) approach. A key component in our approach is the following data structure.

%Importantly, the problem solver initially does not know all the vertices and edges in $G$. 
%\begin{definition}[Currently Known Graph]
%Given an arbitrary OSN exploration process we denote the set of all profiles and all links found by this process at any given time as the Currently Known Graph \(CKG=(V, E)\) where \(V\) is a set of known OSN profiles and \(E\) is a set of known links between them.
%\end{definition}
%The CKG for TONIC contains initially only the set of initial leads $L_0$. During a TONIC process, the CKG is grown and maintained: applying an \acquire{} operator to a profile $p$ adds to the CKG: (1) the profiles in $LOF(p)$ (if they are not already in the CKG), and (2) the edges between $p$ to the profiles in $LOF(p)$. The set of {\em known profiles} in the CKG includes all discovered leads, non-leads, and potential leads (\(V=L\cup NL\cup PL\)). The output of a TONIC process is a set of leads discovered during the search (\(L\)).


%Following standard search terminology, we consider potential leads (\(PL\)) as \textbf{Generated}  and leads / non-leads (\(L\cup NL\)) as \textbf{Expanded}.  {\em Expanding} a node corresponds to acquiring a profile. 
%The output  of a TONIC process is a set of leads discovered during the search (\(L\)). \note{Roni}{We've discussed this in the past. This leaves the question of how do you call a non-lead that was not acquired. Is it expanded? is it generated? I commented this paragraph to avoid this unnecessary confusion}
%The \acquire{} operator reveals its LOF. Those who are seen for the first time are {\em generated} and added to the CKG as potential leads. Links are added to those in the LOF that already exist in the CKG (leads or non-leads).

%Previous work on searching in an unknown graph~\cite{stern2012findingPatterns} proposed a best-first search (BFS) approach. 

Next, we preset a general framework for solving the TONIC problem. The fundamentals of this framework originate from prior work on solving search problems in unknown graphs (described in Section~\ref{sec:relatedWork}). The unknown graph being searched in TONIC is the topology of the OSN, denoted $G=(V,E)$, where $V$ is a set of OSN profiles and $E$ is a set of links such that \((v_1,v_2)\in E\) if $v_1\in LOF(v_2)$. 

A best-first search approach is taken, outlined in Algorithm~\ref{alg:bfs}. Throughout the search, the following data structures are maintained:
%A key data structure used and maintained when searching an unknown graph is the {\em currently known graph (CKG)}~\cite{stern2012findingPatterns}. We define the CKG for TONIC as follows. 
%Algorithm~\ref{bfs:return} outlines the exact details of our TONIC search framework. %a similar search framework specifically designed for TONIC. It encapsulates both RTF and ETF.
%In addition to the CKG, it maintains the following data structures:
\begin{enumerate}
	\item $L$, $NL$ and $PL$, which are the leads, non leads and potential leads found so far, respectively.
	\item The {\em currently known subgraph} of $G$ (denoted CKG), containing all nodes (profiles) and edges (friendship relations between profiles) found so far by the search process (line~\ref{bfs:lists-init})
	\item $OPEN$, a list of profiles considered for either an \islead{} or an \acquire{} query. 
	%profiles that are considered to be expanded. Initially, all the initial leads are expanded and OPEN is seeded with the potential leads from their LOFs.	\note{Roni}{If expansion is acquiring a profile, as was defined above, then OPEN only contains potential leads. But this is not true,it also contains non-leads. Only later you say that you focus on RTF. So I changed the whole thing to be general here, and talk about RTF/ETF later.}
\end{enumerate}

% 

Initially, all the initial leads are expanded and OPEN is seeded with the potential leads from their LOFs. Similarly, the CKG is initialized such that its vertices are the initial leads and their potential-leads neighbors. The edges of the CKG are the links that connect the initial leads. In every iteration, a single profile ($\best$) is chosen from OPEN (line~\ref{bfs:choose}). The exact choice if $\best$ is done via the different {\em ChooseBest()} heuristics that we describe in later sections.
%In RTF OPEN contains only potential leads.

If $\best$ is a potential lead, then 
it is removed form $PL$ and an \islead{$\best$} query is performed (line~\ref{bfs:is-lead}) to reveal if it is a lead or a non-lead. 
If $\best$ is found to be a lead, then it is immediately acquired, as finding leads is always desirable (line~\ref{bfs:acquire-lead}). 
Otherwise, if $\best$ is found to be a non-lead, it is reinserted to $OPEN$ to be considered for acquisition at a later stage (line~\ref{bfs:add-nl-to-open-2}).
Thus, $OPEN$ may contain potential leads that are considered for an \islead{} query, or non-leads considered for an \acquire{} query. 
If $\best$ is a known non-lead, then it is acquired (line~\ref{bfs:expand-nl}). 
When $\best$ is acquired (lines~\ref{bfs:add-pl-to-all} and~\ref{bfs:add-pl-to-all-2}), $CKG$, $PL$, and $OPEN$ are updated as follows: (1) nodes and edges corresponding to the neighbors of $\best$ and the links to them are added to $CKG$, and (2) neighbors of $\best$ that were not previously part of $CKG$ are added to $PL$ and to $OPEN$. 
The TONIC process is halted either by the user  or when all the nodes in the OSN has been acquired. When this happens the set of found leads is returned (line~\ref{bfs:return}). 


The pseudo encapsulates both RTF and ETF. Lines 15 to 18, which are preceded by the letter $E$, are executed only for the ETF framework. As detailed below, RTF will never choose a non-lead as $best$ so these lines may be deleted in an RFT implementation.




Figure~\ref{fig:bfs_example} presents an example execution of Algorithm~\ref{alg:bfs}.
The target is marked by $T$, and there is one initial lead $a$. %[R 1.16]
After acquiring $a$ we reveal $b$ and $c$ as potential leads (step 2).
In the next step, \islead{} is performed on $b$ revealing that it is a non lead (step 3).
Then, \islead{} is performed on $c$ revealing that it is a lead. $c$ is then immediately acquired,  discovering the potential lead $d$ (step 4).
%\note{Roni}{Maybe we want to add here also a stage where a non-lead is acquired. Not critical}




\begin{figure}[t!]
  \centering
	 \includegraphics[width=\linewidth]{btf-process-and-legend-new.jpg}
  \caption{An example of a run of Algorithm~\ref{alg:bfs}. The figure shows the CKG in the different stages}
	\label{fig:bfs_example}\label{fig:basic_fifo}
\end{figure}

% \begin{figure}[t!]
% \centering
%	 \includegraphics[width=0.7\linewidth]{basic_fifo.jpg}
%  \caption{An example the basic FIFO heuristic.}
%\end{figure} 


\section{The Restricted TONIC Framework (RTF)}
\label{sec:rtf}

One clear limitation of Algorithm~\ref{alg:bfs} is that in the worst case, it will acquire all the profiles in the OSN. This can be a serious limitation, as popular OSNs are very large. Moreover, the set of possible profiles to acquire may grow to be very large, and include many profiles that are very unlikely to be leads. Previous work showed that OSNs and social networks in general follow the homophily principle, which means that friends tend to exhibit similar attributes~\cite{mcpherson2001birds,altshuler2012security,fire2012predictingStudent}. Thus, it follows that friends of leads (i.e., profiles that appear in leads' LOFs), are more likely to be leads than randomly selected OSN profiles. 

The Restricted TONIC Framework (RTF) builds on this understanding, and focuses the search for leads by only applying the \acquire{} query to profiles that are known to be leads. Non-leads are never acquired. 
RTF may be implemented with Algorithm~\ref{alg:bfs} setting the $ChooseBest$ function to never choose a non-lead. In particle, with RTF we may simplify Algorithm~\ref{alg:bfs} --  profiles that are found to be non-lead are discarded and are not re-inserted into $OPEN$ (line~\ref{bfs:add-nl-to-open-2}). As a result, $OPEN$ only contains potential leads and lines 15--18 are redundant (they are marked with E for extended framework). 
%~\ref{bfs:expand-nl}-\ref{bfs:add-pl-to-all-2} are redundant (they are marked with E for extended framework). 
Also, a single {\em expand} action can be defined, which performs \islead{} on $best$ and acquires if it is a lead. %\note{Roni}{Last sentence is helpful or not? what motivated me in adding this is that we earlier say that expand=acquire. Thoughts? we can write everything below without mentioning the term ``expand'' but I'm not sure if this won't hurt readability}
%\note{Liron}[It's great. There is some confusion with the terms and this sentence fixes it}
 %It is important to note that for RTF (below) we never allow to acquire non-leads. Therefore, in RTF when a non-lead is added to OPEN the heuristic function will give it a very low priority and in practice it will never be chosen. The pseudocode can be further simplified for RTF as we describe below.


%In this section we present the Restricted TONIC Framework heuristics and experimental results comparing them.
 %As mentioned before, in RTF we assume that {\em friends} of leads (i.e., profiles that appear in leads' LOFs), are more likely to be leads than randomly selected OSN profiles. Therefore, we focused the search by only allowing full acquisition of {\em leads}. Meaning that each potential lead $l$ with isLead(l)=true will be acquired and its LOF(l) will be extracted and each potential lead $nl$ with isLead(nl)=false will not be acquired and its LOF(nl) will not be extracted.
 % \note{Roni}{The above is a very good and clear definition of RTF. It was missing when you talked about RTF earlier.} \note{Liron}{Moved it to the previous section}


\subsection{RTF Heuristics}

We now provide a number of heuristics for choosing which potential lead to expand next in RTF. 

A Key to the efficiency of RTF is to choose intelligently which potential lead to expand in every iteration of Algorithm~\ref{alg:bfs} (line~\ref{bfs:choose}). Next, we present several heuristics designed for this purpose. We refer to these heuristics as {\em RTF heuristics}. As a baseline RTF heuristic, consider expanding profiles in a {\em first-in-first-out} (FIFO) manner. This means that the neighbors of the initial leads are chosen first, then their neighbors and hence forth. 
Figure~\ref{fig:basic_fifo} illustrates such an expansion order. $T$ is the target profile and there is a single initial lead $a$. 
After profile $a$ is acquired (\acquire{$\best$} in Algorithm~\ref{alg:bfs}  line~\ref{bfs:choose}), two profiles are discovered, $b$ and $c$. Then, they are expanded according to the order of their insertion into $OPEN$.
%Another baseline is to randomly choose which potential lead to expand next. These baselines are denoted {\em FIFO} and {\em RND}. Both baselines do not consider the topology of the OSN. \note{Roni}{Why not use the CKG, which we defined above}
Another baseline is to randomly choose the potential lead to expand next. 
These baselines are denoted {\em FIFO} and {\em RND}. Both baselines do not consider the $CKG$ (the currently known subgraph of the OSN). As the search progresses, the $CKG$ grows, containing more information about the searched OSN. By contrast, the heuristics provided next are based on analyzing the CKG in different ways.
 

%While initially only the target and the initial leads are known, more parts of the OSN topology are discovered as the search progresses. Let $V_{CKG}$ and $E_{CKG}$ be the nodes and edges of the $CKG$ (the currently known subgraph of the OSN), respectively. $V_{CKG}$ is the union of the sets $L$, $NL$ and $PL$. The following heuristics choose which potential lead to acquire by analyzing the CKG in different ways. 

% (the found leads, non-leads, and potential leads, respectively) \note{Roni}{Already defined above}
%The discovered subgraph of the OSN graph (i.e., the parts revealed when acquiring profiles) is referred to as the {\em currently known graph} \note{Roni}{Repetition of what was said above}, denoted by $CKG=(V_{CKG}, E_{CKG})$. $V_{CKG}$ is composed of three mutually exclusive sets: set of profiles found to be {\em leads} (\(L\)), the set of profiles found to be {\em non-leads} (\(NL\)), and the set of {\em potential leads} (\(PL\)). The following heuristics choose which potential lead to acquire by analyzing the CKG in different ways. \note{Roni}{Confusing. Aren't $L$, $NL$ and $PL$ maintained separately from the CKG, while here you say tha they are part of it.}

\subsubsection{Clustering Coefficient Heuristic}
Nodes in OSNs tend to form tightly connected clusters in which most people are friends of each other. This phenomenon is quantified using the notion of {\em local clustering coefficient}~\cite{clustering}. 
%The local clustering coefficient of a node in a graph is the density of edges between its neighbors. Formally, the local clustering coefficient for a node $i$ in a graph G = (V;E) with an edge $e_{ij}$ that connects vertex $v_i$ with vertex $v_j$ is: \note{Roni}{What is the difference between a vertex and a node?}
The local clustering coefficient of a node in a graph is the density of edges between its neighbors. Formally, it is the proportion of links between the nodes within its neighborhood divided by the number of links that could possibly exist between them. 
%\note{Roni}{Maybe the next sentence and formula is redundant. Thoughts?}
Let $CC(n_i)$ be the local clustering coefficient of node $n_i$, and let $N(x)$ be the neighborhood of $x$, then
\begin{equation}
CC(n_i) = \frac{2|\{e_{jk}: n_j,n_k \in N(n_i), e_{jk} \in E\}|}{|N(n_i)|(|N(n_i)|-1)}.
\end{equation}


%$k_i$ is the number of vertices, $|N_i|$, in the neighbourhood, $N_i$, of a vertex.
%The local clustering coefficient $C_i$ for a vertex $v_i$ is the proportion of links between the vertices within its neighbourhood divided by the number of %links that could possibly exist between them.

 %\note{Roni}{Consider putting here a formal definition (with the formula)}
%\note{Roni}{Now put the formula for the local clustering coefficient of $n$}
%\note{Liron}{Please review}
%\note{Roni}{some inconsistencies which I fixed. $k$ is used twice (first as a variable in the set, second as $k_i=|N_i|$). Unclear usage of node vs. vertex. }

A profile connected to a cluster of leads is likely to be part of that cluster and thus likely to also be a lead. 
An intuitive example of such a case is a small university department where a member of that department is the target. It seems reasonable that members of that department form a dense cluster in the OSN and are likely to be leads. Therefore, as more leads are found in that cluster, profiles in it will have higher local clustering coefficient and it would be worthwhile to expand them.
%because they would be more %likely to be leads. \note{Roni}{Not sure if this is convincing}

%university cluster is found, it would be easier to reach other leads in that cluster since they are probably connected to the lead found. \note{Roni}{Elaborate more. Why does this example show that the local clustering coefficient would be a good heuristic?}
%\note{Liron}{I added an explanation - please review it}

Building on this intuition we propose a heuristic that is based on computing the local clustering coefficient (CC) of each of the potential leads and choosing to expand the potential lead with the highest CC. 
More formally, let $L(pl)$ be the set of leads that are friends of the potential lead $pl$ in the CKG. The CC of $pl$ in the CKG is the number of links between $L(pl)$ divided by the number of possible links among $L(pl)$ :
\begin{equation}
CC(pl)=\frac{2\cdot\left|\left\{(u,v)\in E_{CKG} | u,v\in L(pl)\right\}\right|}{|L(pl)|\cdot(|L(pl)|-1)}
\end{equation}
In RTF, the neighborhood of a potential lead consists of only the previously acquired leads. Thus $L(pl)=N(pl)$ and the above formula is exactly the local clustering coefficient given earlier. The {\em CC heuristic} is the heuristic that chooses to expand the potential lead with the highest CC. 
% For example, a potential lead $pl$ will have a $CC$ of one if all its lead friends form a clique. 


\begin{figure*}
\centering
\begin{subfloat}[\label{fig:cc}]
  \centering
  \includegraphics[width=0.3\textwidth]{cc.pdf}
\end{subfloat}
\begin{subfloat}[\label{fig:kd}]
  \centering
  \includegraphics[width=0.3\textwidth]{KD_NEW.pdf}
\end{subfloat}
\begin{subfloat}[\label{fig:fm_btf}]
  \centering
  \includegraphics[width=0.15\textwidth]{FM_BTF.pdf}
\end{subfloat}
\caption{Examples used to illustrate the RTF heuristics . Fig.~\ref{fig:cc} is used for the Clustering Coefficient (CC) heuristic, Fig.~\ref{fig:kd} for Known Degree (KD), and Fig.~\ref{fig:fm_btf} for Friends Measure (FM).} 
\end{figure*}




An example of CC heuristic is provided in Figure~\ref{fig:cc}. White nodes are potential leads, black nodes are leads, and white nodes with X are non-leads.
$CC(P1)=1$, since the number of links between $L(P1)$ is 1 (the link between L1 and L4) out of one possible link among $L(P1)$.
$CC(P2)=0$, since there are no links between $L(P2)$. Thus, the CC  heuristic will choose to expand node $P1$ before node $P2$.

\subsubsection{Known-Degree Heuristic}
The CC heuristic ignores the number of friends that a potential lead has. In fact, potential leads with a single friend will have the highest CC score (one). This is a disadvantage of CC, because it has been shown that degree of nodes in a social networks exhibits a power-law distribution~\cite{barabasi1999emergence}, and previous work has shown that an effective strategy for searching in such graphs is to direct the search towards nodes with a high degree~\cite{adamic2001searchInPowerLaw}. 
%\note{Roni}{Rami -- should the relevant network characteristic here be ``preferential attachment'' and not ``power law''? }
%\note{Liron{{Because of the preferential attachment, it creates a power law network in which many profiles have a small number of friends and a few profiles have a large number of friends}
The intuition behind this is that high degree nodes are connected to many other nodes, and thus are better sources for searching than low degree nodes.


Identifying the potential lead with the highest degree, or is connected to the most leads, is not possible in TONIC, since the problem solver does not know the true degree of potential leads before they are acquired. However, the degree of a potential lead in the CKG {\em is} known. This is called the {\em known degree} (KD) of a node and the corresponding heuristic, denoted as the {\em KD heuristic}, expands nodes in the order of their KD. This heuristic was previously used to find cliques in unknown graphs~\cite{stern2012findingPatterns}. In RTF, the KD of a potential lead $pl$ is the number of acquired leads that are friends of $pl$ (denoted earlier as $L(pl)$), since only leads are acquired. An example of KD is provided in Figure~\ref{fig:kd}.
$KD(P1)=1$ (connected to $L1$) while $KD(P2)=2$ (connected to $L1$ and $L2$). Thus, the KD  heuristic will choose to expand node $P2$ before node $P1$.


\subsubsection{Promising-Leads Heuristics}
\label{sec:promising}

The KD heuristic expands potential leads according to the number of acquired leads that are connected to them. This is reasonable if all leads have an equivalent effect on the likelihood that a potential lead connected to them is a lead.
%Liron: Rami, Ariel, Roni - please review this sentence. I am not sure about it's ending
% Roni: not perfect but I do not have a good alternative. Can keep it as is in my view.
Consider the example presented in Fig~\ref{fig:PromiseMotivation}. P1 and P2 are potential leads, both connected to one lead. P1 is connected to a lead with 3 lead friends while P2 is connected to a lead with 3 non lead friends. 
We believe that P1 is more likely to be a lead than P2 since it is connected to a more ``promising'' lead.
 Following, we explore an alternative approach that considers not just the amount of leads that a potential lead is connected to, as the KD heuristic, but also how ``promising'' these leads are %\note{Roni}{Minor: in Latex, instead of using "bla bla", use ``bla bla''. It looks differently in the output and some reviewers are nudnikim. Please fix throughout the paper.},\note{Liron}{Done} 
 in the sense that potential leads connected to them are more likely to be leads. 

\begin{figure}
\centering
%\begin{subfigure}{0.35\linewidth}
\begin{subfloat}[\label{fig:PromiseMotivation}]
  \centering
  \includegraphics[width=0.75\linewidth]{PromiseMotivation.pdf}
\end{subfloat}
%\begin{subfigure}{0.55\linewidth}
\begin{subfloat}[\label{fig:Promising}]
  \centering
  \includegraphics[width=0.95\linewidth]{bysp-good_cropped.pdf}
\end{subfloat}
\caption{Examples illustrating the Promising Heuristic. Fig.~\ref{fig:PromiseMotivation} is used to demonstrate how to compute the Promising Factor and Fig.~\ref{fig:Promising} is used to demonstrate how to aggregate promising factor values. }
\end{figure}

The first step in creating such a heuristic is to define a measure of how ``promising'' a lead is. An ideal ``promising'' measure for a lead $m$ would be the probability that a randomly drawn generated neighbor of $m$ is a lead. This is the ratio of potential leads connected to $m$ that are leads. We denote this ideal promising measure as $pm^*(m)$.

Unfortunately, $pm^*(m)$ cannot be known before {\em all} neighbors of $m$ are acquired. As a practical alternative, we consider the ratio of leads among the {\em expanded} neighbors of $m$. Formally, we divided the LOF of an expanded lead $m$ into three sets: leads, non-leads and potential leads, denoted as $L(m)$, $NL(m)$ and $PL(m)$, respectively. The promising measure we propose, called the {\em promising factor} and denoted by $\pf()$, is computed by $\pf(m)=\frac{L(m)}{L(m)+NL(m)}$.\footnote{Initially, it is possible that $L(m)+NL(m)=0$, making $\pf(m)$ undefined. To avoid this, we set $\pf(m)=0.5$ in this case.}


\subsubsection{Aggregating Promising Leads}

If every potential lead was connected to a single expanded lead, then a straightforward TONIC heuristic that considers the promising factor would expand the potential lead that is a friend of the expanded lead with the highest promising factor. However, a potential lead may be connected to a set of expanded leads, each having a different promising factor.
%Next, we propose several TONIC heuristics that use different ways to consider the promising factor of all the leads in $L(pl)$.

%\subsubsection{Simple Aggregations} 
Two simple ways to aggregate the promising factors of the leads is to take their maximum or their average. We call the corresponding TONIC heuristics $MaxP$ and $AvgP$, respectively. Formally, $MaxP$ chooses to expand the potential lead $pl$ that maximizes $\max_{m\in L(pl)}{\pf(m)}$, while $AvgP$ chooses to expand the potential lead $pl$ that maximizes $\frac{1}{|L(pl)|}\sum_{m\in L(pl)} \pf(m)$. 

%[[R 1.20]]
As an example of these aggregation methods, consider again the graph in Figure~\ref{fig:Promising}. 
There are four potential leads, $P1$, $P2$, $P3$, and $P4$, and three leads $L1$, $L2$, and $L3$. 
The promising factor of leads $L1$, $L2$, and $L3$ is $\frac{2}{3}$, $\frac{2}{3}$, and 
$\frac{1}{3}$, respectively. 
The $MaxP$ values for potential leads $P1$, $P2$, $P3$, and $P4$, are $\frac{2}{3}$, $\frac{2}{3}$, $\frac{2}{3}$, and $\frac{1}{3}$, respectively, while the $AvgP$ values for these potential leads are $\frac{2}{3}$, $\frac{2}{3}$, $\frac{1}{2}$, and $\frac{1}{3}$. Thus, using $MaxP$ will result in choosing first one of the potential leads $P1$, $P2$, and $P3$ (but not $P4$, which has a smaller $MaxP$ of $\frac{1}{3}$). In contrast, using $AvgP$ will not allow choosing $P3$ first, and either $P1$ or $P2$ will be expanded first (since both have $AvgP$ of $\frac{2}{3}$ while $P3$ and $P4$ have an $AvgP$ of $\frac{1}{2}$ and $\frac{1}{3}$, respectively. 

%According to the $MaxP$ heuristic  $MaxP(P1)=\frac{2}{3}$, $MaxP(P2)=\frac{2}{3}$,and $MaxP(P3)=\frac{2}{3}$. 
%Thus, according to the MaxP heuristic all three potential leads are equally preferable, and one may choose arbitrarily which be expanded first (e.g., by breaking ties randomly). 
%According to the $AvgP$ heuristic, $AvgP(P1)=1$,  $AvgP(P2)=1$, and $AvgP(P3)=1$.   and $AvgP(P2)=\frac{1}{3}$. Thus, in P1 is expanded first also according to the $AvgP$ heuristic.



%There are two potential leads, $P1$ and $P2$. The only lead connected to $P1$ is $L1$, which has $\pf(L1)=\frac{3}{3}=1$. $PL2$ is connected to two leads, $L2$ and $L3$, with $\pf(L2)=\pf(L3)=\frac{1}{3}$.
%According to the $MaxP$ heuristic, $MaxP(P1)=1$ and $MaxP(P2)=\frac{1}{3}$. Thus, P1 will be expanded first. According to the $AvgP$ heuristic, $AvgP(P1)=1$ and $AvgP(P2)=\frac{1}{3}$. Thus, in P1 is expanded first also according to the $AvgP$ heuristic.


$MaxP$ only considers the lead that is most promising, and ignores all the other leads in $L(pl)$. $AvgP$ takes into consideration all the leads in $L(pl)$ but may diminish the effect of a very promising lead in $L(pl)$, if $L(pl)$ contains other less promising leads. Next, we consider a more sophisticated way to aggregate the promising factors of the leads.




\subsubsection{Bayesian Aggregation}
The promising factor $pf(m)$ is designed to estimate $pm^*(m)$, which is the probability that a potential lead connected to $m$ is a lead. 
We therefore propose another way to aggregate the promising factors that is based on a Na\"{\i}ve Bayes approach to aggregate probabilities.
\begin{equation}
\displaystyle BysP(pl)=1-\prod_{m\in L(pl)}(1-pf(m)) 
\end{equation}

\noindent The TONIC heuristic that chooses to expand the potential lead $pl$ with the highest $BysP(pl)$ is denoted as the {\em Bayesian Promising} heuristic, or simply $BysP$. $BysP$ has the following desirable attributes. Unlike the $AvgP$, discovering a new lead $m$ that is connected to $pl$ is guaranteed to increase (or at least not decrease) $BysP(pl)$, since $pf(m)\leq 1$. Unlike $MaxP$, any change in the promising factor of each of the leads in $L(pl)$ affects the $BysP(pl)$: it will increase or decrease according to the increase or decrease of the promising factor of the leads in $L(pl)$.


%[[R 1.20]]
As an example of the Bayesian Promising heuristic, consider again the graph in Figure~\ref{fig:Promising}. 
%Figure~\ref{fig:promising_new}. 
The $BysP$ values of the four potential leads are $BysP(P1)=1-(1-pf(L1))=\frac{2}{3}$, 
$BysP(P2)=1-(1-pf(L1))\cdot(1-pf(L2))=\frac{8}{9}$, 
$BysP(P3)=1-(1-pf(L2))\cdot(1-pf(L3))=\frac{7}{9}$, and $BysP(P4)=1-(1-pf(L4))=\frac{1}{3}$. 
Thus, $BysP$ will choose to expand first $P2$. 
In contrast, both $AvgP$ and $MaxP$ may expand some other potential lead first ($P1$ for $AvgP$ and $P1$ or $P3$ for $MaxP$). 

%As mentioned earlier, there are two potential leads, $P1$ and $P2$. The only lead connected to $P1$ is $L1$, which has $pf(L1)=\frac{3}{3}=1$. $P2$ is connected to two leads, $L2$ and $L3$, with $pf(L2)=pf(L3)=\frac{1}{3}$.
%Thus $BysP(P1)=1-(1-pf(L1))=1$. $BysP(P2)=1-(1-pf(L2))(1-pf(L3))=\frac{5}{9}$. Therefore, according to the $BysP$ heuristic $P1$ will be expanded first.



\subsubsection{Friends Measure Heuristic (FM)}
\label{sec:friendsMeasure}

% Link prediction algorithms can be used to do TONIC
The TONIC problem bears some resemblance to the \emph{link prediction} problem \cite{liben2007link}, where the goal is to predict whether two profiles are connected (see Section~\ref{sec:relatedWork} for more details). Link prediction algorithms return the likelihood of a link to exist between two profiles. This suggests the possibility of employing a link prediction algorithms for TONIC, by ranking nodes in $OPEN$ according to the likelihood of a link to exist between a node and \target .\footnote{A more comprehensive discussion on the relation between link prediction and TONIC is given in Section~\ref{sec:relatedWork}.} In fact, a notion very similar to KD was extensively used in link-prediction research, where it is known as the common-friend concept~\cite{liben2007link}. Simply put, we expect a potential lead that has many friends that are leads to also be a lead.


% We tried FM
The \emph{Friends Measure} is a very successful link prediction method that estimates the likelihood of a connection between two profiles by counting the number of common friends and the number of links between the friends of the two profiles~\cite{fire2013linkPrediction}.
Formally, the friends measure ($fm$) between profiles two profiles ($u$ and $v$) is defined as follows:
\begin{equation}
fm(u,v)= \sum\limits_{x\in N(u)}~~\sum\limits_{y \in N(v)} \delta(x,y)
\end{equation}

\begin{equation}
\delta(x,y) = \begin{cases}
1 &\text{if $x=y$ or $(x,y)\in E$ or $(y,x) \in E$}\\
0 &\text{Otherwise}
\end{cases}
\end{equation}
% [R 1.21]
We note that the Friends Measure is a special case of the Katz measure~\cite{katz1953aNewStatus} in undirected graphs, and is somewhat similar to the well-known Jaccard's coefficient~\cite{fire2014computationallyEfficient}. 
%Jaccard's coefficient of two nodes is the ratio between the intersection of the nodes' neighborhoods and the union of their neighborhoods. 
In RTF, we are interested to predict if a given potential lead $pl$ has a link to $target$ (i.e., to predict if $pl$ is a lead). Computing $fm(pl,\target)$ requires knowing the neighborhood of $pl$ and $\target$ ($N(pl)$ and $N(\target)$, respectively). $N(pl)$ is not known before $pl$ is acquired and $N(\target)$ is also unknown, otherwise we would know all the leads. Instead, we use the neighborhoods of $pl$ and $\target$ in the CKG. As only leads are acquired in RTF, $N(pl)$ in the CKG is exactly $L(pl)$. Since we assume that leads are all neighbors of $\target$, then $N(target)$ in the CKG is simply the set of known leads ($L$). Thus, the resulting Friends Measure of $pl$ and $target$ is:
\begin{equation}
fm(pl,target)= \sum\limits_{x\in L}~~\sum\limits_{y\in L(pl)  } \delta(x,y)
\end{equation}
%\note{Roni}{Liron/Rami -- please verify the above}
%\noindent where  $\delta(x,y)$ is defined as before and L represent all the Leads in the CKG.
%x represent the target's neighborhood, which contains only leads (every profile connected to the target is considered a lead) and y represent $p$'s neighborhood. Since in RTF, a profile can only have lead friends, $y$ represents the leads connected to $p$.
\noindent The heuristic that chooses to expand the potential lead $pl$ the highest $fm(pl,\target)$ is called {\em FM}. 




Figure~\ref{fig:fm_btf} provides an example of the FM heuristic. P1 and P2 are two potential leads, and $\target$ is denoted by $T$. P1 has one mutual friend with the target (L1) and therefore $fm(P1,T)=1$. In contrast, P2 also has one mutual friend with the target (L3), however the target's neighborhood and P2's neighborhood's contain an additional mutual friend (L2) and therefore $fm(P2,T)=2$
Therefore, the FM  heuristic will choose to expand node $P2$ before node $P1$.


%In a sequel~\cite{bnaya2013social-journal} we have evaluated a general technique, based on a unique variant of the Multi-Arm Bandit problem. The technique was applied to TONIC and to the problem of finding communities in an OSN. Importantly, the goal of the MAB based approach was a search method that is not based on a domain-specific heuristic such as the BysP or FM. Thus, we mention it here for completeness, but have not evaluated it experimentally. 
%Experimentally, their results were comparable to BysP, and they did not consider ETF at all. 
\newstuff{
\subsubsection{Runtime Complexity}
Our focus in this work is to minimize the number of queries performed. Thus, the CPU runtime of our methods is of lesser importance. Nonetheless, all the proposed RTF heuristics can be 
easily implemented in low-order polynomial time. 
RND and FIFO simply require a suitable data structure (array or queue) to run in constant time. KD can be implemented by sorting the potential leads according to their degrees. 
The CC, FM and Promising heuristics requires runtime that is linear in the number of edges of the CKG. 
Thus, we do not expect computational runtime to be a problem in practice.}

\subsection{Experimental Results}
\label{sec:btf-experimentalResults}
Next, we evaluate the performance of the different RTF heuristics. Most experimental results presented in this paper are on the Google+, but Section~\ref{sec:otherNetworks} presents highlights from our research on other other OSNs. Google+ is one of the largest social networks, having more than 540M registered users and 300M users that are active monthly (according to Wikipedia). 

%\note{Roni}{There is still a problem here. The definition of islead in the prob. def. is different. As I suggested above, I think this definition should be given above in the prob. def. section, and then you don't need to write all this here.} \note{Liron}{Changed it in the beginning and deleted it from this section}\note{Roni}{Good}


%\subsubsection{Data Collection}
%\begin{figure}%[t]
%\centering
%\includegraphics[width=0.7\linewidth]{figure_sample_target_BTF.JPG}
%\caption{Sample network of the RTF relevant neighborhood of a target.}
%\label{fig:net}
%\end{figure}

The data set used in our experiments was obtained from the Google+ network and included 211K profiles with 1.5M links between them. This data set was collected by Fire et. al \cite{fire2011linkPrediction} and made available at \url{http://proj.ise.bgu.ac.il/sns/datasets.html}. From this data set we randomly selected  a set of 100 profiles having at least 30 friends. These profiles were used as the targets in our experiments. 


Since in RTF only potential leads can be acquired, the $CKG$ for each target can contain at most the set of leads and their neighbors throughout the search. We call these set of profiles the {\em relevant neighborhood} of the target. In our data set, the size of relevant neighborhood ranged from 233 to more than 4,000 profiles. 
%Figure \ref{fig:net} presents the relevant neighborhood in RTF of one of the targets in our data set.
%\note{Roni}{Ok, the above is not consistent with current definitions.} \note{Liron}{fixed}

The search for leads for each target was executed using RTF using the following heuristics: RND, FIFO, CC, KD, AvgP, MaxP, BysP, and FM. Three friends of every target were randomly chosen as the initial leads. The search continued until {\em all} potential leads were expanded.

%\note{Roni}{A big plus to the paper would be to say here that the data is availabe online in some website. Can we do that?} \note{Liron}{I added a link to mickey's datasets website - is this ok? can we do that? (copyrights etc))?}\note{Roni}{This is perfect.}
 
 
\begin{figure}%[t]
\centering
\includegraphics[width=0.9\columnwidth,  trim={2.0cm 2.5cm 2.5cm 2.0cm},clip]{BTF_all.pdf}
\caption{\% of leads found vs. \% of potential leads checked.}
\label{fig:checkedVsFound}
\end{figure}
We analyzed the obtained results and evaluated the different TONIC heuristics with respect to the anytime objective function (Definition~\ref{def:budget}). 
Comparing anytime algorithms is usually done by comparing their \emph{performance profile}~\cite{zilberstein96usingAnytime}. The performance profile of an anytime algorithm is a plot showing the solution quality as a function of the algorithm runtime. In our case, the solution quality is the number of leads found, and the algorithm runtime is the number of queries performed. This is shown in Figure~\ref{fig:checkedVsFound}: the $x$-axis of is the  percentage of potential leads queried so far (by \islead{}) out of the total number of potential leads reachable from the initial leads, and the $y$-axis represents the fraction of leads found out of all existing leads, averaged over all the 100 targets in our data set. 
We set the $x$-axis here as the percentage of potential leads queried so far and not the actual number of queries for the following reasons. First, to allow averaging over targets with significantly different number of performed queries. Second, since this experiment is for RTF, we did not count the number of \acquire{} queries as those are only applied to leads (and never to non-leads). In the figures presented later for ETF,  we show the exact number of queries (and not percentage) and also consider the \acquire{} queries. 
Note that since RTF limits the search to only acquire leads, not all leads are reachable from the initial leads, and thus the $y$-axis does not reach 100\% even after all potential leads are checked. 

%shows the following analysis. 
%The $x$-axis represents the percentage of RTF iterations preformed (percentage from the total number of potential-lead reachable from the initial leads), where each iteration represents an \islead{} query and if necessary, an \acquire{} query as well. The $y$-axis represents the fraction of leads found out of all existing leads, averaged over all the 100 targets in our data set. Note that since RTF limits the search to only acquire leads, not all leads are reachable from the initial leads, and thus the $y$-axis does not reach 100\% even after all potential leads are checked. 


%[[AFCOMMENT: I do not like the above paragraphs]]
The result in Figure~\ref{fig:checkedVsFound} show that KD, FM and BysP are able to find more leads earlier during the search process and in general outperform all other heuristics. In particular, BysP and FM dominate all other heuristics. %, and BysP has a slight advantage of FM. 
%\note{Liron}{Should i still say the bysp dominates all other heuristics? bysp and fm are extremely close (avg 64.433 vs 64.292 respectively}
%\note{Roni}{Rewrote to say that BysP and FM are the winners. Liron -- can you check statistical significance in each time step? the numbers above - 64.433 and 64.292 are averages over the entire x-axis, where they looks pretty much the same, but maybe in some time steps the difference is statistically significant}
%\note{Liron}{I did a tTest on the rows in pivot table  (between EbysP and FM) and got 0.000026 . Meaning, significant}.


\section{Extended TONIC Framework (ETF)}
\label{sec:etf}



As seen in the results above, RTF may miss 30\% of the leads. These 30\% of leads are not reachable from the set of initial leads by a path which contains leads only. In this section, we relax the restriction imposed by RTF, allowing non-leads to be acquired. We refer to this TONIC framework as the Extended TONIC Framework (ETF). The scope of the search in ETF is larger than RTF, enabling reaching a larger set of profiles and potentially finding more leads. % (second degree friends of leads as oppose to only first degree friends in RTF). 


To prevent the search from scattering, ETF limits the non leads that may be acquired to profiles that are at most $n$ edges in the CKG from a known lead, where $n$ is a parameter. ETF($n$) denotes ETF with this parameter. Thus, RTF is actually ETF(0), since only leads are acquired, while running Algorithm~\ref{alg:bfs} unrestricted is in fact ETF($\infty$). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\subsection{Reachable Leads in ETF}
%--------------------------------------------------
The choice of the $n$ parameter in ETF affects the number of leads that can be reached. Another factor that affects the number of reachable leads is the number of initial leads. 
Increasing both parameters ($n$ and the number of initial leads) is expected to increase the number of reachable leads. This is demonstrated in Table~\ref{tab:tiers}, which shows the average percentage of reachable leads as a function of these parameters (averaged over all the targets in our data set). We use the term {\em tier} to refer to the set of profiles that are reachable with ETF($n$) for a given number of initial leads.
The table columns represent the number of tiers used, and the rows are the number of initial leads (rows). Note that since the initial leads are expected to be very hard to obtain (e.g., obtained via manual labor), we focused our analysis on a relatively small numbers of initial leads.

%Note that since the initial leads are expected to be very hard to obtain (e.g., obtained via manual labor), we focused on small numbers of initial leads. 

First, consider the impact of the number of initial leads. 
From a single initial lead the TONIC process can reach a significant fraction of all leads (more than 60\% in all cases). 
Every additional initial lead increases the fraction of reachable leads. 
The second initial lead increases the fraction of reachable leads by a margin of 6.6\% in tier 0 and approximately 4\% in higher tiers. 
This margin decreases with each additional initial lead, and we observe only a marginal advantage for adding more than 3 initial leads. 
As an operational guideline we suggest obtaining initial leads with different kinds of acquaintances with the target. For example, one family member, one co-worker, and one blog fan. 


With every additional tier the number of profiles in the corresponding tier grows, and the search will be able to reach more leads. The results in Table~\ref{tab:tiers} show this trend very clearly. The percentage of reachable leads increases significantly when considering also profiles from tier 1. For example, with 3 initial leads 70.51\% leads are reachable in tier 0, while an additional 17\% of the leads become reachable by considering tier 1 profiles too. Thus, in \(ETF(1)\) we can find more leads than in \(RTF\). However there is not much difference between the number of leads found in higher tiers (tier 2 and 3). Therefore we focus in the rest of this paper on ETF(1). 


%However, larger tiers have also more non-leads, causing potential waste in querying them. To provide insight into how to choose $n$ intelligently, Table~\ref{tab:BTFtiers} shows the average percentage of leads reachable in each tier from a certain number of initial leads. As can be seen, the exploration of tier 1 profiles can increase the number of leads found substantially compared to tier 0, i.e., in \(ETF(1)\) we can find more leads than in \(RTF\). However there is not much difference between the number of leads found in higher tiers (tier 2 and 3). Therefore we focus in the rest of this paper on ETF(1). 


%Adding initial leads increases the average number of reachable leads because people tend to be connected to a few social cycles (a.k.a communities) of friends in OSNs. \note{Roni}{This seems very obvious to me}
%In some cases a few links may exist between peoples in different social cycles while in other cases the target can be the only relation between them. In the latter cases, TONIC process starting from initial leads located only within one such social cycle cannot reach leads located in the others. Increasing the number of initial leads increases the number of social cycles that can be explored by the TONIC process. 


%It is also important to note that, the margin due additional initial leads is higher in \(RTF\) than in \(ETF\). 


%TONIC receives as input a small set of initial leads from which the search begins.  As described earlier, obtaining these initial leads may be very costly. However, the set of leads reachable increases as more initial leads are given, thus potentially leading to more leads found and higher net gain.  For a given target and initial leads, ETF partitions the OSN to {\em tiers}, where tier $n$ is the profiles that can be acquired by ETF($n$). 

%Next, we examine the effect of the number of initial leads on the percentage of reachable leads in various tiers. 
%Note that since the initial leads are very hard to obtain, we focus on small numbers of initial leads. 

% Thus, the impact of adding initial leads is more pronounced in RTF (tier 0), while it is relatively small for ETF(1) and higher tiers. 
% For example, the results suggest that unlike RTF, for ETF(1) or higher there is no need for more than three initial leads, as the added \% of leads does not increase significantly.

 


%As $n$ increases, the number of profiles in the corresponding tier grows, and the search will be able to reach more leads. However, larger tiers have also more non-leads, causing potential waste in querying them. To provide insight into how to choose $n$ intelligently, Table~\ref{tab:BTFtiers} shows the average percentage of leads reachable in each tier from a certain number of initial leads. As can be seen, the exploration of tier 1 profiles can increase the number of leads found substantially compared to tier 0, i.e., in \(ETF(1)\) we can find more leads than in \(RTF\). However there is not much difference between the number of leads found in higher tiers (tier 2 and 3). Therefore we focus in the rest of this paper on ETF(1). 


\begin{table}[t!]
\centering
\begin{tabular}{|c | c| c |c| c |}
\hline
			  & \multicolumn{4}{|c}{Tiers}\\
Initial leads & 0 & 1 & 2 & 3 \\
\hline
1 & 61.34\% & 82.78\% & 82.78\% & 83.10\%\\
2 & 67.94\% & 86.75\% & 86.75\% & 87.07\%\\
3 & 70.51\% & 88.28\% & 88.28\% & 88.60\%\\
4 & 72.19\% & 88.52\% & 88.52\% & 88.84\%\\
5 & 73.81\% & 88.82\% & 88.82\% & 89.11\%\\
\hline
\end{tabular}%\vspace{-0.3cm}
\caption{\label{tab:tiers}\label{tab:BTFtiers}\% of leads reachable in different tiers from different numbers of initial leads. Note that tier 0 is actually RTF. %[[R1.22]]
%
}%
\end{table}

%\note{Roni}{We will probably be asked how the number of initial leads impacted the actual search, not just the number of reachable leads}
%\note{Liron}{added the following:}
% We have also compared the performance of the proposed heuristics in terms of DCG as a function of the number of initial
% leads. Naturally, the DCG increases with the number of initial leads, as the first profiles acquired are the initial leads, which are guaranteed to be leads. In addition, the same trends as shown in results section were kept.



\subsection{ETF Heuristics}
A key difference between RTF and ETF is that $OPEN$ in RTF contained only potential leads while in ETF $OPEN$ can also contain non-leads. This is because in RTF a potential lead found to be a non-lead is discarded, while in ETF($n$) discovered non-leads are re-inserted into $OPEN$. These re-inserted profiles are later considered for expansion if they are not too far from a known lead (where ``too far'' is with respect to the $n$ parameter). % (lines~\ref{expand:add-nl-to-open-1}, \ref{expand:add-nl-to-open-2},  and~\ref{expand:add-nl-to-open-3})$d_L(\cdot)\leq n$ (lines~\ref{expand:expand-nl-1}--\ref{expand:expand-nl-2}).
Note that the distance of non-leads to known leads can change as the search progresses and new leads are discovered.

\begin{figure}[t!]

  \centering
  % Requires \usepackage{graphicx}
 % \includegraphics[width=\linewidth]{process-and-legend-2.jpg}\\
	 \includegraphics[width=0.85\linewidth]{process-and-legend-new.jpg}
  \caption{An example of using ETF to search for leads.}\label{fig:etf_process-and-legend}
\end{figure}
%Figure
%\note{Roni}{Figure fig:etf-process-and-legend does not exist}

Figure~\ref{fig:etf_process-and-legend} shows an execution of ETF. Stages (1)-(4) are similar to the RTF (see section~\ref{sec:TONICAsHeuristic}). In stage (5) the non lead $c$ is acquired revealing its LOF ($\{e\}$). \islead{$e$} is then performed, revealing that it as a lead. This search process can continue, finding and acquiring more and more leads.
%
%
%A non-lead \(p\) that was discarded in line~\ref{expand:expand-nl-1} since \(d_L(p)>n\) can be reinserted into the OPEN (line~\ref{expand:add-nl-to-open-1}) when a shorter path connecting it to a lead is discovered.
%Non-leads within the tier limit of ETF($n$) are expanded and generate additional potential leads (line~\ref{expand:expand-nl-2}), thus allowing discovery and acquirement of leads that were unreachable in RTF.
%
%As in RTF, the main challenge in ETF(1) is to choose which node to query next in each iteration. Next, we propose several ETF heuristics for this purpose. 
%
%, which action to preform; isLead() operation on a potential lead or a full acquisition of a non lead profile. In this section, as in the RTF section, leads are automatically acquired when discovered.
%
%ETF pseudocode
%The pseudocode of the extended TONIC framework ETF($n$) is also given in Algorithm~\ref{alg:bfs} with several modifications (Lines \ref{expand:add-nl-to-open-1}-\ref{expand:expand-nl-2} preceded with \emph{E}).
%The key difference between RTF and ETF is handling of non-leads which can now be added to OPEN.
%In RTF, a potential lead found to be a non-lead is discarded.
%In ETF($n$), discovered non-leads are reinserted into OPEN (lines~\ref{expand:add-nl-to-open-1}, \ref{expand:add-nl-to-open-2},  and~\ref{expand:add-nl-to-open-3}), to be later considered for expansion if their  $d_L(\cdot)\leq n$ (lines~\ref{expand:expand-nl-1}--\ref{expand:expand-nl-2}).
%Note that the distance of non-leads can change as the search progresses.
%A non-lead \(p\) that was discarded in line~\ref{expand:expand-nl-1} since \(d_L(p)>n\) can be reinserted into the OPEN (line~\ref{expand:add-nl-to-open-1}) when a shorter path connecting it to a lead is discovered.
%Non-leads within the tier limit of ETF($n$) are expanded and generate additional potential leads (line~\ref{expand:expand-nl-2}), thus allowing discovery and acquirement of leads that were unreachable in RTF.
%
%
Since the number of reachable profiles (and reachable non-leads) with ETF is much larger than with RTF, ETF can potentially perform worse than RTF. Thus, the benefit of ETF depends on having an effective heuristic for choosing the best node to expand. In this section we describe several ETF heuristics.

%Problem def


\subsubsection{EFIFO heuristic}
This simple baseline heuristic chooses $\best$ for expansion in a first-in-first-out (FIFO) order. If a potential
lead was chosen as $\best$ and discovered as a non lead, it is removed from the OPEN and reinserted as non lead at the end of OPEN. 
Figure~\ref{fig:etf_process-and-legend} illustrates such an expansion order. Figure~\ref{fig:PROMISE_FIFONL_HYBRID} shows the performance of EFIFO in our data set (described in Section~\ref{sec:btf-experimentalResults}) versus that of BysP, the best RTF heuristic. The $x$-axis is the number of \islead{}
calls. The $y$-axis is the number of leads found by \islead{} up to that point.\footnote{The exact setting of this experiment is provided below in the experimental section.} As can be seen, EFIFO discovers leads slower than BysP but eventually reaches more leads.
%\ref{fig:PROMISE_FIFONL_HYBRID}.


\subsubsection{Hybrid Heuristic}



\begin{figure*}[t]
\centering
\begin{subfloat}[\label{fig:PROMISE_FIFONL_HYBRID}]%
\centering
\includegraphics[width=0.85\columnwidth, trim={2.0cm 2.5cm 2.5cm 2.0cm},clip]{PROMISE_FIFONL_HYBRID.pdf}
\end{subfloat}
\qquad
\begin{subfloat}[\label{fig:all-nl}]
\centering
\includegraphics[width=0.85\columnwidth, trim={2.0cm 2.5cm 2.5cm 2.0cm},clip]{all_nl_with_promise.pdf}%\vspace{-0.3cm}
\end{subfloat}%
\caption{Performance of ETF heuristics. The $x$-axis is number of executed iterations of Algorithm~\ref{alg:bfs}. The $y$-axis is the percentage of leads found by \islead{} up to that point. Fig.~\ref{fig:PROMISE_FIFONL_HYBRID} compares Hybrid vs. BysP(0) and EFIFO(1). Fig.~\ref{fig:all-nl} compares all the heuristics together.}
\end{figure*}

To enjoy the complementary benefits of BysP, which finds leads fast by effectively focusing on clusters of leads and the extended reachability of EFIFO, we propose an adaptive {\em hybrid} heuristic that starts with BysP and eventually switches to EFIFO. Ideally, we would like to switch as soon as BysP exhausted the set of leads it can reach. To determine the exact switching point we define a bound \(U\) which determines the number of \islead{$\cdot$}~ queries allowed since the last lead was found. If \(U\) unsuccessful \islead{$\cdot$}~queries were done by BysP, the \emph{hybrid} heuristic assumes that BysP has discovered the set of leads it can reach and switches to EFIFO.

We have tried many values for $U$ and have found that the best option is to increment $U$ dynamically according to the following assignment schedule. Initially, set $U$ to some constant. Whenever a lead is acquired (with BysP), $U$ is set to be the number of \islead{$\cdot$}~queries done so far. For example, if a lead was found in the third \islead{$\cdot$} operation then $U$ is set to 3 and if no lead will be found in the next 3 \islead{$\cdot$} operations then we will switch from the BysP heuristic to FIFO. 


Empirical evaluation (see Figure~\ref{fig:PROMISE_FIFONL_HYBRID}) shows that \(hybrid\) is able to outperform both BysP and EFIFO, suggesting that $hybrid$ switches heuristics when EFIFO starts to outperform BysP. 
The $x$-axis in Figure~\ref{fig:PROMISE_FIFONL_HYBRID} corresponds to the number of iterations of the main loop in Algorithm~\ref{alg:bfs} (lines 5--18). 
In each iteration one node is removed from OPEN and is queried according to the Algorithm~\ref{alg:bfs}.

% [R 1.23]
%\subsection{Experimental Results}
%To enjoy the complementary benefits of BysP, which finds leads fasts by effectively focusing on clusters of leads, and the extended reachability of EFIFO, we propose an adaptive {\em hybrid} heuristic that starts the search with BysP and eventually switches to EFIFO. Ideally, we would like to switch as soon as BysP exhausted the set of leads it can reach. To determine the exact switching point we define a bound \(U\) which determines the number of \islead{$\cdot$}~ queries allowed since the last lead was found. If \(U\) unsuccessful \islead{$\cdot$}~queries were done by BysP, the \emph{hybrid} heuristic assumes that BysP has discovered the set of leads it can reach and switches to EFIFO.

%We have tried many values for $U$ and have found that the best option is to increment $U$ dynamically according to the following assignment schedule. $U$ is initially set to some constant. Upon acquisition of a lead (with BysP), \(U\) is set to be the number of \islead{$\cdot$}~queries done so far. For example, if a lead was found in the third \islead()\ operation, U is now set to 3, meaning that unless a lead is found in the next 3 \islead\ operations, the BysP heuristic will be switched to FIFO. 


%Empirical evaluation (see Figure~\ref{fig:PROMISE_FIFONL_HYBRID}) shows that \(hybrid\) is able to outperform both BysP and EFIFO, suggesting that $hybrid$ switches heuristics when EFIFO starts to outperform BysP.  The $x$-axis in Figure~\ref{fig:PROMISE_FIFONL_HYBRID} corresponds to the number of iterations of the main loop in Algorithm~\ref{alg:bfs} (lines 5--18).  In each iteration one node is removed from OPEN and is queried according to the Algorithm~\ref{alg:bfs}.


\subsubsection{Variants of the Known Degree Heuristic}
KD, described above for RTF, expands the potential lead with the highest degree
in the CKG.
Next we discuss how to adapt it to ETF. Let $EKD(p)$ be the degree of $p$ in the
CKG, and let $KDL(p)$  be the number of leads adjacent to $p$ in the CKG.
Since only leads are acquired in RTF, there is at least one lead in every edge
of the CKG. Consequently, in RTF $EKD(p)=KDL(p)=KD(p)$ for every potential lead $p$.
In ETF, $EKD(p)$ and $KDL(p)$ can be different, as a potential lead may be connected to leads and to non-leads. This results in two possible ETF heuristics EKD and KDL, each expanding the node (either potential lead or
non-lead) in $OPEN$ with the highest $EKD(\cdot)$ and $KDL(\cdot)$, respectively.






\begin{figure*}[t]
\centering
\begin{subfloat}[\label{fig:NL_Heuristics}]
\centering
\includegraphics[width=.35\textwidth]{NL_BASE.jpg}
\end{subfloat}%
\begin{subfloat}[\label{fig:PROMISENL}]
  \centering
\includegraphics[width=.35\textwidth]{PROMISENL.jpg}
\end{subfloat}%
\begin{subfloat}[\label{fig:efm}]
  \centering
\includegraphics[width=.25\textwidth]{fm.jpg}
\end{subfloat}%

\caption{Examples used to illustrate the ETF heuristics.  Fig.~\ref{fig:NL_Heuristics} is used for EKD and KDL, 
Fig.~\ref{fig:PROMISENL} is used for EBysP,
and Fig.~\ref{fig:efm} is used for EFM.}
\label{fig:efm-and-ebysp}

\end{figure*}


Figure~\ref{fig:NL_Heuristics} depicts a CKG that demonstrates the difference between EKD and KDL. The legend for this figure is the same legend shown in Figure~\ref{fig:bfs_example}. There are three profiles that can be
expanded: NL1, P1 and P2. KD will expand P1 since $EKD(P1)=4$, $EKD(NL1)=1$, and
$EKD(P2)=3$, while KDL will expand P2 since $KDL(P2)=3$, $KDL(P1)=2$, and
$KDL(NL1)=1$.


The intuition behind EKD and KDL differ. EKD is based on the assumption that
leads tend to cluster together, and thus a profile with many adjacent leads
suggests that this profile is itself lead or is adjacent to many other leads.
KDL is based on the assumption that a profile with a high degree in the CKG has
a high degree in the underlying graph (the OSN), and thus expanding it would
result in finding many other profiles, some of which would be leads.
Our experiments showed that EKD performs significantly better than
KDL in ETF(1) (as shown in Figure \ref{fig:all-nl} explained in the
experimental section).

\subsubsection{BysP and FM Heuristics for ETF}



BysP and FM were the best performing RTF heuristics (see Section~\ref{sec:btf-experimentalResults}), and they can be easily adapted for ETF. The key difference between RTF and ETF is that non-leads can be acquired, and thus while in RTF neighbors of profiles that are considered for expansion (either \islead{} or \acquire{}) were leads, in ETF the neighborhood of a profile that was not acquired yet may also contain non-leads. This requires slight modifications to the BysP and FM heuristic computation. 

For BysP, the BysP score ($BysP(p)$) of a profile $p$ in ETF would aggregate the promising factor of all its neighbors, regardless if they are leads or not. For FM, the Friends Measure would count links between all neighbors of $p$, non-leads included, and all the known leads. To distinguish between BysP and FM for RTF and for ETF, we denote the latter EBysP and EFM, respectively.

Note that both EBysP and EFM expand the profile with the highest score in $OPEN$ (each according to its scoring function), regardless if it is a potential lead or a non-lead. If that profile is a potential lead, then an \islead{} query is applied to it and it is acquired if it is found to be a lead. If the best profile is a non-lead, then it is acquired. 

%BysP was the best performing heuristic for RTF~\cite{stern2013target}. BysP chooses to expand the potential lead $pl\in OPEN$ having the highest
%$BysP(pl)=1-\prod_{m\in L(pl)}(1-pf(m))$. A small modification is required in order to apply it to ETF as follows:
%\[ EBysP(p)=1-\prod_{m\in L(p)\cup NL(p)}(1-pf(m)) \]
%\vspace{0.1cm}\\
%$~~~~~~~~~~~EBysP(p)=1-\prod_{m\in L(p)\cup NL(p)}(1-pf(m))$\\
%\vspace{0.1cm}

%The key difference between $BysP(p)$ and $EBysP(p)$ is that $BysP(p)$ only aggregates the $pf(\cdot)$ values of the leads that are adjacent to $p$ ($L(p)$) 
%while $EBysP(p)$ aggregates over all the acquired neighbors of $p$ ($L(p)\cup NL(p)$). 
%We use EBysP to denote the ETF heuristic that expand the profile $p$ with the highest $EBysP(\cdot)$ in $OPEN$, regardless if $p$ is a potential lead or a non lead.


To illustrate  EBysP, consider Figure~\ref{fig:PROMISENL}. $OPEN$ contains P1,
NL1, NL2, and NL3. These profiles are connected to two acquired profiles, ANL1
and L1, having $pf(\cdot)$ values of $\frac{2}{3}$ and $\frac{1}{4}$, respectively. As a result, P1, NL1, NL2, and NL have $EBysP$ values of
$\frac{2}{3}$, $\frac{9}{12}$, $\frac{1}{4}$, and $\frac{1}{4}$, respectively, and therefore EBysP expands NL1.







%Liron: to delete the FM example?
Figure~\ref{fig:efm} demonstrates EFM. There are two potential leads P1 and P2. According to the EFM definition presented, $fm(T,P1)=2$ and  $fm(T,P2)=1$ (ANL1 is in P2's neighborhood and it is friends with L2 which is in the target's neighborhood). Thus, P1 will be acquired prior to P2.

%\note{Roni}{Need to consider removing both examples. Or, even better, have these examples where we have BysP and EBysP to show the difference, and the same for FM and EFM. Thoughts?}

%\subsubsection{EFM}
%The FM heuristic, described above for RTF, expands the potential lead with the highest Friend Measure score. In RTF, the potential leads' neighborhood contained only leads since they were the only profiles acquired. In ETF however, non leads can also be acquired and therefore the FM heuristic should be adjusted to count both types of profiles and the link between them as mutual friends. To distinguish between FM for RTF and this adjusted FM for ETF, we denote the latter as ETF. 
% We tried FM
%Formally, the extended friends measure ($efm$) between a profile \(p\) ans the target is: 
%\[
%efm(t,p)= \sum\limits_{x\in L}~~\sum\limits_{y | (p,y)\in E} \delta(x,y)
%\]
%\noindent where \(E\) is the edges in the CKG, \(L\) is the set of leads and $\delta(x,y)$ is defined as:
%\begin{equation}
%\delta(x,y) = \begin{cases}
%1 &\text{if $x=y$ or $(x,y)\in E$ or $(y,x) \in E$}\\
%0 &\text{Otherwise}
%\end{cases}
%\end{equation}


%X represent the target's neighborhood, which contains only leads (every profile connected to the target is considered a lead) and y represent $p$'s neighborhood.
%The EFM formula is similar to the FM formula. However now y can represent both leads and non leads profiles connected to a profile $p$. In addition, the profile $p$ considered for expansion can now be either a potential lead or a non lead. \note{Roni}{The reviewers are not that dumb, and repeating to much will insult them (happend to me)}

%The ETF heuristic chooses as $best$ the candidate $p$ with the highest $efm(target,p)$. Experimentally, we show later (see Figure \ref{fig:all-nl}) that $efm$ performs reasonably well as a TONIC heuristic.



In order to evaluated the performance of ETF(1) with the proposed heuristics we used the same benchmark set of targets and initial leads as was used in the RTF experiments earlier (Section~\ref{sec:btf-experimentalResults}). However now, the relevant neighborhood of each target is larger since it contains an additional tier. 
%Figure \ref{fig:googleNewTarget} represents the relevant neighborhood in ETF for the same target that was presented in Figure~\ref{fig:net}.  
%\note{Roni}{Liron. What would be really cool is to show for the same profile how its relevant neighborhood looks in tier 0 and tier 1. Can you do this easily?}

%\begin{figure}[!hb]
%\centering
%\includegraphics[width=0.7\linewidth]{google_new_ETF.JPG}%\vspace{-0.3cm}
%\caption{Sample network of the ETF relevant neighborhood of a target}\label{fig:googleNewTarget}%\vspace{-0.3cm}
%\end{figure}


Figure~\ref{fig:all-nl} compares the percentage of leads found (the $y$-axis) out of all the possible leads by each of the proposed ETF heuristics as a function of the iteration percentage (the $x$-axis).
%The iteration in the ETF, as oppose to the RTF, does not represent only \islead{} operations but also non leads acquisitions. \note{Roni}{First, the reader at this stage will be tired of hearing about this. Second, there's the issue of not counting the acquired leads, which I'm not sure we want to raise.}
%In each iteration the search preforms one of the two mentioned actions.
 For reference, we also present the results for BysP (which was the best RTF heuristic).
At the very beginning of the search, all heuristics perform similarly because the CKG
is too small to be informative and the search is almost blind. As the search
progresses and the CKG grows, EBysP quickly gets better than other  heuristics,
finding more leads faster. In particular, EBysP substantially outperforms BysP throughout the search. 
For example, after  0.8\% of the iterations, BysP found slightly more than 40\% of the leads, while EBysP
found approximately 60\%. This result demonstrates that intelligent acquisition
of non-leads not only enables reaching more leads eventually (as shown in
Table~\ref{tab:BTFtiers}), but also significantly speeds up the acquisition of
leads during  early stages of the search.
%\note{Roni}{A more sensible x-axis for this figure would be nice. It is not clear if it is logarithmic, of some predefined steps with no logic behind it.}


All studied heuristics are computationally efficient as they analyze the
neighborhood of the evaluated profile $p$ only up to two hops away. KD is the
simplest heuristic that only considers the connectivity of $p$. Surprisingly,
its performance is not a lot worse than the performance of the more sophisticated
heuristics EBysP and FM and much better than the performance of KDL which is
more focused toward leads.




\section{Maximizing the Net Gain}
\label{sec:costbenefit}

Up until now, we focused on the anytime objective (Definition~\ref{def:budget} represented by the $x$-axis). The experiments showed given $B$ operations, how many leads have we found?
%, denoted as Utility.
In this section we analyze the proposed TONIC frameworks and heuristics from the perspective of the second objective function we proposed, which aims at maximizing the net gain (Definition~\ref{def:gain}). 
The net gain is roughly related to the steepness of the slopes in Figure~\ref{fig:all-nl}. A steep slope corresponds to finding many leads with few queries, which means high net gain, while a flat line means costs of queries are spent but no leads are found, which means decreased net gain. A trend that is very clear in Figure~\ref{fig:all-nl} is that during late stages of the search the frequency of leads decreases and the slopes become flatter. Therefore, the net gain may drop to a point where the search process is not worthwhile.

\begin{figure}
\centering
\includegraphics[width=.4\textwidth]{Cost_Iteration.pdf}
\caption{Average net-gain as a function of the number iterations for $R_{Acquire}$=40 and $C_{Acquire}$=1).}
\label{fig:CostIteration}
\end{figure}

\begin{table} 
  \centering
\begin{tabular}{|c|r|r|}
\hline 
Reward & BysP & EBysP \\\hline
100 & 2529.45 & {\bf 3100.89} \\
%50 & 1251.95 & {\bf 1495.29} \\
10 & 229.95 & {\bf 250.55} \\
5 & 102.20 & {\bf 104.96} \\
4 & 76.65 & {\bf 76.71} \\
3 & \textbf{51.10} & 49.17 \\
2 & \textbf{25.55} & 22.50 \\
%1.5 & \textbf{12.775} & 10.11 \\
1 & 0 & 0 \\
%0.5 & -1.81 & -1.81 \\
%0.1 & -3.258 & -3.258 \\
\hline 
\end{tabular}%\vspace{-0.3cm}
\caption{Average net-gain for different $R_{Acquire}$ values.}
\label{tab:Reward}
\end{table}

\subsection{Net Gain Results}
\label{sec:netGainResults}
Figure~\ref{fig:CostIteration} demonstrates this, showing the net gain ($y$-axis) as the search progresses ($x$-axis, number of \acquire{} queries executed) for BysP and EBysP. In this experiment we set the cost of \islead{} to be zero, the cost of \acquire{} to one, and the reward of finding a lead is 40.

We chose to evaluate only the BysP and EBysP heuristics because BysP is the best heuristic for RTF(=ETF(0)) and EBysP is the best heuristic for ETF(1). First, observe that the gain of BysP does not decrease throughout the search. This is because RTF only acquires leads, and thus whenever a cost is spent on \acquire{} it is immediately followed by a reward (of passing this profile to the information extraction phase). Thus, the gain in RTF cannot decrease unless either $C_{Acquire} > R_{Acquire}$ or $C_{IsLead}$ is not negligible.



ETF(1) allows acquiring non-leads. When a non lead is acquired, its acquisition
is not followed by immediate reward. However, the acquisition of non leads can
be viewed as a long-term investment, leading to higher rewards and gain in the
future. Indeed, as shown in Figure~\ref{fig:CostIteration} the acquisition of
non leads by EBysP results in much more frequent discovery of leads at the
first stages of the search and overall higher gain compared to BysP.
However, when leads are exhausted, EBysP looses the previously accumulated
reward on useless exploration of the network and may eventually reach negative
gain. In order to gain the most from EBysP one needs to determine when the
search process should be halted. We propose a method for choosing when to stop crawling in Section~\ref{sec:stopping}. 
%While we leave development of sophisticated stop conditions for future work, we illustrate next the potential gain of having such a mechanism.

Table~\ref{tab:Reward} shows potential of having a perfect stopping mechanism for choosing when to stop, showing the maximal gain achievable for BysP and EBysP, for different values of $R_{Acquire}$ and assuming that $C_{Acquire}$=1 and $C_{IsLead}$=0. BysP reaches a maximal gain higher than EBysP when \(R_{Acquire} \leq 3 \), and this reverses when $R_{Acquire}\geq 4$. This is reasonable because larger $R_{Acquire}$ makes the long term investment of EBysP in acquiring of non-leads worthwhile.


\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{reward.pdf}%\vspace{-0.3cm}
\caption{The difference in net gain between BysP(0) and BysP(1)}%\vspace{-0.3cm}
\label{fig:reward3d}
\end{figure}



To gain a deeper understanding of the gains of BysP and EBysP throughout the
search, Figure~\ref{fig:reward3d} shows the difference between their gains (vertical-axis $\uparrow$) as a function of \(R_{Acquire}\)
(horizontal-axis $\nearrow$) and the number of iterations (depth-axis
$\nwarrow$). For example, the solid line at \(R_{Acquire}=40\) represents the
difference between gains of EBysP and BysP as depicted in
Figure~\ref{fig:CostIteration}. The dashed line represents the relation between
\(R_{Acquire}\) and iterations where the gains of both heuristics are equal. EBysP (using ETF(1))
benefits from higher rewards and suffers for longer executions, while BysP (using RTF) is a valid choice if $R_{Acquire}$ is not much larger than $C_{Acquire}$ and we expect a long execution. 
Thus, the choice of between BysP and EBysP could be determined upfront if one knows the
number of iterations the search will be run, $R_{Acquire}$, and $C_{Acquire}$. 

\subsection{Identifying When to Stop}
\label{sec:stopping}
So far, the discussion focused on how to choose the best profile to query in every step. 
As illustrated in Figure~\ref{fig:CostIteration}, in order to maximize the net gain (Definition~\ref{def:gain}) it is extremely important to know when to stop the TONIC process, since every query incurs a cost and the rewards are limited. %Next, we propose a baseline approach for doing so and two approaches that learn from prior searches how when to halt. 
%To simplify presentation, we will continue the assumption that 

A baseline stopping condition for a TONIC process is to stop after a fixed number of queries. However, the maximal net gain as well as the iteration at which it is achieved varies across  different TONIC processes, depending on the total number of leads and the structure of the social network. Moreover, an optimal stopping condition must consider $C_{Acquire}$, $C_{IsLead}$, and $R_{Acquire}$. Next, we explore two stopping condition for deciding when to stop the TONIC process that considers this costs and reward values.  
These stopping condition are designed to take advantage of available knowledge about TONIC processes that were executed in the past. 

% Fixed Learning
\subsubsection{Learning a Zero Rule Stopping Condition}
%[[Roni: I don't like the term ``zero-rule''. I agree this method is not  ingenious, but I think the zero-rule is the one that chooses an arbitrary fixed iteration.]]


%Here, we assume that we are given information about a set $\mathcal{T}$ of $n$ previously performed TONIC processes. 
Let $\mathcal{T}$ be a set of $n$  TONIC processes that were executed in the past. 
For every TONIC process $T\in \mathcal{T}$ and every iteration $i$ of that TONIC process, let $L(T,i)$, 
$NL(T,i)$, 
$PL(T,i)$, 
$\Acquire(T,i)$, 
and $\IsLead(T,i)$ be 
the number of leads, 
non-leads, 
potential leads, 
\Acquire{} queries, 
and \IsLead{} queries, respectively, 
found/performed during the first $i$ iterations of $T$. 
%If $T$ was run for fewer iterations than $i$ then the value for the last iteration of $T$ is reported. 
Given the cost and reward values the 
net-gain of $T$ at every iteration $i$ is: 
\begin{multline}
NG(T,i, R_{\Acquire{}}, C_{\Acquire{}}, C_{\IsLead{}}) =
R_{\Acquire}\cdot L(T,i) - \\
\big(C_{\Acquire}\cdot \Acquire{}(T,i) +
C_{\IsLead{}}\cdot \IsLead{}(T,i) \big)
\end{multline}
When $R_{\Acquire{}}$, $C_{\Acquire{}}$, and $C_{\IsLead{}}$ are clear from context, we use the shorthand notation $NG(T,i)$ to denote the corresponding net gain for stopping in iteration $i$ when running $T$. 

%[[Rami: please read and check if you're happy with this]]
The first stopping condition we propose is called \learnFixed{} and is based on a \emph{zero rule} classifier. A zero rule classifier for Binary classification problems is a classifier that ignores all the features of the classified instance and outputs the class of the majority of instances in the training set. Similar to a zero rule classifier, \learnFixed{} stops every TONIC process after a fixed number of iterations, regardless of any knowledge gained during the current TONIC process. 
This fixed number of iterations is computed according to the set of available TONIC processes ($\mathcal{T}$), such that stopping the TONIC processes in $\mathcal{T}$ in that iteration would have given the maximal net gain, on average. Formally, \learnFixed{} stops at iteration $I_{best}$, which is defined as follows; 
%That is, we computed 
\begin{equation}
I_{best} = \argmax_i \sum_{T\in\mathcal{T}} NG(T,i)/|\mathcal{T}| \label{eq:ibest}
\end{equation}
%All future TONIC processes are halted after performing $I_{best}$ iterations. 


% Limitations
The \learnFixed{} stopping condition has a clear limitation: it stops all future TONIC processes at the same iteration, following a ``one size fits all'' approach. 
Importantly, it ignores the information collected during the TONIC process about the target and its surrounding network. 
This information includes the CKG, the number of acquired leads and non-leads, and the number of potential leads. Indeed, we observed empirically that the structure of the CKG of different targets can be very different. 

\subsubsection{Learning a Dynamic Stopping Condition}
% Modeling as a classification problem and creating the training set
The second stopping condition we propose, denoted as 
\learnDynamic{}, models 
the dilemma of when to stop as a Binary classification problem and solves it via supervised learning~\cite{mitchell1997machineLearning}. 
Every instance being classified is a pair $(T,i)$, where $T$ is a TONIC process and $i$ is an iteration. 
The two possible classes for an instance $(T,i)$ are ``stop'' and ``continue''. 
An iteration $i$ in a TONIC process $T\in\mathcal{T}$ is labeled as ``stop'' if the net gain of all following iterations is less than or equal to $NG(T,i)$ (\(\forall_{j>i} NG(T,j)\leq NG(T,i)\)) and is labeled as ``continue'' otherwise (\(\exists_{j>i} NG(T,j)>NG(T,i)\)).

To create a training set, we label all the iterations of all the TONIC processes in $\mathcal{T}$. 
The resulting training set has therefore $\sum_{T\in\mathcal{T}} |T|$ instances, where $|T|$ is the number of iterations in $T$. 

% How the stopping rule works
Given this training set, we use Machine Learning algorithms to train a Binary classifier that accepts a TONIC process and an iteration $i$ and outputs ``stop'' or ``continue''. 
The \learnDynamic{} stopping condition decides to stop according to this output. 

% Extracing features
In order to apply standard Machine Learning algorithms, we define a set of features to extract from each instance  \((T,i)\). 
We experimented with a wide range of features and have found the following to be most effective. 
\begin{itemize}
\item {\bf Leads acquisition rate.} This feature is the  number of leads found per iteration in the past $X$ iterations, where $X$ is a parameter. Formally, for an instance $(T,i)$, we define the leads acquisition rate feature for parameter $X$ as $\frac{L(T,i)-L(T,i')}{i-i'}$ where $i'=\max(0,i-X)$. In our experiments we used two leads acquisition rate features, one with $X=5$ and the other with $X=10$.
\item {\bf Leads to non-leads ratio.} The ratio between the number leads and non-leads found so far -- $L(T,i)/NL(T,i)$.
\item {\bf Leads to potential-leads ratio.} The ratio between the number leads and potential leads found so far -- $L(T,i)/PL(T,i)$.
\end{itemize}

%two lead rate ($X$) features, one with $X=5$ and the other with $X=10$. 
%it requires that the given TONIC processes in $\mathlca{T}$ are significnantl

% Imbalanced
When the reward for getting a lead ($R_{\Acquire{}}$) is not significantly larger than the query costs, it is worthwhile to stop the TONIC process early. In such cases, most instances in the trainings set will be labeled as ``stop'' creating an \emph{imbalanced} training set. Similarly, when $R_{\Acquire{}}$ is very high compared to the query costs and number of profiles in the target's neighborhood, most instances will be labeled as ``continue'', again creating an imbalanced training set. Most supervised learning algorithms are designed for balanced datasets and may perform poorly when given imbalanced training set. Indeed, we observed this in a preliminary set of experiments (not reported). 

We addressed this shortcoming using \emph{under-sampling}, a known technique for addressing imbalanced training sets, where instances from the majority class are removed until both classes have the same number of instances. 
Instances from the majority class are usually  selected uniformly at random. 
In this study, we chose the instances of the majority class that are closer to the decision boundary in order to improve the prediction accuracy. 
That is, if a TONIC process has 500 iteration, the first 100 labeled ``continue'' and the last 400 labeled ``stop'', then we only chose for our training set the first 200 iterations. 
This TONIC-specific under-sampling method proved to be effective in our experiments. 


% A note on gain, cost, and reward
Both stopping conditions (\learnFixed{} and \learnDynamic{}) are designed specifically for the Max Gain TONIC objective (Definition~\ref{def:gain}). 
As such, they are directly affected by the reward and query costs values ($R_{\Acquire{}}$, $C_{\Acquire{}}$, and $C_{\IsLead{}}$) and adapt to it.  
%That is, for different reward and costs values one will need to recompute the fixed stopping iteration ($I_{best}$) for \learnFixed{} and re-run the learning algorithm for \learnDynamic{}. 
When the rewards or costs change, both models (\learnFixed{} and \learnDynamic{}) need to be recomputed: \learnFixed{} updates $I_{best}$ and \learnDynamic{} re-trains its model. 
However, to compute $I_{best}$ (for \learnFixed{}) or re-train the model (for \learnDynamic{}) there is no need to execute new TONIC processes, only to analyze the existing data. In details, to compute $I_{best}$ for \learnFixed{} according to the new reward and costs, one needs to go over the iterations of the TONIC processes in $\mathcal{T}$, 
recompute the net gain in each iteration according to the new reward and costs, 
and then compute $I_{best}$ according to Equation~\ref{eq:ibest}. 
To re-train the model for \learnDynamic{}, one needs to go over the iterations of the TONIC processes in $\mathcal{T}$, 
re-label them as ``continue'' or ``stop'' according to the new net gain, and re-run the machine learning algorithm to train a new classifier. 
%the best iteration to stop for maximizing the net gain given the new reward, and costs values. 



\subsubsection{Experimental Results}
% Some results
We evaluated the proposed stopping conditions experimentally on the same dataset described earlier, using half of the dataset as the training set 
and the other half as the test set. 
We experimented with $R_{\Acquire{}}$ values 3, 5, 10, 25, 50, and 100; and set $C_{\Acquire{}}=1$ and $C_{\IsLead{}}=0$ as in Section~\ref{sec:netGainResults}. 
After experimenting with several Machine Learning algorithms, we chose the 
XGBoost algorithm~\cite{chen2016xgboost} as it produced the best overall results. 
We tuned its hyperparameters using grid search. %, which provided the best overall results. 

We compared \learnFixed{} and \learnDynamic{} to the following stopping conditions: 
\begin{itemize}
\item {\bf Fixed $X$.} A stopping condition according to which 
the TONIC process stops after exactly $X$ iterations, where $X$ is a parameter. 
\item {\bf Oracle.} The offline-optimal stopping condition, which computes a-posteriori iteration in which the net gain is maximal and halts there. This stopping condition represents an upper bound of the net gain that can be achieved by any stopping condition. 
\end{itemize}

\begin{table}
\centering
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline
$R_{\Acquire{}}$   &    3 & 5 & 10 & 25 & 50 & 100 \\
\hline
\learnDynamic{} & \textbf{0.30}         & \textbf{0.14}         & \textbf{0.17}          & \textbf{0.14}          & 0.15                   & 0.15                    \\
\learnFixed{}   & 1.38                  & 0.54                  & 0.25                   & 0.15                   & 0.14                   & \textbf{0.09}           \\
Fixed 25     & 0.83                  & 0.49                  & 0.43                   & 0.43                   & 0.44                   & 0.46                    \\
Fixed 50     & 1.40                  & 0.46                  & 0.22                   & 0.18                   & 0.19                   & 0.20                    \\
Fixed 100    & 2.86                  & 0.97                  & 0.32                   & \textbf{0.14}          & \textbf{0.11}          & 0.11                    \\
Fixed 250    & 8.87                  & 2.71                  & 0.91                   & 0.29                   & 0.14                   & \textbf{0.09}  \\
\hline
\end{tabular}
\caption{Normalized loss for the different stopping condition.}
\label{tab:stopping}
\end{table}


We present the net gain obtained by each stopping condition with respect to the net gain of \emph{Oracle} since no algorithm can obtain a higher net gain. Specifically, we used the \emph{normalized loss} measure, defined as follows. Overloading the previous notation, let $A$ be a stopping condition, $T$ be a TONIC process, and $NG(A,T)$ be the net gain obtained when using $A$ to stop $T$. 
The \emph{normalized loss} of using $A$ in $T$, denoted $NL(A,T)$, is the 
difference between the net gain obtained by $A$ and the net gain obtained by \emph{Oracle} divided by the net gain of \textit{Oracle}. Formally, 
$NL(A,T)=\big(NG(\textit{Oracle},T)-NG(A,T)\big)/NG(\textit{Oracle},T)$. 
Lower values of normalized loss are better, and a \emph{normalized loss} of zero corresponds to obtaining optimal net gain. 
Table~\ref{tab:stopping} shows the average \emph{normalized loss} for \learnDynamic, \learnFixed, Fixed 20, Fixed 50, Fixed 100 and Fixed 250. 
Different columns correspond to different values of $R_{\Acquire{}}$. 
For every value of $R_{\Acquire{}}$, we highlighted the best result over the evaluated stopping conditions. 
As can be seen, using \learnDynamic{} yields the best results for most reward values, always providing a \emph{normalized loss} smaller than 0.3. 
%The results for \learnFixed{} were similar to those of Fixed 50 because for the evaluated reward values 3, 5, 10, 25, 50, and 100, the corresponding stopping iterations chosen by \learnFixed{} were 49	57	64	85	224	238

\begin{table}
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
$R_{\Acquire{}}$    & 3    & 5   & 10   & 25   & 50   & 100  \\ \hline
Precision & 0.91 & 0.9 & 0.86 & 0.68 & 0.63 & 0.67 \\ 
Recall    & 0.91 & 0.9 & 0.86 & 0.67 & 0.61 & 0.65 \\ 
F1        & 0.91 & 0.9 & 0.86 & 0.66 & 0.59 & 0.64 \\ \hline
\end{tabular}
\caption{Precision, recall, and F1 score for the classifier learned for the \learnDynamic{} stopping rule.}
\label{tab:stopping-classifier}
\end{table}

The advantage of \learnDynamic{} over \learnFixed{} diminishes for larger values of $R_{\Acquire{}}$, and for $R_{\Acquire{}} \geq 50$ the results of \learnFixed{} are even better than \learnDynamic{}. 
To understand this trend, Table~\ref{tab:stopping-classifier} shows the precision, recall, and F1 score of the classifier learned for the \learnDynamic{} stopping rule for different values of $R_{\Acquire{}}$. 
Precision, recall, and F1 score are standard metrics for evaluating classifiers, and range from 0 to 1, where 1 is a perfect classification. 
We observe that the quality of our classifier degrades for higher values $R_{\Acquire{}}$. 
This observation is consistent with the weaker performance of \learnDynamic{} for high values of $R_{\Acquire{}}$. 
This suggests that further improvements to the \learnDynamic{} stopping condition may be obtained by improving the underlying learning algorithm, e.g., by obtaining more data, introducing new features, and using different learning schemes, and more advanced parameter tuning techniques. Nonetheless, the performance of \learnDynamic{} is quite robust across all our experiments, often providing the best results or is at most withing 0.06 \emph{normalized loss}  of the best result. 



\section{TONIC as an Information Retrieval Task}
\label{sec:ir}
%Considering TONIC as an Information Retrieval task allows using known IR metrics for comparing the overall performance of TONIC heuristics. In particular, we consider two such metrics: the area under the ROC curve (AUC) and the discounted cumulative gain (DCG)~\cite{dcg}. 


TONIC can be viewed as an Information Retrieval (IR) task, where the task is to retrieve as many leads as possible. % retrieves an ordered list of profiles given a {\em query} in form of the target and the set of initial leads. IR responses are evaluated based on the positions of relevant and irrelevant results within the ordered list, that is leads and non-leads respectively in case of TONIC.  
\newstuff{
This allows evaluating TONIC solvers 
with standard IR metrics. For example, after performing $x$ \islead{} queries, 
the {\em Precision} is the fraction of leads found so far 
out of the \(x\) queried profiles. {\em Recall} (also known as the true positive rate -- TPR) 
is the fraction of leads found so far out of the total number of leads. 
Precision and Recall are often combined by the F1 measure, computed as 
$F1=2\cdot \frac{Precision\cdot Recall}{Precision+Recall}$.}

\begin{figure*}[t]
\centering
\begin{subfloat}[\label{fig:ir-measures}]%
\centering
\includegraphics[width=0.4\linewidth]{tonic-ir-measures.pdf}
\end{subfloat}
\qquad
\begin{subfloat}[\label{fig:ir-measures-zoomed}]
\centering
\includegraphics[width=0.4\linewidth]{tonic-ir-measures-zoomed.pdf}%\vspace{-0.3cm}
\end{subfloat}%
\caption{F1-measure, recall, and precision results for EBysP on the Google+ dataset. The right-hand side zooms in on the first 100 iterations.}
\end{figure*}

\newstuff{
Figure~\ref{fig:ir-measures} plots average Precision, Recall, and the F1-measure 
as a function of the number of queries performed so far ($x$) for the Google+ 
dataset described above, using our best solver (EBysP). 
The Recall results corresponds to the results reported in the previous sections, showing a diminishing return effect: the recall increases quickly at the beginning of the search and then slows down until convergences.  
Precision is initially very high, but drops quickly as the search progresses and fewer leads are found. This is reasonable as there are significantly more non-leads than leads. 
Figure~\ref{fig:ir-measures-zoomed} zooms-in on the results of the first 100 iterations. 
Observe the precision results: until the 10th iteration the precision decreases, but then, it remains stable until the 30th iteration. 
In this period on average, two out of three queried profiles are leads, showing the strength of our search strategy (EBysP). Then, as the pool of available leads becomes sparser, fewer leads are being found, resulting afterwards in a quick drop in the precision and
a more modest increase of the recall. Indeed, the 30th iteration is exactly the turning point where the F1 measure starts to decrease. In the limit (i.e,. after many iterations), most leads are found (so Recall is close to 1.0), the precision is almost zero since most profiles are not leads, and thus the F1 measure also drops down to zero.} 


\newstuff{
The well-known {\em receiver operating characteristic} (ROC) curve~\cite{croft2010search}, which measures the TPR as a function of the false positive rate (FPR), can also be created, by varying the values of \(x\). 
The area under the ROC curve (AUC) is a popular IR measure, where a larger AUC indicates a better solver. 
}

Figure~\ref{fig:auc} shows the average AUC of the algorithms: FIFO, EFIFO, FM , EFM, BysP and EBysP. The RTF heuristics (run under RTF)  are colored in blue and the ETF heuristics (run under ETF(1)) are colored in purple. AUC results show trends similar to Figure~\ref{fig:all-nl} and Figure~\ref{fig:checkedVsFound}, as could be expected. However it is interesting to see that despite the fact that EFIFO eventually finds more leads then BysP, it's average AUC is still lower, since it preforms worse during most of the search.



%In TONIC, most potential leads are not leads, and thus in general the number of non-leads found is very similar to the total number of \islead{} preformed. Thus, the ROC curve for TONIC greatly resembles the cost-benefit curve shown in Figure~\ref{fig:checkedVsFound} and Figure~\ref{fig:all-nl} (this was also observed empirically).






\begin{figure*}
\centering
\begin{subfloat}[\label{fig:auc}]
  \centering
\includegraphics[width=.4\textwidth,  trim={2.0cm 2.5cm 2.5cm 5.5cm},clip]{AUC_ALL.pdf}
\end{subfloat}%
\quad
\begin{subfloat}[\label{fig:dcg}]
  \centering
\includegraphics[width=.4\textwidth,  trim={2.0cm 2.5cm 2.5cm 5.5cm},clip]{DCG_AllAlgo.pdf}
\end{subfloat}
\caption{Evaluating TONIC heuristics using IR measures. The plots show the average AUC (\ref{fig:auc}) and DCG (\ref{fig:dcg}) obtained on our benchmark.}
\label{fig:auc-and-dcg}
\end{figure*}




 

Discounted cumulative gain (DCG)~\cite{dcg} is yet another metric for evaluating the quality of an ordered  sequence of results.
DCG accumulates the gain of finding the relevant results, i.e. the leads, such that the closer the lead is to the beginning of the sequence the higher its gain. 
Every \islead{} query increases the network footprint of the intelligence collection process and with the footprint grows the chance the process will be discovered or the OSN service will block future acquisitions. 
Therefore, every \islead{} query reduces the gain from further lead acquisitions and it is important to spot the leads as early in the search process as possible.
Let \(p_1,p_2,\ldots\) be the profiles sorted by the order in which \islead{} query was applied to them. 
DCG is computed by $DCG=IsLead(p_1)+\sum_{i=2}^n \frac{IsLead(p_i)}{log_2 i}$, where \islead{\(p_i\)}\(=1\) if the $i^{th}$ profile is a lead and \islead{\(p_i\)}\(=0\) otherwise. 

%[R 3.2]
Figure~\ref{fig:dcg} shows the average DCG of the algorithms mentioned before. First, observe that in terms of DCG, using EFIFO yields worse results than using FIFO. This is in contrast to the AUC results (Figure~\ref{fig:auc}), where EFIFO yielded higher AUC compared to FIFO. 
This advantage of FIFO in terms of DCG is due to the fact that leads more densly populate the first tier. Therefore FIFO will find more leads in earlier iterations -- yielding higher DCG -- since it only searches the first tier and thus its search is less scattered. Thus, in general, for a given TONIC heuristic it may be better to use RTF than ETF if one wants to maximize DCG. 
%[R 3.2]
However, when the more intelligent TONIC heuristics are used, we observe again the benefit of using ETF. This is somewhat surprising, as one could expect that the first leads being found are from the first tier and thus RTF may perform better than ETF. These results suggest that the best performing TONIC heuristics -- BysP and FM -- are intelligent enough to consider expanding non-leads only when it is helpful, thus resulting in finding more leads than in RTF even in early iteration of the search. 
In summary, we observe that EBysP and EFM are robust across both AUC and DCG, showing the best performance in both measures. 

%Note that EBysP is in general robust across both AUC and DCG and that both FM and BysP had shown improvement both in AUC and in DCG when implemented in ETF (EFM, EbysP).



% \subsection{Effects of Network Topology Characteristics}
% Next we investigate the network topology characteristics that influence the performance of the proposed TONIC heuristics.
% For that purpose, we will examine the performance of both RTF and ETF heuristics on the DBLP network \cite{yang2012defining} as an additional OSN to the Google+ network previously discussed.

% \begin{figure}
% \centering
% \includegraphics[width=\linewidth]{dblp_target1.JPG}%\vspace{-0.3cm}
% \caption{\label{fig:dblpTarget}Sample network of the relevant neighborhood of a target in DBLP network
% number}%\vspace{-0.3cm}
% \end{figure}


% We have taken 100 different targets with more than 30 friends and set 3 random friends as initial leads (same as we did for the Google+ network). An example of tier(1) of one of the targets in DBLP is presented in Figure~\ref{fig:dblpTarget}.
% The search was preformed on four heuristics; The RTF and ETF baselines (FIFO and EFIFO) and the dominating heuristics (BysP and EBysP).
% We have also limited the run to 10K iteration, thus also simulating the limitation in the number of queries that exist in part of the OSNs.

% \begin{figure}
% \centering
% \includegraphics[width=\linewidth]{dblp_10k.pdf}%\vspace{-0.3cm}
% \caption{\label{fig:dblp}\% of leads found vs. iteration in DBLP network
% number}%\vspace{-0.3cm}
% \end{figure}


% The results are presented in Figure~\ref{fig:dblp}. An interesting observation that can be made from the figure is that the search is divided into three stages. (1) The beginning of the search in which the ETF heuristics preform similar to the RTF heuristic. (2) The second stage is the stage starting from the point in which the ETF and RTF heuristics cease to preform similarly and the RTF heuristics outperform the ETF heuristics. (3) The last stage is the stage in which the RTF heuristics have already found all of their reachable leads and the ETF heuristic continue to find new leads.

% At the first stage, the CKG is relatively small and the information obtained on the OSN topology is still insufficient to cause different choices of $best$ profiles between the RTF and ETF heuristics.


% In the third stage, we can see that the ETF heuristics continue to find leads after the RTF heuristics already found all of their reachable leads. Meaning that the use of ETF heuristics finds more leads than RTF, as can be expected from the Google+ results.


% The second stage is the most interesting stage. In this stage, EBysP does not outperform BysP as expected from the Google+ results previously shown.
% % Instead it appears as if the EBysP has chosen profiles that caused the search to scatter.

% To understand the differences between the networks, we have experimented with various topology attributes including the {\em clustering coefficient} (CC) of each target, the size of the {\em relem''vant neighborhood} of the target, the number of connected components in the graph excluding the target and the density of this neighborhood. The topology characteristic that has the most distinct impact on the proposed heuristics was the number of connected components in the graph (excluding the target).

% %The decrease resulted in new leads.
% We have checked the number of connected components in ETF(0) (RTF) and in ETF(1). As expected we have seen a decrease in the number of connected components between ETF(0) and ETF(1) both in Google+ and in DBLP. This decrease is caused since the additional tier in EFT(1) contains profiles that connect several connected components in ETF(0). Meaning, ETF(1) contains non leads that connect several connected components. 
% We noticed that the decrese was different between the Google+ and the DBLP networks. In Google+ the decreses was larger than in DBLP (40\% decrease from 15.94 to 9.3 connected components in Google+ as oppose to 30\% decrease from 6.29 to 4.38 connected components in DBLP).

% The non leads in ETF(1) can connect not only existing connected components, that were reachable in ETF(0) (from different initial leads), but also new connected components that were not reachable in ETF(0) and might contain leads. In fact, since ETF find more leads than RTF, as can be seen in the third stage, we know that new connected components containing leads were added to the graph in ETF(1) and are now reachable.

% %ETF has an advantage because it can search for both the old and the new leads
% Due to this decrease, ETF in general and EbysP in particular have the advantage of searching for leads in a larger variety of connected components. Meaning, that instead of focusing the search in the connected component that existed in ETF(0), the ETF heuristics can search for leads in the additional connected component if a lead is more likely to be found there. This advantage was the reason that EbysP preformed better than BysP even in the early stages of the search in the Google+ network. 

% %why does this adventage does not work in DBLP
% However, in DBLP, it is seems that EbysP does not have this advantage. In order to understand why, we have checked the number of reachable leads that were added into the graph in ETF(1). In Google+, 16.53\% new leads in average were added as oppose to 11.52\% new leads in DBLP. We have also checked the likelihood to find the new added lead by calculating the number of added reachable leads divided by all reachable profiles. The likelihood to find an added lead in Google+ is 0.01 as oppose to 0.007 in DBLP.
% Meaning that less leads were added in DBLP and that the likelihood of finding them is smaller than in Google+.
% This relatively small improvement in the number of reachable leads in DBLP, resulting from the relatively small decrease in the number of connected components, reduces the advantage that the ETF heuristics and EbysP in particular have, since the number of connected components to consider in ETF(1) is relatively similar to the number of connected components in ETF(0).
% In addition, the difference in the percentage of reachable leads between ETF(0) and ETF(1) is much lower in DBLP than in Google+. In Google+ the difference in the percentage of leads found is ~17.5\%(from 70\% to 88\% reachable leads) as oppose to only ~9\% (from 75\% to 84\% reachable leads).
% From this we conclude that in networks in which RTF finds a relatively large percentage of leads and the improvement in the percentage of reachable leads between ETF(0)  and ETF(1) is relatively low, such as DBLP, RTF heuristics will preform better during the run. By contrast, in networks such as Google+, in which RTF finds relatively lower percentage of leads and the improvement in the percentage of reachable leads between ETF(0) and ETF(1) is relatively high, ETF heuristics will preform better during the run.
% However, in both cases it is better to use ETF heuristics if we wish to find a larger number of leads.

% \note{Liron}{Write hybrid?}
% %%For that reasson we suggest, to use the hybrid heuristic presented in the paper in networks of the first kind (in which RTF preforms better). By using the hybrid heuristic, we can get the best prefermance by using BysP in the begining of the run in addition to finding more leads due to use of an ETF heuristic at the end of the run, as presented in Figure~.
% %Figure desc: 





\section{Experiments on Different Online Social Networks}
\label{sec:otherNetworks}
To provide further support for our conclusions, we also performed a series of experiments on other OSNs. Namely, we experimented on LiveJournal~\cite{backstrom2006groupFormation,leskovec2009community}, which is an online community that allows member to maintain journals, blogs, and define friendship between profiles, and Pokec~\cite{takac2012data}, which is the most popular OSN is Sloveniya. Both networks were made available as part of the Standform Network Analysis Project (SNAP) at \url{snap.stanford.edu}. Both OSNs are active and large (although not as large as Google+), where LiveJournal has more than 10 millions profiles and Pokec has more than 1.5 millions. 




%We chose to compare only these algorithms as they represent two baseline approaches and the best performing heuristic found for Google+. 

\begin{figure*}
\centering
\begin{subfloat}[\label{fig:live-journal}]
  \centering
\includegraphics[width=.45\textwidth]{LiveJournal_cropped}
\end{subfloat}%
\begin{subfloat}[\label{fig:pokec}]
  \centering
\includegraphics[width=.45\textwidth]{Pokec_cropped}
\end{subfloat}
\caption{Evaluating TONIC heuristics on different OSNs. Fig.~\ref{fig:live-journal} shows results for the Live Journal OSN, and Fig.~\ref{fig:pokec} shows results for the Pokec OSN.}
\label{fig:extra-osns}
\end{figure*}

For each network we randomly chose 50 profiles as targets, considering only profiles with more than 30 friends and 4,000 edges in its 2-tier neighborhood. For each target we present results for both TONIC frameworks (RTF and ETF)
and compare the baseline approaches random and FIFO with the best performing heuristic BysP. 

Figure~\ref{fig:extra-osns} shows the results for these two OSNs, in the same format as in Figure~\ref{fig:efm-and-ebysp}: the $x$-axis is the number of iterations and the $y$-axis is the percentage of leads found. The main trends observed for Google+ are seen here too:
\begin{itemize}
\item {\bf RTF finds fewer profiles.} The RTF algorithms exhausts the set of leads they can find and converges to finding fewer leads than the ETF algorithm.
\item {\bf BysP and EBysP dominate the baseline methods.} For both OSNs, BysP is better than random and FIFO, and EBysP is better than ETF random and EFIFO. 
\item {\bf EBysP dominates BysP.} Even before RTF exhausts all the leads it can reach, we observe that EBysP is able to find more leads faster than BysP. To demonstrate this, the average percentage of leads found after after 200 iterations was 45\% and 64\% for BysP and EBysP, respectively, in the Pokec OSN, and 39\% and 47\% for BysP and EBysP, respectively, in the Live Journal OSN. 
\end{itemize}




\begin{table}
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Framework & Google+ & Pokec & Live Journal \\ \hline
RTF & 0.82 & 0.66 & 0.51 \\ 
ETF & 1.00 & 1.00 & 0.78 \\
\hline
\end{tabular}
\caption{\% of leads reachable with RTF and ETF in different OSNs.}
\label{tab:tiers-other-osns}
\end{table}

It is also interesting to compare the behavior of the different frameworks -- RTF and ETF -- across the three OSNs we experimented with (Google+, Pokec, and Live Journal). Table~\ref{tab:tiers-other-osns} shows the average percentage of reachable leads found using RTF and ETF for our OSNs. We observe that Live Journal OSN is the most difficult in terms of TONIC, in the sense that RTF and even ETF ends up finding fewer percentage of leads compared Google+ and Pokec. Indeed, the observant reader will see that the ETF algorithms in Figure~\ref{fig:live-journal} do not converge to finding all leads. This suggests future research in which the limitation of ETF to the first tier will be reevaluated based on the OSN characteristics. 

%This corresponds to comparing the size of tier zero and one in Table~\ref{tab:tiers}. We can see that Live Journal is the the most difficult OSN, in the sense that 
%The observant reader will notice that  for Live Journal, the ETF algorithms do not converge to finding all leads. This is because in Live Journal, running ETF(1) is not sufficient to find all leads from the initial leads, and exploring further tiers may be useful. Indeed, we also observe that the RTF algorithms for Live Journal also converge to finding a lower percentage of the target's lead, suggesting that the Live Journal OSN is sparser. To support this, Table~\ref{tab:tiers-other-osns} shows the average percentage of leads reachable using RTF and BTF for Google+, Pokec, and Live Journal. We can observe that Google+ has higher reachability 





%The proposed heuristics and frameworks are experimentally evaluated on three OSNs: Google+, Pokec~\cite{takac2012data}, and LiveJournal~\cite{backstrom2006groupFormation,leskovec2009community} (an online commmunity that allows member to maintain journals, blogs, and define friendship between profiles). Results show that each framework performs best in different circumstances. We found that in general \(RTF\) and \(ETF(1)\) are worthwhile while  ETF($n$) for $n>1$ does not contribute significantly to the number of leads found. We further analyze the trade-off between the cost of searching and the benefit of finding more leads. The results of this analysis show that \(ETF(1)\), with the proposed heuristics, is better than \(RTF\) for short searches and when the reward for finding a lead is high; while \(RTF\), with a proper heuristic, is better suited for a long term search process with moderate and low rewards. 
%\note{Roni}{TODO: Double check this after reading the results}


%Pokec is the most popular on-line social network in Slovakia. The popularity of network has not changed even after the coming of Facebook. Pokec has been provided for more than 10 years and connects more than 1.6 million people. Datasets contains anonymized data of the whole network. Profile data contains gender, age, hobbies, interest, education etc. Profile data are in Slovak language. Friendships in Pokec are oriented

%LiveJournal is a free on-line community with almost 10 million members; a significant fraction of these members are highly active. (For example, roughly 300,000 update their content in any given 24-hour period.) LiveJournal allows members to maintain journals, individual and group blogs, and it allows people to declare which other members are their friends they belong.

\section{Conclusion and Future Work}
%\subsection{RTF Conclusion and future work}
\label{sec:conclusions}

%\note{Roni}{Due to incomplete results, conclusions are not done yet}

This paper addressed the Target Oriented Network Intelligence Collection (TONIC) problem, in which the task is to find profiles in an OSN that contain information about a given target profile. Beyond academic interest, TONIC is an integral part of commercial and governmental applications.
TONIC was formalized as a search problem in an unknown graph and two frameworks for solving it were proposed, RTF and ETF. RTF focuses the search by only acquiring leads. ETF generalizes RTF by allowing non leads to be acquired, as long as there exists a known path from them to a lead that is at most $n$ hops long, where $n$ is a parameter. As $n$ grows, more leads are reachable but the search may become too costly and unfocused. Empirical results suggests that $n=1$ serves as a valid middle ground.

For both RTF and ETF(1), we present several heuristics for guiding the search. These heuristics are evaluated experimentally on a real OSN. 
Evaluation results show that:

\begin{enumerate}
\item The Bayesian Promising (BysP and EBysP) heuristics and the heuristics based on the Friends Measure, significantly outperform other heuristics.
\item Using ETF results in substantially more leads than RTF when using the anytime objective. 
\item Depending on the costs of the queries and on the reward of finding leads, either BysP (RTF) or EBysP (ETF(1)) is the preferable when using the MaxGain objective.
\item The number of reachable leads increases with both the number of initial leads and tier. 
\end{enumerate}

%We have also examined two social networks: Google+ and dblp.
%\note{Liron}{after the dblp is done, i need to talk about it here}\note{Roni}{Yes, need to be discussed.}

%Based on the evidence provided in this paper for both RTF and ETF(1) we suggest obtaining 2-3 initial leads with different kinds of acquaintances with the target. For example, one family member, one co-worker, and one blog fan.  \note{Roni}{This is just a statement without any backing up in our experiments. We have not checked where the initial leads come from or how different they are.}


There are many exciting directions for future work.
An obvious future work is to evaluate the proposed algorithms on a larger dataset with more OSNs, and studying how properties of a given OSN affect their performance. 
Another future research direction is to create heuristics that consider a profile's textual data (hobbies, demographic information, etc.) and not just the topology of the CKG as the current heuristics do.
One other direction is to utilize the power of machine learning to predict which potential leads will turn to be leads de facto.
ML models can be trained using both data from past executions on various targets and data on profiles acquired during investigation of current target. 
% [R 2.2]
For example, one can learn a more sophisticated hybrid approach that combines information from several TONIC heuristics. 

% Costs, rewards, and uncertainty
Another direction is to consider leads with different rewards, where finding a lead that provides more information about \target\ is preferred. 
% [R 3.2]
In addition, one may consider higher cost for querying some profiles, e.g., to avoid querying profiles that are more sensitive and thus querying them is more risky. This raises a complex task of how to quantify information and how to quantify risk. Furthermore, information found from one lead can affect the value of information from other leads, as some information may overlap. In addition, we assumed that \islead{} and \acquire{} are always applicable. Future work can consider network errors that may cause queries to fail with some probability, introducing uncertainty.




\section{Ethical Aspects in TONIC}
\label{sec:ethics}
%[R 1.24]

As mentioned earlier in this paper, a particular application of our investigation of effective TONIC solvers it to uncover the LOF of a target profile 
by exploring the LOFs of other profiles. Consequently, an effective TONIC solver may uncover a target's LOF even if the target has blocked direct access to its LOF through its profile. Although this information (other profiles LOF) is publicly available, the ability to automatically and effectively access this information raises some ethical concerns. 
First, one may argue that if the target has blocked access to its LOF, then by searching for its LOF we are accessing to the target's private information, even if the search itself is not done on the target but on other profiles. 
Second, one can imagine settings in which criminals use the proposed algorithm to collect information about citizens for various criminal activities. 

Indeed both concerns are valid and need to be discussed. It is general knowledge that people and organization use OSNs and other publicly available sources to gather information about specific entities (e.g., people, organizations, and other social groups). This is often done manually, for example, before hiring a person, 
or when police forces monitoring affiliates of known criminals in social networks. 
In fact, there are existing tools such as Palantir (\url{www.palantir.com}) that automatically collects publicly available information on a given profile. In that sense, our work is a more effective version of an existing approach (which usually applies a FIFO strategy, which we show to be inferior). 


Moreover, we emphasize that an effective TONIC solver can be used for many good purposes. It can serve as an helpful tool for law enforcement agencies. For example, imagine a search for information about a pedophile in an OSN. In fact, the social network paradigm has been successfully used to investigate organized crime in the Netherlands \cite{klerks2001network}. Alternatively, an effective TONIC solver can be used as a tool for preserving privacy, by allowing a person to find how much publicly available information exists about him/her in a given OSN and change his/her privacy setting accordingly. 
Indeed, like many other advances in science the algorithms we propose can be used for good and bad purposes, depending on its user. 



% use section* for acknowledgment
%\section*{Acknowledgment}



%The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{main}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


% biography section
% 

% if you will not have a photo at all:

\begin{IEEEbiographynophoto}{Rami Puzis}
Rami is a Senior Lecturer in the Department of Software and Information Systems Engineering at Ben Gurion University of the Negev.
He holds a Ph.D. from Ben Gurion University in Information Systems Engineering and a M.Sc. and a B.Sc. from the Department of Software Engineering in Ben Gurion University.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Liron Kachko}
Liron holds an M.Sc. and a B.Sc. from the Department of Software and Information Systems Engineering at Ben Gurion University of the Negev.
\end{IEEEbiographynophoto}


\begin{IEEEbiographynophoto}{Barak Hagbi}
Barak holds an M.Sc. and a B.Sc. from the department of Computer Science in Bar Ilan University, and he is currently pursuing a Ph.D. in the Department of Software and Information Systems Engineering at Ben Gurion University of the Negev.
\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiographynophoto}{Roni Stern}
Roni is a Senior Lecturer in the Department of Software and Information Systems Engineering at Ben Gurion University of the Negev.
He holds a Ph.D. from Ben Gurion University in Information Systems Engineering and a M.Sc. and a B.Sc. from the Department of Computer Science in Bar Ilan University.
\end{IEEEbiographynophoto}


\begin{IEEEbiographynophoto}{Ariel Felner}
Ariel is a Full Professor in the Department of Software and Information Systems Engineering at Ben Gurion University of the Negev.
He holds a Ph.D. from Bar Ilan University in Computer Science and a M.Sc. and a B.Sc. from the Department of Computer Science in the Hebrew University.
\end{IEEEbiographynophoto}


% that's all folks
\end{document}


