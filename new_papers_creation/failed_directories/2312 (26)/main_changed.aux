\relax 
\bibstyle{aaai24}
\citation{long2022pc2}
\citation{he2023grad}
\citation{long2022pc2}
\citation{he2023grad}
\citation{zhang2019review}
\citation{chen2023unsupervised}
\citation{dai2020neural}
\citation{yu2018pu,li2019pu,qian2021pu,feng2022neural}
\citation{li2021point}
\citation{luo2021pu,qian2021deep}
\citation{he2023grad,zhao2023self}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:methods_cpmparison}{{1}{1}{Comparison with PC$^2$-PU \citep  {long2022pc2} and Grad-PU \citep  {he2023grad}. The input point cloud has 2048 points, and ground truth has 8192 points for the palm and 32768 points for the chair. Previous methods upsample the point cloud at the local level, which results in outliers, holes and non-uniform when combining local patches. We represent the entire point cloud as a continuous implicit field and generate globally consistent results.}{}{}}
\citation{alexa2003computing}
\citation{huang2009consolidation}
\citation{huang2013edge}
\citation{lipman2007parameterization}
\citation{wu2015deep}
\citation{yu2018pu,qian2020pugeo,luo2021pu,liu2022spu,feng2022neural}
\citation{yu2018pu}
\citation{li2019pu}
\citation{goodfellow2014generative}
\citation{qian2021pu}
\citation{long2022pc2}
\citation{ye2021meta}
\citation{dell2022arbitrary}
\citation{he2023grad}
\citation{zhao2023self}
\citation{zhang2023fast,ma2023towards}
\citation{mescheder2019occupancy,chen2019learning}
\citation{park2019deepsdf,michalkiewicz2019implicit}
\citation{mildenhall2021nerf}
\citation{ma2022reconstructing,zhou2023levelset,jin2023multi,chen2023gridpull}
\citation{ma2022reconstructing}
\citation{zhao2022self,zhao2023self}
\newlabel{fig:overview}{{2}{2}{Overview of the proposed method. The key idea of our method is to learn an unsigned distance field to represent the sparse point cloud at global level with the guidance from a pre-trained LDI learned from dense local patches.}{}{}}
\citation{long2022pc2,he2023grad}
\citation{ma2021neural}
\newlabel{fig:local_indicator}{{3}{3}{Structure of the local distance indicator. The attention-based distance indicator predicts the distance between the query point and the patch surface.}{}{}}
\newlabel{eq:definition of distance indicator}{{1}{3}{}{}{}}
\newlabel{fig:weight}{{4}{3}{The visualization of learned weights.}{}{}}
\newlabel{eq:final feature for query point}{{2}{3}{}{}{}}
\newlabel{eq:local_distance_indicator}{{3}{3}{}{}{}}
\citation{ma2022reconstructing}
\citation{eldar1997farthest}
\citation{he2023grad}
\citation{zhou2022learning}
\citation{he2023grad}
\citation{huang2017densely}
\citation{park2019deepsdf}
\citation{li2019pu}
\citation{qian2021pu}
\citation{he2023grad}
\citation{he2023grad}
\newlabel{eq:pulling}{{4}{4}{}{}{}}
\newlabel{eq:local_loss}{{5}{4}{}{}{}}
\newlabel{eq:np_loss}{{6}{4}{}{}{}}
\newlabel{eq:np_surf}{{7}{4}{}{}{}}
\newlabel{eq:sp_loss}{{8}{4}{}{}{}}
\newlabel{eq:global_loss}{{9}{4}{}{}{}}
\citation{yu2018pu}
\citation{yifan2019patch}
\citation{li2019pu}
\citation{li2021point}
\citation{qian2021pu}
\citation{long2022pc2}
\citation{qiu2022pu}
\citation{qian2021deep}
\citation{feng2022neural}
\citation{dell2022arbitrary}
\citation{he2023grad}
\citation{yu2018pu}
\citation{yifan2019patch}
\citation{li2019pu}
\citation{li2021point}
\citation{qian2021pu}
\citation{feng2022neural}
\citation{dell2022arbitrary}
\citation{long2022pc2}
\citation{qian2021deep}
\citation{he2023grad}
\citation{yu2018pu,yifan2019patch,qian2021pu,li2021point,qiu2022pu,dell2022arbitrary,he2023grad}
\newlabel{fig:pugan_compare}{{5}{5}{Qualitative comparisons of $16\times $ upsampling results on the the PU-GAN dataset. Our method generates uniform dense point clouds with fewer holes and outliers than state-of-the-art methods.}{}{}}
\newlabel{tab:PUGAN_4X}{{1}{5}{Quantitative comparison between our method and the state-of-the-art methods on the PU-GAN dataset.}{}{}}
\newlabel{tab:PU1K_4X}{{2}{5}{Comparison with the state-of-the-art methods on PU1K dataset.}{}{}}
\newlabel{fig:kitti}{{6}{6}{The results on KITTI dataset. Our method generates visual-appealing results.}{}{}}
\new