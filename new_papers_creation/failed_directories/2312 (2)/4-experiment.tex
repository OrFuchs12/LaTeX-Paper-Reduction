%% Experiments %%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

% %% Datasets %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Datasets}
% \label{sec:datasets}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Experimental setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Setup}
\label{sec:experimental-setup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Evaluation Metrics %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Evaluation metrics}
% \label{sec:evaluation-metrics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Evaluation metrics.} Following the evaluation metrics in \cite{gao2017tall}, we adopt two metrics (`R@$n$,IoU=$m$' and `R@$n$,mIoU').
`R@$n$,IoU=$m$' denotes the percentage of at least one of the top-$n$ predicted temporal locations having a temporal Intersection over Union (IoU) with a ground truth larger than $m$.
`R@$n$,mIoU' denotes the average of the highest IoUs among the $n$ predicted temporal locations.
% On the ActivityNet-Captions dataset, we set the predefined $n$ to 1 or 5 and $m$ to 0.1, 0.3 or 0.5.
% On the Charades-STA dataset, we set the predefined $n$ to 1 or 5 and $m$ to 0.3, 0.5 or 0.7.

\input{tables/1-1-comparison-activitynet}

%% ActivityNet Captions Dataset %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{The ActivityNet Captions dataset}~\cite{krishna2017dense}
contains 37,417, 17,505, and 17,031 video-sentence pairs for training, validating $val_1$, and $val_2$, respectively.
Since a testing set is not publicly available, $val_2$ is used for testing.
Video segment features are extracted via C3D~\cite{tran2015learning}.
Vocabulary sizes are 8,000.
For proposals, $K$, $E_{en}$, and $\sigma$ are set to $5$, $2$, and $4$.
For losses, $\alpha_1$, $\alpha_2$, $\alpha_3$, and $\alpha_4$ are set to $1$, $0.2$, $0.01$, and $0.1$.

%% Charades-STA Dataset %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{The Charades-STA dataset}~\cite{gao2017tall}
contains 16,128 video-sentence pairs from 6,672 videos, which are divided into 12,408 for training and 3,720 for testing.
Video segment features are extracted via I3D~\cite{carreira2017quo}.
Vocabulary sizes are 1,111.
For proposals, $K$, $E_{en}$, and $\sigma$ are set to $7$, $3$, and $9$.
For losses, $\alpha_1$, $\alpha_2$, $\alpha_3$, and $\alpha_4$ are set to $3$, $5$, $0.001$, and $1$.

\paragraph{Implementation details.} We set the maximum number of video segments to 200, and the maximum length of the sentence query to 20.
For the transformers, we use transformers with three-layer and four attention heads.
The dimension of the features ($d_V$, $d_Q$, $d_G$, $d_R$) is set to 256.
We use the equivalent MC Transformer for every reconstruction process.
For the hidden sentence query, we randomly hide a third ($1/3$) of the words.
For training, the Adam optimizer~\cite{kingma2014adam} is used.
We set the learning rate to 0.0004, mini-batch size to 32, and hyper-parameters as $\lambda_1=\lambda_2=0.15$, $\beta_1=0.1$, and $\beta_2=0.15$.
In the $k^{th}$ positive proposal, we set the number of Gaussian masks $E_p$ to $k$ for reflecting a varying number of masks in each proposal, as shown in the top right of \cref{fig:framework}.
% More implementation details are described in Supplementary material.

\input{tables/0-2-ablation-pos-prop} 
\input{tables/1-0-comparison-charades}

% \begin{figure}[t!]
%   \centering
%     \begin{subfigure}[b]{\linewidth}
%          \centering
%          \includegraphics[width=\linewidth]{figures/3-ablation-graph-props.pdf}
%          \caption{}
%          \label{fig:ablation-graph-props}
%     \end{subfigure}
%     \vfill
%     \begin{subfigure}[b]{\linewidth}
%          \centering
%          \includegraphics[width=\linewidth]{figures/3-ablation-graph-alpha.pdf}
%          \caption{}
%          \label{fig:ablation-graph-alpha}
%     \end{subfigure}
%     \caption{Ablation studies by varying (a) the number of proposals $K$ and the number of negative masks $E_{en}$ for each easy negative proposal and (b) $\alpha$ values for the pull-push learning scheme on the ActivityNet Captions dataset.
%     % $\alpha$, $\alpha_3$, and $\alpha_4$ for balancing losses
%     }
% \label{fig:ablation-graph}
% \end{figure}

%% Comparison with State-of-the-Arts %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparison with State-of-the-Art Methods}
\label{sec:comparison-with-state-of-the-art-methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To verify the effectiveness of the proposed method, we compare our PPS with previous weakly supervised temporal video grounding methods:
WS-DEC~\cite{duan2018weakly},
TGA~\cite{mithun2019weakly},
SCN~\cite{lin2020weakly},
WSTAN~\cite{wang2021weakly},
VLANet~\cite{ma2020vlanet},
MARN~\cite{song2020weakly},
CCL~\cite{zhang2020counterfactual},
RTBPN~\cite{zhang2020regularized},
EC-SL~\cite{chen2021towards},
LoGAN~\cite{tan2021logan},
VCA~\cite{wang2021visual},
LCNet~\cite{yang2021local},
FSAN~\cite{wang2022fine},
CWSTG~\cite{Chen_Luo_Zhang_Ma_2022},
CPL~\cite{zheng2022cpl},
CRM~\cite{huang2021cross},
CNM~\cite{zheng2022cnm}, and
IRON~\cite{cao2023iterative}.

In \cref{tab:comparisons-activitynet} for the ActivityNet Captions dataset, our PPS outperforms CPL~\cite{zheng2022cpl} by $3.56\%$, $22.49\%$, and $28.19\%$ at R@1,IoU=0.3, R@5,IoU=0.3, and R@5,IoU=0.5, respectively.
It is worth noting that PPS outperforms the previous learnable mask-based method, CPL, by significant margins at R@5, which means that the generated proposals of PPS promise a higher level of quality.
In \cref{tab:comparisons-charades} for the Charades-STA dataset, our PPS surpasses CPL~\cite{zheng2022cpl} by $3.77\%$ and $2.19\%$ at R@1,IoU=0.7 and R@5,IoU=0.3, respectively.
The methods marked with $^*$ make unfair comparisons with the previous methods.
CRM~\cite{huang2021cross} uses additional paragraph description annotations. CNM~\cite{zheng2022cnm} uses CLIP large-scale pre-trained features~\cite{radford2021learning} and IRON~\cite{cao2023iterative} uses OATrans~\cite{wang2022object} and DistilBERT~\cite{sanh2019distilbert} large-scale pre-trained features.
Although our PPS uses 3D ConvNet and Glove features for fair comparisons with previous methods, PPS shows competitive or higher performance with the methods marked with $^*$.
% To study the impact of large-scale pre-trained features, we conduct the experiment using CLIP features in Supplementary material.

\begin{figure}[t!]
  \centering
  \includegraphics[width=\linewidth]{figures/3-ablation-graph-props.pdf}
    \caption{Ablation studies by varying the number of positive and negative proposals $K$ and the number of Gaussian masks of an easy negative proposal $E_{en}$.
    }
    \label{fig:ablation-graph-props}
\end{figure}

%% Ablation Study %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ablation Study}
\label{sec:ablation-study}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For a more in-depth understanding of the proposed method, we perform ablation studies on our components.
% More details of the variants used in the ablation studies are explained in Supplementary material.

\paragraph{Analysis on the Gaussian mixture proposal.}
As shown in \cref{tab:ablation-positive-proposals}, we study the impact of the different strategies to generate Gaussian mixture proposals for positive proposals.
The results are summarized as follows:
First, the Gaussian mixture proposals are more effective than the single Gaussian proposal, which means that the mixture proposal can better represent a query-relevant temporal location.
Second, learning multiple centers and one width for one mixture proposal performs best.
We conjecture that learning multiple widths makes it complicated to learn proposals, which reduces performance.
Third, importance weighting from the reconstructor yields the best result by representing the importance of each mask for query reconstruction.
On the other hand, importance weighting from the generator is less effective, because it is hard to reflect reconstruction-aware information.
\cref{fig:ablation-graph-props} shows the impact of the number of proposals $K$.
The performance increases until the number is $5$ at R@1,mIoU.
We observe that defining too many proposals makes the proposals redundant and have short lengths due to the impact of the inter-pushing loss $\mathcal{L}^{inter}_{push}$.


\paragraph{Impact on a varying number of masks.}
For positive proposals, we form $\mathbf{P}_{p}^{(k)}$ by a Gaussian mixture of $E_p=k$ Gaussian masks to reflect a varying number of Gaussian masks in each positive proposal.
To verify the effectiveness of the varying number of Gaussian masks, we compare the performance of fixing the number of Gaussian masks for every positive proposal in \cref{tab:ablation-positive-proposals-fixing}.
The results show that using a varying number of Gaussian masks for each positive proposal performs better than using a fixed Gaussian number of Gaussian masks.
We find that combinations of different numbers of Gaussian masks can represent a diverse number of query-relevant events.

\input{tables/0-3-ablation-others}
\input{tables/0-1-ablation-loss}

\paragraph{Effect of the pull-push learning scheme.}
In \cref{tab:ablation-loss}, we verify the effectiveness of our pull-push learning scheme.
Among combinations of three losses ($\mathcal{L}_{pull}$, $\mathcal{L}^{intra}_{push}$, $\mathcal{L}^{inter}_{push}$), adopting all three losses yields the best performance.
We conjecture that our pull-push learning scheme helps Gaussian masks to capture diverse events for better representing a temporal location.
It is notable that adopting only the pulling loss can yield competitive or higher results to the state-of-the-art methods in \cref{tab:comparisons-activitynet}.
If the pulling loss $\mathcal{L}_{pull}$ is excluded, the performance decreases significantly.
We observe that Gaussian masks for one Gaussian mixture proposal are spread sparsely throughout the entire video without $\mathcal{L}_{pull}$, which can not represent one proper temporal location.
Additionally, the results suggest that two pushing losses ($\mathcal{L}^{intra}_{push}$, $\mathcal{L}^{inter}_{push}$) are used with $\mathcal{L}_{pull}$ for a synergy effect, because the goal of the pushing losses is to make less overlapped masks for moderate coupling.
For a more in-depth understanding of the pulling loss $\mathcal{L}_{pull}$, we conduct ablation studies of different strategies for $\mathcal{L}_{pull}$ in \cref{tab:ablation-pulling-loss}.
Among the strategies, pulling two distant masks closer or pulling two distant masks to the middle mask performs best.
The results imply that pulling fewer masks is better and pulling more masks may ruin the structure of the mixture proposal due to overlapped masks.
\cref{fig:ablation-graph-alpha} presents the impact of controlling the balance of the losses.
The results show that a high $\alpha_2$ value for $\mathcal{L}_{pull}$ is needed to produce densely generated masks and the adequate $\alpha_3$ and $\alpha_4$ values for $\mathcal{L}^{intra}_{push}$ and $\mathcal{L}^{inter}_{push}$ are needed to cause proper discrimination between the masks and between the proposals, respectively.

\begin{figure}[t!]
  \centering
    \includegraphics[width=\linewidth]{figures/3-ablation-graph-alpha.pdf}
    \caption{Ablation studies by varying $\alpha$ values for the pull-push learning scheme on the ActivityNet Captions dataset.
    }
    \label{fig:ablation-graph-alpha}
\end{figure}

%% Qualitative Results %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Qualitative Results}
\label{sec:qualitative-results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cref{fig:qualitative} shows qualitative results of our PPS and other variants of PPS.
It is notable that PPS captures accurate query-relevant locations, while the ground truth, which can be noisy due to the subjectivity of annotators, includes redundant locations such as a logo at the beginning of the video.
% More qualitative results for the visualization of proposals are shown in Supplementary material.


\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/4-qualitative.pdf}
  \caption{
  Qualitative results on the Activity-Net Captions dataset.
  Given a video and a query, PPS yields a predicted temporal location (red).
  We also visualize the predictions of variants using a positive proposal of one Gaussian mask without the mixture (yellow) or excluding a pulling loss (green) or excluding pushing losses (purple).
  }
\label{fig:qualitative}
\end{figure}