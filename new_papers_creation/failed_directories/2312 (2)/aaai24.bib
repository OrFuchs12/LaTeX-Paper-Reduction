
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% my papers

@inproceedings{kim2019skeleton,
  title={Skeleton-based action recognition of people handling objects},
  author={Kim, Sunoh and Yun, Kimin and Park, Jongyoul and Choi, Jin Young},
  booktitle={WACV},
  pages={61--70},
  year={2019},
  organization={IEEE}
}

@inproceedings{kim2021plrn,
  author={Kim, Sunoh and Yun, Kimin and Choi, Jin Young},
  booktitle={AVSS}, 
  title={Position-aware Location Regression Network for Temporal Video Grounding}, 
  year={2021},
  volume={},
  number={},
  pages={1-8}
}

@inproceedings{kim2022swag,
    author = {Kim, Sunoh and Ha, Taegil and Yun, Kimin and Choi, Jin Young},
    title = {SWAG-Net: Semantic Word-Aware Graph Network for Temporal Video Grounding},
    year = {2022},
    booktitle = {ACM CIKM},
    pages = {982â€“992},
    numpages = {11}
}

w

%% datasets and pretrained models
@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{wang2022object,
  title={Object-aware video-language pre-training for retrieval},
  author={Wang, Jinpeng and Ge, Yixiao and Cai, Guanyu and Yan, Rui and Lin, Xudong and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={CVPR},
  pages={3313--3322},
  year={2022}
}

@inproceedings{gao2017tall,
  title={Tall: Temporal activity localization via language query},
  author={Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
  booktitle={ICCV},
  pages={5267--5275},
  year={2017}
}

@inproceedings{sigurdsson2016hollywood,
  title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
  author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
  booktitle={ECCV},
  pages={510--526},
  year={2016},
  organization={Springer}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={ICCV},
  pages={706--715},
  year={2017}
}

@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={CVPR},
  pages={1725--1732},
  year={2014}
}

@inproceedings{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL-HLT},
  year={2019},
  doi={10.18653/v1/N19-1423}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  pages={6299--6308},
  year={2017}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={ICCV},
  pages={4489--4497},
  year={2015}
}

@article{regneri2013grounding,
  title={Grounding action descriptions in videos},
  author={Regneri, Michaela and Rohrbach, Marcus and Wetzel, Dominikus and Thater, Stefan and Schiele, Bernt and Pinkal, Manfred},
  journal={Transactions of the Association for Computational Linguistics},
  volume={1},
  pages={25--36},
  year={2013},
  publisher={MIT Press}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

%% techniques


@inproceedings{guzman2012multiple,
  title={Multiple choice learning: Learning to produce multiple structured outputs},
  author={Guzman-Rivera, Abner and Batra, Dhruv and Kohli, Pushmeet},
  booktitle={NeurIPS},
  volume={25},
  year={2012}
}

@incollection{zhou2021ensemble,
  title={Ensemble learning},
  author={Zhou, Zhi-Hua},
  booktitle={Machine learning},
  pages={181--210},
  year={2021},
  publisher={Springer}
}

@inproceedings{wang2014learning,
  title={Learning fine-grained image similarity with deep ranking},
  author={Wang, Jiang and Song, Yang and Leung, Thomas and Rosenberg, Chuck and Wang, Jingbin and Philbin, James and Chen, Bo and Wu, Ying},
  booktitle={CVPR},
  pages={1386--1393},
  year={2014}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  volume={30},
  year={2017}
}

@article{lin2017structured,
  title={A structured self-attentive sentence embedding},
  author={Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.03130},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@inproceedings{kim2016hadamard,
  title={Hadamard product for low-rank bilinear pooling},
  author={Kim, Jin-Hwa and On, Kyoung-Woon and Lim, Woosang and Kim, Jeonghee and Ha, Jung-Woo and Zhang, Byoung-Tak},
  year={2017},
  booktitle={ICLR}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={CVPR},
  pages={1492--1500},
  year={2017},
}

@article{schuster1997bidirectional,
  title={Bidirectional recurrent neural networks},
  author={Schuster, Mike and Paliwal, Kuldip K},
  journal={IEEE transactions on Signal Processing},
  volume={45},
  number={11},
  pages={2673--2681},
  year={1997},
  publisher={Ieee}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={ICCV},
  pages={1440--1448},
  year={2015}
}

@inproceedings{ren2015faster,
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle = {NeurIPS},
  title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  volume = {28},
  year = {2015}
}


@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR},
  year={2015}
}

@inproceedings{manning2014stanford,
  title={The Stanford CoreNLP natural language processing toolkit},
  author={Manning, Christopher D and Surdeanu, Mihai and Bauer, John and Finkel, Jenny Rose and Bethard, Steven and McClosky, David},
  booktitle={ACL},
  pages={55--60},
  year={2014}
}

@inproceedings{pennington2014glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "EMNLP",
    month = oct,
    year = "2014",
    pages = "1532--1543"
}

@inproceedings{neubeck2006efficient,
  title={Efficient non-maximum suppression},
  author={Neubeck, Alexander and Van Gool, Luc},
  booktitle={ICPR},
  volume={3},
  pages={850--855},
  year={2006},
  organization={IEEE}
}

% other video-level vision problems

@inproceedings{piergiovanni2019temporal,
  title={Temporal gaussian mixture layer for videos},
  author={Piergiovanni, AJ and Ryoo, Michael},
  booktitle={ICML},
  pages={5152--5161},
  year={2019},
  organization={PMLR}
}

@inproceedings{long2019gaussian,
  title={Gaussian temporal awareness networks for action localization},
  author={Long, Fuchen and Yao, Ting and Qiu, Zhaofan and Tian, Xinmei and Luo, Jiebo and Mei, Tao},
  booktitle={CVPR},
  pages={344--353},
  year={2019}
}

@inproceedings{sultani2018real,
  title={Real-world anomaly detection in surveillance videos},
  author={Sultani, Waqas and Chen, Chen and Shah, Mubarak},
  booktitle={CVPR},
  pages={6479--6488},
  year={2018}
}

@inproceedings{leung2011handling,
  title={Handling label noise in video classification via multiple instance learning},
  author={Leung, Thomas and Song, Yang and Zhang, John},
  booktitle={ICCV},
  pages={2056--2063},
  year={2011},
  organization={IEEE}
}

@inproceedings{babenko2009visual,
  title={Visual tracking with online multiple instance learning},
  author={Babenko, Boris and Yang, Ming-Hsuan and Belongie, Serge},
  booktitle={CVPR},
  pages={983--990},
  year={2009},
  organization={IEEE}
}

@inproceedings{ju2021divide,
  title={Divide and conquer for single-frame temporal action localization},
  author={Ju, Chen and Zhao, Peisen and Chen, Siheng and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
  booktitle={ICCV},
  pages={13455--13464},
  year={2021}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={CVPR},
  pages={9879--9889},
  year={2020}
}

%% video grounding applications
@inproceedings{ma2002user,
  title={A user attention model for video summarization},
  author={Ma, Yu-Fei and Lu, Lie and Zhang, Hong-Jiang and Li, Mingjing},
  booktitle={ACM MM},
  pages={533--542},
  year={2002}
}

@inproceedings{dong2019dual,
  title={Dual encoding for zero-example video retrieval},
  author={Dong, Jianfeng and Li, Xirong and Xu, Chaoxi and Ji, Shouling and He, Yuan and Yang, Gang and Wang, Xun},
  booktitle={CVPR},
  pages={9346--9355},
  year={2019},
  doi={10.1109/CVPR.2019.00957}
}

%% video grounding
@inproceedings{zhang2019cross,
  title={Cross-modal interaction networks for query-based moment retrieval in videos},
  author={Zhang, Zhu and Lin, Zhijie and Zhao, Zhou and Xiao, Zhenxin},
  booktitle={ACM SIGIR},
  pages={655--664},
  year={2019},
  doi={10.1145/3331184.3331235}
}

@inproceedings{mun2020local,
  title={Local-global video-text interactions for temporal grounding},
  author={Mun, Jonghwan and Cho, Minsu and Han, Bohyung},
  booktitle={CVPR},
  pages={10810--10819},
  year={2020}
}

@inproceedings{xiao2021boundary,
  title={Boundary Proposal Network for Two-Stage Natural Language Video Localization},
  author={Xiao, Shaoning and Chen, Long and Zhang, Songyang and Ji, Wei and Shao, Jian and Ye, Lu and Xiao, Jun},
  booktitle={AAAI},
  pages={2986--2994},
  year={2021},
  URL={https://ojs.aaai.org/index.php/AAAI/article/view/16406}
}

@inproceedings{xu2019multilevel,
  title={Multilevel language and vision integration for text-to-clip retrieval},
  author={Xu, Huijuan and He, Kun and Plummer, Bryan A and Sigal, Leonid and Sclaroff, Stan and Saenko, Kate},
  booktitle={AAAI},
  pages={9062--9069},
  year={2019},
  doi={10.1609/aaai.v33i01.33019062}
}

@inproceedings{ghosh2019excl,
  title={ExCL: Extractive Clip Localization Using Natural Language Descriptions},
  author={Ghosh, Soham and Agarwal, Anuva and Parekh, Zarana and Hauptmann, Alexander G},
  booktitle={NAACL-HLT},
  pages={1984--1990},
  year={2019},
  doi={10.18653/v1/N19-1198}
}

@inproceedings{zeng2020dense,
  title={Dense regression network for video grounding},
  author={Zeng, Runhao and Xu, Haoming and Huang, Wenbing and Chen, Peihao and Tan, Mingkui and Gan, Chuang},
  booktitle={CVPR},
  pages={10287--10296},
  year={2020},
  doi={10.1109/cvpr42600.2020.01030}
}

@inproceedings{yuan2019find,
  title={To find where you talk: Temporal sentence localization in video with attention based location regression},
  author={Yuan, Yitian and Mei, Tao and Zhu, Wenwu},
  booktitle={AAAI},
  pages={9159--9166},
  year={2019},
  doi={10.1609/aaai.v33i01.33019159}
}

@inproceedings{yuan2021closer,
  title={A closer look at temporal sentence grounding in videos: Dataset and metric},
  author={Yuan, Yitian and Lan, Xiaohan and Wang, Xin and Chen, Long and Wang, Zhi and Zhu, Wenwu},
  booktitle={Proceedings of the 2nd International Workshop on Human-centric Multimedia Analysis},
  pages={13--21},
  year={2021}
}

@inproceedings{zhou2021embracing,
  title={Embracing uncertainty: Decoupling and de-bias for robust temporal grounding},
  author={Zhou, Hao and Zhang, Chongyang and Luo, Yan and Chen, Yanjun and Hu, Chuanping},
  booktitle={CVPR},
  pages={8445--8454},
  year={2021}
}


%% weakly-supervised video grounding

@inproceedings{cao2023iterative,
  title={Iterative Proposal Refinement for Weakly-Supervised Video Grounding},
  author={Cao, Meng and Wei, Fangyun and Xu, Can and Geng, Xiubo and Chen, Long and Zhang, Can and Zou, Yuexian and Shen, Tao and Jiang, Daxin},
  booktitle={CVPR},
  pages={6524--6534},
  year={2023}
}

@inproceedings{wang2022fine,
  title={Fine-grained semantic alignment network for weakly supervised temporal language grounding},
  author={Wang, Yuechen and Zhou, Wengang and Li, Houqiang},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{lin2020weakly,
  title={Weakly-supervised video moment retrieval via semantic completion network},
  author={Lin, Zhijie and Zhao, Zhou and Zhang, Zhu and Wang, Qi and Liu, Huasheng},
  booktitle={AAAI},
  volume={34},
  pages={11539--11546},
  year={2020}
}

@inproceedings{mithun2019weakly,
  title={Weakly supervised video moment retrieval from text queries},
  author={Mithun, Niluthpol Chowdhury and Paul, Sujoy and Roy-Chowdhury, Amit K},
  booktitle={CVPR},
  pages={11592--11601},
  year={2019}
}

@article{chen2020look,
  title={Look closer to ground better: Weakly-supervised temporal grounding of sentence in video},
  author={Chen, Zhenfang and Ma, Lin and Luo, Wenhan and Tang, Peng and Wong, Kwan-Yee K},
  journal={arXiv preprint arXiv:2001.09308},
  year={2020}
}

@article{wang2021weakly,
  title={Weakly supervised temporal adjacent network for language grounding},
  author={Wang, Yuechen and Deng, Jiajun and Zhou, Wengang and Li, Houqiang},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ma2020vlanet,
  title={Vlanet: Video-language alignment network for weakly-supervised video moment retrieval},
  author={Ma, Minuk and Yoon, Sunjae and Kim, Junyeong and Lee, Youngjoon and Kang, Sunghun and Yoo, Chang D},
  booktitle={ECCV},
  pages={156--171},
  year={2020},
  organization={Springer}
}

@inproceedings{tan2021logan,
  title={Logan: Latent graph co-attention network for weakly-supervised video moment retrieval},
  author={Tan, Reuben and Xu, Huijuan and Saenko, Kate and Plummer, Bryan A},
  booktitle={WACV},
  pages={2083--2092},
  year={2021}
}

@article{song2020weakly,
  title={Weakly-supervised multi-level attentional reconstruction network for grounding textual queries in videos},
  author={Song, Yijun and Wang, Jingwen and Ma, Lin and Yu, Zhou and Yu, Jun},
  journal={arXiv preprint arXiv:2003.07048},
  year={2020}
}

@inproceedings{huang2021cross,
  title={Cross-sentence temporal and semantic relations in video activity localisation},
  author={Huang, Jiabo and Liu, Yang and Gong, Shaogang and Jin, Hailin},
  booktitle={ICCV},
  pages={7199--7208},
  year={2021}
}

@article{yang2021local,
  title={Local correspondence network for weakly supervised temporal sentence grounding},
  author={Yang, Wenfei and Zhang, Tianzhu and Zhang, Yongdong and Wu, Feng},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={3252--3262},
  year={2021},
  publisher={IEEE}
}

@inproceedings{zhang2020regularized,
  title={Regularized two-branch proposal networks for weakly-supervised moment retrieval in videos},
  author={Zhang, Zhu and Lin, Zhijie and Zhao, Zhou and Zhu, Jieming and He, Xiuqiang},
  booktitle={ACM MM},
  pages={4098--4106},
  year={2020}
}

@inproceedings{duan2018weakly,
  title={Weakly supervised dense event captioning in videos},
  author={Duan, Xuguang and Huang, Wenbing and Gan, Chuang and Wang, Jingdong and Zhu, Wenwu and Huang, Junzhou},
  booktitle={NeurIPS},
  volume={31},
  year={2018}
}

@inproceedings{chen2021towards,
  title={Towards bridging event captioner and sentence localizer for weakly supervised dense event captioning},
  author={Chen, Shaoxiang and Jiang, Yu-Gang},
  booktitle={CVPR},
  pages={8425--8435},
  year={2021}
}

@article{gao2019wslln,
  title={Wslln: Weakly supervised natural language localization networks},
  author={Gao, Mingfei and Davis, Larry S and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1909.00239},
  year={2019}
}

@inproceedings{wu2020reinforcement,
  title={Reinforcement learning for weakly supervised temporal grounding of natural language in untrimmed videos},
  author={Wu, Jie and Li, Guanbin and Han, Xiaoguang and Lin, Liang},
  booktitle={ACM MM},
  pages={1283--1291},
  year={2020}
}

@article{fang2020weak,
  title={Weak supervision and referring attention for temporal-textual association learning},
  author={Fang, Zhiyuan and Kong, Shu and Wang, Zhe and Fowlkes, Charless and Yang, Yezhou},
  journal={arXiv preprint arXiv:2006.11747},
  year={2020}
}

@inproceedings{zhang2020counterfactual,
  title={Counterfactual contrastive learning for weakly-supervised vision-language grounding},
  author={Zhang, Zhu and Zhao, Zhou and Lin, Zhijie and He, Xiuqiang and others},
  booktitle={NeurIPS},
  volume={33},
  pages={18123--18134},
  year={2020}
}

@inproceedings{wang2021visual,
  title={Visual co-occurrence alignment learning for weakly-supervised video moment retrieval},
  author={Wang, Zheng and Chen, Jingjing and Jiang, Yu-Gang},
  booktitle={ACM MM},
  pages={1459--1468},
  year={2021}
}

@inproceedings{zheng2022cnm,
  title={Weakly supervised video moment localization with contrastive negative sample mining},
  author={Zheng, Minghang and Huang, Yanjie and Chen, Qingchao and Liu, Yang},
  booktitle={AAAI},
  volume={1},
  pages={3},
  year={2022}
}

@inproceedings{zheng2022cpl,
  title={Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning},
  author={Zheng, Minghang and Huang, Yanjie and Chen, Qingchao and Peng, Yuxin and Liu, Yang},
  booktitle={CVPR},
  pages={15555--15564},
  year={2022}
}

@inproceedings{Chen_Luo_Zhang_Ma_2022,
  title={Explore Inter-contrast between Videos via Composition for Weakly Supervised Temporal Sentence Grounding},
  author={Chen, Jiaming and Luo, Weixin and Zhang, Wei and Ma, Lin},
  booktitle={AAAI},
  year={2022}
}

@article{mo2022multi,
  title={Multi-Scale Self-Contrastive Learning with Hard Negative Mining for Weakly-Supervised Query-based Video Grounding},
  author={Mo, Shentong and Liu, Daizong and Hu, Wei},
  journal={arXiv preprint arXiv:2203.03838},
  year={2022}
}

%% Rebuttal

@article{yang2022video,
  title={Video moment retrieval with cross-modal neural architecture search},
  author={Yang, Xun and Wang, Shanshan and Dong, Jian and Dong, Jianfeng and Wang, Meng and Chua, Tat-Seng},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  year={2022},
  publisher={IEEE}
}

@inproceedings{liu2021context,
  title={Context-aware biaffine localizing network for temporal sentence grounding},
  author={Liu, Daizong and Qu, Xiaoye and Dong, Jianfeng and Zhou, Pan and Cheng, Yu and Wei, Wei and Xu, Zichuan and Xie, Yulai},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{zhang2020learning,
  title={Learning 2d temporal adjacent networks for moment localization with natural language},
  author={Zhang, Songyang and Peng, Houwen and Fu, Jianlong and Luo, Jiebo},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{yuan2019semantic,
  title={Semantic conditioned dynamic modulation for temporal sentence grounding in videos},
  author={Yuan, Yitian and Ma, Lin and Wang, Jingwen and Liu, Wei and Zhu, Wenwu},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{liu2022memory,
  title={Memory-guided semantic learning network for temporal sentence grounding},
  author={Liu, Daizong and Qu, Xiaoye and Di, Xing and Cheng, Yu and Xu, Zichuan and Zhou, Pan},
  booktitle={AAAI},
  volume={36},
  number={2},
  pages={1665--1673},
  year={2022}
}

@inproceedings{zhu2023rethinking,
  title={Rethinking the Video Sampling and Reasoning Strategies for Temporal Sentence Grounding},
  author={Zhu, Jiahao and Liu, Daizong and Zhou, Pan and Di, Xing and Cheng, Yu and Yang, Song and Xu, Wenzheng and Xu, Zichuan and Wan, Yao and Sun, Lichao and others},
  booktitle={EMNLP},
  year={2022}
}

@inproceedings{wang2022negative,
  title={Negative sample matters: A renaissance of metric learning for temporal grounding},
  author={Wang, Zhenzhi and Wang, Limin and Wu, Tao and Li, Tianhao and Wu, Gangshan},
  booktitle={AAAI},
  year={2022}
}


%% GMM
@inproceedings{zong2018deep,
  title={Deep autoencoding gaussian mixture model for unsupervised anomaly detection},
  author={Zong, Bo and Song, Qi and Min, Martin Renqiang and Cheng, Wei and Lumezanu, Cristian and Cho, Daeki and Chen, Haifeng},
  booktitle={ICLR},
  year={2018}
}

@article{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  journal={NeurIPS},
  volume={31},
  year={2018}
}

