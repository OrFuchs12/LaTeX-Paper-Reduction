\section{Introduction}

% The effective handling of emergency and non-emergency reports is critical for public safety and well-being. Statistics show the city of New York receives approximately 114,000 emergency and non-emergency calls per day on average. Many cities in the United States utilize a single communication center, with different line numbers, to handle both types of calls. Through collaboration with local governments and call centers, we found the increased volume of non-emergency calls to the 311 line leads to longer wait times for emergency 911 calls. This is due to cities having fixed resources to manage both emergency and non-emergency calls. With emergency call centers across the nation facing a labor shortage \cite{nbc-ems-shortage}, there is an urgent need to efficiently direct non-emergency calls. This allows more resources to be allocated to emergency calls. Streamlining the handling of non-emergency calls is vital to ensure emergency calls are prioritized and answered quickly.


% The effective handling of emergency and non-emergency reports is critical for public safety and well-being. The city of New York receives approximately 114,000 emergency and non-emergency calls per day on average based on available statistics \cite{nyc311report, nycnextgen911, fdnycitywide}. Nashville, like many other cities in the United States uses a single communication center, with different line numbers, to handle both emergency and non-emergency calls. Through our collaboration with the Metro Nashville Government and DEC, we uncover that the increased burden on using the 311 (non-emergency) phone line means that wait times for emergency calls increase, given that the cities have fixed resources to manage both emergency and non-emergency calls. Further, with a crippling labor shortage \cite{nbc-ems-shortage} that most emergency call centers across the nation are facing, there is an urgent need to efficiently and appropriately handle non-emergency calls so that more resources can be assigned to deal with emergency calls. 

Emergency and non-emergency response systems are essential services provided by local governments and critical to protecting lives, the environment, and property. While 911 is primarily used for emergency services, 311 is a non-emergency phone number that people can call to find information about municipal services, make complaints, or report problems like stolen property, road damage, etc. Both emergency and non-emergency calls are operated by the Department of Emergency Communication (DEC) in most cities. DECs across the nation receive an overwhelmingly high number of calls, with the national yearly average of 911 calls being close to 240 million~\cite{nycnextgen911, ma2019data}. The growing use of response systems comes at a time when local governments face increasing pressure to do more with less resources. Indeed, the number of local government employees in the United States has shrunk by nearly 5\% in 2021~\cite{2021annual}, and a large proportion of counties and municipalities anticipate a significant general fund shortfall as the United States transitions out of the COVID pandemic~\cite{g12afonso2021planning}. 


% The city of Nashville, similar to many other cities in the United States, uses a single communication center to handle both emergency and non-emergency calls, receiving around 41,000 emergency calls and 39,000 non-emergency calls per month on average. Residents can report non-life-threatening issues, like abandoned vehicles and noise complaints, through two channels of the 311 non-emergency system: a website and app called hubNashville \cite{nashville-gov-website}, and a dedicated non-emergency phone line. Through our collaboration with the city of Nashville and DEC, we uncovered that the increased burden on using the 311 phone line means that wait times for emergency calls increase, given that the cities have fixed resources to manage both emergency and non-emergency calls. In addition, emergency call centers across the nation are facing a crippling labor shortage \cite{nbc-ems-shortage}, further burdening emergency response. 

% To mitigate this issue, we developed an automated system called Auto311 to generate and complete case reports for first responders. Auto311 consists of several modules, including incident type detection and information itemization. The incident type detection module suggests the most likely incident type(s) based on the current call. Auto311 then dynamically creates and updates a case report for the detected type(s). Concurrently, the case report guides the information itemization module to obtain essential details to complete the report. The system not only detects incident types but also collects key information to generate comprehensive case reports.

% To mitigate this issue, we develop Auto311, the first automated system to handle 311 non-emergency calls. Auto311 consists of incident type detection and information itemization. Auto311 not only suggests the most likely incident type(s) based on current calls with the help of the incident type detection module but also dynamically creates and updates the case report regarding the detected type(s). Concurrently, the case report also guides the information itemization module to obtain the essential information to fulfill the case report.


To mitigate this issue, we introduce Auto311, the first automated system to handle 311 non-emergency calls. Auto311 features two key components: incident type detection and information itemization. It identifies probable incident types from ongoing calls and dynamically generates and updates case reports accordingly. Simultaneously, these reports direct the information itemization module to gather necessary information, streamlining the process.

% Previous works have aimed to optimize emergency and non-emergency management \cite{sun2020applications, wex2014emergency, manoj2007communication, perry2003preparedness, chen2008coordination}. However, most focus on emergency resource allocation after a case report is filed, such as route optimization for ambulances and response center localization for faster response times \cite{mukhopadhyay2022review}. Although frameworks like AWS Lex \cite{amazonlex} and Google DialogFlow \cite{dialogflow} can quickly set up automated dialogue services, they require fixed dialogue charts to guide each conversation. For non-emergency calls with diverse incident types and unique dialogue needs, separately handling each incident type is unrealistic. However, at a system level, Auto311 strategically optimizes dialogues by leveraging confidence scores from each component. Rather than pre-defined conversations, Auto311 detects incident types and collects key information to generate case reports. This allows flexible, automated handling of non-emergency calls.

Previous works have aimed to optimize (non-)emergency management \cite{sun2020applications, wex2014emergency, manoj2007communication, 
ma2021novel, 
ma2021toward, 
ma2018cityresolver, 
chen2008coordination}. However, most of those works focus more on the emergency resource allocation after one case report is placed, for example, route optimization for ambulances and response center localization for faster responses \cite{mukhopadhyay2022review}. Although other available could frameworks like AWS's Lex \cite{amazonlex} and Google's DialogFlow \cite{dialogflow} can set up automated dialogue service within a few hours, they require clear and relatively fixed dialogue charts to guide the conversation. When it comes to non-emergency call handling, leaving alone privacy and safety issues brought by online solutions, most incident types have unique dialogue charts compared to others, making it unrealistic to separately handle the conversation for each incident type. However, Auto311, at a system level, takes full advantage of the emitted confidence scores of each component to strategically optimize the dialogue. 

% challenge 1: multiple incident types along the conversation
% challenge 2: measure confidence in the info itemization
% challenge 3: task-specific data

However, developing Auto311 poses some key \textbf{challenges}. First, unlike plenty of work that has been done to solve text classification problems \cite{kowsari2019text, mironczuk2018recent, minaee2021deep, aggarwal2012survey} with outputting the most likely one category in the end, the incident prediction in this task has to cope with calls involving multiple incident types instead, see Section Motivating Study for more details. Second, although measuring confidence in machine learning models has become more and more popular recently, refer to Section Related Work for more details, there still lacks an effective method to measure the confidence score behind the model outputs in a textual format. Lastly, although pretrained models yield satisfying performance on datasets with general purposes, e.g., Bert \cite{devlin2018bert} on SQuAD \cite{rajpurkar2016squad}, Auto311 has to align with more task-specific data and goals under the non-emergency call handling scope. We summarize our \textbf{contributions} as follows:
\begin{itemize}
    \item We collect, transcribe, annotate, and analyze 11,796 authentic audio recordings from non-emergency calls, with permission from Metro Nashville Governement.
    \item We build the first automated system Auto311 to handle non-emergency 311 calls. \item We create a novel approach to measure the confidence score that is used to guide the behaviour of the system.
    % \item In this study, we introduce a novel metric specifically designed for evaluating emergency response systems. Our metric considers both syntactic and semantic features to evaluate the predicted answers under this specific non-emergency response scenario. To validate the effectiveness of our proposed metric, we conducted experiments in real-world cases. Our results indicate that the proposed metric closely approximates human evaluation and can provide a reliable and accurate evaluation of the performance of emergency response systems.
    % \item We utilize a new text comparison metric to produce a confidence score alongside the textual predictions from the information itemization module. This confidence score boosts Auto311's performance both component-wise and system-wise.
    \item We thoroughly evaluate the performance of Auto311's modules. Auto311 achieves an average F-1 score of 92.54\% on the incident type prediction task and an average score of 0.9329 when dealing with real-world recordings in information itemization.
    % \item We evaluate the potential utility of our system under unseen scenarios. Testing employs questions and contexts unseen during training (synthesized incorporating distinct features from non-Nashville cities). The results demonstrate strong cross-city transfer learning potential for our model, with an average score of 0.9948 in unseen scenarios.
    \item We emulate the usage of Auto311 using recordings from our dataset and analyze Auto311's system-level impacts. Auto311 dynamically adjusts to shifting incident types, reduces follow-up conversations, and yields an overall average accuracy of 94.49\% while categorizing the emulated call utterances.
    % \item Our study introduces a novel confidence score for our system, which is used to build a confidence-checking and -boosting procedure during the conversation between callers and dispatchers. In addition to outputting the indicated answers, our system provides a confidence score that reflects its level of certainty about the provided responses. This confidence score is used to strategically schedule the subsequent questions, ensuring that the system's confidence score is maximized and the number of interactions between the caller and the dispatcher is minimized. By using this procedure, we can efficiently provide critical information to emergency responders while minimizing the burden on callers and dispatchers.
\end{itemize}

% Most traditional neural network-based text classification models apply a softmax layer as the last activation to obtain the category only with the highest probability. Upon reviewing our dataset, we discover that individual call conversations often obtain references to multiple incident types, see Section Motivating Study for more details. Thus, we need a method to handle multiple incident types independently and accurately.

% We formulate the incident type prediction process as a multi-layer text classification task. Although plenty of work has been done to solve the text classification problem \cite{kowsari2019text, mironczuk2018recent, minaee2021deep, aggarwal2012survey}, we still find this \textbf{challenging}. Unlike static traditional text classification tasks that commonly apply softmax to obtain the distribution and track the highest probabilities, upon reviewing our dataset, we discovered that individual call conversations often contain references to multiple incident types or change from one incident type to another as the conversation progresses. For example, ``...someone busted my car and my wallet is gone...'' indicates two incident types – ``someone busted my car'' suggests damage to property while ``my wallet is gone'' implies lost or stolen property. And in ``... I saw a car illegally parked at the same spot in the garage for a while... oh, wait I think it is abandoned instead cuz the bumper is off and rusted ...'', the caller was to report an illegal parking case, but then figured out this should be reported as an abandoned vehicle based on details like ``the bumper is off and rusted''. The first challenge is that the incident type prediction module needs to accurately predict all possible incident type categories without ignoring any of the possible categories using activation functions like softmax. Secondly, our system needs to monitor and adapt to changes in the predicted incident type throughout the conversation, based on the predicted results and emitted confidence scores from the incident type prediction module.


% The information itemization module is rooted in an extractive question-answering (QA) stricture, leveraging the ability to take arbitrary queries and then output the most relevant context segments. Although existing pipelines like DistilBERT \cite{sanh2019distilbert} and BERT \cite{devlin2018bert} achieve impressive performance on benchmarks such as SQuAD 2.0 \cite{rajpurkar2016squad}, information itemization remains \textbf{challenging} for this task for the following reasons. One issue is that current models are trained on open-domain datasets for general purposes, while emergency response situations demand greater reliability and robustness in addressing more detailed, task-specific topics not present in existing training data. For instance, questions like ``Can you provide more details about the suspect’s description?'' and ``Please provide the address of the accident'' require high precision, which generic models may lack. Additionally, existing text comparison approaches to evaluate those models do not fully capture the core objective -- providing first responders with critical downstream information. Also, a proper text comparison metric is needed to produce the confidence score of the information itemization module during runtime.

% previous works on emergency management: \cite{sun2020applications, wex2014emergency, manoj2007communication, perry2003preparedness, chen2008coordination}. call handling in different scenarios: \cite{al2019smart, blancou2016ecall}

% but also highlights essential contextual information to fulfill internal case reports for the dispatcher. In other words, our system consists of two primary modules – call dispatching and information extracting. The call dispatching module takes ongoing caller utterances as input and outputs the most probable category. The information extracting module tracks potential answers to 9 critical questions based on the latest user utterance. A manual review of over 10,000 audio recordings of 911/311 calls identifies these 9 questions as highly salient for internal case filing. This module ensures all 9 questions receive confident, accurate answers. The two modules operate simultaneously and cooperatively.



% The Department of Emergency Communications (DEC) employs differentiated priority tiers, with cases in lower tiers deemed less urgent than those in higher tiers. Ideally, cases with higher priority tiers should receive greater resource allocation. Although the Metropolitan Nashville Government has implemented platforms such as hubNashville to handle non-emergencies (e.g. noise violations, illegal parking), DEC still receives a substantial volume of non-emergency calls. This high non-emergency call volume negatively impacts resource assignments for more urgent high-tier cases.



% We formulate the call dispatching module as a multi-layer text classification task. Unlike static traditional text classification tasks \cite{kowsari2019text, mironczuk2018recent, minaee2021deep, aggarwal2012survey} that commonly apply softmax to obtain the distribution and track the highest probabilities, a review of our dataset reveals a strong likelihood of individual contexts containing more than one incident type. For example, ``...someone busted my car and my wallet is gone...'' indicates two incident types – ``someone busted my car'' suggests damage to property while ``my wallet is gone'' implies lost or stolen property. Thus, we hierarchically segregate each incident type and detect whether the current context contains information about a specific incident type at each layer.

% We develop the information extraction module in a question-answering (QA) framework. Although existing QA pipelines like DistilBERT-QA \cite{sanh2019distilbert} and BERT-QA \cite{devlin2018bert} achieve impressive performance on benchmarks such as SQuAD 2.0 \cite{rajpurkar2016squad}, QA remains \textbf{challenging} for this task. One reason involves training current QA models and pipelines on open domain datasets for general purposes, whereas emergency response situations necessitate greater reliability and robustness, addressing more detailed, task-specific topics than existing model training data. For example, questions like “Can you provide more details about the suspect’s description?” and “Please provide the address of the accident” require high precision. Furthermore, existing metrics do not fully capture the current objective—providing critical downstream information to assist entities like the police. Finally, unlike traditional QA systems, our system aims to minimize questioning by concurrently evaluating confidence in potential question answers during dispatch.

% Considering the trustworthiness issues brought by most AI applications \cite{kaur2022trustworthy, seshia2022toward}, we design our system to play the role of an assistant, which means it supports the decision maker (dispatcher) instead of being the one who makes any decisions. The dispatcher has full control over the system during the conversation and can modify the suggested dispatching result and extracted information anytime. We acknowledge there could be emergency calls dialed to non-emergency numbers, once the ongoing call shows any signs of emergency, the system alerts the dispatcher and no longer provides suggestions. A call is identified as an emergency if it triggers our rule-based handover control.

% The timely and effective handling of emergency and non-emergency reports is essential for public safety and well-being. Emergency reports, such as reports of fires, floods, or crimes in progress, must be handled immediately to prevent further damage or loss of life. Non-emergency reports, such as reports of potholes or downed power lines, may not be as urgent, but they can still cause significant inconvenience or disruption if they are not handled promptly. Previous works \cite{sun2020applications, wex2014emergency, manoj2007communication, perry2003preparedness, chen2008coordination} offer emergency response solutions in different scenarios once a report is placed.

% Similarly, there are different priority tiers within DEC (Davidson Emergency Communication), with cases with lower priority tiers considered less emergent than those with higher tiers. Ideally, more resources are supposed to be assigned to cases with higher tiers. Although Metropolitan Nashville Government has deployed platforms like hubNashville for non-emergencies (e.g., noise violation, illegal parking), there are still a considerable amount of calls regarding non-emergencies coming into DEC, which would negatively impact the resources assigned to cases with higher tiers.

% In an effort to mitigate this issue, we developed an assistant system to help the dispatchers more efficiently handle non-emergency calls. The system not only suggests the most likely category out of provided non-emergency types based on current calls, but it also highlights essential context information that would be helpful to fulfill an internal case report for the dispatcher. In other words, our system consists of two main modules -- call dispatching and information extracting. The call dispatching module takes ongoing utterances from the caller as input and outputs the most likely category. The information extracting module tracks the potential answers to 9 critical questions based on the latest user utterance. Those 9 questions are identified through our manual review of over 10,000 audio recordings of 911/311 calls and are considered highly important to file internal cases. This module is designed to ensure that all 9 questions are answered confidently and accurately. Two modules work simultaneously and cooperatively.

% We formulate the call dispatching module a multi-layer text classification task. Unlike static traditional text classification tasks \cite{kowsari2019text, mironczuk2018recent, minaee2021deep, aggarwal2012survey}, which commonly apply softmax to obtain the distribution and track the highest ones. When reviewing our dataset, we find there is a great chance of one context carrying more than one incident type. E.g., ``... someone busted my car and my wallet is gone ...'', this context indicates there are two incidents that happened: ``someone busted my car'' -- damage to property and ``my wallet is gone'' -- lost or stolen property. Thus, we hierarchically segregate each incident type and detect if the current context carries one certain incident type information at each layer. 

% We formulate the call dispatching module a multi-layer text classification task. Unlike static traditional text classification tasks, during reviewing our dataset, we find there is a great chance of one context carrying more than one incident type. E.g., ``... someone busted my car and my wallet is gone ...'', this context indicates there are two incidents that happened: ``someone busted my car'' -- damage to property and ``my wallet is gone'' -- lost or stolen property. It is also possible for the caller to change the incident type as the conversation goes on. E.g., ``... I found a vehicle that has been parked in the garage since ... oh wait, it got flat tires and rusted bumper, looks like an abandoned'', this context first suggests that it could be an illegal parking case -- ``I found a vehicle that has been parked in the garage since'', however when the caller found ``it got flat tires and rusted bumper'', the context later switches to report an abandoned vehicle. Thus, we segregate each incident type and detect if the current context carries one certain incident type information at each layer. 

% We develop the information extracting module in a Q\&A-like fashion. Although existing Q\&A pipelines, such as DistilBERT-QA \cite{sanh2019distilbert} and BERT-QA \cite{devlin2018bert}, have achieved impressive results on benchmarks like SQuAD 2.0 \cite{rajpurkar2016squad}, the task of question-answering remains \textbf{challenging}. One reason for this challenge is that current QA models and pipelines are trained on open datasets with general purposes. However, in emergency response situations, there is a need for greater reliability and robustness, as the topics addressed are more detailed and task-specific than those used to train existing models. For instance, questions such as ``Can you provide more details about the suspect's description?'' and ``Please provide the address of the accident'' require a high level of precision. Furthermore, the existing metrics are not entirely suitable for the current task, as the ultimate objective is to provide as much critical information as possible that would be useful in downstream tasks, such as helping the police locate the accident. Lastly, unlike traditional QA systems, our system aims to minimize the number of questions posed to the caller by providing the possible answers with confidence checking to all potential questions during dispatching.

