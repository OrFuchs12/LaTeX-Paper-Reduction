

\section{The ETDA Algorithm}
\label{sec:etda:appendix}

\subsection{Algorithmic Description}




Inspired by \citet{kong2023player}, we further propose a more efficient explore-then-DA (ETDA) algorithm for many-to-one markets. 
Recall that each arm $a_j$ has a capacity $C_j$ under responsiveness. Denote $C_{\min} = \min_{j \in [K]} C_j$ as the minimum capacity among all arms and $j_{\min} \in \argmin_{j \in [K]} C_j$ as one arm that has the minimum capacity. 
The following algorithm runs with $N \le K\cdot C_{\min}$. 



Following ETDA, each player would first estimate an index in the first $N$ rounds (Line \ref{alg:etda:index}); then explore its unknown preferences in a round-robin way based on its index (Line \ref{alg:p2:start}-\ref{alg:p2:end}). After estimating a good preference ranking, it will follow DA with the player side proposing to find a player-optimal stable matching (Line \ref{alg:p3:start}-\ref{alg:p3:end}). 


\begin{algorithm}[thb!]
    \caption{explore-then-DA (ETDA, from view of $p_i$)}\label{alg:etda}
    \begin{algorithmic}[1]
    \STATE Input: player set $\cN$, arm set $\cK$ \label{alg:input}
    \STATE Initialize: $\hat{\mu}_{i,j}=0, T_{i,j}=0, \forall j\in[K]$
    \STATE For $t\in[N]$: estimate an index $\mathrm{Index}$ \label{alg:etda:index}
    \FOR{$\ell=1,2,\ldots $}\label{alg:p2:start}
        \FOR{$t=N+2^{\ell}-1,\ldots, N+2^{\ell}-1+2^{\ell}$} \label{alg:p2:learn:start} 
            \STATE  $A_i(t)=a_{(\mathrm{Index}+t-1)\%K+1}$ \label{alg:p2:learn:select}
            \STATE Observe $X_{i,A_i(t)}(t)$ and update $\hat{\mu}_{i,A_i(t)}$, $T_{i,A_i(t)}$ if $\bar{A}_i(t) = A_i(t) $ \label{alg:p2:learn:update}
        \ENDFOR\label{alg:p2:learn:end}
        \STATE $t = N+2^{\ell}+2^{\ell}$\label{alg:monitor:round}
        \STATE Compute $\ucb_{i,j}$ and $\lcb_{i,j}$ for each $j\in[K]$ \label{alg:p2:computeUCBLCB}
        \IF{$\exists \sigma$ such that $\lcb_{i,\sigma_{k}}>\ucb_{i,\sigma_{k+1}}$ for any $k\in[K-1]$ } \label{alg:p2:rank:start}
        \STATE $A_i(t) = a_{\mathrm{Index}}$
        \STATE Enter DA phase with $\sigma$ if $\cup_{j\in[K]} \set{\bar{A}^{-1}_{j}(t)}= \cN$ \label{alg:p2:enterP3}
        \ELSE 
        \STATE $A_i(t) = \emptyset$
        \ENDIF \label{alg:p2:rank:end}
    \ENDFOR\label{alg:p2:end} 
    \STATE //DA phase: initialize $s=1$ \label{alg:p3:start}
    \STATE Always propose $a_{\sigma_{s}}$; update $s=s+1$ if rejected \label{alg:p3:end}
    \end{algorithmic}
\end{algorithm}

 
At the $1$st round, all players would propose to arm $a_{j_{\min}}$. And $a_{j_{\min}}$ would accept $C_{\min}$ of them. Those accepted players get an index $1$. At the $2$nd round, players rejected at the $1$st round would still propose to $a_{j_{\min}}$ and other players would propose to any other arm except for $a_{j_{\min}}$. Among those who propose to $a_{j_{\min}}$,  $C_{\min}$ of them would then be accepted and get index $2$. Following this process, all players would get an index at the end of $N$th round as $C_{\min}>0$. 
 % (arms with $0$ capacity can be removed from the market)


Since only no more than $C_{\min}$ players have the same index, players sharing the same index can be successfully accepted when they propose to any arm. Thus all players can explore arms in a round-robin way based on their indices.  
The exploration phase is broken into several epochs: the $\ell$th epoch contains an exploration block of length $2^\ell$ and a communication round. During the exploration block (Line \ref{alg:p2:learn:start}-\ref{alg:p2:learn:end}), players would propose to arms according to their indices in a round-robin way. And at the communication round, players try to estimate all players' estimation status in the market. 
For this purpose, each player needs to first determine its own estimation status. Specifically, each player $p_i$ would first compute a confidence interval for each $\mu_{i,j}$ with UCB and LCB to be the upper and lower bound. 
If the confidence intervals of all arms are disjoint, the player can determine that its preference ranking has been estimated well and establish the estimated ranking $\sigma$ based on the estimated preference values (Line \ref{alg:p2:rank:start}-\ref{alg:p2:rank:end}). 
Players can also transmit their current estimation status to others through its action: if a player estimates its preferences well, it will propose to the arm labeled by its index; otherwise, it will give up the proposing chance in this round. 
Recall that all players would be accepted when proposing to the arm together with other players having the same index. Thus if a player observes that all players are successfully matched in this round, it can determine all players have estimated their unknown preferences well and would enter the DA phase to find a stable matching (Line \ref{alg:p2:enterP3}).

In the DA phase, all players would act based on the procedure of the offline DA algorithm with the player side proposing \cite{roth1984stability,roth1992two}. At the first round of the DA phase, all players propose to their most preferred arm according to their estimated rankings. And each arm $a_j$ would only accept the top $C_j$ highest players among those who propose it. 
In the following each round, each player still proposes to its most preferred arm among those who have not rejected it, and each arm accepts its most preferred $C_j$ players among those who propose to it.  
Until no rejection happens, all players would not change their actions in the following rounds. 
Since each arm can reject each player at most once, such a process would continue for at most $NK$ rounds before converging. If the estimated preference ranking of each player is correct, this process is equivalent to the offline DA algorithm with the player side proposing and the final matching is shown to be player-optimal \citep{roth1984stability,roth1992two}.












\subsection{Proof of Theorem \ref{thm:etda}}\label{sec:proof:etda}

Before the main proof, we first introduce some notations that will be used in the full Appendix. 
Let $T_{i,j}(t),\hat{\mu}_{i,j}(t)$ be the value of $T_{i,j},\hat{\mu}_{i,j}$ at the end of round $t$. Define the bad event 
$\cF = \set{\exists t\in[T], i\in[N],j\in[K], \abs{\hat{\mu}_{i,j}(t)-\mu_{i,j}} > \sqrt{\frac{6\log T}{ T_{i,j}(t)}} }$
to represent that some estimations are far from the real preference value at some round. 





% Define the bad event 
% $\cF = \set{\exists t\in[T], i\in[N],j\in[K], \abs{\hat{\mu}_{i,j}(t)-\mu_{i,j}} > \sqrt{\frac{6\log T}{ T_{i,j}(t)}} }$
% to represent that some estimations are inaccurate at some rounds. 

The player-optimal stable regret of each player $p_i$ by following our ETDA algorithm (Algorithm \ref{alg:etda}) satisfies
\begin{align}
    \overline{R}_i(T) &=\EE{\sum_{t=1}^T \bracket{\mu_{i,\overline{m}_i} - X_{i}(t)} } \notag \\
    &\le \EE{\sum_{t=1}^T \bOne{\bar{A}(t) \neq \overline{m}} \cdot \mu_{i,\overline{m}_i}} \notag \\
    &\le N \overline{\Delta}_{i,\max}+ \EE{\sum_{t=N+1}^T \bOne{\bar{A}(t) \neq \overline{m}} \mid  \urcorner \cF }\cdot \mu_{i,\overline{m}_i} + T\PP{\cF }\cdot \mu_{i,\overline{m}_i} \notag \\
    &\le N \mu_{i,\overline{m}_i}+ \EE{\sum_{t=N+1}^T \bOne{\bar{A}(t) \neq \overline{m}}\mid \urcorner \cF }\cdot \mu_{i,\overline{m}_i}  + 2NK\mu_{i,\overline{m}_i} \label{eq:dueto:bad} \\
    &\le N \mu_{i,\overline{m}_i}+\EE{ \sum_{\ell=1}^{\ell_{\max}  }\bracket{2^{\ell} +1} +NK }\cdot \mu_{i,\overline{m}_i} + 2NK\mu_{i,\overline{m}_i} \label{eq:dueto:phases:and:def_lmax}\\
    &\le {N \mu_{i,\overline{m}_i}}+  {\bracket{ \frac{192K\log T}{\Delta^2} + \log\bracket{ \frac{192K\log T}{\Delta^2}} }\cdot \mu_{i,\overline{m}_i}} +{\min\set{N^2, NK}\mu_{i,\overline{m}_i}} + {2NK\mu_{i,\overline{m}_i}} \label{eq:end} \\
    &= O\bracket{K\log T/\Delta^2} \notag \,,
\end{align}
where Eq.\eqref{eq:dueto:bad} comes from Lemma \ref{lem:cen:badevent}, Eq. \eqref{eq:dueto:phases:and:def_lmax} holds according to Algorithm \ref{alg:etda} and Lemma \ref{lem:phase3}, Eq. \eqref{eq:end} holds based on Lemma \ref{lem:phase2}.~\\ 
\newline

\begin{lemma}\label{lem:cen:badevent}
\begin{align*}
T\cdot \PP{\cF}  \le 2NK \,.
\end{align*}
\end{lemma}

\begin{proof}
\begin{align}
T\cdot \PP{\cF} &= T\cdot \PP{ \exists t\in[T], i\in[N],j\in[K]: \abs{\hat{\mu}_{i,j}(t)-\mu_{i,j}}>\sqrt{\frac{6\log T}{T_{i,j}(t)}}  } \notag \\
&\le T\cdot \sum_{t=1}^T \sum_{i\in[N]}\sum_{j\in[K]} \PP{ \abs{\hat{\mu}_{i,j}(t)-\mu_{i,j}}>\sqrt{\frac{6\log T}{T_{i,j}(t)}} } \notag\\
&\le T\cdot \sum_{t=1}^T \sum_{i\in[N]}\sum_{j\in[K]} \sum_{w = 1}^{t} \PP{T_{i,j}(t)=w, \abs{\hat{\mu}_{i,j}(t)-\mu_{i,j}}>\sqrt{\frac{6\log T}{T_{i,j}(t)}} } \notag\\ 
&\le T\cdot \sum_{t=1}^T \sum_{i\in[N]}\sum_{j\in[K]} t\cdot 2\exp\bracket{ -3\log T } \label{eq:upper:chernoff}\\ 
&\le 2NK\,. \notag 
\end{align}
where Eq.\eqref{eq:upper:chernoff} comes from Lemma \ref{lem:chernoff}. 
\end{proof}


\begin{lemma}\label{lem:phase3}
Conditional on $ \urcorner \cF$, 
at most $\min\set{N^2, NK}$ rounds are needed in phase 3 before $\sigma_{i,s} = \overline{m}_i$. In all of the following rounds, $s$ would not be updated and $p_i$ would always be successfully accepted by $\overline{m}_i$.
\end{lemma}

\begin{proof}
According to Lemma \ref{lem:cen:ucblcb} and Algorithm \ref{alg:etda}, when player $p_i$ enters in DA phase with $\sigma_i$, we have 
\begin{align*}
    \mu_{i,\sigma_{i,k}} > \mu_{i,\sigma_{i,k+1}}, \text{ for any $k\in[K-1]$ }\,.
\end{align*}
That's to say, $\sigma_i$ is just the real preference ranking of player $p_i$. 
Further, according to Lemma \ref{lem:phase2}, all players enter in the DA phase simultaneously. 
Above all, the procedure of the DA phase is equivalent to the procedure of the offline DA algorithm with the player proposing \citep{roth1984stability} as well as the players' real preference rankings. 
Thus at most $\min\set{N^2, NK}$ rounds are needed before each player $p_i$ successfully finds the optimal stable arm $\overline{m}_i$ (Lemma \ref{lem:DA:steps}). 
Once the optimal stable matching is reached, no rejection happens anymore and $s$ will not be updated. Thus each player $p_i$ would always be accepted by $\overline{m}_{i}$ in the following rounds. 
\end{proof}


\begin{lemma}\label{lem:phase2}
Conditional on $\urcorner \cF$, phase 2 will proceed in at most $\ell_{\max}$ epochs where 
\begin{align}
    \ell_{\max} = \min\set{\ell: \sum_{\ell'=1}^{\ell} 2^{\ell'} \ge 96K\log T/\Delta^2}\,, \label{eq:def:ellmax}
\end{align}
which implies that $\sum_{\ell'=1}^{\ell_{\max}} 2^{\ell'} \le 192K\log T/\Delta^2$ and $\ell_{\max} = \log \bracket{\log \bracket{192K\log T/\Delta^2} }$  since the epoch length grows exponentially. 
And all players will enter in the DA phase simultaneously at the end of the $\ell_{\max}$-th epoch. 
\end{lemma}

\begin{proof}
Since players propose to arms based on their distinct indices in a round-robin way and $C_j \ge C_{\min},\forall j\in[K]$, all players can be successfully accepted at each round during the exploration rounds. Thus at the end of the epoch $\ell_{\max}$ defined in Eq. \eqref{eq:def:ellmax}, it holds that $T_{i,j}\ge 96\log T/\Delta^2$ for any $i\in[N],j\in[K]$.  
 
According to Lemma \ref{lem:cen:pulltime} (where $S_i(t)=\cK$ for all player $p_i$ in this algorithm before entering in the DA phase), when $T_{i,j}\ge 96\log T/\Delta^2$ for any arm $a_j$, player $p_i$ finds a permutation $\sigma_i$ over arms such that $\lcb_{i,\sigma_{i,k}}>\ucb_{i,\sigma_{i,k+1}}$ for any $k\in[K-1]$.  


Thus, at the communication round of epoch $\ell_{\max}$, each player $p_i$ would propose to the arm with its distinct index. And each player can then observe that $\abs{ \cup_{i'\in[N]} \set{\bar{A}_{i'}(t)} }= N$. 
Based on this observation, all players would enter in the DA phase simultaneously at the end of the $\ell_{\max}$-th epoch. 
\end{proof}



\begin{lemma}\label{lem:DA:steps}

The offline DA algorithm stops in at most $\min\set{N^2, NK}$ steps. 
And the player-optimal stable arm of each player is the first $\min\set{N,K}$-ranked in its preference list. 
\end{lemma}
\begin{proof}
According to the offline DA algorithm procedure, once an arm has been proposed by players, this arm has a temporary partner.
Above all, once $N$ arms have been proposed, they will occupy $N$ players and the algorithm stops. So before the algorithm stops, at most $N-1$ arms have been previously proposed. 
Since players propose to arms one by one according to their preference list, a player can only be rejected by an arm at most once. Thus $N-1$ arms can reject at most $N$ players. The worst case is that one rejection happens at one step, resulting in the $N^2$ total time complexity. 
And since there are at most $K$ arms, the DA algorithm would stop in $\min\set{N^2, NK}$ steps. 

And since only $\min\set{N,K}$ arms have been proposed at the end, the final matched arm of each player must belong to the first $\min\set{N,K}$-ranked in its preference list. 

\end{proof}








\begin{lemma}\label{lem:cen:ucblcb}
Conditional on $\urcorner \cF$, $\ucb_{i,j}(t)<\lcb_{i,j'}(t)$ implies $\mu_{i,j}<\mu_{i,j'}$ for any time $t$. 
\end{lemma}

\begin{proof}
Conditional on $\urcorner \cF$, for each $i\in[N],j\in[K]$, we have
\begin{align*}
 \lcb_{i,j}(t) =\hat{\mu}_{i,j}(t)-\sqrt{\frac{6\log T}{ T_{i,j}(t)}}  \le \mu_{i,j} \le \hat{\mu}_{i,j}(t)+\sqrt{\frac{6\log T}{ T_{i,j}(t)}} = \ucb_{i,j}(t)\,.
\end{align*}
Thus if $\ucb_{i,j}(t)<\lcb_{i,j'}(t)$, there would be 
\begin{align*}
  \mu_{i,j} \le  \ucb_{i,j}(t) <\lcb_{i,j'}(t) \le \mu_{i,j'}\,.
\end{align*}
\end{proof}









\begin{lemma}\label{lem:cen:pulltime}
Let $T_i(t) = \min\set{T_{i,j}(t): j \in S_i(t)}$, $\bar{T}_i = \frac{96\log T}{\Delta^2}$. Conditional on $\urcorner \cF$, if $T_i(t) > \bar{T}_i$, we have $\ucb_{i,j}(t)< \lcb_{i,j'}(t)$ for any $j,j'\in S_{i}(t)$ with $\mu_{i,j}<\mu_{i,j'}$. 
\end{lemma} 

\begin{proof}
By contradiction, suppose there exists pair $j,j' \in S_{i}(t)$ with $\mu_{i,j}<\mu_{i,j'}$ such that $\ucb_{i,j}(t)\ge \lcb_{i,j'}(t)$. Conditional on $\urcorner \cF$, we have 
\begin{align*}
 \mu_{i,j'}- 2\sqrt{\frac{6\log T}{{T}_{i}(t)}} \le \lcb_{i,j'}(t) \le \ucb_{i,j}(t) \le \mu_{i,j}+2\sqrt{\frac{6\log T}{{T}_{i}(t)}} \,.
\end{align*}
We can then conclude $\Delta_{i,j,j'} \le 4 \sqrt{\frac{6\log T}{{T}_{i}(t)}}$ and thus ${T}_{i}(t) \le \frac{96 \log T}{\Delta^2}$, which contradicts $T_i(t) > \bar{T}_i$. 
\end{proof}



