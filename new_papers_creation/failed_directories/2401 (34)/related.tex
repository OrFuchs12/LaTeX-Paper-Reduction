%!TEX root =  main.tex
\section{Related Work}\label{sec:related}

The matching market model characterizes many applications such as labor market \citep{roth1984evolution}, house allocation \citep{abdulkadirouglu1999house}, college admission and marriage problems \citep{gale1962college}, among which the  many-to-one setting is very common and widely studied \citep{roth1992two}. 
Responsiveness and substitutability are most generally known conditions to guarantee the existence of a stable matching \citep{kelso1982job,roth1984stability,roth1992two,abdulkadirouglu2005college} and the deferred acceptance (DA) algorithm is a classical offline algorithm to find a stable matching under this property \citep{kelso1982job,roth1984stability}. 


For simplicity, we refer to the setting where one-side participants (players) have unknown preferences as the online setting. 
This line of works relies on the technique of MAB, a classical online learning framework with a single player and $K$ arms \citep{lattimore2020bandit}. 
The explore-then-commit (ETC) \citep{garivier2016explore}, upper confidence bound (UCB) \citep{auer2002finite}, Thompson sampling (TS) \citep{agrawal2012analysis} and elimination \citep{auer2010ucbelimination} algorithms are common strategies to obtain $O(K\log T/\Delta)$ regret where $\Delta$ is the minimum suboptimality gap among arms. 

Multiple-player MAB (MP-MAB) generalizes the standard MAB problem by considering more than one player in the environment. 
In this setting, each player selects an arm at each time and a player will receive nothing if it collides with others by selecting the same arm. 
The MP-MAB problem has been studied in both homogeneous and heterogeneous settings. The former assumes different players share the same preference over arms \citep{rosenski2016multi,bubeck2021cooperative} and the latter allows players to have different preferences \citep{bistritz2018distributed,shi2021heterogeneous}. 
Both settings aim to minimize the collective cumulative regret of all players. 
% which is compared with the maximum collective reward received by all players. 


The matching market problem is different from above MP-MAB framework by considering that each arm also has a preference ranking over players.  
When multiple players select one arm, the player preferred most by the arm would not be collided and would gain a reward.   
The objective in this setting is to learn a stable matching and minimize the stable regret for players. 
\citet{das2005two} first introduce the bandit learning problem in one-to-one matching markets and explore the empirical performances of the proposed algorithms in the market where all participants on each side have the same preferences. 
Recently, \citet{liu2020competing} study a variant of the problem and present the first theoretical guarantees in a centralized setting where a central platform assigns allocations to players in each round. 
Later,  \citet{sankararaman2021dominate}, \citet{basu21beyond} and \citet{maheshwari2022decentralized} successively study this setting in a decentralized manner where players make their own decisions without a central platform. 
These works additionally assume the preferences of participants satisfy some constraints to ensure the uniqueness of the stable matching.  
For a general decentralized one-to-one market, \citet{liu2021bandit} and \citet{kong2022thompson} propose UCB and TS-type algorithms with guarantees for player-pessimal stable regret, respectively. 
Until recently, the theoretical analysis for the stronger player-optimal stable regret objective has been derived \citep{zhang2022matching,kong2023player}. 

Due to the generality when modeling real applications, \citet{wang2022bandit} start to study the bandit problem in many-to-one settings. They assume arms have responsive preferences and derive algorithms both in centralized and decentralized settings. For the decentralized setting, they only guarantee the player-pessimal stable regret with the upper bound $O(N^5K^2\log^2 T/(\varepsilon^{N^4}\Delta^2))$ where $\varepsilon\in(0,1)$ is a hyper-parameter. 
Please see Table \ref{table:comparison} for a comprehensive comparison among these works. 

% \shuai{introduce table 1 somewhere. table 1 does not introduce N,K,Delta}