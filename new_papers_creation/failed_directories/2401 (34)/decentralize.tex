\section{Online DA Algorithm for Substitutability }\label{sec:decen}
% Preferences

In many-to-one markets, arms may have combinatorial preferences over groups of players, which may not be well characterized by responsiveness. In this setting, we consider the markets with substitutability, which is one of the most common and general conditions that ensure the existence of a stable matching and is defined below. 


\begin{definition}{(Substitutability)}\label{def:substi}
The preference of arm $a_j$ satisfy substitutability if for any player set $P\subseteq \cN$ that contains $p_i$ and $p_{i'}$, $p_i \in \ch_j(P\setminus \set{p_{i'}})$when $p_i \in \ch_j(P)$.
\end{definition}

The above property states that arm $a_j$ keeps accepting player $p_i$ when other players become unavailable. This is the sense that $a_j$ regards players in a team as substitutes rather than complementary individuals (in which case the arm may give up accepting the player when others become unavailable). 
Such a phenomenon appears in many real applications and covers responsiveness as proved below. 


\begin{remark} 
Select a player set $P\subseteq \cN$ which contains $p_{i}$ and $p_{i'}$. 
Suppose $p_i \in \ch_j(P)$, i.e., $p_i$ is one of the $C_j$ highest-ranked players in $P$.  
Then when the available set becomes $P\setminus\set{p_{i'}}$, 
$p_i$ is still one of the $C_j$ highest-ranked players, i.e., $p_i \in \ch_j(P\setminus\set{p_{i'}})$.
\end{remark}


The substitutability property is more general than responsiveness as arms' preferences can have combinatorial structures. The following is an example that satisfies substitutability but not responsiveness \cite{roth1992two}. 

\begin{example}
There are $3$ players and $2$ arms, i.e., $\cN=\set{p_1,p_2,p_3}, \cK=\set{a_1, a_2}$. 
The arms' preference rankings over subsets of players are
\begin{itemize}
    \item $a_1: \set{p_1,p_2},\set{p_1,p_3},\set{p_2,p_3},\set{p_3},\set{p_2},\set{p_1}$.
    \item $a_2: \set{p_3},\emptyset$.
\end{itemize}
That is to say, $\ch_j(P)$ is the subset that ranks highest among all subsets listed above that only contain players in $P$. Taking the preferences of $a_2$ as an example, when $p_3 \in P$, then $\ch_j(P)=\set{p_3}$; otherwise, $\ch_j(P)=\emptyset$. 
\end{example}


For many-to-one markets with substitutable preferences, we propose an online deferred acceptance (ODA) algorithm (presented in Algorithm \ref{alg:decen}). ODA is inspired by the idea of the DA algorithm with the arm side proposing, which finds a player-pessimal stable matching when players know their preferences. 
Specifically, the DA algorithm with the arm proposing proceeds in several steps. 
In the first step, each arm proposes to its most preferred subset among all players. 
Each player would reject all but the most preferred arm among those who propose it. 
In the following each step, each arm still proposes to its most preferred subset of players among those who have not rejected it and each player rejects all but the most preferred one among those who propose to it. This process stops when no rejection happens and the final matching is the player-pessimal stable matching \citep{kelso1982job,roth1992two}. 


\begin{algorithm}[thb!]
    \caption{online deferred acceptance (from view of $p_i$)}\label{alg:decen}
    \begin{algorithmic}[1]
    \STATE Input: player set $\cN$, arm set $\cK$ \label{alg:decen:input}\\
        \STATE Initialize: $P_{i,j}=\cN,  \hat{\mu}_{i,j}=0, T_{i,j}=0$ for each $j\in [K]$; $S_i(1)=\set{a_j\in \cK: p_i \in \ch_j(P_{i,j})}$ \label{alg:decen:initial} 
        \FOR{each round $t=1,2,\cdots$}
            \STATE Select $A_i(t)\in S_i(t)$ in a round-robin way \label{alg:decen:roundrobin}
            \STATE Update $\hat{\mu}_{i,\bar{A}_i(t)}$ and $T_{i,\bar{A}_i(t)}$ if $\bar{A}_i(t) = A_i(t) \neq \emptyset$
        \label{alg:decen:updatemuT}
            \STATE $S_i(t+1)=S_i(t)$
            \FOR{$a_j \in S_{i}(t)$ and $\ucb_{i,j}(t) < \max_{a_{j'} \in S_{i}(t)} \lcb_{i,j'}(t)$}\label{alg:decen:delete:suboptimal:condition}
                	\STATE $S_i(t+1) = S_i(t+1)\setminus \set{a_j}$ \label{alg:decen:delete:suboptimal}
            \ENDFOR
                \IF{$t\ge 2$ and $\forall p_{i'}\in \cN: \bar{A}_{i'}(t)=\bar{A}_{i'}(t-1)$}\label{alg:decen:update:available:start}
                    \STATE $\forall j\in[K]$, $P_{i,j} = P_{i,j}\setminus\set{p_{i'}: \bar{A}_{i'}(t)\neq j, \exists t'<t-1 \text{ s.t. } \bar{A}_{i'}(t')=j }$\label{alg:decen:update:available}
                    \STATE $S_{i}(t+1) = \set{a_j: p_i \in \ch_j(P_{i,j}) }$ \label{alg:decen:update:plausible}
                \ENDIF \label{alg:decen:update:available:end}
    \ENDFOR
    \end{algorithmic}
\end{algorithm}




The ODA algorithm is designed with the guidance of this procedure but players decide which arm to select in each round. 
Specifically, each player $p_i$ needs to record the available player set $P_{i,j}$ for each arm $a_j$, which consists of players who have not rejected arm $a_j$ and is initialized as the full player set $\cN$. 
Then if a player $p_i$ is in the choice set of $a_j$ when the set $P_{i,j}$ of players is available, i.e., $p_{i} \in \ch_j(P_{i,j})$,  $p_i$ would be accepted if it proposes to $a_j$ together with other players in $P_{i,j}$. 
The main purpose of the algorithm is to let players wait for this opportunity to choose arms that will successfully accept them. 

% , rather than blindly proposing to arms at the beginning and dealing with the frequent conflicts.


Each player $p_i$ can further construct the plausible set $S_i$ to contain those arms that may successfully accept it, i.e., $S_i = \set{ a_j: p_i \in \ch_j(P_{i,j})}$.  
Here for simplicity, we additionally assume each player $p_i$ knows whether $p_i \in \ch_j(P)$ for each possible $P\subseteq \cN$. This assumption is only used for clean analysis and the algorithm can also be generalized to the case where this information is unavailable by letting players in $P_{i,j}$ pull $a_j$ and observe whether it is accepted. Since arms know their own preferences and conflicts are deterministically resolved, at most $2^N$ rounds are needed to obtain this information.
Apart from $P_{i,j}$ and $S_i$, each player $p_i$ also maintains $\hat{\mu}_{i,j}$ and $T_{i,j}$ to record the estimated value for $\mu_{i,j}$ and the number of its observations. At the beginning, both values are initialized to $0$. 


In each round $t$, each player $p_i$ proposes to the arm $a_j$ in the plausible set $S_i(t)$ in a round-robin way (Line \ref{alg:decen:roundrobin}). If they are successfully matched with each other (Line \ref{alg:decen:updatemuT}), $p_i$ would update the corresponding $\hat{\mu}_{i,j}, T_{i,j}$ as Section \ref{sec:aetda}. 
When the $\ucb$ of $a_j$ is even lower than the $\lcb$ of other plausible arms, $a_j$ is considered to be less preferred. 
In this case, the final stable arm of player $p_i$ must be more preferred than $a_j$ and thus there is no need to select $a_j$ anymore (Line \ref{alg:decen:delete:suboptimal}). 



Recall that the plausible sets of players are constructed based on the available sets for arms. 
To ensure each player successfully be accepted by arms in their own plausible set, all players need to keep the available sets for arms updated in sync. 
With the awareness that players always select plausible arms in a round-robin way, once $p_i$ observes that all players focus on the same arm in the recent two rounds, it believes all players have determined the most preferred one. 
In this way, $p_i$ would update the available set $P_{i,j}$ for each arm $a_j$ by deleting players who do not consider $a_j$ as stable arms anymore (Line \ref{alg:decen:update:available}).
Since all players have the same observations, the update times of $P_{i,j}$ would be the same. 
Such a stage in which all players determine the most preferred arm in the plausible set can just be regarded as a step of the offline DA algorithm (with the arm side proposing) where each player rejects all but the most preferred one among those who propose to it. 
Thus the update times of $P_{i,j}$ just divide the total horizon into several stages with each corresponding to a step of DA. 



\subsection{Theoretical Analysis}\label{sec:main:analysis}

We first provide the regret bound for Algorithm \ref{alg:decen}. 


\begin{theorem}\label{thm:decen}
   Following Algorithm \ref{alg:decen}, the player-pessimal stable regret of each player $p_i$ satisfies
    \begin{align}
        \underline{R}_i(T) \le 
        % NK \bracket{\frac{128\log T}{\Delta^2}+2+ \frac{\pi^2}{3}} \mu_{i,\underline{m}_i}  =
        O(NK\log T/\Delta^2) \,.
    \end{align}
\end{theorem}



Apart from the regret guarantee, we also discuss the incentive compatibility of the algorithm. 


\begin{theorem}\label{thm:decen:strategy}{(Incentive Compatibility)}
Suppose that all of the other players follow the ODA algorithm, then a single player $p_i$ has no incentive to select arms beyond $S_i$.  
And if $p_i$ misreports its estimated optimal arm in $S_i$ towards the optimal manipulation for itself, i.e., a manipulation under which the DA algorithm would match $p_i$ with an arm has a higher ranking than that under other manipulations, all of the other players would also benefit from this behavior. 
\end{theorem}


How to define arms' preferences over combinatorial sets of players is an interesting question. 
Our method provides the first attempt. 
The dependence on $2^N$ is the cost of learning arms' combinatorial preferences. 
Removing such dependence would be more preferred. 
But as a preliminary step for combinatorial preferences, understanding algorithmic performance under more comprehensive information conditions is pivotal as it lays the groundwork for further exploration in more generalized settings.


Our considered setting generalizes previously studied one-to-one and many-to-one markets with responsiveness.
For these two reduced settings, the complexity to learn arms' preferences is just $KN^2$ by letting every two players propose to an arm and observe who is more preferred. Though stated in a more general setting, we want to emphasize that such an algorithm achieves a significant improvement from $O(N^5K^2 \log^2 T/(\varepsilon^{N^4}\Delta^2))$ to $O(NK\log T/\Delta^2)$ compared with \citet{wang2022bandit}. 

Due to the space limit, the proofs of Theorem \ref{thm:decen} and Theorem \ref{thm:decen:strategy} are provided in Appendix \ref{sec:oda:appendix}.  










% \paragraph{Known arms' preferences. }
% To the best of our knowledge, Theorem \ref{thm:decen} is the first theoretical result for online learning in many-to-one matching markets with combinatorial substitutable preferences. 
% Our algorithm not only works in more general markets but also achieves a significant improvement in the recovered many-to-one setting with responsiveness \citep{wang2022bandit}. 
% Note that in the recovered many-to-one markets with responsive preferences, to get the knowledge of whether $p_i\in \ch_j(P_{i,j})$ for every player $p_i$, arm $a_j$ and possible set $P_{i,j}\subseteq \cN$, only additional $N^2K$ rounds are needed by letting every two players propose to each arm to check who is more preferred, which is only a constant term.
% This knowledge is also used in previous decentralized many-to-one markets \citep{wang2022bandit}. 
% Under the exact same assumptions of knowing arms' preferences and observing their matched players as \citet{wang2022bandit}, our algorithm achieves a significant improvement from $O(N^5K^2 \log^2 T/(\varepsilon^{N^4}\Delta^2))$ to $O(NK\log T/\Delta^2)$.

 



% we provide a proof sketch of Theorem \ref{thm:decen} in Appendix \ref{sec:proof:sketch} and the detailed proof is deferred to Appendix \ref{sec:proof:full}. 

















