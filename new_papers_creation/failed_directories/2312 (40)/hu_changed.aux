\relax 
\bibstyle{aaai24}
\citation{DBLP:journals/corr/VilnisM14}
\citation{DBLP:conf/iclr/PereyraTCKH17,DBLP:conf/iclr/MiyatoDG17,gunel2020supervised}
\citation{DBLP:conf/iclr/OhMPRSG19,DBLP:conf/iccv/ShiJ19}
\citation{DBLP:conf/iclr/MahabadiBH21,DBLP:conf/emnlp/0001HDZJMS22}
\citation{DBLP:journals/corr/KingmaW13,DBLP:conf/iclr/AlemiFD017,DBLP:conf/iclr/HigginsMPBGBML17,DBLP:journals/entropy/Fischer20,DBLP:conf/cvpr/AnJC23}
\citation{tishby1999information,tishby2015deep}
\citation{DBLP:journals/jsait/GoldfeldP20}
\citation{DBLP:journals/corr/KingmaW13}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{2}{Comparison of our SPC with existing deterministic embedding and probabilistic embedding methods.}{}{}}
\citation{DBLP:conf/iclr/AlemiFD017,DBLP:journals/entropy/Fischer20,DBLP:conf/cvpr/AnJC23}
\citation{achille2018information,amjad2019learning}
\citation{DBLP:conf/emnlp/BarbieriCAN20}
\citation{DBLP:conf/semeval/BarbieriCRABBPS18}
\citation{DBLP:conf/semeval/MohammadBSK18}
\citation{DBLP:conf/semeval/BasileBFNPPRS19}
\citation{DBLP:conf/semeval/HeeLH18}
\citation{DBLP:conf/semeval/ZampieriMNRFK19}
\citation{DBLP:conf/semeval/RosenthalRNS14}
\citation{DBLP:conf/semeval/MohammadKSZC16}
\citation{scherer1994evidence}
\citation{DBLP:conf/acl/PoriaHMNCM19}
\citation{DBLP:conf/acl/DemszkyMKCNR20}
\citation{DBLP:conf/semeval/CerDALS17}
\citation{DBLP:conf/semeval/RothAS22}
\citation{DBLP:conf/naacl/DevlinCLT19}
\citation{DBLP:journals/corr/abs-1907-11692}
\citation{cortes1995support}
\citation{joulin2017bag}
\citation{hochreiter1997long}
\citation{DBLP:conf/iclr/PereyraTCKH17}
\citation{DBLP:conf/iclr/MiyatoDG17}
\citation{gunel2020supervised}
\citation{khosla2020supervised}
\citation{DBLP:conf/iclr/AlemiFD017,DBLP:conf/iclr/MahabadiBH21}
\citation{tishby2015deep}
\citation{DBLP:conf/icml/BelghaziBROBHC18}
\citation{DBLP:conf/cvpr/AnJC23}
\citation{DBLP:conf/emnlp/BarbieriCAN20}
\citation{kim2015t}
\citation{DBLP:journals/corr/KingmaB14}
\citation{DBLP:conf/emnlp/BarbieriCAN20}
\citation{DBLP:conf/emnlp/BarbieriCAN20}
\newlabel{tab:datasets}{{1}{4}{The statistics of all datasets. }{}{}}
\newlabel{sec:eval}{{}{4}{}{}{}}
\newlabel{code}{{2}{4}{}{}{}}
\newlabel{tab:classification}{{2}{5}{Classification evaluation (\%) on 10 benchmark datasets. $^\dag  $ means the results are from \citet  {DBLP:conf/emnlp/BarbieriCAN20}. For other methods, we run five random seeds and report the average result on test sets. BERT and RoBERTa are the model backbones for deep representation learning technologies. Best results for each dataset are highlighted in bold. $^{*}$ represents statistical significance over state-of-the-art scores under the $t$ test ($p < 0.05$). }{}{}}
\newlabel{tab:Regression}{{3}{5}{Regression evaluation (\%) on 2 benchmark datasets with RoBERTa backbone. For each method, we run five random seeds and report the average result on test sets. $^{*}$ represents statistical significance over state-of-the-art scores under the $t$ test ($p < 0.05$). }{}{}}
\citation{DBLP:conf/acl/0001BWZH23}
\citation{DBLP:conf/iclr/PereyraTCKH17}
\citation{DBLP:conf/iclr/MiyatoDG17}
\citation{gunel2020supervised,DBLP:conf/acl/0001BWZH23}
\citation{DBLP:journals/corr/VilnisM14}
\citation{DBLP:conf/iclr/OhMPRSG19,DBLP:conf/iccv/ShiJ19,chang2020data,DBLP:conf/iclr/RameC21}
\citation{DBLP:conf/iclr/MahabadiBH21,DBLP:conf/iclr/WangWCGJLL21,DBLP:conf/emnlp/0001HDZJMS22}
\citation{DBLP:journals/corr/KingmaW13,DBLP:conf/iclr/AlemiFD017,DBLP:conf/iclr/HigginsMPBGBML17,DBLP:journals/entropy/Fischer20,DBLP:conf/cvpr/AnJC23}
\citation{tishby1999information,tishby2015deep}
\citation{DBLP:conf/iclr/AlemiFD017}
\citation{DBLP:conf/icml/BelghaziBROBHC18}
\citation{DBLP:conf/cvpr/RagonesiVCM21}
\citation{DBLP:journals/entropy/Fischer20}
\citation{DBLP:conf/iclr/RameC21}
\citation{DBLP:journals/corr/KingmaW13}
\citation{DBLP:conf/iclr/HigginsMPBGBML17}
\citation{DBLP:conf/emnlp/0001HDZJMS22}
\citation{DBLP:conf/cvpr/AnJC23}
\newlabel{tab:abla}{{4}{6}{Ablation results (\%) on classification tasks. We experiment with RoBERTa backbone. }{}{}}
\newlabel{fig:training}{{2}{6}{Results of different methods against different sizes of training set with RoBERTa backbone.}{}{}}
\newlabel{tab:ood-performance}{{5}{6}{Out-of-distribution evaluation results (\%). For instance, ``EmotionEval $\rightarrow $ GoEmotions" refers to training the model on the training set of EmotionEval and making predictions using the test set of GoEmotions. We experiment with RoBERTa backbone. We run five random seeds and report the average results on test sets of target domains. Labels that do not appear in the training corpus are not evaluated. }{}{}}
\newlabel{exp:noise}{{6}{7}{Results (\%) against different ratios of label noises. RoBERTa is applied as the model backbone. }{}{}}
\newlabel{fig:struct}{{3}{7}{Clustering performances of the output representations learned by different optimization objectives. Silhouette coefficient (SC) and adjusted rand index (ARI) are used to measure data-related and task-related clustering abilities, respectively. We experiment with RoBERTa backbone.}{}{}}
\bibdata{aaai24}
\citation{DBLP:conf/semeval/BarbieriCRABBPS18}
\citation{DBLP:conf/semeval/MohammadBSK18}
\citation{DBLP:conf/semeval/BasileBFNPPRS19}
\citation{DBLP:conf/semeval/HeeLH18}
\citation{DBLP:conf/semeval/ZampieriMNRFK19}
\citation{DBLP:conf/semeval/RosenthalRNS14}
\citation{DBLP:conf/semeval/MohammadKSZC16}
\citation{scherer1994evidence}
\citation{DBLP:conf/acl/PoriaHMNCM19}
\citation{DBLP:conf/acl/HuWH20}
\citation{DBLP:conf/acl/DemszkyMKCNR20}
\citation{DBLP:conf/semeval/CerDALS17}
\citation{DBLP:conf/semeval/RothAS22}
\newlabel{tab:spc}{{7}{9}{Hyperparameters of the proposed SPC with RoBERTa backbone on classification tasks.}{}{}}
\newlabel{tab:spc1}{{8}{9}{Hyperparameters of the proposed SPC with RoBERTa backbone on regression tasks.}{}{}}
\newlabel{fig:para}{{4}{9}{Performance against different trade-off weights $\beta $ of probabilistic coding for classification tasks. The experiments are conducted based on RoBERTa backbone. The grey line represents the results of CE baseline.}{}{}}
\newlabel{fig:para_gam}{{5}{10}{Performance of the optimal trade-off weight $\gamma $ for classification tasks. We experiment with RoBERTa backbone. The Y-axis refers to relative improvements between SPC and its variant SPC w/o Structured. }{}{}}
\gdef \@abspage@last{10}
