@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

inproceedings{wagenmaker2020active,
  title={Active learning for identification of linear dynamical systems},
  author={Wagenmaker, Andrew and Jamieson, Kevin},
  booktitle={Conference on Learning Theory},
  pages={3487--3582},
  year={2020},
  organization={PMLR}
}

@article{blanchini1999set,
  title={Set invariance in control},
  author={Blanchini, Franco},
  journal={Automatica},
  volume={35},
  number={11},
  pages={1747--1767},
  year={1999},
  publisher={John Wiley \& SonsElsevier}
}

@phdthesis{kerrigan2001robust,
  title={Robust constraint satisfaction: Invariant sets and predictive control},
  author={Kerrigan, Eric Colin},
  year={2001},
  school={University of Cambridge UK}
}

@article{blanchini1994ultimate,
  title={Ultimate boundedness control for uncertain discrete-time systems via set-induced Lyapunov functions},
  author={Blanchini, Franco},
  journal={IEEE Transactions on automatic control},
  volume={39},
  number={2},
  pages={428--433},
  year={1994},
  publisher={IEEE}
}

@inproceedings{dorea1996computation,
  title={Computation of maximal admissible sets of constrained linear systems},
  author={D{\'o}rea, Carlos ET and Hennet, Jean-Claude},
  booktitle={Proc. of 4th IEEE Med. Symposium},
  pages={286--291},
  year={1996}
}

@inproceedings{li2017provably,
  title={Provably optimal algorithms for generalized linear contextual bandits},
  author={Li, Lihong and Lu, Yu and Zhou, Dengyong},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017},
}

@inproceedings{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018},
}

@article{filippi2010parametric,
  title={Parametric bandits: The generalized linear case},
  author={Filippi, Sarah and Cappe, Olivier and Garivier, Aur{\'e}lien and Szepesv{\'a}ri, Csaba},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2010}
}

@inproceedings{faury2020improved,
  title={Improved optimistic algorithms for logistic bandits},
  author={Faury, Louis and Abeille, Marc and Calauz{\`e}nes, Cl{\'e}ment and Fercoq, Olivier},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{wachi2021safe,
  title={Safe Policy Optimization with Local Generalized Linear Function Approximations},
  author={Wachi, Akifumi and Wei, Yunyue and Sui, Yanan},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{amani2021safe,
  title={Safe reinforcement learning with linear function approximation},
  author={Amani, Sanae and Thrampoulidis, Christos and Yang, Lin},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021},
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for {Markov} decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{auer2007logarithmic,
  title={Logarithmic online regret bounds for undiscounted reinforcement learning},
  author={Auer, Peter and Ortner, Ronald},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2007}
}

@article{bura2022dope,
  title={DOPE: Doubly optimistic and pessimistic exploration for safe reinforcement learning},
  author={Bura, Archana and HasanzadeZonuzy, Aria and Kalathil, Dileep and Shakkottai, Srinivas and Chamberland, Jean-Francois},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@inproceedings{NIPS2011_e1d5be1c,
 author = {Abbasi-yadkori, Yasin and P\'{a}l, D\'{a}vid and Szepesv\'{a}ri, Csaba},
 booktitle = {Neural Information Processing Systems (NeurIPS)},
 title = {Improved Algorithms for Linear Stochastic Bandits},
 year = {2011}
}

@inproceedings{bennett2023provable,
  title={Provable Safe Reinforcement Learning with Binary Feedback},
  author={Bennett, Andrew and Misra, Dipendra and Kallus, Nathan},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTAT)},
  year={2023}
}

@article{dulac2021challenges,
  title={Challenges of real-world reinforcement learning: definitions, benchmarks and analysis},
  author={Dulac-Arnold, Gabriel and Levine, Nir and Mankowitz, Daniel J and Li, Jerry and Paduraru, Cosmin and Gowal, Sven and Hester, Todd},
  journal={Machine Learning},
  pages={1--50},
  year={2021},
  publisher={Springer}
}

@article{amodei2016concrete,
  title={Concrete problems in {AI} safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}

@article{rockafellar2000optimization,
  title={Optimization of conditional value-at-risk},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav and others},
  journal={Journal of risk},
  volume={2},
  pages={21--42},
  year={2000},
  publisher={Citeseer}
}

@inproceedings{wachi2020safe,
  title={Safe reinforcement learning in constrained Markov decision processes},
  author={Wachi, Akifumi and Sui, Yanan},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@article{tessler2018reward,
  title={Reward constrained policy optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  journal={arXiv preprint arXiv:1805.11074},
  year={2018}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017}
}

@InProceedings{pmlr-v119-yang20h,
    title = {Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
    author = {Yang, Lin and Wang, Mengdi},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2020}
}

@inproceedings{turchetta2016safe,
  title={Safe exploration in finite {Markov} decision processes with {Gaussian} processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2016}
}

@inproceedings{stooke2020responsive,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{ames2019control,
  title={Control barrier functions: Theory and applications},
  author={Ames, Aaron D and Coogan, Samuel and Egerstedt, Magnus and Notomista, Gennaro and Sreenath, Koushil and Tabuada, Paulo},
  booktitle={European control conference (ECC)},
  year={2019},
}

@inproceedings{cheng2019end,
  title={End-to-end safe reinforcement learning through barrier functions for safety-critical continuous control tasks},
  author={Cheng, Richard and Orosz, G{\'a}bor and Murray, Richard M and Burdick, Joel W},
  booktitle={AAAI conference on artificial intelligence (AAAI)},
  year={2019}
}

@inproceedings{roderick2021provably,
  title={Provably safe PAC-MDP exploration using analogies},
  author={Roderick, Melrose and Nagarajan, Vaishnavh and Kolter, Zico},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTAT)},
  year={2021},
}

@article{ok2018exploration,
  title={Exploration in structured reinforcement learning},
  author={Ok, Jungseul and Proutiere, Alexandre and Tranos, Damianos},
  journal={Neural Information Processing Systems (NeurIPS)},
  volume={31},
  year={2018}
}

@inproceedings{koller2018learning,
  title={Learning-based model predictive control for safe exploration},
  author={Koller, Torsten and Berkenkamp, Felix and Turchetta, Matteo and Krause, Andreas},
  booktitle={IEEE conference on decision and control (CDC)},
  year={2018}
}

@article{lin2021perturbation,
  title={Perturbation-based regret analysis of predictive control in linear time varying systems},
  author={Lin, Yiheng and Hu, Yang and Shi, Guanya and Sun, Haoyuan and Qu, Guannan and Wierman, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5174--5185},
  year={2021}
}

@article{wachi2023safe,
  title={Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms},
  author={Wachi, Akifumi and Hashimoto, Wataru and Shen, Xun and Hashimoto, Kazumune},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{tsukamoto2021contraction,
  title={Contraction theory for nonlinear stability analysis and learning-based control: A tutorial overview},
  author={Tsukamoto, Hiroyasu and Chung, Soon-Jo and Slotine, Jean-Jaques E},
  journal={Annual Reviews in Control},
  volume={52},
  pages={135--169},
  year={2021},
  publisher={Elsevier}
}