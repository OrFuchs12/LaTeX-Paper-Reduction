\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Alegre et~al.(2022)Alegre, Felten, Talbi, Danoy, Now{\'e}, Bazzan, and da~Silva}]{Alegre+2022bnaic}
Alegre, L.~N.; Felten, F.; Talbi, E.-G.; Danoy, G.; Now{\'e}, A.; Bazzan, A. L.~C.; and da~Silva, B.~C. 2022.
\newblock {MO-Gym}: A Library of Multi-Objective Reinforcement Learning Environments.
\newblock In \emph{Proceedings of the 34th Benelux Conference on Artificial Intelligence BNAIC/Benelearn 2022}.

\bibitem[{Ayer, Alagoz, and Stout(2012)}]{ayer2012or}
Ayer, T.; Alagoz, O.; and Stout, N.~K. 2012.
\newblock OR Forumâ€”A POMDP approach to personalize mammography screening decisions.
\newblock \emph{Operations Research}, 60(5): 1019--1034.

\bibitem[{Barrett and Narayanan(2008)}]{barrett2008learning}
Barrett, L.; and Narayanan, S. 2008.
\newblock Learning all optimal policies with multiple criteria.
\newblock In \emph{Proceedings of the 25th international conference on Machine learning}, 41--47.

\bibitem[{Baucum et~al.(2022)Baucum, Khojandi, Vasudevan, and Davis}]{baucum2022adapting}
Baucum, M.; Khojandi, A.; Vasudevan, R.; and Davis, R. 2022.
\newblock Adapting Reinforcement Learning Treatment Policies Using Limited Data to Personalize Critical Care.
\newblock \emph{INFORMS Journal on Data Science}, 1(1): 27--49.

\bibitem[{Breton et~al.(2020)Breton, Kanapka, Beck, Ekhlaspour, Forlenza, Cengiz, Schoelwer, Ruedy, Jost, Carria et~al.}]{breton2020randomized}
Breton, M.~D.; Kanapka, L.~G.; Beck, R.~W.; Ekhlaspour, L.; Forlenza, G.~P.; Cengiz, E.; Schoelwer, M.; Ruedy, K.~J.; Jost, E.; Carria, L.; et~al. 2020.
\newblock A randomized trial of closed-loop control in children with type 1 diabetes.
\newblock \emph{New England Journal of Medicine}, 383(9): 836--845.

\bibitem[{Capponi, Olafsson, and Zariphopoulou(2022)}]{capponi2022personalized}
Capponi, A.; Olafsson, S.; and Zariphopoulou, T. 2022.
\newblock Personalized robo-advising: Enhancing investment through client interaction.
\newblock \emph{Management Science}, 68(4): 2485--2512.

\bibitem[{Dempster, Laird, and Rubin(1977)}]{dempster1977maximum}
Dempster, A.~P.; Laird, N.~M.; and Rubin, D.~B. 1977.
\newblock Maximum likelihood from incomplete data via the EM algorithm.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, 39(1): 1--22.

\bibitem[{den Hengst et~al.(2020)den Hengst, Grua, el~Hassouni, and Hoogendoorn}]{den2020reinforcement}
den Hengst, F.; Grua, E.~M.; el~Hassouni, A.; and Hoogendoorn, M. 2020.
\newblock Reinforcement learning for personalization: A systematic literature review.
\newblock \emph{Data Science}, 3(2): 107--147.

\bibitem[{Diana et~al.(2021)Diana, Dick, Elzayn, Kearns, Roth, Schutzman, Sharifi-Malvajerdi, and Ziani}]{diana2021algorithms}
Diana, E.; Dick, T.; Elzayn, H.; Kearns, M.; Roth, A.; Schutzman, Z.; Sharifi-Malvajerdi, S.; and Ziani, J. 2021.
\newblock Algorithms and learning for fair portfolio design.
\newblock In \emph{Proceedings of the 22nd ACM Conference on Economics and Computation}, 371--389.

\bibitem[{el~Hassouni et~al.(2022)el~Hassouni, Hoogendoorn, Ciharova, Kleiboer, Amarti, Muhonen, Riper, and Eiben}]{el2022ph}
el~Hassouni, A.; Hoogendoorn, M.; Ciharova, M.; Kleiboer, A.; Amarti, K.; Muhonen, V.; Riper, H.; and Eiben, A. 2022.
\newblock pH-RL: A personalization architecture to bring reinforcement learning to health practice.
\newblock In \emph{Machine Learning, Optimization, and Data Science: 7th International Conference, LOD 2021, Grasmere, UK, October 4--8, 2021, Revised Selected Papers, Part I}, 265--280. Springer.

\bibitem[{El~Hassouni et~al.(2019)El~Hassouni, Hoogendoorn, Eiben, Van~Otterlo, and Muhonen}]{el2019end}
El~Hassouni, A.; Hoogendoorn, M.; Eiben, A.~E.; Van~Otterlo, M.; and Muhonen, V. 2019.
\newblock End-to-end Personalization of Digital Health Interventions using Raw Sensor Data with Deep Reinforcement Learning.
\newblock In \emph{IEEE/WIC/ACM International Conference on Web Intelligence}, 258--264.

\bibitem[{Finn, Abbeel, and Levine(2017)}]{finn2017model}
Finn, C.; Abbeel, P.; and Levine, S. 2017.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, 1126--1135. PMLR.

\bibitem[{Goindani and Neville(2020)}]{goindani2020cluster}
Goindani, M.; and Neville, J. 2020.
\newblock Cluster-based social reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2003.00627}.

\bibitem[{Grua and Hoogendoorn(2018)}]{grua2018exploring}
Grua, E.~M.; and Hoogendoorn, M. 2018.
\newblock Exploring clustering techniques for effective reinforcement learning based personalization for health and wellbeing.
\newblock In \emph{2018 IEEE Symposium Series on Computational Intelligence (SSCI)}, 813--820. IEEE.

\bibitem[{Hans et~al.(2008)Hans, Schneega{\ss}, Sch{\"a}fer, and Udluft}]{hans2008safe}
Hans, A.; Schneega{\ss}, D.; Sch{\"a}fer, A.~M.; and Udluft, S. 2008.
\newblock Safe exploration for reinforcement learning.
\newblock In \emph{ESANN}, 143--148. Citeseer.

\bibitem[{Hassouni et~al.(2018)Hassouni, Hoogendoorn, van Otterlo, and Barbaro}]{hassouni2018personalization}
Hassouni, A.~e.; Hoogendoorn, M.; van Otterlo, M.; and Barbaro, E. 2018.
\newblock Personalization of health interventions using cluster-based reinforcement learning.
\newblock In \emph{PRIMA 2018: Principles and Practice of Multi-Agent Systems: 21st International Conference, Tokyo, Japan, October 29-November 2, 2018, Proceedings 21}, 467--475. Springer.

\bibitem[{Hayes et~al.(2022)Hayes, R{\u{a}}dulescu, Bargiacchi, K{\"a}llstr{\"o}m, Macfarlane, Reymond, Verstraeten, Zintgraf, Dazeley, Heintz et~al.}]{hayes2022practical}
Hayes, C.~F.; R{\u{a}}dulescu, R.; Bargiacchi, E.; K{\"a}llstr{\"o}m, J.; Macfarlane, M.; Reymond, M.; Verstraeten, T.; Zintgraf, L.~M.; Dazeley, R.; Heintz, F.; et~al. 2022.
\newblock A practical guide to multi-objective reinforcement learning and planning.
\newblock \emph{Autonomous Agents and Multi-Agent Systems}, 36(1): 1--59.

\bibitem[{Huang et~al.(2022)Huang, Dossa, Raffin, Kanervisto, and Wang}]{shengyi2022the37implementation}
Huang, S.; Dossa, R. F.~J.; Raffin, A.; Kanervisto, A.; and Wang, W. 2022.
\newblock The 37 Implementation Details of Proximal Policy Optimization.
\newblock In \emph{ICLR Blog Track}.

\bibitem[{JDRF(2022)}]{jdrf_blog_2022}
JDRF. 2022.
\newblock FDA Authorizes a Fourth Artificial Pancreas System.
\newblock \url{https://www.jdrf.org/blog/2022/01/28/fda-authorizes-a-fourth-artificial-pancreas-system/}.
\newblock Accessed: 2024-01-11.

\bibitem[{Junges et~al.(2016)Junges, Jansen, Dehnert, Topcu, and Katoen}]{junges2016safety}
Junges, S.; Jansen, N.; Dehnert, C.; Topcu, U.; and Katoen, J.-P. 2016.
\newblock Safety-constrained reinforcement learning for MDPs.
\newblock In \emph{Tools and Algorithms for the Construction and Analysis of Systems: 22nd International Conference, TACAS 2016, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2016, Eindhoven, The Netherlands, April 2-8, 2016, Proceedings}, 130--146. Springer.

\bibitem[{Kar et~al.(2023)Kar, Kosan, Mandal, Medya, Silva, Dey, and Sanyal}]{kar2023feature}
Kar, D.; Kosan, M.; Mandal, D.; Medya, S.; Silva, A.; Dey, P.; and Sanyal, S. 2023.
\newblock Feature-based Individual Fairness in k-clustering.
\newblock In \emph{Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems}, 2772--2774.

\bibitem[{Kingma and Ba(2014)}]{kingma2014adam}
Kingma, D.~P.; and Ba, J. 2014.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}.

\bibitem[{Lee, Sun, and Lebanon(2012)}]{lee2012prea}
Lee, J.; Sun, M.; and Lebanon, G. 2012.
\newblock Prea: Personalized recommendation algorithms toolkit.
\newblock \emph{The Journal of Machine Learning Research}, 13(1): 2699--2703.

\bibitem[{Littman(1994)}]{littman1994markov}
Littman, M.~L. 1994.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Machine learning proceedings 1994}, 157--163. Elsevier.

\bibitem[{Lloyd(1982)}]{lloyd1982least}
Lloyd, S. 1982.
\newblock Least squares quantization in PCM.
\newblock \emph{IEEE transactions on information theory}, 28(2): 129--137.

\bibitem[{MacQueen(1967)}]{macqueen1967classification}
MacQueen, J. 1967.
\newblock Classification and analysis of multivariate observations.
\newblock In \emph{5th Berkeley Symp. Math. Statist. Probability}, 281--297.

\bibitem[{Mandal and Gan(2022)}]{mandal2022socially}
Mandal, D.; and Gan, J. 2022.
\newblock Socially fair reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2208.12584}.

\bibitem[{Martin and Arroyo(2004)}]{martin2004agentx}
Martin, K.~N.; and Arroyo, I. 2004.
\newblock AgentX: Using reinforcement learning to improve the effectiveness of intelligent tutoring systems.
\newblock In \emph{Intelligent Tutoring Systems: 7th International Conference, ITS 2004, Macei{\'o}, Alagoas, Brazil, August 30-September 3, 2004. Proceedings 7}, 564--572. Springer.

\bibitem[{Moldovan and Abbeel(2012)}]{moldovan2012safe}
Moldovan, T.~M.; and Abbeel, P. 2012.
\newblock Safe exploration in markov decision processes.
\newblock \emph{arXiv preprint arXiv:1205.4810}.

\bibitem[{Nadiger, Kumar, and Abdelhak(2019)}]{nadiger2019federated}
Nadiger, C.; Kumar, A.; and Abdelhak, S. 2019.
\newblock Federated reinforcement learning for fast personalization.
\newblock In \emph{2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 123--127. IEEE.

\bibitem[{Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga et~al.}]{paszke2019pytorch}
Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.; Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.; et~al. 2019.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32.

\bibitem[{Perkins and Barto(2002)}]{perkins2002lyapunov}
Perkins, T.~J.; and Barto, A.~G. 2002.
\newblock Lyapunov design for safe reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 3(Dec): 803--832.

\bibitem[{Schulman et~al.(2015{\natexlab{a}})Schulman, Levine, Abbeel, Jordan, and Moritz}]{schulman2015trust}
Schulman, J.; Levine, S.; Abbeel, P.; Jordan, M.; and Moritz, P. 2015{\natexlab{a}}.
\newblock Trust region policy optimization.
\newblock In \emph{International conference on machine learning}, 1889--1897. PMLR.

\bibitem[{Schulman et~al.(2015{\natexlab{b}})Schulman, Moritz, Levine, Jordan, and Abbeel}]{schulman2015high}
Schulman, J.; Moritz, P.; Levine, S.; Jordan, M.; and Abbeel, P. 2015{\natexlab{b}}.
\newblock High-dimensional continuous control using generalized advantage estimation.
\newblock \emph{arXiv preprint arXiv:1506.02438}.

\bibitem[{Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov}]{schulman2017proximal}
Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and Klimov, O. 2017.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}.

\bibitem[{Shepitsen et~al.(2008)Shepitsen, Gemmell, Mobasher, and Burke}]{shepitsen2008personalized}
Shepitsen, A.; Gemmell, J.; Mobasher, B.; and Burke, R. 2008.
\newblock Personalized recommendation in social tagging systems using hierarchical clustering.
\newblock In \emph{Proceedings of the 2008 ACM conference on Recommender systems}, 259--266.

\bibitem[{Tabatabaei, Hoogendoorn, and van Halteren(2018)}]{tabatabaei2018narrowing}
Tabatabaei, S.~A.; Hoogendoorn, M.; and van Halteren, A. 2018.
\newblock Narrowing reinforcement learning: Overcoming the cold start problem for personalized health interventions.
\newblock In \emph{PRIMA 2018: Principles and Practice of Multi-Agent Systems: 21st International Conference, Tokyo, Japan, October 29-November 2, 2018, Proceedings 21}, 312--327. Springer.

\bibitem[{Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden, Abdolmaleki, Merel, Lefrancq et~al.}]{tassa2018deepmind}
Tassa, Y.; Doron, Y.; Muldal, A.; Erez, T.; Li, Y.; Casas, D. d.~L.; Budden, D.; Abdolmaleki, A.; Merel, J.; Lefrancq, A.; et~al. 2018.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}.

\bibitem[{Todorov, Erez, and Tassa(2012)}]{todorov2012mujoco}
Todorov, E.; Erez, T.; and Tassa, Y. 2012.
\newblock MuJoCo: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 5026--5033. IEEE.

\bibitem[{Tunyasuvunakool et~al.(2020)Tunyasuvunakool, Muldal, Doron, Liu, Bohez, Merel, Erez, Lillicrap, Heess, and Tassa}]{tunyasuvunakool2020}
Tunyasuvunakool, S.; Muldal, A.; Doron, Y.; Liu, S.; Bohez, S.; Merel, J.; Erez, T.; Lillicrap, T.; Heess, N.; and Tassa, Y. 2020.
\newblock dm$\_$control: Software and tasks for continuous control.
\newblock \emph{Software Impacts}, 6: 100022.

\bibitem[{Wu et~al.(2023)Wu, Wu, Huang, and Xie}]{wu2023personalized}
Wu, C.; Wu, F.; Huang, Y.; and Xie, X. 2023.
\newblock Personalized news recommendation: Methods and Challenges.
\newblock \emph{ACM Transactions on Information Systems}, 41(1): 1--50.

\bibitem[{Yao et~al.(2020)Yao, Dou, Xu, and Wen}]{yao2020rlper}
Yao, J.; Dou, Z.; Xu, J.; and Wen, J.-R. 2020.
\newblock RLPer: A reinforcement learning model for personalized search.
\newblock In \emph{Proceedings of The Web Conference 2020}, 2298--2308.

\bibitem[{Zhu et~al.(2018)Zhu, Guo, Xu, Liao, Yang, and Huang}]{zhu2018group}
Zhu, F.; Guo, J.; Xu, Z.; Liao, P.; Yang, L.; and Huang, J. 2018.
\newblock Group-driven reinforcement learning for personalized mhealth intervention.
\newblock In \emph{Medical Image Computing and Computer Assisted Intervention--MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I}, 590--598. Springer.

\end{thebibliography}
