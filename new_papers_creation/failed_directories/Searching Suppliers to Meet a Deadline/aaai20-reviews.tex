META-REVEW
================================
The authors consider the Supplier Assignment for Meeting a Deadline (SAMD) problem, which is quite specific problem and might not be of interest for a wider audience.

More critically, the authors did not look sufficiently deep into the problem (for a full AAAI paper), not discussing some obvious baseline ideas or relevant approaches from the MDP literature. The authors pointed out that their "algorithm addresses the special characteristic of the SAMD problem". However, this does not automatically imply that it will perform better than the standard methods, so this would have to be quantified by an empirical evaluation.

Besides this, the clarity of the paper should be improved (cf. review 2).


REVIEWS:
================================

Reviewer #1
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
The authors claim to introduce a new problem, and then describe and implement an algorithm to solve it. A job requires a fixed sequence of different tasks to complete it. For each task, there are multiple different suppliers. For each supplier for each task, there is a probability distribution of how long that supplier will take to complete that task. The problem addressed is how to choose a supplier for each task in order to maximize the probability of meeting a deadline for the overall job. The authors apply what they call A* to the problem with a heuristic function, and compare to a really bad brute-force search algorithm.

2. [Relevance] Is this paper relevant to an AI audience?
Relevant to researchers in subareas only
3. [Significance] Are the results significant?
Not significant
4. [Novelty] Are the problems or approaches novel?
Not novel
5. [Soundness] Is the paper technically sound?
Technically sound
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Not convincing
7. [Clarity] Is the paper well-organized and clearly written?
Satisfactory
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
My biggest problem with this paper is that in the hour or so it took to read this paper, I was able to think of a number of alternative heuristic search approaches to this problem that are not mentioned at all. Thus, I don't think the authors dug very deeply into the problem. Below are some of those ideas, interspersed with comments.

I wouldn't call this algorithm A*, since there really aren't any edge costs.

Please explain how to compute the probability distribution of a complete assignment. Is it the obvious cross-product of the distributions of the individual tasks?

Please explain how to compute the heuristic.

One can run a simple brute-force branch and bound algorithm on this problem. Compute the probability of meeting the deadline with only a partial set of tasks completed at each node. This will be monotonically non-increasing with each additional added task.

One can add a simple optimistic heuristic to this algorithm by assuming that each remaining task will be completed in the minimum possible time among all the suppliers for that task.

As one goes down this search tree, the probabilities of completing the tasks so far at various times can be computed incrementally, rather than waiting for a complete assignment and then computing the distribution.

In the search tree, there is no need to add the tasks in the order in which they must actually be completed. A different order might give a better initial solution, leading to more pruning. Similarly, the order in which tasks are considered doesn't have to be the same in every branch of the tree.

More detailed comments follow below.

In first sentence of abstract, "project" should be "projects"

What is the NP-hard problem that computing the probability that an assignment meets the deadline is equivalent to?

"...since such problems are much easily solvable..." should be, "more easily solved" In the same sentence, "distribution" should be plural.
9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.
Are you sure you are the first to address this problem?

Are all the distibutions discrete?

Do you assume that all the distributions are independent of each other? I assume yes, but I didn't find it stated.
10. [OVERALL SCORE]
3 - Clear reject
15. Please acknowledge that you have read the author rebuttal. If your opinion has changed, please summarize the main reasons below.
I have read the author rebuttal. Unfortunately, it doesn't change my view of the paper.


Reviewer #2
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
The focus of the proposed research is the problem of assigning suppliers to tasks such that the probability of meeting an overall deadline is maximized, where each task can be executed by one supplier from a subset of task-capable suppliers, and for each supplier there is a known distribution for task execution time. This is a difficult problem, a result from literature states that even for a given assignment of suppliers to the tasks, computing the probability to meet the deadline is NP-hard. Related previous research (also referenced in the paper) on estimating the probability of meeting a deadline has focused on task trees (hierarchical tasks). The simple sequence of tasks in the SAMD problem also makes it similar to robust one-machine scheduling with duration uncertainty; however, scheduling research published for the one-machine problem uses normal distributions for the durations (and flowtime instead of deadline), and SAMD has the additional requirement of assigning to each task one of a set of modes (suppliers capable to execute it).

An A* algorithm is proposed, to optimally identify the supplier assignment that maximizes the probability of meeting the deadline. The paper also includes an empirical study that compares A* with two simple heuristic approaches and an exhaustive brute-force approach on both synthetic and real data.
2. [Relevance] Is this paper relevant to an AI audience?
Relevant to researchers in subareas only
3. [Significance] Are the results significant?
Moderately significant
4. [Novelty] Are the problems or approaches novel?
Somewhat novel or somewhat incremental
5. [Soundness] Is the paper technically sound?
Has minor errors
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Somewhat weak
7. [Clarity] Is the paper well-organized and clearly written?
Poor
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
My main two issues with the paper are that the presentation is unclear (in particular, the description for A*), and the results section is rather weak and difficult to follow. More details below.

The description of the A* algorithm in section 4.2 is unclear:
-- Change (2) required to adapt A* for maximization problems states that "the search can only halt after the cost of the best solution found is smaller than or equal to g(n)+h(n)". This seems wrong, the search can stop when the cost of the best solution found is *greater* than or equal to g(n)+h(n) for all n in OPEN, since h(n) is never smaller than the cost to reach the goal. Note that the pseudo-code for the algorithm does check the correct condition U(n)<= M_best.

-- The description of U(n), how it's used with A*, and what it signifies in the context of the problem solved should be clarified. Equation (2) seems wrong to me, for two reasons:
1. Admissibility motivation is unclear (wrong) in the context of problem maximization: "the real completion time of any single supplier must be larger than this value (or at least equal). Thus, it can be used as an admissible heuristic.". Note how this describes an admissible heuristic for minimization (it underestimates), and contradicts the fact that for maximization, the heuristic value must be "never smaller than the real cost" (should never underestimate).
2. It is not estimating the cost of the considered problem (the probability of an assignment to meet the deadline): in line 6 in the pseudo-code the probability of the best-so-far assignment meeting the deadline is compared to the value computed by U, which does not compute a probability, as far as I can tell.

I assume that in (2) the probability of the whole sum being less than or equal to d is what is meant. But in that case, while it's clear that the supplier assignments that result in the fastest task completion for the unassigned tasks will produce an underestimate of the completion time for all the tasks (and meet the deadline if possible), it is not obvious to me why the probability of this assignment is an upper bound over the cost of all goal nodes in the subtree rooted in n, so I think some additional explanations would be needed.

A description for OPTAPPROX should be included. What is an "inverse version of OPTAPPROX", there are no details included here.
Using the terms "pessimistic" and "optimistic" in the context of a maximization problem (and with all the previously mentioned issues) should be followed by a short statement that clarifies what that means (for example, pessimistic might reflect a lower probability to meet the deadline -- note that the CDF of X' seems to point the other way, this is not clear).

The empirical results section is sometimes difficult to follow, certain details are missing, especially with respect to to the A* runs, and the analysis of the results can be improved:
-- Based on the A* description, since the approximate computation uses a requested support size m, I expected to see how A* performance varies depending on the values considered for m and the initial support size of the distributions (perhaps including a comment about running A* without the approximation). Instead, it seems that all the distributions are of size 4, not clear what is the value of m in the experiments.

-- While the empirical setup clearly describes the types of synthetic and real distributions that are considered, in the Results section it's sometimes difficult to tell which distribution types were used in which experiments. For example, there is no mention of either synthetic or random distributions in the analysis of the results (they only appear in the captions for Figure 2 and Table 1). Also, the variation in number of tasks (layers) is mentioned in the empirical setup for the real data, but in the Results section, there is only a mention of intervals for the average error results (I guess across all the different number of layers, this is not clear).

-- It's not clear why the 0.5 x maxd results are missing from Table 1, especially since the EXPECTATION heuristic performed well for these instances.

-- Looking at Table 2, it seems to me that Exp. mostly outperforms Sampl. for the real data distribution, while on the synthetic data (in Table 1), Sampl. performed better; also, the actual #Opt values are much smaller than for the synthetic data. A mention of this and some intuition on possible reasons are missing.
-- Table 2 mentions a deadline of 4 seconds for real data, I thought the deadlines for the real data were measured as number of sprints?

Minor issues:
-- section 5.2, last paragraph "meed" instead of "meet"
-- a quick explanation of the notation used for the random distribution examples in 5.1 would help
-- section 5.3, page 7, column 1, "effects" instead of "affects"
9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.
1. Equation (2): How does U(n) work with A*? (see comments above). Is something missing here (probability)?
2. Please explain admissibility of U(n) in the A* algorithm for maximization
3. Please comment on what the inverse version of OPTAPPROX does and how it's used in the context of (2).
4. Was the approximation used when running A*? What were the values for the support size m.
10. [OVERALL SCORE]
4 - Reject
15. Please acknowledge that you have read the author rebuttal. If your opinion has changed, please summarize the main reasons below.
I have read the authors' response. Unfortunately, my opinion did not change.


Reviewer #3
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
This paper revisited SAMD problem, which maximizes the probability that supplier assignments meet the deadline. Firstly, they show sampling strategy can be used to estimate the probabilities and supplier assignment can also be solved based on the expected criterion. Secondly, they formalize SAMD as a graph search problem and show A* style algorithm can solve it. They define the heuristic accumulated cost U(n) by assuming all suppliers perform unassigned tasks simultaneously. Since U(n) is also expensive to compute, they apply the OPTAPPROX operator to approximate it, and they show OPTAPPROX approximation is also admissible. In the experiment, they compare their algorithm with the brute force approach.
2. [Relevance] Is this paper relevant to an AI audience?
Of limited interest to an AI audience
3. [Significance] Are the results significant?
Moderately significant
4. [Novelty] Are the problems or approaches novel?
Somewhat novel or somewhat incremental
5. [Soundness] Is the paper technically sound?
Technically sound
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Sufficient
7. [Clarity] Is the paper well-organized and clearly written?
Satisfactory
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
This paper focus on a very specific problem - Supplier Assignment for Meeting a Deadline (SAMD). SAMD is too specific, and I think it is of only limited interest to an AI audience. I feel it is better if the authors can discuss it under a wider background.

If we consider time as cost, a Supplier Assignment (SA) problem without a deadline can totally be formalized as a standard probabilistic planning problem - a Markov decision process (MDP). The criterion that maximizes the probability that supplier assignments meet the deadline has also been widely discussed and applied on different probabilistic planning models, such as follows:
Hou, P.; Yeoh, W.; and Varakantham, P. 2014. Revisiting risk-sensitive MDPs: New algorithms and results. In Proceedings of ICAPS.
Hou, P.; Yeoh, W.; and Varakantham, P. 2016. Solving RiskSensitive POMDPs With and Without Cost Observations. In Proceedings of AAAI.
Any algorithms that solve MDP with the probability maximization criterion can be also applied to solve SAMD problem.

The key contribution of this paper is they proposed heuristic accumulated cost U(n) and applied OPTAPPROX to simply the computation. This is a good example (specific case) of estimation under sparse and late rewards. For SAMD, we need a complete supplier assignment to compute the probability, but we need to estimate how good a partial assignment it is. It is similar to we only know win or lose of a game until we finish the game, but we need to estimate how good the situation is in the middle of a game. I hope the author can review some related work and include them in this paper.

By the way, the reference is not with AAAI format. Please use AAAI template.
9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.
see [Detailed Comments]
10. [OVERALL SCORE]
5 - Marginally below threshold
15. Please acknowledge that you have read the author rebuttal. If your opinion has changed, please summarize the main reasons below.
I acknowledge having read the author's rebuttal.