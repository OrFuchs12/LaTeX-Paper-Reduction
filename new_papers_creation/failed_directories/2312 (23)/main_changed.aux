\relax 
\bibstyle{aaai24}
\nicematrix@redefine@check@rerun 
\citation{liu2022brio,wang2018glue,rajpurkar2018know,rajpurkar2016squad,li2019unified,li2019dice,yu-etal-2020-named,ijcai2020p560}
\citation{nadeem2021stereoset,meade2021empirical,zayed2022deep,zayed2023should}
\citation{nadeem2021stereoset}
\citation{smith2022using,brown2020language,cohen2022lamda,rae2021scaling,lieber2021jurassic,hoffmann2022training}
\citation{Fan2020Reducing,voita-etal-2019-analyzing,fan-etal-2021-layer,behnke-heafield-2021-pruning,prasanna-etal-2020-bert,voita-etal-2019-analyzing}
\citation{voita-etal-2019-analyzing,NEURIPS2019_2c601ad9,he-choi-2021-stem,bian-etal-2021-attention,zhang-etal-2021-enlivening}
\citation{wang2022interpretability,voita-etal-2019-analyzing,he-choi-2021-stem}
\citation{behnke2021pruning}
\citation{narang2017exploring,h.2018to}
\citation{behnke2021pruning}
\citation{voita-etal-2019-analyzing}
\citation{NEURIPS2019_2c601ad9}
\citation{he-choi-2021-stem}
\citation{bian-etal-2021-attention}
\citation{zhang-etal-2021-enlivening}
\citation{sajjad2023effect}
\citation{devlin2018bert}
\citation{Fan2020Reducing}
\citation{frankle2018the}
\citation{behnke-heafield-2020-losing}
\citation{prasanna-etal-2020-bert}
\citation{caliskan2017semantics,guo2021detecting,may2019measuring}
\citation{cao-etal-2022-intrinsic,delobelle-etal-2022-measuring}
\citation{webster2020measuring,kurita2019measuring}
\citation{delobelle-etal-2022-measuring}
\citation{nadeem2021stereoset,nangia2020crows}
\citation{blodgett2021stereotyping}
\citation{zhao-etal-2018-gender}
\citation{rudinger2018gender}
\citation{levy2021collecting}
\citation{zhao-etal-2018-gender}
\citation{rudinger2018gender}
\citation{nangia2020crows}
\citation{dhamala2021bold}
\citation{smith2022m}
\citation{dhamala2021bold}
\citation{dixon2018measuring}
\newlabel{sec:fairness_metrics}{{2}{2}{}{}{}}
\newlabel{sec:background}{{3}{2}{}{}{}}
\citation{dixon2018measuring}
\citation{voita-etal-2019-analyzing,NEURIPS2019_2c601ad9}
\citation{meritypointer}
\citation{rotman2021model}
\newlabel{eq:pinned_toxicity}{{1}{3}{}{}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bias_quantification}{{\caption@xref {fig:bias_quantification}{ on input line 364}}{3}{}{}{}}
\newlabel{tab:bias_quantification}{{1}{3}{Illustration of social bias assessment. The average toxicity is $(0.6+0.8)/2 = 0.7$, and hence bias is $|0.6-0.7| + |0.8-0.7| = 0.2$ following Eq. \eqref  {eq:pinned_toxicity}. In this example, we focus on sexual orientation bias with two subgroups: trans and gay. }{}{}}
\newlabel{eq:ATE_bias}{{2}{3}{}{}{}}
\newlabel{eq:ATE_perf}{{3}{3}{}{}{}}
\citation{smith2022m}
\citation{han2015learning,han2015deep}
\citation{NEURIPS2019_2c601ad9}
\citation{dhamala2021bold}
\citation{radford2019language}
\citation{gpt-neo}
\citation{gpt-j}
\citation{touvron2023llama}
\newlabel{fig:head_pruning_1}{{1}{4}{Illustration of applying FASP {to a model with 6 layers and 12 heads per layer, \textit  {e.g.} DistilGPT-2}. Initially, we identify and exclude the heads that significantly impact performance from the pruning process ({black squares}). Subsequently, the remaining heads are prioritized for removal based on their contribution to bias, ensuring that the heads contributing the most to bias are pruned first ({red squares}).}{}{}}
\newlabel{prompts}{{5}{4}{}{}{}}
\newlabel{baselines}{{5}{4}{}{}{}}
\newlabel{sec:metrics}{{5}{4}{}{}{}}
\newlabel{sec:models}{{5}{4}{}{}{}}
\newlabel{exp_details}{{6}{4}{}{}{}}
\newlabel{fig:gender_bias_pruning}{{2}{5}{The percentage of change in gender bias and language modeling perplexity across DistilGPT-2, GPT-2, GPT-Neo $125$M, GPT-Neo $1.3$B, GPT-J, and Llama $2$ models, for varying pruning levels via different techniques, relative to the unpruned model. Among the methods, FASP is the only method to consistently reduce bias while upholding a relatively low language modeling perplexity.}{}{}}
\newlabel{fig:head_ids_pruned}{{3}{6}{The indices of most impactful attention heads on five social biases, at a $20\%$ pruning rate ($\alpha = 0.2$). The existence of heads that offer pruning advantages to multiple social biases indicates the potential for a simultaneous positive impact on several biases through pruning.}{}{}}
\newlabel{fig:correlation_maps}{{4}{6}{Pearson correlation heat maps depict the relationships among attention head scores on nationality, sexual orientation, religion, race, and gender biases, within DistilGPT-2, GPT-2, and GPT-Neo with a parameter count of $125$M. Notably, all social biases exhibit positive correlations, except religion bias, where correlations are either absent or slightly negative, varying based on the specific model.}{}{}}
\newlabel{fig:effect_on_ther_biases_gpt2}{{5}{7}{An analysis on DistilGPT-2, GPT-2, and GPT-Neo (with $125$M parameters) showing the percentage of change in language modeling perplexity and nationality, race, religion, and sexual orientation biases, relative to the unpruned model, using varying pruning levels and different pruning techniques. While FASP focuses on gender bias mitigation through head pruning, it also addresses other biases whose head scores are positively correlated with gender bias scores, while maintaining robust language model perplexity. }{}{}}
\bibdata{aaai24}
\ExplSyntaxOn \cs_if_free:NT \pgfsyspdfmark {\cs_set_eq:NN \pgfsyspdfmark \@gobblethree }\ExplSyntaxOff 
\ExplSyntaxOn 
\char_set_catcode_space:n {32}
\tl_gset:cn {c__nicematrix_1_tl}{\seq_gset_from_clist:Nn \g__nicematrix_size_seq {1,13,13,1,5,5}\tl_gset:Nn \g__nicematrix_pre_code_before_tl {\__nicematrix_rectanglecolor []{lightgray}{7-1}{7-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{13-1}{13-\int_use:N \c@jCol }}}
\ExplSyntaxOff 
\ExplSyntaxOn 
\char_set_catcode_space:n {32}
\tl_gset:cn {c__nicematrix_2_tl}{\seq_gset_from_clist:Nn \g__nicematrix_size_seq {1,15,15,1,5,5}\tl_gset:Nn \g__nicematrix_pre_code_before_tl {\__nicematrix_rectanglecolor []{lightgray}{8-1}{8-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{9-1}{9-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{15-1}{15-\int_use:N \c@jCol }}}
\ExplSyntaxOff 
\ExplSyntaxOn 
\char_set_catcode_space:n {32}
\tl_gset:cn {c__nicematrix_3_tl}{\seq_gset_from_clist:Nn \g__nicematrix_size_seq {1,20,20,1,5,5}\tl_gset:Nn \g__nicematrix_pre_code_before_tl {\__nicematrix_rectanglecolor []{lightgray}{10-1}{10-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{11-1}{11-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{19-1}{19-\int_use:N \c@jCol }\__nicematrix_rectanglecolor []{lightgray}{20-1}{20-\int_use:N \c@jCol }}}
\ExplSyntaxOff 
\newlabel{tab:hyperparamaters}{{2}{11}{The range of values tried for the hyperparameter $\gamma $ and the final values based on the validation dataset, for different models. }{}{}}
\citation{NEURIPS2019_2c601ad9}
\newlabel{fig:gender_bias_pruning_gamma}{{6}{12}{The percentage of change in gender bias and language modeling perplexity across DistilGPT-2, GPT-2, GPT-Neo $125$M, GPT-Neo $1.3$B, GPT-J, and Llama $2$ models, for varying pruning levels and using different $\gamma $ values, relative to the unpruned model.}{}{}}
\newlabel{sec:compute_scores}{{B}{12}{}{}{}}
\newlabel{fig:head_ids_pruned_more_models_2}{{7}{13}{The indices of most impactful attention heads on five social biases in DistilGPT-2 and GPT-Neo $125$M, at a $20\%$ pruning rate ($\alpha = 0.2$). The existence of heads that offer pruning advantages to multiple social biases indicates the potential for a simultaneous positive impact on several biases through pruning.}{}{}}
\newlabel{sec:compute_baselines}{{B}{13}{}{}{}}
\pgfsyspdfmark {nm-1-position}{3552215}{39917401}
\pgfsyspdfmark {pgfid2}{3552215}{39917401}
\pgfsyspdfmark {pgfid3}{3552215}{39917401}
\pgfsyspdfmark {nm-1-row-1}{3552215}{44806386}
\pgfsyspdfmark {pgfid5}{3552215}{44819493}
\pgfsyspdfmark {pgfid6}{3945432}{44288654}
\pgfsyspdfmark {pgfid7}{5013336}{44288654}
\pgfsyspdfmark {pgfid8}{12323789}{44288654}
\pgfsyspdfmark {pgfid9}{18552607}{44288654}
\pgfsyspdfmark {pgfid10}{36892669}{44288654}
\pgfsyspdfmark {nm-1-row-2}{3552215}{44059276}
\pgfsyspdfmark {pgfid11}{3552215}{44072383}
\pgfsyspdfmark {pgfid12}{3945432}{43541544}
\pgfsyspdfmark {pgfid13}{12651464}{43541544}
\pgfsyspdfmark {pgfid14}{24691655}{43541544}
\pgfsyspdfmark {pgfid15}{36892669}{43541544}
\pgfsyspdfmark {nm-1-row-3}{3552215}{43312166}
\pgfsyspdfmark {pgfid16}{3552215}{43325273}
\pgfsyspdfmark {pgfid17}{3945432}{42820648}
\pgfsyspdfmark {pgfid18}{6739219}{42820648}
\pgfsyspdfmark {pgfid19}{12378180}{42820648}
\pgfsyspdfmark {pgfid20}{23296071}{42820648}
\pgfsyspdfmark {pgfid21}{36892669}{42820648}
\pgfsyspdfmark {nm-1-row-4}{3552215}{42591270}
\pgfsyspdfmark {pgfid22}{3552215}{42604377}
\pgfsyspdfmark {pgfid23}{3945432}{42099752}
\pgfsyspdfmark {pgfid24}{7040669}{42099752}
\pgfsyspdfmark {pgfid25}{12342140}{42099752}
\pgfsyspdfmark {pgfid26}{23763972}{42099752}
\pgfsyspdfmark {pgfid27}{36892669}{42099752}
\pgfsyspdfmark {nm-1-row-5}{3552215}{41870374}
\pgfsyspdfmark {pgfid28}{3552215}{41883481}
\pgfsyspdfmark {pgfid29}{3945432}{41378856}
\pgfsyspdfmark {pgfid30}{5510419}{41378856}
\pgfsyspdfmark {pgfid31}{13570272}{41378856}
\pgfsyspdfmark {pgfid32}{25842099}{41378856}
\pgfsyspdfmark {pgfid33}{36892669}{41378856}
\pgfsyspdfmark {nm-1-row-6}{3552215}{41149478}
\pgfsyspdfmark {pgfid34}{3552215}{41162585}
\pgfsyspdfmark {pgfid35}{3945432}{40657960}
\pgfsyspdfmark {pgfid36}{12983400}{40657960}
\pgfsyspdfmark {pgfid37}{24965563}{40657960}
\pgfsyspdfmark {pgfid38}{36892669}{40657960}
\pgfsyspdfmark {nm-1-row-7}{3552215}{40428582}
\pgfsyspdfmark {pgfid39}{3552215}{40441689}
\pgfsyspdfmark {pgfid40}{3945432}{39937064}
\pgfsyspdfmark {pgfid41}{13315953}{39937064}
\pgfsyspdfmark {pgfid42}{25842425}{39937064}
\pgfsyspdfmark {pgfid43}{36892669}{39937064}
\pgfsyspdfmark {nm-1-row-8}{3552215}{39707686}
\pgfsyspdfmark {pgfid44}{3552215}{39720793}
\pgfsyspdfmark {pgfid45}{3945432}{39189954}
\pgfsyspdfmark {pgfid46}{12651464}{39189954}
\pgfsyspdfmark {pgfid47}{23577552}{39189954}
\pgfsyspdfmark {pgfid48}{36892669}{39189954}
\pgfsyspdfmark {nm-1-row-9}{3552215}{38960576}
\pgfsyspdfmark {pgfid49}{3552215}{38973683}
\pgfsyspdfmark {pgfid50}{3945432}{38469058}
\pgfsyspdfmark {pgfid51}{6739219}{38469058}
\pgfsyspdfmark {pgfid52}{12378180}{38469058}
\pgfsyspdfmark {pgfid53}{24262696}{38469058}
\pgfsyspdfmark {pgfid54}{36892669}{38469058}
\pgfsyspdfmark {nm-1-row-10}{3552215}{38239680}
\pgfsyspdfmark {pgfid55}{3552215}{38252787}
\pgfsyspdfmark {pgfid56}{3945432}{37748162}
\pgfsyspdfmark {pgfid57}{7195320}{37748162}
\pgfsyspdfmark {pgfid58}{12342140}{37748162}
\pgfsyspdfmark {pgfid59}{23051934}{37748162}
\pgfsyspdfmark {pgfid60}{36892669}{37748162}
\pgfsyspdfmark {nm-1-row-11}{3552215}{37518784}
\pgfsyspdfmark {pgfid61}{3552215}{37531891}
\pgfsyspdfmark {pgfid62}{3945432}{37027266}
\pgfsyspdfmark {pgfid63}{13570272}{37027266}
\pgfsyspdfmark {pgfid64}{22267475}{37027266}
\pgfsyspdfmark {pgfid65}{36892669}{37027266}
\pgfsyspdfmark {nm-1-row-12}{3552215}{36797888}
\pgfsyspdfmark {pgfid66}{3552215}{36810995}
\pgfsyspdfmark {pgfid67}{3945432}{36306370}
\pgfsyspdfmark {pgfid68}{12983400}{36306370}
\pgfsyspdfmark {pgfid69}{22329105}{36306370}
\pgfsyspdfmark {pgfid70}{36892669}{36306370}
\pgfsyspdfmark {nm-1-row-13}{3552215}{36076992}
\pgfsyspdfmark {pgfid71}{3552215}{36090099}
\pgfsyspdfmark {pgfid72}{3945432}{35585474}
\pgfsyspdfmark {pgfid73}{13315953}{35585474}
\pgfsyspdfmark {pgfid74}{23000822}{35585474}
\pgfsyspdfmark {pgfid75}{36892669}{35585474}
\pgfsyspdfmark {nm-1-row-14}{3552215}{35356096}
\pgfsyspdfmark {pgfid76}{3552215}{35369203}
\pgfsyspdfmark {nm-1-col-1}{3565322}{35342989}
\pgfsyspdfmark {pgfid77}{3552215}{35342989}
\pgfsyspdfmark {nm-1-col-2}{10825317}{35342989}
\pgfsyspdfmark {pgfid78}{10838424}{35342989}
\pgfsyspdfmark {nm-1-col-3}{16289012}{35342989}
\pgfsyspdfmark {pgfid79}{16302119}{35342989}
\pgfsyspdfmark {nm-1-col-4}{35369624}{35342989}
\pgfsyspdfmark {pgfid80}{35382731}{35342989}
\pgfsyspdfmark {nm-1-col-5}{38389500}{35342989}
\pgfsyspdfmark {pgfid81}{38402607}{35342989}
\pgfsyspdfmark {nm-1-col-6}{39175933}{35342989}
\pgfsyspdfmark {pgfid82}{39189040}{35342989}
\pgfsyspdfmark {pgfid83}{39189040}{39917401}
\pgfsyspdfmark {pgfid85}{39189040}{39917401}
\newlabel{tab:qualitative_examples}{{3}{14}{Evaluating GPT-2 model continuations with distinct pruning techniques (at $10$\% pruning) using prompts aimed at trans and non-binary communities. While all pruning methods produce non-toxic outcomes for the prompt intended for non-binary individuals, only FASP and fairness only baselines generate a non-toxic continuation for the prompt meant for trans individuals. This highlights FASP's reduced bias, as its consistent toxicity level extends across diverse subgroups. }{}{}}
\pgfsyspdfmark {nm-2-position}{3552298}{18345350}
\pgfsyspdfmark {pgfid87}{3552298}{18345350}
\pgfsyspdfmark {pgfid88}{3552298}{18345350}
\pgfsyspdfmark {nm-2-row-1}{3552298}{23955231}
\pgfsyspdfmark {pgfid90}{3552298}{23968338}
\pgfsyspdfmark {pgfid91}{3945515}{23437499}
\pgfsyspdfmark {pgfid92}{5013419}{23437499}
\pgfsyspdfmark {pgfid93}{10364380}{23437499}
\pgfsyspdfmark {pgfid94}{16593198}{23437499}
\pgfsyspdfmark {pgfid95}{37700184}{23437499}
\pgfsyspdfmark {nm-2-row-2}{3552298}{23208121}
\pgfsyspdfmark {pgfid96}{3552298}{23221228}
\pgfsyspdfmark {pgfid97}{3945515}{22690389}
\pgfsyspdfmark {pgfid98}{10692055}{22690389}
\pgfsyspdfmark {pgfid99}{24650451}{22690389}
\pgfsyspdfmark {pgfid100}{37700184}{22690389}
\pgfsyspdfmark {nm-2-row-3}{3552298}{22461011}
\pgfsyspdfmark {pgfid101}{3552298}{22474118}
\pgfsyspdfmark {pgfid102}{3945515}{21969493}
\pgfsyspdfmark {pgfid103}{6215657}{21969493}
\pgfsyspdfmark {pgfid104}{10418771}{21969493}
\pgfsyspdfmark {pgfid105}{23188023}{21969493}
\pgfsyspdfmark {pgfid106}{37700184}{21969493}
\pgfsyspdfmark {nm-2-row-4}{3552298}{21740115}
\pgfsyspdfmark {pgfid107}{3552298}{21753222}
\pgfsyspdfmark {pgfid108}{3945515}{21248597}
\pgfsyspdfmark {pgfid109}{4433758}{21248597}
\pgfsyspdfmark {pgfid110}{10382731}{21248597}
\pgfsyspdfmark {pgfid111}{23188023}{21248597}
\pgfsyspdfmark {pgfid112}{37700184}{21248597}
\pgfsyspdfmark {nm-2-row-5}{3552298}{21019219}
\pgfsyspdfmark {pgfid113}{3552298}{21032326}
\pgfsyspdfmark {pgfid114}{3945515}{20527701}
\pgfsyspdfmark {pgfid115}{11610863}{20527701}
\pgfsyspdfmark {pgfid116}{21820313}{20527701}
\pgfsyspdfmark {pgfid117}{37700184}{20527701}
\pgfsyspdfmark {nm-2-row-6}{3552298}{20298323}
\pgfsyspdfmark {pgfid118}{3552298}{20311430}
\pgfsyspdfmark {pgfid119}{3945515}{19806805}
\pgfsyspdfmark {pgfid120}{11023991}{19806805}
\pgfsyspdfmark {pgfid121}{25266478}{19806805}
\pgfsyspdfmark {pgfid122}{37700184}{19806805}
\pgfsyspdfmark {nm-2-row-7}{3552298}{19577427}
\pgfsyspdfmark {pgfid123}{3552298}{19590534}
\pgfsyspdfmark {pgfid124}{3945515}{19085909}
\pgfsyspdfmark {pgfid125}{20715697}{19085909}
\pgfsyspdfmark {nm-2-row-8}{3552298}{18856531}
\pgfsyspdfmark {pgfid126}{3552298}{18869638}
\pgfsyspdfmark {pgfid127}{3945515}{18365013}
\pgfsyspdfmark {pgfid128}{11356544}{18365013}
\pgfsyspdfmark {pgfid129}{25020700}{18365013}
\pgfsyspdfmark {pgfid130}{37700184}{18365013}
\pgfsyspdfmark {nm-2-row-9}{3552298}{18135635}
\pgfsyspdfmark {pgfid131}{3552298}{18148742}
\pgfsyspdfmark {pgfid132}{3945515}{17644117}
\pgfsyspdfmark {pgfid133}{17692881}{17644117}
\pgfsyspdfmark {nm-2-row-10}{3552298}{17414739}
\pgfsyspdfmark {pgfid134}{3552298}{17427846}
\pgfsyspdfmark {pgfid135}{3945515}{16897007}
\pgfsyspdfmark {pgfid136}{10692055}{16897007}
\pgfsyspdfmark {pgfid137}{20753058}{16897007}
\pgfsyspdfmark {pgfid138}{37700184}{16897007}
\pgfsyspdfmark {nm-2-row-11}{3552298}{16667629}
\pgfsyspdfmark {pgfid139}{3552298}{16680736}
\pgfsyspdfmark {pgfid140}{3945515}{16176111}
\pgfsyspdfmark {pgfid141}{5938446}{16176111}
\pgfsyspdfmark {pgfid142}{10418771}{16176111}
\pgfsyspdfmark {pgfid143}{16714778}{16176111}
\pgfsyspdfmark {pgfid144}{37700184}{16176111}
\pgfsyspdfmark {nm-2-row-12}{3552298}{15946733}
\pgfsyspdfmark {pgfid145}{3552298}{15959840}
\pgfsyspdfmark {pgfid146}{3945515}{15455215}
\pgfsyspdfmark {pgfid147}{10382731}{15455215}
\pgfsyspdfmark {pgfid148}{23860759}{15455215}
\pgfsyspdfmark {pgfid149}{37700184}{15455215}
\pgfsyspdfmark {nm-2-row-13}{3552298}{15225837}
\pgfsyspdfmark {pgfid150}{3552298}{15238944}
\pgfsyspdfmark {pgfid151}{3945515}{14734319}
\pgfsyspdfmark {pgfid152}{11610863}{14734319}
\pgfsyspdfmark {pgfid153}{22504819}{14734319}
\pgfsyspdfmark {pgfid154}{37700184}{14734319}
\pgfsyspdfmark {nm-2-row-14}{3552298}{14504941}
\pgfsyspdfmark {pgfid155}{3552298}{14518048}
\pgfsyspdfmark {pgfid156}{3945515}{14013423}
\pgfsyspdfmark {pgfid157}{11023991}{14013423}
\pgfsyspdfmark {pgfid158}{19393513}{14013423}
\pgfsyspdfmark {pgfid159}{37700184}{14013423}
\pgfsyspdfmark {nm-2-row-15}{3552298}{13784045}
\pgfsyspdfmark {pgfid160}{3552298}{13797152}
\pgfsyspdfmark {pgfid161}{3945515}{13292527}
\pgfsyspdfmark {pgfid162}{11356544}{13292527}
\pgfsyspdfmark {pgfid163}{18840400}{13292527}
\pgfsyspdfmark {pgfid164}{37700184}{13292527}
\pgfsyspdfmark {nm-2-row-16}{3552298}{13063149}
\pgfsyspdfmark {pgfid165}{3552298}{13076256}
\pgfsyspdfmark {nm-2-col-1}{3565405}{13050042}
\pgfsyspdfmark {pgfid166}{3552298}{13050042}
\pgfsyspdfmark {nm-2-col-2}{8865908}{13050042}
\pgfsyspdfmark {pgfid167}{8879015}{13050042}
\pgfsyspdfmark {nm-2-col-3}{14329603}{13050042}
\pgfsyspdfmark {pgfid168}{14342710}{13050042}
\pgfsyspdfmark {nm-2-col-4}{36177139}{13050042}
\pgfsyspdfmark {pgfid169}{36190246}{13050042}
\pgfsyspdfmark {nm-2-col-5}{39197015}{13050042}
\pgfsyspdfmark {pgfid170}{39210122}{13050042}
\pgfsyspdfmark {nm-2-col-6}{39983448}{13050042}
\pgfsyspdfmark {pgfid171}{39996555}{13050042}
\pgfsyspdfmark {pgfid172}{39996555}{18345350}
\pgfsyspdfmark {pgfid174}{39996555}{18345350}
\newlabel{tab:qualitative_examples_2}{{4}{14}{Evaluating GPT-2 model continuations with distinct pruning techniques (at $2$\% pruning) using prompts aimed at demisexual and bisexual communities. While all pruning methods produce non-toxic outcomes for the prompt intended for bisexual individuals, only FASP and fairness only baseline generate a non-toxic continuation for the prompt meant for demisexual individuals. This highlights FASP's reduced bias, as its consistent toxicity level extends across diverse subgroups. }{}{}}
\pgfsyspdfmark {nm-3-position}{3552215}{41775763}
\pgfsyspdfmark {pgfid176}{3552215}{41775763}
\pgfsyspdfmark {pgfid177}{3552215}{41775763}
\pgfsyspdfmark {nm-3-row-1}{3552215}{49187884}
\pgfsyspdfmark {pgfid179}{3552215}{49200991}
\pgfsyspdfmark {pgfid180}{3945432}{48670152}
\pgfsyspdfmark {pgfid181}{5013336}{48670152}
\pgfsyspdfmark {pgfid182}{10464561}{48670152}
\pgfsyspdfmark {pgfid183}{16693379}{48670152}
\pgfsyspdfmark {pgfid184}{39265045}{48670152}
\pgfsyspdfmark {nm-3-row-2}{3552215}{48440774}
\pgfsyspdfmark {pgfid185}{3552215}{48453881}
\pgfsyspdfmark {pgfid186}{3945432}{47923042}
\pgfsyspdfmark {pgfid187}{10792236}{47923042}
\pgfsyspdfmark {pgfid188}{25683204}{47923042}
\pgfsyspdfmark {pgfid189}{38730867}{47923042}
\pgfsyspdfmark {nm-3-row-3}{3552215}{47693664}
\pgfsyspdfmark {pgfid190}{3552215}{47706771}
\pgfsyspdfmark {pgfid191}{3945432}{47202146}
\pgfsyspdfmark {pgfid192}{10518952}{47202146}
\pgfsyspdfmark {pgfid193}{25693394}{47202146}
\pgfsyspdfmark {pgfid194}{38730867}{47202146}
\pgfsyspdfmark {nm-3-row-4}{3552215}{46972768}
\pgfsyspdfmark {pgfid195}{3552215}{46985875}
\pgfsyspdfmark {pgfid196}{3945432}{46481250}
\pgfsyspdfmark {pgfid197}{5752570}{46481250}
\pgfsyspdfmark {pgfid198}{23651941}{46481250}
\pgfsyspdfmark {nm-3-row-5}{3552215}{46251872}
\pgfsyspdfmark {pgfid199}{3552215}{46264979}
\pgfsyspdfmark {pgfid200}{3945432}{45760354}
\pgfsyspdfmark {pgfid201}{6265706}{45760354}
\pgfsyspdfmark {pgfid202}{10482912}{45760354}
\pgfsyspdfmark {pgfid203}{25567542}{45760354}
\pgfsyspdfmark {pgfid204}{38730867}{45760354}
\pgfsyspdfmark {nm-3-row-6}{3552215}{45530976}
\pgfsyspdfmark {pgfid205}{3552215}{45544083}
\pgfsyspdfmark {pgfid206}{3945432}{45039458}
\pgfsyspdfmark {pgfid207}{5634602}{45039458}
\pgfsyspdfmark {pgfid208}{11711044}{45039458}
\pgfsyspdfmark {pgfid209}{25659288}{45039458}
\pgfsyspdfmark {pgfid210}{38730867}{45039458}
\pgfsyspdfmark {nm-3-row-7}{3552215}{44810080}
\pgfsyspdfmark {pgfid211}{3552215}{44823187}
\pgfsyspdfmark {pgfid212}{3945432}{44318562}
\pgfsyspdfmark {pgfid213}{25825057}{44318562}
\pgfsyspdfmark {nm-3-row-8}{3552215}{44089184}
\pgfsyspdfmark {pgfid214}{3552215}{44102291}
\pgfsyspdfmark {pgfid215}{3945432}{43597666}
\pgfsyspdfmark {pgfid216}{11124172}{43597666}
\pgfsyspdfmark {pgfid217}{24950175}{43597666}
\pgfsyspdfmark {pgfid218}{38730867}{43597666}
\pgfsyspdfmark {nm-3-row-9}{3552215}{43368288}
\pgfsyspdfmark {pgfid219}{3552215}{43381395}
\pgfsyspdfmark {pgfid220}{3945432}{42876770}
\pgfsyspdfmark {pgfid221}{16806438}{42876770}
\pgfsyspdfmark {nm-3-row-10}{3552215}{42647392}
\pgfsyspdfmark {pgfid222}{3552215}{42660499}
\pgfsyspdfmark {pgfid223}{3945432}{42155874}
\pgfsyspdfmark {pgfid224}{11456725}{42155874}
\pgfsyspdfmark {pgfid225}{25800525}{42155874}
\pgfsyspdfmark {pgfid226}{38730867}{42155874}
\pgfsyspdfmark {nm-3-row-11}{3552215}{41926496}
\pgfsyspdfmark {pgfid227}{3552215}{41939603}
\pgfsyspdfmark {pgfid228}{3945432}{41434978}
\pgfsyspdfmark {pgfid229}{19038241}{41434978}
\pgfsyspdfmark {nm-3-row-12}{3552215}{41205600}
\pgfsyspdfmark {pgfid230}{3552215}{41218707}
\pgfsyspdfmark {pgfid231}{3945432}{40687868}
\pgfsyspdfmark {pgfid232}{10792236}{40687868}
\pgfsyspdfmark {pgfid233}{26098999}{40687868}
\pgfsyspdfmark {pgfid234}{38730867}{40687868}
\pgfsyspdfmark {nm-3-row-13}{3552215}{40458490}
\pgfsyspdfmark {pgfid235}{3552215}{40471597}
\pgfsyspdfmark {pgfid236}{3945432}{39966972}
\pgfsyspdfmark {pgfid237}{6038630}{39966972}
\pgfsyspdfmark {pgfid238}{10518952}{39966972}
\pgfsyspdfmark {pgfid239}{23513640}{39966972}
\pgfsyspdfmark {pgfid240}{38730867}{39966972}
\pgfsyspdfmark {nm-3-row-14}{3552215}{39737594}
\pgfsyspdfmark {pgfid241}{3552215}{39750701}
\pgfsyspdfmark {pgfid242}{3945432}{39246076}
\pgfsyspdfmark {pgfid243}{6021585}{39246076}
\pgfsyspdfmark {pgfid244}{10482912}{39246076}
\pgfsyspdfmark {pgfid245}{19680798}{39246076}
\pgfsyspdfmark {pgfid246}{38730867}{39246076}
\pgfsyspdfmark {nm-3-row-15}{3552215}{39016698}
\pgfsyspdfmark {pgfid247}{3552215}{39029805}
\pgfsyspdfmark {pgfid248}{3945432}{38525180}
\pgfsyspdfmark {pgfid249}{5634602}{38525180}
\pgfsyspdfmark {pgfid250}{11711044}{38525180}
\pgfsyspdfmark {pgfid251}{25691695}{38525180}
\pgfsyspdfmark {pgfid252}{38730867}{38525180}
\pgfsyspdfmark {nm-3-row-16}{3552215}{38295802}
\pgfsyspdfmark {pgfid253}{3552215}{38308909}
\pgfsyspdfmark {pgfid254}{3945432}{37804284}
\pgfsyspdfmark {pgfid255}{21624921}{37804284}
\pgfsyspdfmark {nm-3-row-17}{3552215}{37574906}
\pgfsyspdfmark {pgfid256}{3552215}{37588013}
\pgfsyspdfmark {pgfid257}{3945432}{37083388}
\pgfsyspdfmark {pgfid258}{11124172}{37083388}
\pgfsyspdfmark {pgfid259}{25818186}{37083388}
\pgfsyspdfmark {pgfid260}{38730867}{37083388}
\pgfsyspdfmark {nm-3-row-18}{3552215}{36854010}
\pgfsyspdfmark {pgfid261}{3552215}{36867117}
\pgfsyspdfmark {pgfid262}{3945432}{36362492}
\pgfsyspdfmark {pgfid263}{16182864}{36362492}
\pgfsyspdfmark {nm-3-row-19}{3552215}{36133114}
\pgfsyspdfmark {pgfid264}{3552215}{36146221}
\pgfsyspdfmark {pgfid265}{3945432}{35641596}
\pgfsyspdfmark {pgfid266}{11456725}{35641596}
\pgfsyspdfmark {pgfid267}{25749413}{35641596}
\pgfsyspdfmark {pgfid268}{38730867}{35641596}
\pgfsyspdfmark {nm-3-row-20}{3552215}{35412218}
\pgfsyspdfmark {pgfid269}{3552215}{35425325}
\pgfsyspdfmark {pgfid270}{3945432}{34920700}
\pgfsyspdfmark {pgfid271}{18309481}{34920700}
\pgfsyspdfmark {nm-3-row-21}{3552215}{34691322}
\pgfsyspdfmark {pgfid272}{3552215}{34704429}
\pgfsyspdfmark {nm-3-col-1}{3565322}{34678215}
\pgfsyspdfmark {pgfid273}{3552215}{34678215}
\pgfsyspdfmark {nm-3-col-2}{8966089}{34678215}
\pgfsyspdfmark {pgfid274}{8979196}{34678215}
\pgfsyspdfmark {nm-3-col-3}{14429784}{34678215}
\pgfsyspdfmark {pgfid275}{14442891}{34678215}
\pgfsyspdfmark {nm-3-col-4}{37742000}{34678215}
\pgfsyspdfmark {pgfid276}{37755107}{34678215}
\pgfsyspdfmark {nm-3-col-5}{40761876}{34678215}
\pgfsyspdfmark {pgfid277}{40774983}{34678215}
\pgfsyspdfmark {nm-3-col-6}{41548309}{34678215}
\pgfsyspdfmark {pgfid278}{41561416}{34678215}
\pgfsyspdfmark {pgfid279}{41561416}{41775763}
\pgfsyspdfmark {pgfid281}{41561416}{41775763}
\newlabel{tab:qualitative_examples_3}{{5}{15}{Evaluating GPT-2 model continuations with distinct pruning techniques (at $2$\% pruning) using prompts aimed at Native Americans and Guatemalans. While all approaches produce non-toxic extensions for prompts related to Guatemalan individuals, only FASP and the fairness only baseline achieve the same outcome when presented with sentences about Native Americans. This uniformity in toxicity levels underscores FASP's capacity to mitigate bias. }{}{}}
\newlabel{tab:dataset_statistics}{{6}{15}{Statistics and examples from the holistic bias prompts employed in the bias assessment. Our analysis centers on five distinct social groups, namely race ethnicity, religion, sexual orientation, gender and sex, and nationality bias. }{}{}}
\newlabel{tab:computing_the_score}{{7}{15}{The different choices of arguments to compute the attention head scores for different models, heads, and social biases. $N_h$ refers to the total number of attention heads in each model. }{}{}}
\newlabel{tab:baselines}{{8}{15}{The different choices of arguments to compare the performance and bias of FASP to other baseline pruning methods for different models and biases. }{}{}}
\gdef \@abspage@last{15}
