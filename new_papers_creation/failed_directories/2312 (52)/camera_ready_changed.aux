\relax 
\bibstyle{aaai24}
\citation{kipf2017semi,velivckovic2018graph,wu2019simplifying,ling2023graph,han2022g,han2022geometric}
\citation{hamilton2017inductive}
\citation{hamaguchi2017knowledge}
\citation{ying2018graph}
\citation{dai2021say}
\citation{mehrabi2021survey}
\citation{suresh2019framework}
\citation{kose2021fairness}
\citation{dong2022edits}
\citation{jiang2022generalized}
\citation{dai2021say}
\citation{Zhu:2020vf,zhu2021graph,agarwal2021towards,ling2023learning}
\citation{dai2021say}
\citation{ma2021unified,zhu2021graph}
\newlabel{sect:intro}{{}{1}{}{}{}}
\citation{ma2021unified,zhu2021interpreting}
\citation{ma2021unified,zhu2021interpreting}
\citation{ma2021unified}
\citation{xu2018representation}
\citation{ma2021unified}
\citation{ma2021unified,belkin2001laplacian,kalofolias2016learn}
\citation{ma2021unified,zhu2021interpreting}
\citation{ghadimi2014optimal,varma2019vector}
\citation{rockafellar2015convex}
\citation{liu2021elastic}
\citation{rockafellar2015convex}
\newlabel{eq:optimization}{{1}{3}{}{}{}}
\newlabel{eq:minmax}{{4}{3}{}{}{}}
\citation{loris2011generalization,chen2013primal}
\citation{loris2011generalization}
\citation{ma2021unified,liu2021elastic}
\newlabel{prop:conjugate}{{0.1}{4}{}{}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:illu}{{1}{4}{The model pipeline consists of three steps: MLP (feature transformation), propagation with skip connection, and debiasing via low-rank perturbation in probability space. }{}{}}
\newlabel{theo:grad_comp}{{0.2}{4}{}{}{}}
\citation{dai2021say}
\citation{takac2012data}
\citation{louizos2015variational,beutel2017data}
\citation{kipf2017semi}
\citation{velivckovic2018graph}
\citation{wu2019simplifying}
\citation{klicpera2019predict}
\citation{xu2018representation}
\citation{chuang2021fair}
\citation{fisher2020debiasing}
\citation{chuang2020fair}
\citation{louppe2017learning}
\citation{bruna2013spectral,defferrard2016convolutional,henaff2015deep}
\citation{kipf2017semi}
\citation{velivckovic2018graph}
\citation{hamilton2017inductive}
\citation{wu2019simplifying}
\citation{klicpera2019predict}
\citation{gao2018large,monti2017geometric}
\citation{henaff2015deep,zhao2019pairnorm}
\citation{ma2021unified,zhu2021interpreting}
\citation{jiang2022generalized,han2023retiring,jiang2023weight,chuang2020fair,zhang2018mitigating,du2021fairness,yurochkin2020sensei,creager2019flexibly,feldman2015certifying}
\citation{rahman2019fairwalk}
\citation{dai2021say,bose2019compositional,fisher2020debiasing}
\citation{buyl2020debayes}
\citation{ma2021subgroup}
\citation{laclau2021all,li2021dyadic}
\citation{agarwal2021towards,kose2021fairness,ling2023learning}
\citation{laclau2021all,li2021dyadic,dong2021individual,wang2022improving,zha2023data}
\newlabel{table:comp_gnns}{{1}{6}{Comparative Results with Baselines on Node Classification.}{}{}}
\newlabel{sect:related}{{}{6}{}{}{}}
\newlabel{fig:pareto}{{2}{7}{DP and Acc trade-off performance on three real-world datasets compared with adding regularization (Top) and adversarial debiasing (Bottom). The trade-off curve close to the right bottom corner means better trade-off performance. The units for x- and y-axis are percentages ($\%$).}{}{}}
\bibdata{fmp}
\newlabel{app:fairnessobj}{{}{10}{}{}{}}
\newlabel{lemma:softmax}{{.3}{10}{}{}{}}
\citation{chuang2021fair}
\newlabel{algo:FMP}{{1}{13}{FMP Training Algorithm}{}{}}
\newlabel{app:stat}{{}{13}{}{}{}}
\newlabel{table:statistics}{{3}{13}{Statistical Information on Datasets}{}{}}
\newlabel{app:more_exp}{{}{13}{}{}{}}
\newlabel{app:exp_detail}{{}{13}{}{}{}}
\newlabel{app:fairmixup}{{}{13}{}{}{}}
\newlabel{fig:tradeoff_fairmixup}{{3}{14}{DP and Acc trade-off performance on three real-world datasets compared with (manifold) Fair Mixup.}{}{}}
\newlabel{app:influprob}{{}{14}{}{}{}}
\newlabel{app:runningtime}{{}{14}{}{}{}}
\newlabel{app:hyper}{{}{14}{}{}{}}
\citation{jiang2022generalized}
\citation{dai2021say}
\newlabel{fig:infprobe}{{4}{15}{The visualization of logit layer node representation for training with/without (left/right) sensitive attribute for FMP and several baselines across three real-world datasets. The data point with different colors represents different sensitive attributes.}{}{}}
\newlabel{app:impact}{{}{15}{}{}{}}
\newlabel{fig:runtime}{{5}{16}{The running time comparison.}{}{}}
\newlabel{fig:hyper}{{6}{16}{Hyperparameter study on fairness and smoothness hyperparameter for demographic parity and Accuracy.}{}{}}
\newlabel{fig:tradeoff_manual}{{7}{17}{DP and Acc trade-off performance on three real-world datasets compared with adding regularization, adversarial debiasing, and (manifold) Fair Mixup in additional datasets.}{}{}}
\gdef \@abspage@last{17}
