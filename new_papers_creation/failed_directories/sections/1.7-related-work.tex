




\section{Applications \& Implementation} \label{sec:applications}
\ryan{Change the figure to all-superscripts?}
\ryan{Cite frameworks paper.}
\ryan{Illustrate nodes with +VoC?}

Graphical criteria can help with modeling agents' incentives in a 
wide range of settings including 
(factored) Partially Observed Markov Decision Processes (POMDPs)
and Modified-action Markov Decision Processes \citep{langlois2021rl}.
For concreteness, 
we show how our contributions can aid in analysing a supervision POMDP \citep{Milli2017}.
In a supervision POMDP, an AI interacts with its environment, given suggested actions from a 
human player.
We will assume that the human's policy has already been selected, in order to focus on 
the incentives of the AI system.~\looseness=-1

\input{figures/spomdp}

Given the graph in \cref{fig:spomdp}, we can apply the VoI criterion to each $A^H_i$, the sole parent of $A^i$.
The minimal d-reduction is identical to the original graph, 
so since $A^H_i \!\not \dsep\! R^{i+1} \!\mid\! \emptyset$, 
the observation $A^H_i$ can have positive VoI.
This formalises the claim of \citet{Milli2017} that in a supervision POMDP, the agent ``can learn about reward through [the human's] orders''. 
We can say the same about Cooperative Inverse Reinforcement Learning (CIRL).
CIRL differs from supervision POMDPs only in that each human action 
$A^H_i$
directly 
affects the state $S_{i+1}$. 
If $\calG$ is modified by adding edges $A^H_i \to S_{i+1}$,
and the VoI criterion is applied at $A^H_i$ once again,
we find that 
$A^H_i$ may have positive VoI for $A^i$, 
thereby formalising
the claim that the robot is
``incentivised to learn''
\citep[Remark 1]{Hadfield-Menell2016cirl}.~\looseness=-1


To facilitate convenient use of the graphical criterion, 
we have implemented it in the open source ID library \emph{pycid} \citep{Fox2021pycid}, 
whereas the previous implementation was limited to single-decision IDs.%
\footnote{Code is available at {\url{www.github.com/causalincentives/pycid.}}}~\looseness=-1

\section{Related Work} \label{sec:related-work}


\newcommand{\aref}[1]{\hyperref[#1]{Appendix~\ref{#1}}} %

\paragraph{Value of information}
The concept of value of information dates back to the earliest
papers on influence diagrams \citep{Howard1966,matheson1968economic}.
For a review of recent advances, 
see \citet{borgonovo2016sensitivity}.~\looseness=-1

Previous results have shown how to identify 
observations with zero VoI or equivalent properties
in various settings.
In the no forgetting setting, 
\citet{Fagiuoli1998} and \citet{Nielsen1999}
identified ``structurally redundant''
and ``required nodes'' respectively.
In soluble IDs,
\citet{nilsson2000evaluating} 
proved that optimal decisions need not 
rely on nonrequisite nodes.
Completeness proofs in a setting of one decision have been discovered for VoI and its analogues by
\citet{zhang2020causal,lee2020characterizing,Everitt2021agent}.
Finally, in insoluble IDs,
\citet{lee2020characterizing}
proved that certain nodes are
``redundant under optimality''.
Of these works, only \citet{Nielsen1999} attempts a completeness result for the multi-decision setting.
However, as pointed out by \citet{Everitt2021agent}, it falls short in two respects:
Firstly, the criterion $X \not \dsep \sU^D \mid \Pa(D)$ is proposed, which differs from 
nonrequisiteness
in the conditioning set.
Secondly, and more importantly, 
the proof is incomplete because it 
assumes that positive VoI follows from d-connectedness.%

\paragraph{Submodel-trees}
Trees of systems are loosely related to the ``submodel-trees'' of \citet{lee2021submodel}.
In both cases, the tree encodes an ordering in which the ID can be solved, so the edges in a tree of systems are analogous to those in a submodel-tree. 
The nodes, however, (i.e.\ systems and submodels) differ.
Whereas a submodel-tree aids with solving IDs, a tree of systems helps with parameterising an ID graph. 
As a result, a submodel contains all nodes relevant for $D$, whereas a system consists just one set of info-/control-/obs-paths. 
Relatedly, in a submodel, downstream decisions may be solved and replaced with a value node, whereas in a tree of systems, they are not.~\looseness=-1














