\section{Completeness of the VoI Criterion} \label{sec:voi-completeness-main} %
We will now prove that the 
\emph{value of information} (VoI)
criterion 
of \citet{nilsson2000evaluating}
is complete for chance nodes
(details are deferred to \cref{sec:preliminaries-systems-and-trees,sec:model-definition}).


\subsection{Parameterising one system} \label{sec:tree} %
To prove 
that the criterion from \cref{thm:voi} is complete
we must show that for any graph where $X\to D$ is in the minimal d-reduction, 
$X$ has positive VoI for $D$.
For example, consider the graph in \cref{fig:trivial-completeness}, 
which is its own d-reduction, and contains $X \to D$.
In this graph, we can choose for $X$ to be Bernoulli distributed, 
for $D$ to have the boolean domain $\{0,1\}$, and for 
$U$ to be equal to $1$ if and only if $X$ and $D$ match.
Clearly, the policy $d=x$ will obtain $\mathbb{E}[U]=1$.
In contrast, 
if $X$ were not observed (no link $X\to D)$, then no policy could achieve expected utility more than $0.5$;
so the VoI of $X$ in this ID is $0.5$.~\looseness=-1

\input{figures/trivial-completeness}

A general procedure for parameterising any single-decision ID graph meeting the \cref{thm:voi} criterion to exhibit positive VoI has been established by \citet{Everitt2021agent} and \citet{lee2020characterizing}.
This procedure consists of two steps:
first, establish the existence of some paths, 
then choose CPDs for the nodes on those paths.
We call the paths found in the first step a \textit{system}, which will be a building block for our analysis of IDs with multiple decisions.
A fully-general illustration of a system is shown in \cref{fig:regions}.~\looseness=-1
\ryan{Maybe move some of these definitions down to wherever they're used.}


\input{definitions/system}
\input{figures/system}
The existence of these paths follow from the graphical criterion of \cref{thm:voi}.
In particular, since $X \!\to\! D$ is in the minimal d-reduction of $\calG$, 
there must exist a path
from $X$ to some utility node $U \in \sU \cap \Desc^{D^s}\!$, active given $\Fa(D^s) \!\setminus\! \{X^s\}$ (the ``info path" in \cref{def:system-minimal}).




The second step is to choose CPDs for the nodes $\sV^s$ in the system $s$, as also illustrated in \cref{fig:regions}.
The idea is to require
the decision $D^s$ to match the value of $Q^s$, by letting
the utility $U^s$ equal $1$ if and only if its parents along the control 
and information paths are equal.
If $X^s$ is observed, the decision $D^s=X^s \oplus O^1 ... \oplus O^n=Q^s$
yields $\mathbb{E}[U^s]=1$, where $\oplus$ denotes \emph{exclusive or} (XOR).
Otherwise, the observations $O^1,...,O^n$ are insufficient to decrypt $Q^s$, 
giving $\mathbb{E}[U^s]<1$.
So $X^s$ has positive VoI.
The intuitive idea is that $U^s$ tests whether $D^s$ knows $Q^s$, 
based on the value $d^s$ transmitted along $\scontrol^s$.~\looseness=-1
\chris{Above is a bit hard to follow I think.}






\subsection{Parameterising two systems} 
\input{figures/multi-dec-param-1}

When we have two decisions, however, it becomes insufficient to parameterise just one system.
For example, suppose that we try to apply 
the same scheme as in the previous subsection
to the graph of \cref{fig:multi-dec-param-1}.
Then, we would generate a random bit at $X$ and stipulate that the utility is $U=1$
if the parents $X$ and $D'$ on the red paths are equal.
One might hope that this would give $D$ an incentive to observe $X$, so that $d=x$ is copied through $D'$ to obtain $\mathbb{E}[U]=1$.
And that is indeed one way to obtain optimal expected utility.
However, the presence of a second decision $D'$ means that maximal utility of $U=1$ may also be obtained using the policy $d=0,d'=x$, 
which does not require $X$ to be observed by $D$.~\looseness=-1

To achieve positive VoI, it is necessary to parameterise two systems as shown in \cref{fig:multi-dec-param-2}.
We first parameterise the second (blue) system 
to ensure that $x'$ is transmitted to $U$, 
and then parameterise the initial (red) system. 

To check that $X$ has positive VoI for $D$, we now solve the combined model.
Due to the solubility assumption, we know that the optimal 
decision rule at $D'$ does not depend on the decision rule taken at $D$.
So let us consider $D'$ first.
$D'$ chooses a pair $(i, j)$ where $i$ is interpreted as an index of the bits generated at $Q'$, and $j$ is interpreted as a claim about the $i\textsuperscript{th}$ bit of $Q'$.
The first term of the utility $U$ is equal to $1$ if and only if the ``claim" made by $D'$ is correct, i.e.\ if the $i\textsuperscript{th}$ bit generated by $Q'$ really is $j$.
$X'$ contains (only) the $v\textsuperscript{th}$ digit of $Q'$.
Hence $D'$ can only ensure its ``claim" is correct if it chooses $d'=x'=(v,q'[v])$, 
where $q'[v]$ denotes the $v\textsuperscript{th}$ bit of $q'$.
Having figured out the optimal policy for $D'$, we next turn our attention to $D$.
Intuitively, the task of $D$ is to match $X$, as in \cref{fig:trivial-completeness}.
The parameterization encodes this task, by letting $D$ determine $V$, which in turn influences which bit of $Q'$ is revealed to $D'$.
This allows $U$ to check the output of $D$ via the index outputted by $D'$, and thereby check whether $D$ matched $X$.
This means the second term of $U$ is 1 if and only if $D=X$
so $d=x$ the optimal policy for $D$, with expected utility $\mathbb{E}[U]=2$.\looseness=-1

In contrast, if $X$ were unobserved by $D$, then it would no-longer be possible to achieve a perfect score on both terms of $U$, so $\mathbb{E}[U]<2$.
This shows that $X$ has positive VoI for $D$.\looseness=-1

\subsection{A tree of systems} \label{sec:tree-main}
\todo{add explanation here}


In order to generalise this approach to arbitrary number of decisions, 
we 
need a structure that specifies a system for each decision, and indicates 
what downstream decisions that system may depend on.
These relationships may be represented by a tree.~\looseness=-1

\input{definitions/tree}



The idea of a tree of systems is that 
if a decision $D^{s'}$ lies on a path in the system $s$ 
of some decision $D^s$, then $s$ is a predecessor of $s'$.
We will use this tree to parameterise the ID graph,
and then we will also use it to supply an ordering over the decisions 
(from leaf to root) in which the model can be solved by backward induction.
\ryan{Added some explanation here.}

\input{figures/cidhom-ensures-nft}
In order to generalise the approach taken to parameterising two systems, we need to reason
about the systems independently, in reverse order.
If the systems overlap, however, this 
makes it harder
to reason about them independently.
Thus it is useful to define a notion of systems called \emph{normal form} that are well-behaved.~\looseness=-1
\input{definitions/normalform}


An arbitrarily chosen tree will not generally be in normal form. 
For example, \cref{fig:transform-1}
contains two systems (a red root system for $X^s \to D^s$
and a blue child system for $X' \to D'$) that constitute a tree, 
but this tree fails all three requirements for being in normal form.
However, by a series of homomorphic transformations,
it is possible to obtain a new graph with a tree of systems that is in normal form (as in \cref{fig:transform-4}).~\looseness=-1



\begin{restatable}[Normal Form Existence]{lemma}{lenormalformtransform}
\label{le:20nov29.1-Existence-of-adequate-CID-split-from-nothing}
Let $\sG$ be a soluble ID graph whose minimal $d$-reduction $\sG^*$ contains $X\to D$. 
Then there is a 
normal form tree $T'$
on a soluble ID graph $\sG'$,
with a homomorphism $h$ from $\calG'$ to $\calG$
where the information link $X' \to D'$ of the root system of $T'$,
has $h(X')=X$, $h(D')=D$,
and every node in $\sG$ is also in $\sG'$ 
but the only nodes in $\sG$ that are in $T'$ are $X$ and $D$.~\looseness=-1
\end{restatable}
\ryan{Is it actually meaningful for nodes in $\calG$ to be in $T'$, or do we 
need to talk about applying $h^{-1}$ to them first?}
\ryan{Need to state that $\calG^3=\calG',T^3=T',h'=\hfirsttolast$ in the proof.}
\ryan{Maybe remark at this point that it's interesting that 
we can homomorphically modify the tree to obtain one that behaves
differently, describing how this relates to the unidirectionality of the homomorphism property? / Address the apparent contradiction that homomorphisms preserved the 
properties of a tree, but that we can analyse them differently.}

Essentially, the procedure for obtaining a normal form tree proceeds in four steps:
\begin{enumerate}
    \item Construct a tree of systems on $X \to D$: First, pick any system for $X\to D$. Then, pick any system for every other information link $X' \to D'$ in the existing system. Iterate until every link in the tree has a system. 
    
    \item 
    Make a copy (lemma 12) of each node for each position (basically, each path) that node has in the tree. 
    This ensures position-in-tree-uniqueness.
    
    \item For systems whose infopath starts with an incoming link $X \gets Y$, copy $X$ (lemma 12), to obtain $X\to  O \gets Y$. 
    This ensures no-backdoor-infopaths.
    
    \item Prune the graph (using lemma 13), by removing any (non-information) links outside the tree of systems. 
    This ensures no-redundant-links.
\end{enumerate}
For example, in \cref{fig:transform-1,fig:transform-2,fig:transform-3,fig:transform-4},
three transformations are performed, each of which makes the tree meet one additional 
requirement, ultimately yielding a normal form tree (\cref{fig:transform-4}) with a homomorphism to the original.~\looseness=-1


\subsection{Proving positive VoI given a normal form tree} \label{sec:voi-given-nft-main}


The reason for using normal form trees is that they enable each system to be parameterized and solved independently.
In particular, we know that the optimal policy for one system involves reproducing information from ancestor nodes such as $Q^s$.
As optimal policies can be found with backwards induction in soluble graphs, our approach involves finding optimal policies in reverse order.
It will therefore suffice to prove that 
non-descendant systems cannot provide information about ancestor nodes within the system.
For example, 
in \cref{fig:transform-1}, when solving for $\pi^{D'}$, 
we would like to know that $D^s$ cannot provide information about $Q'$.~\looseness=-1

\input{theorems/knowledge-lemma}

For example, \cref{fig:transform-4}, has a normal form tree, 
which implies the assurance that $X'$ cannot use information from the red system 
to tell it about $Q'$; formally, $Q' \dsep (Y \cup X^s) \mid X'$. %
Given that each decision $D^s$ in the tree cannot use information from ancestor systems, we can then 
prove that $D^s$
cannot know enough about $X^s$ and $Q^s$ to 
perform optimally, without observing $X^s$.
More formally: ~\looseness=-1


\input{theorems/materiality-on-normal-form-tree}

The formal proof is given in \cref{sec:model-has-incentives}.
Informally, in order to show that the decision of each system is forced to behave as intended despite there now being a tree of systems full of other decisions, we use \cref{le:2v2-graph-knowledge-lemma} to show that the utility that a decision obtains in system $s$ only depends on the information it obtains from within system $s$. This rules out that ancestor decisions can observe and pass along relevant information via a path outside the system. 
Moreover, we know by the solubility assumption that the optimal decision rule at a later decision 
cannot depend on the decision rule followed by earlier decisions.
The argument then proceeds by backward induction.
The final decision $D^{s^n}$ must copy the value of $X^{s_n}$.
Given that it does so, the penultimate decision $D^{s^{n-1}}$ must do the same.
And so on, until we find that 
$D$ must copy $X$, and cannot do so in any way other than by observing it, 
meaning that $X$ has positive VoI for $D$.~\looseness=-1\chris{I think these explanatory paragraphs can be better.}
\ryan{Is this accurate \& better?}






Finally, we can prove our main result, that there exists an ID on $\calG$ where $X$ has positive VoI. 



\input{theorems/matcompl-proof}

