\section{Introduction}

One approach to analysing the safety and fairness of AI systems is to represent them using variants of Bayesian networks \citep{Everitt2019modeling, Kusner2017}.
Influence diagrams (IDs) can be viewed an extension of Bayesian networks for representing agents \citep{Howard2005,Everitt2021agent}.
This graphical perspective offers a concise view of key relationships, that abstracts away from much of the internal complexity of modern-day AI systems.


Once a decision problem is represented graphically, key aspects can be summarised.
One well-studied concept is the \emph{value of information} (VoI) \citep{Howard1966}, which describes how much more utility 
an agent is able to obtain if it can observe a variable in its environment, compared with if it cannot.
Other summary concepts includes ``materiality'', ``value of control'', 
``response incentives''.~\looseness=-1


These concepts have been used to analyse the
redirectability \citep{everitt2019tampering,Holtman2020} of AI systems,
fairness \citep{Everitt2021agent,Ashurst2022}, 
ambitiousness \citep{cohen2020unambitious},
and %
the safety of reward learning systems
\citep{Armstrong2020pitfalls,Everitt2019modeling,langlois2021rl,Evans2021,Farquhar2022}.
Typically, this analysis involves applying \emph{graphical criteria}, that indicate which properties can or
cannot occur in a given diagram, based on the graph structure alone.
Graphical criteria are useful because they
enable qualitative judgements 
even when the precise functional relationships between variables
are unknown or unspecified.
~\looseness=-1

For the single-decision case, complete criteria have been established for all four of the aforementioned concepts \citep{Everitt2021agent}.
However, many AI applications such as reinforcement learning involve an agent making multiple decisions.
For the multi-decision case, multiple criteria for VoI have been proposed
\citep{Nielsen1999,Shachter1998,nilsson2000evaluating},
but none proven complete.
\looseness=-1

\input{figures/multi-dec-graph}

This means that for some graphs, it is not known whether a node can have positive VoI.
For example, in \cref{fig:no-voi-graph}, it is not known whether it can be valuable for $D$
to observe $X$.
Specifically, the edge $X \to D$ does not meet the criterion of \emph{nonrequisiteness} used by \citet{nilsson2000evaluating}, 
so we cannot rule out that it contains valuable information.
However, the procedure that is used to prove completeness in the single-decision setting \citep{Everitt2021agent} does not establish positive VoI.


We prove that the graphical criterion of \citet{nilsson2000evaluating} is complete,  in that any environmental variable not guaranteed to have zero VoI by their criterion must have positive VoI in some compatible ID.
In the course of the proof, we develop several tools for reasoning about soluble IDs.
In summary, our main contributions are:
\begin{itemize}
    \item \textbf{ID homomorphisms}. These allow us to transform an ID into another with similar properties, that may be more easily analysed (\cref{sec:CID-homomorphisms-main}).
    \item \textbf{Trees of systems}. A system is a set of paths that make information valuable to a decision.
    A tree of systems describes how those paths traverse other decisions (\cref{sec:tree-main}).
    \looseness=-1
    \item \textbf{A complete VoI criterion}. We prove the criterion in \cref{sec:voi-completeness-main}. In \cref{sec:applications} we explain why this criterion may be useful, how it may be used in an AI safety application, and share an open source implementation.
\end{itemize}










































