%%%% ijcai19.tex

\typeout{Domain-dependent and domain-independent problem solving techniques}

% These are the instructions for authors for IJCAI-19.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai19.sty is NOT the same than previous years'
\usepackage{ijcai19}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\urlstyle{same}


\newcommand{\tuple}[1]{\ensuremath{\left \langle #1 \right \rangle }}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{color, colortbl}
\definecolor{LightCyan}{rgb}{0.88,1,1}


\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{rotating}
\usepackage{multirow}
\usepackage{xspace}
\newcommand{\commentout}[1]{ }

\newcommand{\history}{past-conflicts\xspace}



%
% Add comments in the text
%
\newboolean{showcomments}
\setboolean{showcomments}{true}
%\setboolean{showcomments}{false}

\ifthenelse{\boolean{showcomments}}
  {\newcommand{\nb}[3]{
  {\color{#2}\small\fbox{\bfseries\sffamily\scriptsize#1}}
  {\color{#2}\sffamily\small$\triangleright~$\textit{\small #3}$~\triangleleft$}
  }
  }
  {\newcommand{\nb}[3]{}
  }

\newcommand\konstantin[1]{\nb{\textbf{Konstantin:}}{red}{#1}}
\newcommand\roni[1]{\nb{\textbf{Roni:}}{orange}{#1}}
\newcommand\anton[1]{\nb{\textbf{Anton:}}{cyan}{#1}}





%\usepackage[smaller]{acronym}
\usepackage{acronym}

\acrodef{EPEA*}{Enhanced Partial Expansion A$^*$}
\acrodef{LSP}{Longest Simple Path}
\acrodef{PBS}{Probably Bounded-Suboptimal}
\acrodef{AI}{Artificial Intelligence}
\acrodef{NA}{Network Alignment}
\acrodef{MBD}{Model-Based Diagnosis}
\acrodef{PS}{Potential Search}
\acrodef{DPS}{Dynamic Potential Search}
\acrodef{EES}{Explicit Estimation Search}
\acrodef{BEES}{Bounded-cost Explicit Estimation Search}
\acrodef{SOC}{sum of costs}
\acrodef{GBFS}{Greedy Best-First Search}
\acrodef{SIPP}{Safe interval path planning}
\acrodef{CBS}{Conflict-based search}
\acrodef{CCBS}{Continuous-time conflict-based search}
\acrodef{MAPF}{Multi-Agent Pathfinding}
\acrodef{ICTS}{Increasing Cost Tree Search}
\acrodef{MCCBS}{Multi-Constraint CBS}
\acrodef{AWA*}{Anytime Weighted A$^*$}
\acrodef{ARA*}{Anytime Repairing A$^*$}
\acrodef{CT}{Constraint Tree}


\newcommand{\lsp}{\ac{LSP}\xspace}
\newcommand{\pbs}{\ac{PBS}\xspace}
\newcommand{\open}{\textsc{OPEN}\xspace}
\newcommand{\focal}{\textsc{FOCAL}\xspace}
\newcommand{\ees}{\ac{EES}\xspace}
\newcommand{\bees}{\ac{BEES}\xspace}
\newcommand{\ccbs}{\ac{CCBS}\xspace}
\newcommand{\ct}{\ac{CT}\xspace}
\newcommand{\sipp}{\ac{SIPP}\xspace}
\newcommand{\dps}{\ac{DPS}\xspace}
\newcommand{\ps}{\ac{PS}\xspace}
\newcommand{\astar}{A$^*$\xspace}
\newcommand{\ida}{IDA$^*$\xspace}
\newcommand{\wastar}{wA$^*$\xspace}
\newcommand{\ara}{\ac{ARA*}\xspace}
\newcommand{\awa}{\ac{AWA*}\xspace}
\newcommand{\mbd}{\ac{MBD}\xspace}
\newcommand{\epea}{\ac{EPEA*}\xspace}
\newcommand{\na}{\ac{NA}\xspace}
\newcommand{\AI}{\ac{AI}\xspace}
\newcommand{\gbfs}{\ac{GBFS}\xspace}
\newcommand{\astarepsilon}{A$^*_\epsilon$\xspace}



%\newcommand{\mapfr}{MAPF$_R$\xspace}
\newcommand{\mapfr}{\ac{MAPF}$_R$\xspace}
\newcommand{\mapf}{\ac{MAPF}\xspace}
\newcommand{\const}{\textit{constraints}\xspace}
\newcommand{\safe}{\textit{Safe}\xspace}


\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}


% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{Domain-Dependent and Domain-Independent Problem Solving Techniques}

% Single author syntax
%\author{
%Anton Andreychuk$^1,^3$
%\and
%Konstantin Yakovlev$^1,^2$\and
%Dor Atzmon$^4$\And
%Roni Stern$^4$
%\affiliations
%$^1$Federal Research Center ``Computer Science and Control'' of Russian Academy of Sciences\\
%$^2$National Research University ``Higher School of Economics''\\
%$^3$Peoples’ Friendship University of Russia (RUDN University)\\
%$^4$Ben-Gurion University of the Negev
%\emails
%andreychuk@mail.com, 
%yakovlev@isa.ru,
%\{dorat,sternron\}@post.bgu.ac.il
%}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% Check the ijcai19-multiauthor.tex file for detailed instructions
%\iffalse
\author{Roni Stern
\affiliations
Ben-Gurion University of the Negev
\emails
sternron@post.bgu.ac.il
}
%\fi

\begin{document}

\maketitle



\begin{abstract}
Heuristic search is a general problem-solving method. 
Some heuristic search algorithms, like the well-known \astar algorithm, are \emph{domain-independent}, in the sense that their knowledge of the problem at-hand is limited to the
(1) initial state, 
(2) state transition operators and their costs, 
(3) goal-test function, 
and (4) black-box heuristic function that estimates the value of a state. 
Prominent examples are \astar and Weighted \astar. 
Other heuristic search algorithms are domain-dependent, that is, customized to solve problems from a specific domain. 
A well-known example is conflict-directed \astar, which is specifically designed to solve model-based diagnosis problems. 
In this paper, we review our recent advancements in both domain-independent and domain-dependent heuristic search, and outline several challenging open questions. 
 
% to solve 
%   Many AI-related problems can be solved by reduction to a more general type of problem, e.g., Boolean satisfiability (SAT), Constraint program (CP), and Mixed integer linear program (MILP),
% and then obtaining a solution by using a general-purpose solver. An alternative approach is to use dedicated algorithms that are customized to the problem at hand. In this talk, I will discuss my own experience in doing so for two types of problems: consistency-based diagnosis and multi-agent pathfinding. Both tasks have been solved with both approaches, with competing claims on which approach is better. I will also share the lessons I have learned in the process of developing solvers, general-purpose and domain-specific, for these problems, with hopes that it will shed some light on future research on solving such combinatorial problems.
\end{abstract}



\section{Introduction}
\acresetall 
%Domain-dependent and domain-independent problem solving techniques


\emph{Heuristic search} is one of the fundamental problem-solving techniques used in \AI, dating back to Newell and Simon's General Problem Solving program~\cite{newell1959report}. Heuristic search algorithms, such as \astar, are still the cornerstone of performing higher-level \AI tasks such as automated planning~\cite{bonet2001planning} and \mbd~\cite{reiter1987theory,de1987diagnosing}. 

When solving a problem using a search algorithm, 
the world is abstracted as a set of \emph{states}. 
Every state $s$ is associated with a set of \emph{state-transition operators} $O(s)$, where each $o\in O(s)$ is a function that maps $s$ to a possibly different state $s'$. 
A \emph{path} from state $s$ to $s'$ is a sequence of state-transition operators %$o_1, o_2, \ldots o_m$ such that applying this sequence to  $s$ results in $s'$.
such that applying this sequence to $s$ results in $s'$.  
It is common for operators to have a cost, 
and to define the \emph{cost of a path} as the sum of costs of its constituent operators. 
\emph{Path finding} is a common type of search problem where the objective is to find a path from a given initial state to a \emph{goal state}. 
A goal state is defined explicitly or implicitly via a goal-test function. Classical STRIPS-based planning is a prime example of a path finding problem~\cite{bonet2001planning,fikes1971strips}. 
A common requirement in path finding problems is that the path has a low \emph{cost}. An \emph{optimal} solution in such cases is a lowest-cost path from the initial state to a goal state. 

%In some search problems, the objective is not to find a path to a goal state, but to just find a goal state. There is a reduction from such problems to path finding problems. 

% denoted $O(s)$. A state-transition operator is a function that accepts a state and outputs a state. A \emph{path} from state $s$ to $s'$ is a sequence of state-transition operators $o_1, o_2, \ldots o_m$ such that $o_1\in O(s)$, 
% $\forall i\in\{2,\ldots,m\} o_i\in O(o_{i-1}(o_{i-1}(\cdots o_1(s)\cdots)))$, 
% and $o_m(\cdots o_1(s)\cdots)=s'$. 

A search algorithm is called a \emph{heuristic} search algorithm if it considers some imperfect source of information about the problem it is used to solve. In some heuristic search algorithms, this imperfect information is encapsulated in a black-box heuristic function $h$ that accepts a state $s$ and outputs a number that estimates the cost of a lowest-cost path from $s$ to a goal. We refer to such algorithms as \emph{domain-independent} heuristic search algorithms. We use this term to emphasize that all the problem solver knows about the domain beyond the initial state, operators, and goal-test function, is a black-box heuristic function. 


Prominent examples are \astar~\cite{hartNR68Astar} and \wastar~\cite{Pohl70HeuristicSearchPathFinding}. %Even with this minimal knowledge, such algorithm can guarantee to return optimal or almost optimal solutions. 
 Other heuristic search algorithms are domain-dependent, in the sense that their behavior is customized to solve a specific type of problems. For example, Conflict-Directed \astar~\cite{williams2007conflict} is a heuristic search algorithm that is specifically designed to solve \mbd problems. Similarly, Increasing Cost Tree Search~\cite{sharon2013increasing} is specifically designed to solve \mapf problems. 
 
 In this paper, we review our contributions in developing algorithms and theory for domain-independent and domain-dependent heuristic search. In particular, we describe several recent algorithms aimed at satisfying various requirements about solution quality, and review a range of domain-dependent heuristic search algorithms we developed. Throughout, we highlight open challenges and topics that are left for future research. 
%

\section{Background}

% There are many types of search problems and more than one way to categorize them. Most of my research so far has been on search problems in which the task was to find a \emph{path} in a search space to a goal state. Which states are goal states is defined either explicitly or by a goal-test function.  Every state  $s$ is associated with a set of \emph{state-transition} operators, denoted $O(s)$. A state-transition operator is a function that accepts a state and outputs a state. 
% A \emph{path} from state $s$ to $s'$ is a sequence of state-transition operators $o_1, o_2, \ldots o_m$ 
% such that $o_1\in O(s)$, 
% $\forall i\in\{2,\ldots,m\} o_i\in O(o_{i-1}(o_{i-1}(\cdots o_1(s)\cdots)))$, 
% and $o_m(\cdots o_1(s)\cdots)=s'$. 
% The objective in a path finding problem is to find a path from a given initial state to a goal state. Classical STRIPS-based planning is a prime example of a path-finding problem~\cite{bonet2001planning,fikes1971strips}. 


% A \emph{state} is as an assignment of values to variables. 
% In a fairly general class of search problems, the task is to find a state that satisfies a given set of requirements or constraints. 
% Such a state is referred to as a \emph{goal state}. 

% % What is a path. What is a path finding problem
% \paragraph{Path finding problems.}
% In path finding problems every state  $s$ is associated with a set of \emph{state-transition} operators, denoted $O(s)$. A state-transition operator is a function that accepts a state and outputs a state. 
% A \emph{path} from state $s$ to $s'$ is a sequence of state-transition operators $o_1, o_2, \ldots o_m$ 
% such that $o_1\in O(s)$, 
% $\forall i\in\{2,\ldots,m\} o_i\in O(o_{i-1}(o_{i-1}(\cdots o_1(s)\cdots)))$, 
% and $o_m(\cdots o_1(s)\cdots)=s'$. 
% The objective in a path finding problem is to find a path from a given initial state to a goal state. Classical STRIPS-based planning is a prime example of a path-finding problem~\cite{bonet2001planning,fikes1971strips}. 


% two types of search problems that I will refer to here as \emph{state finding} problems and \emph{path finding} problems.


% % What is a state. What is a state finding problem. 
% \paragraph{State finding problems.}
% A \emph{state} is as an assignment of values to variables. 
% In a fairly general class of search problems, the task is to find a state that satisfies a given set of requirements or constraints. 
% Such a state is referred to as a \emph{goal state}. 
% I refer to this type of search problems as \emph{state finding} problems. An examples of state finding problems is the famous N-queen problem. Task allocation, number partitioning~\cite{schreiber2018optimal}, and model-based diagnosis~\cite{reiter1987theory,de1987diagnosing} are other well-known examples of state finding problem. 


% Blind search
Best-first search is a general framework for solving search problems. 
% in general and path finding problems in particular
A best-first search maintains a list of states called \open. Initially, \open contains the initial state. Then, in every iteration, a single state $s$ is removed from \open and \emph{expanded}. 
To expand a state $s$ means that for every operator $o\in O(s)$ 
we \emph{generate} a new state $o(s)$ and insert it into \open. 
%For every operator $o\in O(s)$, a new state $o(s)$ is \emph{generated} and inserted to \open. 
Later iterations can choose to expand these new states, generating newer states. The search can halt when a goal state is generated. 

%halts when a goal 00 that it can be popped out of \open in future iterations.   state transition operator that is applicable to that state is then applied, \emph{generating} new states to be considered. This is called to \emph{expand} a state. The generated states are inserted to \open, so they can be selected later and expanded. The search halts when a goal state is expanded. 

% A heuristic
There are many design choices when implementing a best-first search, e.g., whether to insert to \open a state that was already generated by another state. A particularly important design choice is how to choose which state to remove from \open in every iteration. \emph{Heuristic search} algorithm use the heuristic function $h$ to make this choice. For example, the famous \astar algorithm chooses from \open the state $s$ with the smallest $f(s)=g(s)+h(s)$, where $g(s)$ is the cost of the lowest-cost path known so far from the initial state to $s$. 
A heuristic $h$ is \emph{admissible} if for every state $s$ it outputs a value that is smaller than or equal to the cost of a lowest-cost path from $s$ to a goal. 
Given an admissible heuristic, \astar is guaranteed to have found an optimal solution once a goal node is expanded~\cite{hartNR68Astar}. Most heuristic search algorithms that return optimal solutions also rely on an admissible heuristic, e.g., \ida~\cite{korf1985depth} and RBFS~\cite{Korf1992LinearSpaceBestFirstSearch}. %$$, that return optimal solutions and also rely on an


% Classic heuristic search algorithm: A*, IDA*, RBFS

% Theoretical limits: ``optimally effective''. Mention Meir and Rob

\section{Domain-Independent Search}
%In this section, we discuss our recent progress in the development of domain-independent heuristic search algorithms. 
%We use the term domain-independent to denote that all the problem solver knows about the problem is the initial state, the  goal-test function, the set of state transition operators with their cost, and a black-box heuristic function. Indeed, in such a setting, one can run textbook \astar to find an optimal solution. 


%The problem is that 
Many search problems are just too hard to solve optimally, even with \astar and a very accurate heuristic~\cite{helmert2008good}. 
To this end, a range of suboptimal search algorithms has been developed. 
One way to classify suboptimal search algorithms is by the theoretical guarantee they provide over the solution they return. 

\subsection{Incomplete and Not-Optimal Search}
Some search algorithms are incomplete, i.e., they may not find a solution even if such exists. 
Hill Climbing and Genetic Algorithms~\cite{holland1992genetic}
are examples of incomplete algorithms. Such algorithms are used for extremely difficult search problems. 

%\paragraph{Complete but Not-optimal search}
%\paragraph{Not-optimal search}
Other search algorithms are guaranteed to find a solution if such exists, but provide no guarantee regarding the quality of that solution. \gbfs~\cite{doran1966experiments}, also known as Pure heuristic search, is a popular example. \gbfs is a best-first search that expands in every iteration the state in \open with the smallest heuristic value. Beam search is another popular algorithm from this class~\cite{zhou2005beam,sabuncuoglu1999job,furcy2005limited}. 
There is a limited understanding of the behavior of these algorithms, although recent research has been trying to identify the relation between their performance and the heuristic landscape~\cite{wilt2016effective,heusner2018best}. 


In many cases, it is not sufficient to find any solution, and there are some restrictions on the cost of the desired solution. We have explored several such cost-related restrictions. 

\subsection{Bounded-Cost Search}
In a \emph{bounded-cost search} problem, the user defines a cost bound $C$ and aims to find a solution whose cost is at most $C$. This type of search problem arises, for example, in scenarios where there is a limited budget. Bounded-cost search problem has rarely been studied in a domain-independent manner. 

We closed this gap by proposing a search algorithm called \ps~\cite{SternFBPSG14} that is specifically designed to solve bounded-cost search problems. 
\ps is a best-first search based on a unique evaluation function $u(s)=\frac{C-g(s)}{h(s)}$.
In every iteration, \ps expands the state with the highest $u(s)$. The $u(\cdot)$ evaluation function was discovered independently by two research groups~\cite{PotentialSearch2011,van2011anytime} in the context of \emph{anytime search} (see later) and through different mathematical derivations. 

The derivation relevant to bounded-cost search relates $u(s)$ to the \emph{potential} of $s$. The potential of a state with respect to $C$ is the probability that it part of a solution of cost lower than $C$. Under certain probabilistic relation between the available heuristic function and the cost it estimates, it can be shown that the state with the highest $u(\cdot)$ in \open is also the one with the highest potential. 
Empirically, we observed \ps to be useful over a range of search domains. However, we also observed that \ps may perform poorly on domains in which the \emph{length} of a path, i.e., the number of its constituent operators, is not correlative with its cost. 

For such domains, we proposed \bees~\cite{ThayerSFR12}. \bees is based on \ees~\cite{ThayerR11BoundedSuboptimalSearch}, and considers additional heuristics including a heuristic that estimates the length of an optimal path to a goal. %, and an inadmissible but potentially accurate heuristic that estimates the cost of an optimal path to a goal. 
Empirical evaluations showed that BEES is particularly useful in these non-uniform domains. %on some domains. 
%and poorer results on others. Here too, further research and deeper understanding is needeed. 
%\roni{Maybe say something about how we do not understand enough waht is going on}
%However, the search literature still has no theo, but still no theoretical analysis is current known in the literature 
An open research challenge is to provide a more rigorous theory for the behavior of \ps and \bees, and in general to bounded-cost search problems. 

% is still an open research challenge. 

% %\roni{Maybe talk about other heuristic models?}
% In particular, it has been shown that \ps performs poorly on some domains in which the length of a path, i.e., the number of its constituent operators, is not correlative with its cost. This occurs in some domains where different operators have different costs. %Such domains are also known as domains with \emph{non-unit edge cost}. 
% %These domains highlight the fact that if one wishes to





\subsection{Bounded-Suboptimal Search}
%The term \emph{suboptimal search} has been used to refer to search algorithms that are not guaranteed to return an optimal solution. This term is misleading, as it suggests some closeness to optimality. 
A common way to quantify the \emph{suboptimality} a solution is by measuring the ratio between between its cost and the cost of an optimal solution. This is often called the \emph{suboptimality} of a solution.\footnote{Other ways to define suboptimality of a solution exist, e.g., the difference from the optimal solution cost~\cite{valenzano2013using}.} 
The suboptimality of an optimal solution is one, and higher suboptimality means a worse solution (i.e., higher cost). A \emph{bounded-suboptimal} search algorithm is an algorithm that accepts a parameter $B\geq 1$ and is guaranteed to return a solution whose suboptimality is at most $B$. %That is, the cost of any solution returned by such an algorithm is at most $B$ times the cost of an optimal solution. 
An ideal bounded-suboptimal search algorithm trades off solution cost for runtime, i.e., increasing $B$ results in worse (higher) solution cost and better (lower) search runtime. % until such a solution is found. 



% Background
%The literature on bounded-suboptimal search algorithms starts several decades ago, with the famous \wastar algorithm~\cite{Pohl70HeuristicSearchPathFinding,Pohl1973ACH} and the later \astarepsilon~\cite{PearlKimSAH1982}. 
\wastar is a well-known bounded-suboptimal search algorithm~\cite{Pohl70HeuristicSearchPathFinding} that is still widely used. 
It expands in every iteration the state $n$ in \open with the smallest $g(n)+B\cdot h(n)$. 


\astarepsilon~\cite{PearlKimSAH1982} is another well-known bounded-suboptimal search algorithm. In \astarepsilon, the minimal $f$ value in \open, referred to as $f_{min}$, is maintained. 
$f_{min}$ is used to define \focal, which is the set containing every state $s$ in \open  for which $f(s)\leq B\cdot f_{min}$. 
\astarepsilon chooses in every iteration to expand a state from \focal. To choose which state in \focal to expand, \astarepsilon uses a different, possibly  inadmissible heuristic. Since \astarepsilon does not define this secondary heuristic, it is, in fact, a search framework, which is known today as \emph{Focal search}~\cite{ThayerR11BoundedSuboptimalSearch,EbendtD09}. 

%,GILON2016
%cohen2018anytime,

%The original \astarepsilon suggested to expand the state in \focal with the lowest $h$ value. , but more modern algorithms such as \ees~\cite{ThayerR11BoundedSuboptimalSearch} use more sophisticated heuristics. 

% In a Focal search, the minimal $f$ value in \open, referred to as $f_{min}$, is maintained. The \emph{\focal} is a subset of \open that contains every node $n$ for which $f(n)\leq B\cdot f_{min}$. A Focal search chooses in every iteration to expand a node from \focal. To choose which node in \focal to expand, a different, possibly  inadmissible heuristic, is used. 
% The original \astarepsilon used $h(n)$ as a heuristic for choosing from \focal, but more modern algorithms such as \ees~\cite{ThayerR11BoundedSuboptimalSearch} use more sophisticated heuristics. 


All Focal search algorithms are bounded-suboptimal because throughout the search $f_{min}$ is always a lower bound on the cost of an optimal solution, given that $f$ is computed with an admissible heuristic. This understanding allowed us to develop a novel bounded-suboptimal search algorithm called \dps. \dps considers both $f_{min}$ and the $u(\cdot)$ function used by \ps~\cite{GILON2016}. \dps is a best-first search that expands in every iteration the state with the highest $u(\cdot)$. Since a cost bound $C$ is not given in a bounded-suboptimal search problem, \dps sets $C$ to be $B\cdot f_{min}$. This guarantees that any solution found will indeed be bounded suboptimal. 
If $f_{min}$ changes, \dps will re-sort \open to update the $u$ values. 
%Whenever \dps expands a goal node, it is guaranteed to have the desired suboptimality. 
In a sense, \dps is running a sequence of bounded-cost searches, where the cost bound is $B\cdot f_{min}$. A major advantage of \dps over Focal search algorithms is that it does not need to maintain \focal. Empirically, \dps performs well on a range of domains.
%Like \ps, however, \dps performs poorly in some non-unit edge cost domains. 
%Nevertheless, modern bounded-suboptimal search algorithms, such as \dps and \ees, outperform textbook bounded-suboptimal search algorithms such as \wastar and \astarepsilon.


\dps, as well as \ees, \wastar, and \astarepsilon, are all in the best-first search framework. Thus, there are cases where memory will be a bottleneck to the search. To address this, there are several modern bounded-suboptimal search algorithms that run in linear space~\cite{hatem2014bounded,hatem2013bounded} and outperform traditional bounded-suboptimal linear-space algorithms such as weighted \ida and weighted RBFS~\cite{Korf1992LinearSpaceBestFirstSearch}. 



Indeed, the past decade has seen an explosion of bounded-suboptimal search algorithms. However, the theoretical understanding of these algorithms is, to-date, limited. 
For example, in optimal search, under some conditions, any best-first search must expand at least the set of nodes expanded by \astar~\cite{dechter1985generalized,goldenberg2014enhanced,holte2019onThe}. An equivalent claim does not exist for bounded-suboptimal search. Also, there is no clear answer for which bounded-suboptimal algorithm to use in a given domain. There are important directions for future work. 



% This additional form of solution quality guarantee is hway to 


% That is, running a PBs algorithin at least $1-\delta$ cases

% the suboptimality it returns 

% with probablity at least $1-\delta$, 


% Finding an optimal solution to a search problem is often desirable, but can be too difficult in many cases. A common approach in such cases is to try to find a solution whose suboptimality is bounded, where a parameter ϵ defines how far from optimal a solution can be while still being acceptable. A scarcely studied alternative is to try to find a solution that is probably optimal, where a parameter δ defines the confidence required in the solution's optimality. This paper explores this option and introduces the concept of a probably bounded-suboptimal search (pBS search) algorithm. Such a search algorithm accepts two parameters, ϵ and δ, and outputs a solution that with probability at least  costs at most  times the optimal solution. A general algorithmic framework for pBS search algorithms is proposed. Several instances of this framework are described and analyzed theoretically and experimentally on a range of search domains. Results show that pBS search algorithms are often faster than a state-of-the-art bounded-suboptimal search algorithm. This shows in practice that finding solutions that satisfy a given suboptimality bound with high probability can be done faster than finding solutions that satisfy the same suboptimality bound with certainty.


\subsection{Anytime Search}
An \emph{anytime} algorithm is an algorithm ``whose quality of results improves gradually as computation time increases''~\cite{zilberstein1996using}. An anytime search algorithm finds an initial solution quickly, and then, given more running time, finds better solutions. Several anytime search algorithms have been proposed over the years. Prominent examples are \ara~\cite{likhachevGT03AnytimeRepairingAstar}, \awa~\cite{hansen2007anytime}, Anytime Windowed \astar~\cite{aine2007awa}, and 
Restarting Weighted \astar~\cite{richter2010joy}. A major limitation of all these algorithms is that they accept a parameter and there is no clear theory on how to set it. To address this, we developed a \emph{non-parametric} anytime search algorithm, that works as follows. First, it finds an initial solution with \gbfs. Then, we run \ps and set the cost-bound to be the cost of the incumbent solution. 
This will return a new, better, solution. Then, we run \ps again with the cost of the new solution. This process continues until time has run out or the optimal solution has been found. 
%Each of the bounded-cost search problems is solved with \ps. 
The resulting anytime search algorithm is, to-date, one of the best anytime search algorithms.\footnote{Due to its dual origin, this algorithm has two names: Anytime \ps or Anytime Non-Parametric \astar (AN\astar).}


This anytime algorithm and the bounded-suboptimal algorithm \dps are both built on top of \ps. However, they demonstrate a more general approach in which one can use a bounded-cost search algorithm to construct an anytime search algorithm as well as a bounded-suboptimal search algorithm. 
Thus, future work on developing better bounded-cost search algorithms can have a wide impact beyond solving bounded-cost search problems. 


%This algorithm, was developed independently by two groups with different names: Anytime \pts (APTS) and Anytime Non-Paramteric \astar (AN\astar). 




\subsection{Probably Bounded-Suboptimal Search}
%Bounded-suboptimal search algorithms, by definition, must guarantee that the suboptimality of the solution they return is at most $B$ for \emph{any} given search problem. 
Recently, we explored the notion of \emph{probabilistic} solution quality guarantees, where the suboptimality of a solution must be bounded in \emph{most} cases, but not always~\cite{stern2019probably}. 
More formally, a \pbs search algorithm is an algorithm that accepts, in addition to a suboptimality bound $B$, a \emph{confidence} parameter $\delta$. The guarantee provided by a \pbs is that the suboptimality of the solution it returns is at most $B$ with probability at least $1-\delta$. 
We proposed several \pbs algorithms based on running an anytime search algorithm and analyzing the domain and previously solved problems in it. Experimentally, we showed that allowing a non-zero $\delta$, i.e., a non-zero probability of returning a solution without the desired suboptimality, can lead to significant search speedup. 


The \pbs algorithms we proposed can be viewed as a middle-ground between domain-independent and domain-specific search. Indeed, we envision such forms of analysis of the domain can provide a bridge to introducing data-driven methods into heuristic search algorithms that provide some form of solution quality guarantees. 

%analysis of the domain and how the search algorithm behaves in it, thereby providing an automated way to customize a domain-independent search algorithm to the exact domain at hand. One such direction is to apply Machine Learning tools to model the relation between search context features and the likelihood that the incumbent solution can be improved. 





\section{Domain-Dependent Search}
Domain-independent heuristic search algorithms, such as those listed in the previous section, are widely used in a range of domains. 
%somewhat agnostic to the actual search problem they are being used to solve. They only consider the start state, the state transition operators, their cost, a goal-test function,  and a black-box heuristic function that estimates the cost to a goal state. 
However, an in-depth understanding of the problem domain is needed in some domains in order to guide the search effectively. 
In this section, we  describe a partial list of domain-specific search problems that we have worked on. %, and discuss their unique properties. 



\subsection{Multi-Agent Pathfinding}


% What is MAPF
A \mapf problem consists of a graph and $n$ agents. Each agent has a unique start node and a unique goal node. Time is discretized into time steps. In each time step, each agent can either move to an adjacent node or wait in its current node. A \emph{plan} for a single agent is a sequence of (more or wait) actions that moves the agent from its start  to its goal.  Two agents cannot occupy the same node at the same time, as that would cause a collision. 
A valid solution to a \mapf problem is a \emph{joint plan}, which is a 
set of plans, one for each agent, such that no collisions will occur. 
\mapf has topical applications in warehouse management~\cite{wurman2008coordinating}, airport towing~\cite{morris2016planning}, autonomous vehicles, robotics~\cite{veloso2015cobots}, and digital entertainment~\cite{ma2017feasibility}.


% Search space challenges
In many cases, there is also a requirement to minimize some cumulative cost function, such as the time spent or costs incurred until all agents have reached their goals. Solving \mapf optimally is NP-Hard~\cite{DBLP:conf/aaai/YuL13,DBLP:conf/aaai/Surynek10}. 
\mapf is particularly challenging for domain-independent search algorithms because the number of operators in a given state is exponential in the number of agents, since agents can move concurrently. %. . Consider solving this problem is \astar. A \emph{state} in \mapf, would an assignment of agent to the it occupies in a specific time step. Since all agents can move concurrently, every state transition operator corresponds to a set of action to perform in a given time, one per agent. Thus, if each agent has $b$ possible actions it can take, 
%the number of state transition operators in a state would be $b^n$. Such an exponential branching factor makes the cost of every node expansion to be prohibitively large, and thus \mapf is a particularly challenging for \astar and other best-first search algorithms. 

To address this, we developed the \epea algorithm ~\cite{goldenberg2014enhanced}, that uses a domain-specific \emph{operator selection function} to choose to use only a subset of the applicable operators when a state is expanded. \epea is, in fact, applicable to any problem with a large branching factor. We also developed more sophisticated, domain-specific \mapf,  that solve \mapf by solving two different search problems that interact with each other. For more details, see Felner et al.~\shortcite{felner2017searchBased}. 


%agents~\cite{wagner2015subdimensional,ICBS,surynek2012towards,yu2013planning}. 


% Search space challenges



% A hint of ID, OD, ICTS, and CBS
\subsection{Longest Simple Path}
The \lsp problem is the problem of finding the longest \emph{simple} path in a graph from one node to another. A path is \emph{simple} iff no node appears twice in the path. \lsp is a classical graph theory problem with various applications. A key challenge in \lsp is that it is \emph{non-monotonic}, i.e., longer paths are better. This makes it harder to identify when an optimal solution has been found~\cite{SternFBPSG14}. We describe how to adapt \astar to such problems, and propose several heuristics for \lsp, and for a particular type of \lsp called \emph{snake in the box}, which has application in coding~\cite{palombo2015solving}.  

A second challenge in \lsp is the simple-path requirement. This requirement prohibits pruning multiple paths that reach the same node, thereby making the search much harder. A similar challenge exists in other search problems, such as the target-value search~\cite{lopez2013target}. Creating a general, domain-independent algorithm for problems with this requirement, is an open challenge. 


\subsection{Model-Based Diagnosis}
An \mbd  problem occurs when an observation of a system is inconsistent with an available model of that system and the assumption that all the system components are not faulty. The task of a consistency-based \mbd algorithm is to infer \emph{diagnoses}, which are 
assumptions about which system components are faulty that explain the observation. 


\mbd is a classical problem in the Artificial Intelligence literature with numerous applications~\cite{reiter1987theory,de1987diagnosing}. \mbd can be modeled as a search problem. A state is an assumption about which component is faulty. The initial state assumes all components are not faulty. 
A state transition operator adds an assumption that one component is faulty. A goal-test function checks if the assumption represented by a state is consistent with the observation and the available system model. 


\mbd is a challenging problem because the number of operators applicable in a state is the number of system components. A common way to address this is to limit the search using \emph{conflicts}. A conflict is a set of components that contain at least one faulty component. Conflict-directed \astar~\cite{williams2007conflict} and other algorithms~\cite{reiter1987theory,de1987diagnosing} work by identifying conflicts, and then limiting the search to only consider hitting sets of identified conflicts. 

Identifying conflicts, however, is a hard problem in its own right. %Thus, several modern \mbd algorithm do not consider conflicts directly, and instead employ the power of current SAT solvers to find diagnosis effectively~\cite{metodi2014novel,nica2013route}.  
To address this, we proposed an \mbd-specific search algorithm that runs two searches in parallels: one searching for conflicts and the other searching for diagnoses~\cite{stern2012exploring}. Due to the duality between conflicts and diagnoses, these searches effectively interact, where finding diagnoses helps finding conflicts and vice versa.  




% \paragraph{Network Alignment}
% Very recently, we have begun to develop search algorithms for solving the \na  problem. The input to \na is a pair of graphs $G_1=(V_1,E_1)$ and  
% $G_2=(V_2,E_2)$ and the task is to find a \emph{alignment}, which is a function that maps a node in $V_1$ to a node in $V_2$. Alignments are associated with a score, and the objective is to find an alignment with the maximizes this score. 
% \na has important applications in a range of AI-domains, but it has received a particular interest in biology. 


% There is more than on way to solve \na as a search problem. One is to start with an empty alignment, and add a single mapping of one node in $V_1$ when generating a new state. An alternative is to start with a random full alignment, and the state transition operators are to swap between the images of two nodes. In our preliminary work on \na, we explored using the latter search modeling, and used a simple local search algorithm -- simulated annealing. We proposed a way to prune the set of possible alignments in a way that maintains completeness of the underlying search. The resulting algorithm is complete, but not optimal. Exciting future work would be to develop effective heuristic and search mechanism to find optimal, or bounded-suboptimal alignments. 



\section{Conclusion}

Recent years have shown tremendous progress in both domain-independent and domain-dependent heuristic search algorithms. We believe that cross-fertilization between domain-independent and domain-dependent search algorithms can lead to impactful advancement in the field. This calls for automating the process of learning domain properties and extracting useful information from them that can be used in search. 



\section*{Acknowledgments}
The contributions in this paper are a result of collaborations with many other researchers. Special thanks go to Ariel Felner, my long-time mentor and friend, as well as to Meir Kalech, Rami Puzis, and Robert Holte, for their key role in 
this research and my academic education. 
This research is supported by ISF grants no. 210/17 to Roni Stern. 

\small
%\pagebreak
\bibliographystyle{named}
\bibliography{short-library} 

\end{document}

