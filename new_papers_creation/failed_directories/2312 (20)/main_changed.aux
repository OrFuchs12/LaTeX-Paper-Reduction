\relax 
\bibstyle{aaai24}
\citation{VDN,NEURIPS2022_c40d1e40,QMIX,chen2023minimizing,chen2022multi}
\citation{QMIX}
\citation{WQMIX}
\citation{WQMIX}
\citation{QTRAN}
\citation{QPLEX}
\citation{ResQ}
\citation{ResQ}
\citation{mei2023remix}
\citation{WQMIX}
\citation{marl,dop,zhou2022value,gogineni2023accmer,mei2022mac}
\citation{VDN}
\citation{QMIX}
\citation{VDN}
\citation{QMIX}
\citation{WQMIX}
\citation{QTRAN}
\citation{QPLEX}
\citation{ResQ}
\citation{maddpg}
\citation{maac}
\citation{coma}
\citation{pac}
\citation{VDAC}
\citation{dop}
\citation{qatten}
\newlabel{eq:qmix_objective}{{1}{2}{}{}{}}
\citation{balls_into_bins}
\citation{concaveopt}
\citation{convex_conjugate}
\newlabel{S_mono}{{3}{3}{}{}{}}
\newlabel{P_X_1}{{3}{3}{}{}{}}
\newlabel{maxY}{{4}{3}{}{}{}}
\citation{convex_optimization}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{framework}{{1}{4}{The overall architecture of ConcaveQ. The concave mixing network represents $Q_{tot}$ as a concave function of local $Q_a$. With the help of iterative action selection, we can select the optimal actions during training. As for the execution process, the soft policy network is used to find the optimal actions. }{}{}}
\citation{WQMIX}
\citation{samvelyan2019starcraft}
\citation{QMIX}
\citation{WQMIX}
\citation{pac}
\citation{QPLEX}
\citation{ResQ}
\citation{fop}
\newlabel{eq:qcentral_loss}{{11}{5}{}{}{}}
\newlabel{exp_stag_hunt}{{2}{6}{Average reward on the Predator-Prey tasks.}{}{}}
\newlabel{exp_smac}{{3}{6}{Average test win rate on the SMAC tasks.}{}{}}
\newlabel{exp_ablation}{{4}{7}{Ablations results comparing CONCAVEQ and its ablated versions on SMAC map \texttt  {3s\_vs\_5z}}{}{}}
\bibdata{Ref}
\newlabel{subsec:Theorems}{{}{9}{}{}{}}
\newlabel{S_mono}{{2}{9}{}{}{}}
\newlabel{P_X_1}{{2}{9}{}{}{}}
\newlabel{P_maxY_union}{{3}{9}{}{}{}}
\newlabel{P_maxY_union}{{4}{9}{}{}{}}
\newlabel{P_maxY_union}{{5}{9}{}{}{}}
\newlabel{P_maxY_union}{{6}{9}{}{}{}}
\newlabel{P_maxY_union}{{7}{9}{}{}{}}
\newlabel{P_maxY_union}{{8}{9}{}{}{}}
\citation{convex_conjugate}
\newlabel{E_maxY}{{9}{10}{}{}{}}
\newlabel{alg_action_selction}{{1}{10}{Iterative action selection}{}{}}
\citation{ResQ}
\citation{pac}
\citation{QPLEX}
\citation{fop}
\citation{deep_coori_graph}
\newlabel{q_pi_1}{{18}{11}{}{}{}}
\newlabel{q_pi_2}{{19}{11}{}{}{}}
\newlabel{q_pi_3}{{20}{11}{}{}{}}
\citation{smac}
\citation{QMIX}
\citation{WQMIX}
\citation{ResQ}
\citation{pac}
\citation{fop}
\citation{QPLEX}
\newlabel{predator}{{}{12}{}{}{}}
\newlabel{smac}{{}{12}{}{}{}}
\newlabel{tab:my-table}{{1}{13}{Concise overview of SMAC Map scenarios employed in experimental settings}{}{}}
\gdef \@abspage@last{13}
