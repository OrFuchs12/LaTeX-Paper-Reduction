% V-Cornia
@INPROCEEDINGS{vcornia,
  author={J. {Xu} and P. {Ye} and Y. {Liu} and D. {Doermann}},
  booktitle={2014 IEEE International Conference on Image Processing (ICIP)}, 
  title={No-reference video quality assessment via feature learning}, 
  year={2014},
  volume={},
  number={},
  pages={491-495},
  doi={10.1109/ICIP.2014.7025098}}


% COME
@INPROCEEDINGS{come,
  author={C. {Wang} and L. {Su} and W. {Zhang}},
  booktitle={2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={COME for No-Reference Video Quality Assessment}, 
  year={2018},
  volume={},
  number={},
  pages={232-237},
  doi={10.1109/MIPR.2018.00056}}


@INPROCEEDINGS{multi-video-slice,
author = {Peng Yan and Xuanqin Mou},
title = {{No-reference video quality assessment based on perceptual features extracted from multi-directional video spatiotemporal slices images}},
volume = {10817},
booktitle = {Optoelectronic Imaging and Multimedia Technology V},
editor = {Qionghai Dai and Tsutomu Shimura},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {335 -- 344},
keywords = {video quality assessment, multi-directional video spatiotemporal slices images, no-reference, support vector machine},
year = {2018},
doi = {10.1117/12.2503149},
URL = {https://doi.org/10.1117/12.2503149}
}

@INPROCEEDINGS{SIVP13,
  author={D Varga and T Szirányi},
  booktitle={Signal, Image and Video Processing 13}, 
  title={No-reference video quality assessment via pretrained CNN and LSTM networks}, 
  year={2019},
  pages={1569–1576},
  url={https://doi.org/10.1007/s11760-019-01510-8}}

% Deep VQA NR- ICIP 2019
@INPROCEEDINGS{deep3dcnnvqa,
  author={J. {You} and J. {Korhonen}},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)}, 
  title={Deep Neural Networks for No-Reference Video Quality Assessment}, 
  year={2019},
  volume={},
  number={},
  pages={2349-2353},
  doi={10.1109/ICIP.2019.8803395}}


% Deep VQA NR ICIP 2018
@INPROCEEDINGS{cnnvqaicip2018,
  author={S. {Ahn} and S. {Lee}},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Deep Blind Video Quality Assessment Based on Temporal Human Perception}, 
  year={2018},
  volume={},
  number={},
  pages={619-623},
  doi={10.1109/ICIP.2018.8451450}}


% Deep vqa FR-ECCV 18
@InProceedings{Kim_2018_ECCV,
author = {Kim, Woojae and Kim, Jongyoo and Ahn, Sewoong and Kim, Jinwoo and Lee, Sanghoon},
title = {Deep Video Quality Assessor: From Spatio-temporal Visual Sensitivity to A Convolutional Neural Aggregation Network},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}


%hosdden
@ARTICLE{hosdden,
  author={Q. {Jiang} and W. {Gao} and S. {Wang} and G. {Yue} and F. {Shao} and Y. -S. {Ho} and S. {Kwong}},
  journal={IEEE Transactions on Instrumentation and Measurement},
  title={Blind Image Quality Measurement by Exploiting High-Order Statistics With Deep Dictionary Encoding Network}, 
  year={2020},
  volume={69},
  number={10},
  pages={7398-7410},
  doi={10.1109/TIM.2020.2984928}}

%vmaf
@INPROCEEDINGS{vmaf,
  author={R. {Rassool}},
  booktitle={2017 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={{VMAF} reproducibility: Validating a perceptual practical video quality metric}, 
  year={2017},
  volume={},
  number={},
  pages={1-2},}
%ms_ssim  
@INPROCEEDINGS{ms_ssim,
  author={Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
  booktitle={The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003}, 
  title={Multiscale structural similarity for image quality assessment}, 
  year={2003},
  volume={2},
  number={},
  pages={1398-1402 Vol.2},
  doi={10.1109/ACSSC.2003.1292216}}

% ST-MAD
@INPROCEEDINGS{stmad,
  author={Vu, Phong V. and Vu, Cuong T. and Chandler, Damon M.},
  booktitle={2011 18th IEEE International Conference on Image Processing}, 
  title={A spatiotemporal most-apparent-distortion model for video quality assessment}, 
  year={2011},
  volume={},
  number={},
  pages={2505-2508},
  doi={10.1109/ICIP.2011.6116171}}

% MOVIE
@article{movie,
    title = {Motion tuned spatio-temporal quality assessment of natural videos},
    author = {Seshadrinathan, Kalpana and Bovik, Alan C},
    journal = {IEEE Transactions on Image Processing},
    volume = {19},
    number = {2},
    pages = {335--350},
    year = {2009}
}

% vmeon
@inproceedings{vmeon,
author = {Liu, Wentao and Duanmu, Zhengfang and Wang, Zhou},
title = {End-to-End Blind Quality Assessment of Compressed Videos Using Deep Neural Networks},
year = {2018},
isbn = {9781450356657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240508.3240643},
doi = {10.1145/3240508.3240643},
booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
pages = {546–554},
numpages = {9},
keywords = {convolutional neural network, blind video quality assessment, multi-task learning},
location = {Seoul, Republic of Korea},
series = {MM ’18}
}

@ARTICLE{stfr,
  author={C. G. {Bampis} and Z. {Li} and A. C. {Bovik}},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Spatiotemporal Feature Integration and Model Fusion for Full Reference Video Quality Assessment}, 
  year={2019},
  volume={29},
  number={8},
  pages={2256-2270},}

% LIVE VQA DB  
@article{live_sd1,
    title = {Study of subjective and objective quality assessment of video},
    author = {Seshadrinathan, Kalpana and Soundararajan, Rajiv and Bovik, Alan C and Cormack, Lawrence K},
    journal = {IEEE Transactions on Image Processing},
    volume = {19},
    number = {6},
    pages = {1427--1441},
    year = {2010}
}

@inproceedings{livesd2,
    title = {A subjective study to evaluate video quality assessment algorithms},
    author = {Seshadrinathan, Kalpana and Soundararajan, Rajiv and Bovik, Alan C and Cormack, Lawrence K},
    booktitle = {SPIE Human Vis. Electron. Imag.},
    year = {2010}
}

% EPFL-PoliMI DB
@INPROCEEDINGS{epfl1,
  author={F. {De Simone} and M. {Tagliasacchi} and M. {Naccari} and S. {Tubaro} and T. {Ebrahimi}},
  booktitle={2010 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={A {H}.264/{AVC} video database for the evaluation of quality metrics}, 
  year={2010},
  volume={},
  number={},
  pages={2430-2433},}
  
@INPROCEEDINGS{epfl2,
  author={F. {De Simone} and M. {Naccari} and M. {Tagliasacchi} and F. {Dufaux} and S. {Tubaro} and T. {Ebrahimi}},
  booktitle={2009 International Workshop on Quality of Multimedia Experience}, 
  title={Subjective assessment of H.264/{AVC} video sequences transmitted over a noisy channel}, 
  year={2009},
  volume={},
  number={},
  pages={204-209},}
  

% LIVE Mobile
@ARTICLE{mobile1,
  author={A. K. {Moorthy} and L. K. {Choi} and A. C. {Bovik} and G. {de Veciana}},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Video Quality Assessment on Mobile Devices: Subjective, Behavioral and Objective Studies}, 
  year={2012},
  volume={6},
  number={6},
  pages={652-671},}
  
 
% CSIQ VQ DB
@article{csiq,
author = {Phong V. Vu and Damon M. Chandler},
title = {{ViS3: an algorithm for video quality assessment via analysis of spatial and spatiotemporal slices}},
volume = {23},
journal = {Journal of Electronic Imaging},
number = {1},
publisher = {SPIE},
pages = {1 -- 25},
keywords = {Video, Distortion, Databases, Image filtering, Image quality, Visualization, Video compression, Motion models, Motion estimation, Visual process modeling},
year = {2014},
doi = {10.1117/1.JEI.23.1.013016},
URL = {https://doi.org/10.1117/1.JEI.23.1.013016}
}

% ECVQ & EVVQ

@article{ecvq_evvq1,
author = {Rimac-Dr\i{}je, Snje\v{z}ana and Vranje\vS, Mario and \v{Z}agar, Drago},
title = {Foveated Mean Squared Error--a Novel Video Quality Metric},
year = {2010},
issue_date = {September 2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-009-0442-1},
doi = {10.1007/s11042-009-0442-1},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {425–445},
numpages = {21},
keywords = {Video quality metric, Foveated vision, Subjective quality assessment, Spatio-temporal activity, Retinal image velocity}
}

@article{10.1007/s11042-009-0442-1,
author = {Rimac-Dr\i{}je, Snje\v{z}ana and Vranje\v{s}, Mario and \v{Z}agar, Drago},
title = {Foveated Mean Squared Error--a Novel Video Quality Metric},
year = {2010},
issue_date = {September 2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-009-0442-1},
doi = {10.1007/s11042-009-0442-1},
journal = {Multimedia Tools and Applications},
month = {sep},
pages = {425–445},
numpages = {21},
keywords = {Retinal image velocity, Spatio-temporal activity, Foveated vision, Subjective quality assessment, Video quality metric}
}
@article{ecvq_evvq2,
title = "Review of objective video quality metrics and performance comparison using different databases",
journal = "Signal Processing: Image Communication",
volume = "28",
number = "1",
pages = "1 - 19",
year = "2013",
issn = "0923-5965",
doi = "https://doi.org/10.1016/j.image.2012.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S0923596512001919",
author = "Mario Vranješ and Snježana Rimac-Drlje and Krešimir Grgić",
keywords = "Video quality metrics, Video databases, Subjective quality evaluation, Objective metrics comparison, Metric complexity",
}




% tlvqm

@ARTICLE{tlvqm,
  author={J. {Korhonen}},
  journal={IEEE Transactions on Image Processing}, 
  title={Two-Level Approach for No-Reference Consumer Video Quality Assessment}, 
  year={2019},
  volume={28},
  number={12},
  pages={5923-5938},}


% NIQE
@ARTICLE{niqe,  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C.},  journal={IEEE Signal Processing Letters},   title={Making a “Completely Blind” Image Quality Analyzer},   year={2013},  volume={20},  number={3},  pages={209-212},  doi={10.1109/LSP.2012.2227726}}

% ST-RRED
@article{strred,
    title = {Video Quality Assessment by Reduced Reference Spatio-Temporal Entropic Differencing},
    author = {Soundararajan, Rajiv and Bovik, Alan C},
    journal = {IEEE Transactions on Circuits and Systems for Video Technology},
    volume = {23},
    number = {4},
    pages = {684--694},
    year = {2013}
}

% RRED
@INPROCEEDINGS{rred,
  author={R. {Soundararajan} and A. C. {Bovik}},
  booktitle={2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={RRED indices: Reduced reference entropic differencing framework for image quality assessment}, 
  year={2011},
  volume={},
  number={},
  pages={1149-1152},}
  
% weakly_sup
@ARTICLE{weakly_sup,
  author={Y. {Zhang} and X. {Gao} and L. {He} and W. {Lu} and R. {He}},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Blind Video Quality Assessment With Weakly Supervised Learning and Resampling Strategy}, 
  year={2019},
  volume={29},
  number={8},
  pages={2244-2255},}
  
% 3d_dct
@ARTICLE{3d_dct,
  author={X. {Li} and Q. {Guo} and X. {Lu}},
  journal={IEEE Transactions on Image Processing}, 
  title={Spatiotemporal Statistics for Video Quality Assessment}, 
  year={2016},
  volume={25},
  number={7},
  pages={3329-3342},}
  
% nstss
@ARTICLE{nstss,
  author={S. V. {Reddy Dendi} and S. S. {Channappayya}},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Video Quality Assessment Using Natural Spatiotemporal Scene Statistics}, 
  year={2020},
  volume={29},
  number={},
  pages={5612-5624},}
  
% spped_qa
@ARTICLE{speed_qa,
  author={C. G. {Bampis} and P. {Gupta} and R. {Soundararajan} and A. C. {Bovik}},
  journal={IEEE Signal Processing Letters}, 
  title={SpEED-{QA}: Spatial Efficient Entropic Differencing for Image and Video Quality}, 
  year={2017},
  volume={24},
  number={9},
  pages={1333-1337},}
  
% Video BLIINDS
@article{vbliind,
    title = {Blind Prediction of Natural Video Quality},
    author = {Saad, Michele A and Bovik, Alan C and Charrier, Christophe},
    journal = {IEEE Transactions on Image Processing},
    volume = {23},
    number = {3},
    pages = {1352--1365},
    year = {2014}
}

% robust_strred
@article{robust_strred,
    title = {On the Robust Performance of the {ST-RRED} Video Quality Predictor},
    author={ A. C. {Bovik} and R. {Soundararajan} and C. G. {Bampis}},
    url = {https://live.ece.utexas.edu/research/Quality/ST-RRED},
    year = {2017}
}
    
% ResNet
@INPROCEEDINGS{resnet,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}}

% SACONVA
@article{saconva,
    title = {No-Reference Video Quality Assessment With 3D Shearlet Transform and Convolutional Neural Networks},
    author = {Li, Yuming and Po, Lai-Man and Cheung, Chun-Ho and Xu, Xuyuan and Feng, Litong and Yuan, Fang and Cheung, Kwok-Wai},
    journal = {IEEE Transactions on Circuits and Systems for Video Technology},
    volume = {26},
    number = {6},
    pages = {1044--1057},
    year = {2016}
}

% Unreasonable-Effectiveness

@INPROCEEDINGS{unreason_deepfeat,
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}, 
  year={2018},
  volume={},
  number={},
  pages={586-595},
  doi={10.1109/CVPR.2018.00068}}
  
% deep feat predictor
@ARTICLE{bovik_deep_feat,
  author={J. {Kim} and H. {Zeng} and D. {Ghadiyaram} and S. {Lee} and L. {Zhang} and A. C. {Bovik}},
  journal={IEEE Signal Processing Magazine}, 
  title={Deep Convolutional Neural Models for Picture-Quality Prediction: Challenges and Solutions to Data-Driven Image Quality Assessment}, 
  year={2017},
  volume={34},
  number={6},
  pages={130-141},}


@article{adam_old,
        title = {Adam: A Method for Stochastic Optimization},
        author = {Diederik P. Kingma and Jimmy Ba},
        journal = {arXiv preprint arXiv:1412.6980},
        year={2014}
}

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{qa_in_the_wild,
author = {Li, Dingquan and Jiang, Tingting and Jiang, Ming},
title = {Quality Assessment of In-the-Wild Videos},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343031.3351028},
doi = {10.1145/3343031.3351028},
pages = {2351–2359},
numpages = {9},
keywords = {human visual system, in-the-wild videos, content dependency, temporal-memory effects, video quality assessment},
location = {Nice, France},
series = {MM '19}
}

@ARTICLE{videval,
  author={Tu, Zhengzhong and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={UGC-VQA: Benchmarking Blind Video Quality Assessment for User Generated Content}, 
  year={2021},
  volume={30},
  number={},
  pages={4449-4464},
  doi={10.1109/TIP.2021.3072221}}
% ssim
@ARTICLE{ssim,
  author={ {Zhou Wang} and A. C. {Bovik} and H. R. {Sheikh} and E. P. {Simoncelli}},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},}
  
@article{livevqc,
    title = {Large-Scale Study of Perceptual Video Quality},
    author = {Sinno, Zeina and Bovik, Alan C},
    journal = {IEEE Transactions on Image Processing},
    volume = {28},
    number = {2},
    pages = {612--627},
    year = {2019}
}

@INPROCEEDINGS{optical_nrvqa,
  author={K. {Manasa} and S. S. {Channappayya}},
  booktitle={2016 IEEE International Conference on Image Processing (ICIP)}, 
  title={An optical flow-based no-reference video quality assessment algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={2400-2404},}
  
% konvid-1k

@inproceedings{konvid,
title = {The Konstanz natural video database 
(KoNViD-1k)},
author = {Hosu, Vlad and Hahn, Franz and Jenadeleh, 
Mohsen and Lin, Hanhe and Men, Hui and Szir{\'a}nyi,
Tam{\'a}s and Li, Shujun and Saupe, Dietmar},
booktitle = {2017 Ninth International Conference on 
Quality of Multimedia Experience (QoMEX)},
pages = {1--6},
year = {2017},
organization = {IEEE}
}

% cvd2014

@ARTICLE{cvd2014,
  author={M. {Nuutinen} and T. {Virtanen} and M. {Vaahteranoksa} and T. {Vuori} and P. {Oittinen} and J. {Häkkinen}},
  journal={IEEE Transactions on Image Processing}, 
  title={{CVD}2014—A Database for Evaluating No-Reference Video Quality Assessment Algorithms}, 
  year={2016},
  volume={25},
  number={7},
  pages={3073-3086},}
  
  @ARTICLE{viideo,
  author={Mittal, Anish and Saad, Michele A. and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={A Completely Blind Video Integrity Oracle}, 
  year={2016},
  volume={25},
  number={1},
  pages={289-300},
  doi={10.1109/TIP.2015.2502725}}
  
  @ARTICLE{nrsted,
  author={Mitra, Shankhanil and Soundararajan, Rajiv and Channappayya, Sumohana S.},
  journal={IEEE Signal Processing Letters}, 
  title={Predicting Spatio-Temporal Entropic Differences for Robust No Reference Video Quality Assessment}, 
  year={2021},
  volume={28},
  number={},
  pages={170-174},
  doi={10.1109/LSP.2021.3049682}}
  
@inproceedings{cnntlvqm,
author = {Korhonen, Jari and Su, Yicheng and You, Junyong},
title = {Blind Natural Video Quality Prediction via Statistical Temporal Features and Deep Spatial Features},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413845},
doi = {10.1145/3394171.3413845},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {3311–3319},
numpages = {9},
keywords = {machine learning, human visual system, convolutional neural network, video quality assessment},
location = {Seattle, WA, USA},
series = {MM '20}
}
  @inproceedings{pseudolabel,
    title = {Pseudo-label: The simple and efficient semisupervised learning method for deep neural networks},
    author = {Lee, Dong-Hyun},
    booktitle = {ICML Workshop on Challenges in Representation Learning},
    year = {2013}}

@Article{entropoyminimize,
  author =    "M. Sajjadi and M. Javanmardi and T. Tasdizen",
  title =     "Regularization With Stochastic Transformations and
              Perturbations for Deep Semi-Supervised Learning",
  journal =   "NIPS",
  year =      "2016",
  url =       "http://www.sci.utah.edu/publications/Saj2016b/1606.04586.pdf",
}

@ARTICLE{liveiqc,
  author={Ghadiyaram, Deepti and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Massive Online Crowdsourced Study of Subjective and Objective Picture Quality}, 
  year={2016},
  volume={25},
  number={1},
  pages={372-387},
  doi={10.1109/TIP.2015.2500021}}
  
@ARTICLE{liveqcomm,
  author={Ghadiyaram, Deepti and Pan, Janice and Bovik, Alan C. and Moorthy, Anush Krishna and Panda, Prasanjit and Yang, Kai-Chieh},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={In-Capture Mobile Video Distortions: A Study of Subjective Behavior and Objective Algorithms}, 
  year={2018},
  volume={28},
  number={9},
  pages={2061-2077},
  doi={10.1109/TCSVT.2017.2707479}}
  
  @INPROCEEDINGS{semi_iqa,
  author={Tang, Huixuan and Joshi, Neel and Kapoor, Ashish},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Blind Image Quality Assessment Using Semi-supervised Rectifier Networks}, 
  year={2014},
  volume={},
  number={},
  pages={2877-2884},
  doi={10.1109/CVPR.2014.368}}
  
  @article{semi_iqa_ensemble,
  author    = {Zhihua Wang and
               Dingquan Li and
               Kede Ma},
  title     = {Semi-Supervised Deep Ensembles for Blind Image Quality Assessment},
  journal   = {CoRR},
  volume    = {abs/2106.14008},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.14008},
  eprinttype = {arXiv},
  eprint    = {2106.14008},
  timestamp = {Wed, 30 Jun 2021 16:14:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-14008.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{sslIQA,  author={Yue, Guanghui and Cheng, Di and Li, Leida and Zhou, Tianwei and Liu, Hantao and Wang, Tianfu},  journal={IEEE Transactions on Multimedia},   title={Semi-Supervised Authentically Distorted Image Quality Assessment with Consistency-Preserving Dual-Branch Convolutional Neural Network},   year={2022},  volume={},  number={},  pages={1-13},  doi={10.1109/TMM.2022.3209889}}
  
  @inproceedings{nrvqa_1,
author = {Jorge E. Caviedes and Franco Oberti},
title = {{No-reference quality metric for degraded and enhanced video}},
volume = {5150},
booktitle = {Visual Communications and Image Processing 2003},
editor = {Touradj Ebrahimi and Thomas Sikora},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {621 -- 632},
keywords = {Objective image quality metric, no-reference image quality, video impairment metric},
year = {2003},
doi = {},
URL = {https://doi.org/10.1117/12.510112}
}

@INPROCEEDINGS{nrvqa_2,
  author={Farias, M.C.Q. and Mitra, S.K.},
  booktitle={IEEE International Conference on Image Processing 2005}, 
  title={No-reference video quality metric based on artifact measurements}, 
  year={2005},
  volume={3},
  number={},
  pages={III-141},
  doi={10.1109/ICIP.2005.1530348}}
  
  @ARTICLE{nrvqa_3,
  author={Fuzheng Yang and Shuai Wan and Yilin Chang and Hong Ren Wu},
  journal={IEEE Signal Processing Letters}, 
  title={A novel objective no-reference metric for digital video quality assessment}, 
  year={2005},
  volume={12},
  number={10},
  pages={685-688},
  doi={10.1109/LSP.2005.855553}}
  
  @ARTICLE{dipIQ,
  author={Ma, Kede and Liu, Wentao and Liu, Tongliang and Wang, Zhou and Tao, Dacheng},
  journal={IEEE Transactions on Image Processing}, 
  title={dipIQ: Blind Image Quality Assessment by Learning-to-Rank Discriminable Image Pairs}, 
  year={2017},
  volume={26},
  number={8},
  pages={3951-3964},
  doi={10.1109/TIP.2017.2708503}}
  
  @INPROCEEDINGS{lbl_ssl,
  author={Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ondrej},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Label Propagation for Deep Semi-Supervised Learning}, 
  year={2019},
  volume={},
  number={},
  pages={5065-5074},
  doi={10.1109/CVPR.2019.00521}}
  
  @INPROCEEDINGS{scarce_ssl,
  author={Rebuffi, Sylvestre-Alvise and Ehrhardt, Sebastien and Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Semi-Supervised Learning with Scarce Annotations}, 
  year={2020},
  volume={},
  number={},
  pages={3294-3302},
  doi={10.1109/CVPRW50498.2020.00389}}

@InProceedings{simPLE,
    author    = {Hu, Zijian and Yang, Zhengyu and Hu, Xuefeng and Nevatia, Ram},
    title     = {SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {15099-15108}
}

@inproceedings{mean_teach,
  author    = {Antti Tarvainen and
               Harri Valpola},
  title     = {Mean teachers are better role models: Weight-averaged consistency
               targets improve semi-supervised deep learning results},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {1195--1204},
  year      = {2017}
}

@inproceedings{consistancy1,
  author    = {Qizhe Xie and
               Zihang Dai and
               Eduard H. Hovy and
               Thang Luong and
               Quoc Le},
  title     = {Unsupervised Data Augmentation for Consistency Training},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12},
  year      = {2020}
}

@inproceedings{consistancy2,
 author = {Jeong, Jisoo and Lee, Seungeui and Kim, Jeesoo and Kwak, Nojun},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Consistency-based Semi-supervised Learning for Object detection},
 volume = {32},
 year = {2019}
}

@ARTICLE{utube_ugc,
  author={Tu, Zhengzhong and Wang, Yilin and Birkbeck, Neil and Adsumilli, Balu and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={UGC-VQA: Benchmarking Blind Video Quality Assessment for User Generated Content}, 
  year={2021},
  volume={30},
  number={},
  pages={4449-4464},
  doi={10.1109/TIP.2021.3072221}}
  
% two Step QA

@ARTICLE{twostepQA,
  author={Yu, Xiangxu and Bampis, Christos G. and Gupta, Praful and Bovik, Alan Conrad},
  journal={IEEE Transactions on Image Processing}, 
  title={Predicting the Quality of Images Compressed After Distortion in Two Steps}, 
  year={2019},
  volume={28},
  number={12},
  pages={5757-5770},
  doi={10.1109/TIP.2019.2922850}}
  
% Wilcoxon Test

@ARTICLE{wilcoxonTest,
  author={Wilcoxon,F.},
  journal={Biometrics Bulletin}, 
  title={Individual Comparisons by Ranking Methods}, 
  year={1945},
  volume={1},
  number={6},
  pages={80-83}}
  
  https://live.ece.utexas.edu/research/Quality/ST-RRED/
  
@ARTICLE{robustSTRRED,
  author={Bovik, Alan C. and Soundararajan, Rajiv and Bampis, Christos G.},
  journal={}, 
  title={On the Robust Performance of the ST-RRED Video Quality Predictor}, 
  year={2017},
  url = {'https://live.ece.utexas.edu/research/Quality/ST-RRED/'}
  }
  
@ARTICLE{speedQA,
  author={Bampis, Christos G. and Gupta, Praful and Soundararajan, Rajiv and Bovik, Alan C.},
  journal={IEEE Signal Processing Letters}, 
  title={SpEED-QA: Spatial Efficient Entropic Differencing for Image and Video Quality}, 
  year={2017},
  volume={24},
  number={9},
  pages={1333-1337},
  doi={10.1109/LSP.2017.2726542}}
  
@ARTICLE{vif,
  author={Sheikh, Hamid R. and Bovik, Alan C.},
  journal={}, 
  title={A Visual Information Fidelity measure for image quality assessment}, 
  year={2006},
  url = {'https://live.ece.utexas.edu/research/Quality/VIF.htm'} 
  }
  
  
  @article{rapique,
  author    = {Zhengzhong Tu and
               Xiangxu Yu and
               Yilin Wang and
               Neil Birkbeck and
               Balu Adsumilli and
               Alan C. Bovik},
  title     = {{RAPIQUE:} Rapid and Accurate Video Quality Prediction of User Generated
               Content},
  journal   = {CoRR},
  volume    = {abs/2101.10955},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.10955},
  eprinttype = {arXiv},
  eprint    = {2101.10955},
  timestamp = {Sun, 31 Jan 2021 17:23:50 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-10955.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{ucda,
    author    = {Chen, Pengfei and Li, Leida and Wu, Jinjian and Dong, Weisheng and Shi, Guangming},
    title     = {Unsupervised Curriculum Domain Adaptation for No-Reference Video Quality Assessment},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {5178-5187}
}

@ARTICLE{cspt,
  author={Chen, Pengfei and Li, Leida and Wu, Jinjian and Dong, Weisheng and Shi, Guangming},
  journal={IEEE Transactions on Image Processing}, 
  title={Contrastive Self-Supervised Pre-Training for Video Quality Assessment}, 
  year={2022},
  volume={31},
  number={},
  pages={458-471},
  doi={10.1109/TIP.2021.3130536}}
  
@inproceedings{rirnet,
author = {Chen, Pengfei and Li, Leida and Ma, Lei and Wu, Jinjian and Shi, Guangming},
title = {RIRNet: Recurrent-In-Recurrent Network for Video Quality Assessment},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413717},
doi = {10.1145/3394171.3413717},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {834–842},
numpages = {9},
keywords = {motion perception, temporal frequency, speed tuning, video quality assessment},
location = {Seattle, WA, USA},
series = {MM '20}
}
@inproceedings{consistency_reg,
title={Transformation Consistency Regularization--A Semi-supervised Paradigm for Image-to-Image Translation},
author={Mustafa, Aamir and Mantiuk, Rafa{\l} K},
booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVIII 16},
pages={599--615},
year={2020},
organization={Springer}
}

@ARTICLE{STEM,
  author={Kancharla, Parimala and Channappayya, Sumohana S.},
  journal={IEEE Transactions on Image Processing}, 
  title={Completely Blind Quality Assessment of User Generated Video Content}, 
  year={2022},
  volume={31},
  number={},
  pages={263-274},
  doi={10.1109/TIP.2021.3130541}}
  
@ARTICLE{konvid150k,
  author={Götz-Hahn, Franz and Hosu, Vlad and Lin, Hanhe and Saupe, Dietmar},
  journal={IEEE Access}, 
  title={KonVid-150k: A Dataset for No-Reference Video Quality Assessment of Videos in-the-Wild}, 
  year={2021},
  volume={9},
  number={},
  pages={72139-72160},
  doi={10.1109/ACCESS.2021.3077642}}
  
@INPROCEEDINGS {paq-2-piq,
author = {Z. Ying and H. Niu and P. Gupta and D. Mahajan and D. Ghadiyaram and A. Bovik},
booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {From Patches to Pictures (PaQ-2-PiQ): Mapping the Perceptual Space of Picture Quality},
year = {2020},
volume = {},
issn = {},
pages = {3572-3582},
doi = {10.1109/CVPR42600.2020.00363},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR42600.2020.00363},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@InProceedings{patchVQ,
    author    = {Ying, Zhenqiang and Mandal, Maniratnam and Ghadiyaram, Deepti and Bovik, Alan},
    title     = {Patch-VQ: 'Patching Up' the Video Quality Problem},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {14019-14029}
}
  
@InProceedings{cmc,
author="Tian, Yonglong
and Krishnan, Dilip
and Isola, Phillip",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Contrastive Multiview Coding",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="776--794",
isbn="978-3-030-58621-8"
}

@InProceedings{dpc_ssl,
  author       = "Tengda Han and Weidi Xie and Andrew Zisserman",
  title        = "Video Representation Learning by Dense Predictive Coding",
  booktitle    = "Workshop on Large Scale Holistic Video Understanding, ICCV",
  year         = "2019",
}

@inproceedings{vcop_ssl,
  title={Self-supervised Spatiotemporal Learning via Video Clip Order Prediction},
  author={Xu, Dejing and Xiao, Jun and Zhao, Zhou and Shao, Jian and Xie, Di and Zhuang, Yueting},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@InProceedings{prp_ssl,  
author = {Yao, Yuan and Liu, Chang and Luo, Dezhao and Zhou, Yu and Ye, Qixiang},  
title = {Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning},  
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},  
month = {June},  
year = {2020}  
}

@inbook{iic_ssl,
author = {Tao, Li and Wang, Xueting and Yamasaki, Toshihiko},
title = {Self-Supervised Video Representation Learning Using Inter-Intra Contrastive Framework},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413694},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {2193–2201},
numpages = {9}
}

@ARTICLE{heke-csvt,
  author={Liu, Yongxu and Wu, Jinjian and Li, Leida and Dong, Weisheng and Zhang, Jinpeng and Shi, Guangming},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Spatiotemporal Representation Learning for Blind Video Quality Assessment}, 
  year={2022},
  volume={32},
  number={6},
  pages={3500-3513},
  doi={10.1109/TCSVT.2021.3114509}}

@article{contrique,
  author    = {Pavan C. Madhusudana and
               Neil Birkbeck and
               Yilin Wang and
               Balu Adsumilli and
               Alan C. Bovik},
  title     = {Image Quality Assessment using Contrastive Learning},
  journal   = {CoRR},
  volume    = {abs/2110.13266},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.13266},
  eprinttype = {arXiv},
  eprint    = {2110.13266},
  timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-13266.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ffmpeg,
author = {Tomar, Suramya},
title = {Converting Video Formats with FFmpeg},
year = {2006},
issue_date = {June 2006},
publisher = {Belltown Media},
address = {Houston, TX},
volume = {2006},
number = {146},
issn = {1075-3583},
abstract = {FFmpeg is a mini Swiss Army knife of format conversion tools.},
journal = {Linux J.},
month = {jun},
pages = {10}
}

@InProceedings{tvl1,
author="Zach, C.
and Pock, T.
and Bischof, H.",
editor="Hamprecht, Fred A.
and Schn{\"o}rr, Christoph
and J{\"a}hne, Bernd",
title="A Duality Based Approach for Realtime TV-L1 Optical Flow",
booktitle="Pattern Recognition",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="214--223"
}

@InProceedings{simclr,
  title = 	 {A Simple Framework for Contrastive Learning of Visual Representations},
  author =       {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1597--1607},
  year = 	 {2020},
  editor = 	 {III, Hal DaumÃ© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR}
}

@INPROCEEDINGS{youtube_ugc,
  author={Wang, Yilin and Inguva, Sasi and Adsumilli, Balu},
  booktitle={2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={YouTube UGC Dataset for Video Compression Research}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/MMSP.2019.8901772}}
  
@inproceedings{VQPM,
author = {Tang, Jiapeng and Fang, Yi and Dong, Yu and Xie, Rong and Gu, Xiao and Zhai, Guangtao and Song, Li},
title = {Blindly Predict Image and Video Quality in the Wild},
year = {2021},
isbn = {9781450386074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469877.3490588},
doi = {10.1145/3469877.3490588},
booktitle = {ACM Multimedia Asia},
articleno = {8},
numpages = {7},
keywords = {in the wild, supervised contrastive learning, image/video quality prediction, relation-guided temporal attention},
location = {Gold Coast, Australia},
series = {MMAsia '21}
}

@Article{mdtvsfa,
author={Li, Dingquan
and Jiang, Tingting
and Jiang, Ming},
title={Unified Quality Assessment of in-the-Wild Videos with Mixed Datasets Training},
journal={International Journal of Computer Vision},
year={2021},
month={Apr},
day={01},
volume={129},
number={4},
pages={1238-1257},
issn={1573-1405},
doi={10.1007/s11263-020-01408-w},
url={https://doi.org/10.1007/s11263-020-01408-w}
}

@ARTICLE{gmsd,
  author={Xue, Wufeng and Zhang, Lei and Mou, Xuanqin and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual Image Quality Index}, 
  year={2014},
  volume={23},
  number={2},
  pages={684-695},
  doi={10.1109/TIP.2013.2293423}}

@INPROCEEDINGS{noisy_student,
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Self-Training With Noisy Student Improves ImageNet Classification}, 
  year={2020},
  volume={},
  number={},
  pages={10684-10695},
  doi={10.1109/CVPR42600.2020.01070}}
  
@InProceedings{fastVQA,
author="Wu, Haoning
and Chen, Chaofeng
and Hou, Jingwen
and Liao, Liang
and Wang, Annan
and Sun, Wenxiu
and Yan, Qiong
and Lin, Weisi",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="FAST-VQA: Efficient End-to-End Video Quality Assessment with Fragment Sampling",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="538--554",
isbn="978-3-031-20068-7"
}

@INPROCEEDINGS {swinT,
author = {Z. Liu and Y. Lin and Y. Cao and H. Hu and Y. Wei and Z. Zhang and S. Lin and B. Guo},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
year = {2021},
volume = {},
issn = {},
pages = {9992-10002},
abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.},
keywords = {image segmentation;computer vision;visualization;computational modeling;semantics;object detection;computer architecture},
doi = {10.1109/ICCV48922.2021.00986},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00986},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@ARTICLE{survey_semiVQA,
  author={Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Deep Semi-Supervised Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-20},
  doi={10.1109/TKDE.2022.3220219}}

@inproceedings{fixmatch,
author = {Sohn, Kihyuk and Berthelot, David and Li, Chun-Liang and Zhang, Zizhao and Carlini, Nicholas and Cubuk, Ekin D. and Kurakin, Alex and Zhang, Han and Raffel, Colin},
title = {FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {51},
numpages = {13},
pages = {596–608},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}
@ARTICLE{brisque,
  author={Mittal, Anish and Moorthy, Anush Krishna and Bovik, Alan Conrad},
  journal={IEEE Transactions on Image Processing}, 
  title={No-Reference Image Quality Assessment in the Spatial Domain}, 
  year={2012},
  volume={21},
  number={12},
  pages={4695-4708},
  doi={10.1109/TIP.2012.2214050}}
  
@article{friquee,
    author = {Ghadiyaram, Deepti and Bovik, Alan C.},
    title = "{Perceptual quality prediction on authentically distorted images using a bag of features approach}",
    journal = {Journal of Vision},
    volume = {17},
    number = {1},
    pages = {32-32},
    year = {2017},
    month = {01},
    issn = {1534-7362},
    doi = {10.1167/17.1.32},
    url = {https://doi.org/10.1167/17.1.32},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/jov/935953/i1534-7362-17-1-32.pdf},
}
@inproceedings{ladder_network,
author = {Rasmus, Antti and Valpola, Harri and Honkala, Mikko and Berglund, Mathias and Raiko, Tapani},
title = {Semi-Supervised Learning with Ladder Networks},
year = {2015},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
pages = {3546–3554},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}

@inproceedings{rankNet,
author = {Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
title = {Learning to Rank Using Gradient Descent},
year = {2005},
isbn = {1595931805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1102351.1102363},
doi = {10.1145/1102351.1102363},
pages = {89–96},
numpages = {8},
location = {Bonn, Germany},
series = {ICML '05}
}

@ARTICLE{hierarchical_nrvqa,  author={Shen, Wenhao and Zhou, Mingliang and Liao, Xingran and Jia, Weijia and Xiang, Tao and Fang, Bin and Shang, Zhaowei},  journal={IEEE Transactions on Broadcasting},   title={An End-to-End No-Reference Video Quality Assessment Method With Hierarchical Spatiotemporal Feature Representation},   year={2022},  volume={68},  number={3},  pages={651-660},  doi={10.1109/TBC.2022.3164332}}

@inproceedings{vision,
author = {Mitra, Shankhanil and Soundararajan, Rajiv},
title = {Multiview Contrastive Learning for Completely Blind Video Quality Assessment of User Generated Content},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548064},
doi = {10.1145/3503161.3548064},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {1914–1924},
numpages = {11},
keywords = {multiview contrastive learning, blind video quality assessment, user generated content},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{NVQE,
author = {Liao, Liang and Xu, Kangmin and Wu, Haoning and Chen, Chaofeng and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
title = {Exploring the Effectiveness of Video Perceptual Representation in Blind Video Quality Assessment},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547849},
doi = {10.1145/3503161.3547849},
pages = {837–846},
numpages = {10},
keywords = {perceptual trajectories, temporal modeling, blind video quality assessment, primary visual cortex},
location = {Lisboa, Portugal},
series = {MM '22}
}

@misc{CONVIQT,
  doi = {10.48550/ARXIV.2206.14713},
  url = {https://arxiv.org/abs/2206.14713},
  author = {Madhusudana, Pavan C. and Birkbeck, Neil and Wang, Yilin and Adsumilli, Balu and Bovik, Alan C.},
  title = {CONVIQT: Contrastive Video Quality Estimator},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{cmpl,
    author    = {Xu, Yinghao and Wei, Fangyun and Sun, Xiao and Yang, Ceyuan and Shen, Yujun and Dai, Bo and Zhou, Bolei and Lin, Stephen},
    title     = {Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {2959-2968}
}

@InProceedings{TCL,
    author    = {Singh, Ankit and Chakraborty, Omprakash and Varshney, Ashutosh and Panda, Rameswar and Feris, Rogerio and Saenko, Kate and Das, Abir},
    title     = {Semi-Supervised Action Recognition With Temporal Contrastive Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {10389-10399}
}
@InProceedings{video_swin_t,
    author    = {Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
    title     = {Video Swin Transformer},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {3202-3211}
}

@article{csvt_bvqa,
  title={Blindly Assess Quality of In-the-Wild Videos via Quality-aware Pre-training and Motion Perception},
  author={Li, Bowen and Zhang, Weixia and Tian, Meng and Zhai, Guangtao and Wang, Xianpei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={9},
  pages={5944-5958},
  year={2022}
}

@InProceedings{mpl,
    author    = {Pham, Hieu and Dai, Zihang and Xie, Qizhe and Le, Quoc V.},
    title     = {Meta Pseudo Labels},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {11557-11568}
}

@inproceedings{adamw,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Decoupled Weight Decay Regularization},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=Bkg6RiCqY7},
  timestamp = {Thu, 25 Jul 2019 14:26:04 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LoshchilovH19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{video_action_ssl,
    author    = {Kumar, Akash and Rawat, Yogesh Singh},
    title     = {End-to-End Semi-Supervised Learning for Video Action Detection},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {14700-14710}
}

@InProceedings{mixmatch,
author = {Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Oliver, Avital and Papernot, Nicolas and Raffel, Colin},
title = {MixMatch: A Holistic Approach to Semi-Supervised Learning},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {454},
numpages = {11}
}

@ARTICLE{chipQA,
  author={Ebenezer, Joshua Peter and Shang, Zaixi and Wu, Yongjun and Wei, Hai and Sethuraman, Sriram and Bovik, Alan C.},
  journal={IEEE Transactions on Image Processing}, 
  title={ChipQA: No-Reference Video Quality Prediction via Space-Time Chips}, 
  year={2021},
  volume={30},
  number={},
  pages={8059-8074},
  doi={10.1109/TIP.2021.3112055}}

@ARTICLE{viqe,
  author={Zheng, Qi and Tu, Zhengzhong and Zeng, Xiaoyang and Bovik, Alan C. and Fan, Yibo},
  journal={IEEE Signal Processing Letters}, 
  title={A Completely Blind Video Quality Evaluator}, 
  year={2022},
  volume={29},
  number={},
  pages={2228-2232},
  doi={10.1109/LSP.2022.3215311}}

@misc{semi_iqa_kedema,
  title={Semi-supervised deep ensembles for blind image quality assessment},
  author={Wang, Zhihua and Li, Dingquan and Ma, Kede},
  journal={arXiv preprint arXiv:2106.14008},
  year={2021}
}

@inproceedings{semi_iqa_conformer,
  title={Conformer and blind noisy students for improved image quality assessment},
  author={Conde, Marcos V and Burchi, Maxime and Timofte, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={940--950},
  year={2022}
}
@article{koniq10k,
  title={KonIQ-10k: An ecologically valid database for deep learning of blind image quality assessment},
  author={Hosu, Vlad and Lin, Hanhe and Sziranyi, Tamas and Saupe, Dietmar},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4041--4056},
  year={2020},
  publisher={IEEE}
}

@inproceedings{spaq,
  title={Perceptual quality assessment of smartphone photography},
  author={Fang, Yuming and Zhu, Hanwei and Zeng, Yan and Ma, Kede and Wang, Zhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3677--3686},
  year={2020}
}

@article{maxVQA,
  title={Towards Explainable In-the-Wild Video Quality Assessment: a Database and a Language-Prompted Approach},
  author={Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  journal={arXiv preprint arXiv:2305.12726},
  year={2023}
}

@inproceedings{goodfellow_ssl,
author = {Oliver, Avital and Odena, Augustus and Raffel, Colin and Cubuk, Ekin D. and Goodfellow, Ian J.},
title = {Realistic Evaluation of Deep Semi-Supervised Learning Algorithms},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {3239–3250},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@article{manifold_regularization,
author = {Belkin, Mikhail and Niyogi, Partha and Sindhwani, Vikas},
title = {Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples},
year = {2006},
issue_date = {12/1/2006},
publisher = {JMLR.org},
volume = {7},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = {dec},
pages = {2399–2434},
numpages = {36}
}