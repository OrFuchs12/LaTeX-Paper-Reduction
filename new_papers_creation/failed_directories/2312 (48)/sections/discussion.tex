\section{Discussion}
\label{sec:discussion}


\paragraph{Relations to DICE~\cite{sun2022dice}.} Our work differs from DICE in two crucial
aspects, both in terms of training loss and test-time OOD detection mechanism.
As introduced in Section~\ref{sec:method}, \name can be viewed as \emph{training-time} regularization with subspace. In contrast, DICE~\cite{sun2022dice}  only explored \emph{test-time} weight sparsification mechanism, without explicitly learning the subspace in training. Specifically, DICE employs the standard cross-entropy loss, whereas we contribute a new learning objective (\emph{c.f.} Section~\ref{sec:train}) for OOD detection. Importantly, we show that training-time regularization provides substantial gains over simple post-hoc sparsification. For example, as evidenced in Table~\ref{tab:cifar-100},  post-hoc sparsification can severely affect the ID test accuracy. In contrast, our method bakes the inductive bias of ``feature subspace'' into training time, and exhibits stronger ID generalization in testing time. Besides, another major difference between \name and DICE lies in how test-time OOD detection is performed. In particular, \name is a distance-based method that operates in the \emph{feature} space, whilst DICE derives OOD scores from the model \emph{output} space. Different from DICE, \name is motivated to address the curse-of-dimensionality issue for OOD detection. Table~\ref{tab:cifar-100} compares the OOD detection performance of \name with DICE. For example, on CIFAR-100, \name reduces FPR95 by \textbf{18.47\%} compared to DICE. Improved performance validates the advantage of learning a subspace in training as opposed to test-time sparsification.



\paragraph{Relations to Dropout strategies.} A commonly used technique to prevent over-parameterization is Unit Dropout~\cite{hinton2012improving,srivastava2014dropout}. Unlike Random Subspace~\cite{ho1998nearest}, Unit Dropout randomly sets elements in the feature activation vector $h(\*x)$ to be 0. \citet{ba2013adaptive} propose Adaptive Dropout, which generalizes the prior approach by learning the dropout probability using a binary belief network. \citet{gomez2019learning} proposed Targeted Dropout which is based on keeping top-$k$ weights in a fully connected layer with the highest magnitude. Their motivation is that low-valued weights should be allowed to increase their value during training, if they become important. Hence, instead of completely pruning the rest of the weights, they apply dropout with a fixed rate to randomly drop a fraction of the low-valued weights. We contrast the OOD detection performance of \name with these dropout strategies in Table 7 (Appendix). Notably, \name improves FPR95 by \textbf{37.90\%} and \textbf{20.14\%} as compared to Targeted Dropout~\cite{gomez2019learning} and Adaptive Dropout~\cite{ba2013adaptive}, respectively. Lastly, \citet{wong2021leveraging} proposed an elastic net formulation to enforce sparsity for model interpretability. In Appendix D.5, we provide an extended discussion contrasting the OOD detection performance of \name with \cite{wong2021leveraging}.

