\input{tables/calibration_main}

\noindent Now we move beyond OOD detection tasks and systematically investigate the calibration performance on ID data itself. With our subspace learning, the model learns the feature subspace for each class. We hypothesize that learning the feature subspace helps alleviate the problem of over-confident predictions, thereby improving model calibration. Following the literature, we evaluate calibration performance based on two common metrics: {Expected Calibration Error (ECE)}~\cite{naeini2015obtaining} and  {Static Calibration Error (SCE)}~\cite{nixon2019measuring}. 

\paragraph{Description of calibration baselines.}

Before comparing the calibration performance, we first provide a brief description of loss functions for model calibration, along with hyperparameters in training: (1)~\textbf{Label Smoothing~\cite{muller2019does}.} In Label smoothing (LS), instead of using a one-hot encoded target $y$, a soft target vector $\*q$ is defined for each sample. Specifically, $q_i = \frac{\alpha}{C-1}$ if $i \neq y$, else $q_i = 1-\alpha, ~~~\forall i \in \{1,2,...,C\}$. Here, $\alpha$ is a hyperparameter. In this study, we set $\alpha = 0.05$. (2)~\textbf{Focal Loss~\cite{lin2017focal, mukhoti2020calibrating}.} Given input $\*x$, let $\hat{p}_c = \mathbb{P}(\hat{y}=c|\*x)$ be the output softmax probability of $\*x$ belonging to class $c$. The focal loss is defined as -$(1 - \hat{p}_y)^{\gamma}\text{log}(\hat{p}_y)$, where $y$ is the ground truth label and $\gamma$ is a user-defined hyperparameter. Following the original implementation, we set $\gamma=3$ for all experiments. 


\paragraph{Learning subspace improves calibration.} 
In Table~\ref{tab:calibration_1}, we observe that our subspace-regularized training algorithm improves calibration performance. In particular, we consider three losses that are commonly studied for calibration: (1) Cross Entropy Loss (NLL), (2) Label Smoothing~\cite{muller2019does}, and (3) Focal Loss (FL)~\cite{lin2017focal}.  We train the model with each of these losses and compare calibration performance with and without subspace regularization. For each dataset, we split the train set into two mutually exclusive sets: (1) $90\%$ of the train samples are used for training the model, and (2) the remaining $10\%$ of samples are used for validation. We observe from Table~\ref{tab:calibration_1} that \name improves the calibration performance for all loss functions.

