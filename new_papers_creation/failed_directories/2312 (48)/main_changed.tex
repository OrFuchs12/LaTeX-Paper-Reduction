%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{enumitem, array}
\input{maths_commands}
\usepackage{newfloat}
\usepackage{listings}
\usepackage{tikz}
\usepackage{comment}
\usepackage{amsmath,amssymb} % define this before the line numbering.
% \usepackage{color}
\usepackage{cite}
\usepackage{subcaption}
\usepackage{tabularray}
\usepackage{booktabs}
% \usepackage{unicode-math}
\usepackage[utf8]{inputenc} % allow utf-8 input     % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}
\usepackage{xspace}
\def\X{{\mathcal{X}}}
\def\Y{{\mathcal{Y}}}
\def\D{{\mathcal{D}}}
\def\etal{{et al.\xspace}}
\def\dP{{\mathbb{P}}}
\def\cP{{\mathcal{P}}}
\def\cQ{{\mathcal{Q}}}
\def\cM{{\mathcal{M}}}

\def\real{{\mathbb{R}}}

\def\ood{\textsc{ood}\xspace}
\def\iid{\emph{i.i.d}\xspace}
\def\id{\textsc{id}\xspace}
\def\sota{\textsc{sota}\xspace}
\def\name{$\mathcal{S}$NN\xspace}

\def\xt{{\Tilde{x}}}
\def\yt{{\Tilde{y}}}
\def\hbe{{\mathbf{\emph{h}}}}
\def\HC{{\mathcal{H}}}

\def\X{{\mathcal{X}}}
\def\Y{{\mathcal{Y}}}
\def\D{{\mathcal{D}}}

\def\dP{{\mathbb{P}}}
\def\cP{{\mathcal{P}}}
\def\cQ{{\mathcal{Q}}}
\def\cM{{\mathcal{M}}}

\def\real{{\mathbb{R}}}
\def\*#1{\mathbf{#1}}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage{url}
\usepackage{mathtools}
\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}


%%%%%%%%%%%%%%%%%%%%%%% Annotation Libraries begin %%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xspace}
\usepackage{array}
\usepackage{ragged2e}
\newcolumntype{P}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}
\newcolumntype{X}[1]{>{\RaggedRight\hspace*{0pt}}p{#1}}
\usepackage{tcolorbox}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees,mindmap}
\usepackage[edges]{forest}
\usetikzlibrary{arrows.meta}
\colorlet{linecol}{black!75}
\usepackage{xkcdcolors}


% for colorful equation
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows,shapes}
\usetikzlibrary{tikzmark}
\usetikzlibrary{calc}
% Commands for Highlighting text -- non tikz method
\newcommand{\highlight}[2]{\colorbox{#1!17}{$\displaystyle #2$}}
\newcommand{\highlightdark}[2]{\colorbox{#1!47}{$\displaystyle #2$}}


% Commands for Highlighting text -- non tikz method
\renewcommand{\highlight}[2]{\colorbox{#1!17}{#2}}
\renewcommand{\highlightdark}[2]{\colorbox{#1!47}{#2}}
\usepackage[capitalize,noabbrev]{cleveref}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% % \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{How to Overcome Curse-of-Dimensionality for Out-of-Distribution Detection?}

% \title{How to Overcome Curse-of-Dimensionality for OOD Detection?}
\author{
    %Authors
    % All authors must be in the same font size and format.
    Soumya Suvra Ghosal\footnote{Equal contributions},
    Yiyou Sun*,
    Yixuan Li
}
\affiliations{
    %Afiliations
    Department of Computer Sciences, University of Wisconsin -- Madison\\
    \{sghosal, sunyiyou, sharonli\}@cs.wisc.edu

}
% \author{
%     %Authors
%     % All authors must be in the same font size and format.
%     Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
%     AAAI Style Contributions by Pater Patel Schneider,
%     Sunil Issar,\\
%     J. Scott Penberthy,
%     George Ferguson,
%     Hans Guesgen,
%     Francisco Cruz\equalcontrib,
%     Marc Pujol-Gonzalez\equalcontrib
% }
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar\textsuperscript{\rm 2},
%     % J. Scott Penberthy\textsuperscript{\rm 3},
%     % George Ferguson\textsuperscript{\rm 4},
%     % Hans Guesgen\textsuperscript{\rm 5}
%     % Note that the comma should be placed after the superscript

%     1900 Embarcadero Road, Suite 101\\
%     Palo Alto, California 94303-3310 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     proceedings-questions@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high-dimensional feature space.
To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (\name), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace).  Subspace learning yields highly distinguishable distance measures between ID and OOD data.
We provide comprehensive experiments and ablations to validate the efficacy of \name.
Compared to the current best distance-based method, \name reduces the average FPR95 by $15.96\%$ on the CIFAR-100 benchmark.
\end{abstract}
\input{sections/introduction}
\input{sections/background}
\input{sections/method}
\input{sections/experiments}
\input{sections/ablations}
\input{sections/discussion}
\input{sections/related_works}
\input{sections/conclusion}

\section*{Acknowledgement}
Research is supported by the AFOSR Young Investigator Program under award number FA9550-23-1-0184, National Science Foundation (NSF) Award No. IIS-2237037 \& IIS-2331669, Office of Naval Research under grant number N00014-23-1-2643, and faculty research awards/gifts from Google and Meta.  Any opinions, findings, conclusions, or recommendations
 expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements either expressed or implied, of the sponsors.

Odit deleniti ipsam possimus est quas inventore recusandae sint ad, labore suscipit est debitis facilis earum ipsam, rem ratione itaque iure ipsa est animi illo eaque quod, a aliquam sunt aut laboriosam necessitatibus qui culpa?Debitis asperiores suscipit ducimus, deserunt voluptatum temporibus tempora magni facere praesentium id totam aspernatur illo sapiente, illo hic similique fugiat temporibus quisquam dicta iste perspiciatis nobis alias, ducimus qui provident est temporibus porro a voluptate at dicta, facilis laboriosam laborum quibusdam quasi provident neque dolore cupiditate voluptatum a.Perferendis quo doloremque amet itaque veniam saepe incidunt atque illo beatae, esse vero aperiam velit fuga ad?Amet consequuntur voluptas vero commodi, excepturi hic reiciendis earum sunt.Odit dolore nisi porro quae placeat voluptas labore excepturi autem reprehenderit sed, laudantium ullam mollitia eligendi adipisci obcaecati sit consequatur blanditiis, tempora totam doloremque commodi earum quidem reprehenderit distinctio, ad sint deserunt, expedita fuga asperiores optio quaerat?Recusandae ipsum culpa cupiditate autem ab totam officia sit consequatur similique sint, maiores corporis nihil.Saepe libero beatae voluptatibus ab a magni officia rem, aliquid doloremque odio, doloribus culpa atque cumque quo, non voluptas minima nesciunt autem laborum similique adipisci eveniet porro deleniti quia, neque eligendi architecto.Delectus magni corrupti sit non, temporibus quidem accusamus nesciunt itaque blanditiis impedit molestiae alias maiores dolore commodi, quam sapiente aliquid nisi obcaecati sint.Architecto quis in deleniti molestias ad debitis eveniet natus, voluptas saepe aliquid unde doloremque, ut fuga hic esse debitis, accusantium excepturi omnis nisi illo quasi.Magni deleniti distinctio nam porro mollitia quae unde quis commodi iusto quia, minima ipsam doloremque, perferendis nesciunt delectus sequi quis non eligendi, expedita earum itaque ratione aut tenetur ad animi, suscipit eius unde illum accusamus ratione laboriosam ipsa cum?Aliquam fugit cumque rerum est, minus quo quod dignissimos nisi velit provident autem iste.Delectus ullam officia expedita reiciendis ipsam modi maiores quidem natus, illo explicabo quibusdam nesciunt voluptatum id earum at, distinctio deleniti corrupti architecto dolores quis amet itaque soluta, culpa omnis ipsa recusandae debitis.Hic aperiam quasi ipsa recusandae voluptatem ab distinctio tempora ad, consequatur odio ut voluptas hic, enim libero sint dolores culpa?Omnis doloremque animi provident unde aut maiores tempore recusandae, enim quo reprehenderit illo nihil eaque voluptate accusantium eligendi, veniam iusto dolore officia aliquid laborum dolorum impedit consectetur?Debitis officia labore, a consequatur saepe voluptatibus temporibus qui earum numquam officiis eaque assumenda impedit.Repudiandae similique necessitatibus adipisci, in blanditiis obcaecati ex veniam explicabo?Officia blanditiis quas culpa sint, minima iure iste, ab cum exercitationem.Sed beatae sint consectetur perspiciatis dolor temporibus, quod consequatur facere, nostrum culpa deserunt facilis autem voluptates nesciunt quidem dignissimos aperiam rerum voluptatum, quidem aut eaque a culpa obcaecati saepe quam laborum veritatis accusantium exercitationem?Officia debitis quo, ipsum quod illo repellat laborum id illum pariatur, omnis in tenetur maiores at.\clearpage
\bibliography{egbib}
\clearpage

\appendix
\section{Societal Impact}
\label{sec:impact}
In this paper, we show that in high-dimensional spaces, the efficacy of distance-based out-of-distribution (OOD) detection methods can be limited by curse-of-dimensionality. To combat this problem, we propose a novel framework of subspace learning for OOD detection. OOD detection is a critically important component for a vast range of systems which include
business applications (e.g., content understanding), transportation (e.g., autonomous vehicles), and health care (e.g., unseen disease identification). Our study has positive societal impacts. We hope that it will further enhance the understanding regarding the crucial issue of how curse-of-dimensionality affects distance-based OOD detection methods. Our study does not involve any human subjects or violation of legal compliance. We do not anticipate the potentially harmful consequences of our work. Through our study and releasing our code, we hope to raise stronger research and societal attention to the problem of OOD detection.

\input{sections/proof}


\section{Supplementary Experiment Details}
\label{app:experimental_details}
 \subsection{Training details}
\label{app:train_details}
For main experimentation, we train DenseNet-101~\cite{huang2018densely} for 100 epochs using SGD with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 64. We set the
initial learning rate as 0.1 and reduce it by a factor of 10 at 50, 75, and 90 epochs. For ResNet-50~\cite{he2016deep}, we use SGD with a momentum of 0.9, weight decay of 0.0001, batch size of 128, and train the model for 100 epochs. The learning rate is adjusted using the same schedule as used for training the DenseNet model.
The relevance ratio $r \in \{0.05, 0.15, 0.25, 0.35, 0.55, 0.75\}$ and number of neighbors $k \in \{5,10,20,50,100,200,500,1000\}$ are cross-validated as described in Appendix~\ref{app:validation}. For all experiments on CIFAR-10/100 benchmark using DenseNet~\cite{huang2018densely}, we use $r=0.25$ and $k=20$ based on our validation strategy. For experimentation using ResNet-50~\cite{he2016deep}, we set $r=0.05$ and $k=20$. We report ablation results for the effect of $r$ and $k$ in Section~\ref{sec:ablations}.

\subsection{Software and Hardware}
\label{app:hardware}
We run all experiments with Python 3.7.4 and PyTorch 1.9.0. For all experimentation, we use Nvidia RTX 2080-Ti and A6000 GPUs.


\subsection{Description of OOD baselines}
\label{app:ood_description}
In this section, we include a brief description of all the OOD baseline methods.
\subsubsection{Methods using model outputs}


\paragraph{Maximum Softmax Probability (MSP)~\cite{hendrycks2016baseline}} uses the maximum softmax probability (or the confidence score) to detect OOD examples.

\paragraph{ODIN~\cite{liang2018enhancing}} ODIN utilizes the confidence score after temperature scaling and input perturbations for OOD detection. We set temperature parameter $T=1000$ for all experiments on the CIFAR-10/100 benchmark. Perturbation Magnitude $\eta$ is chosen by validating on 1000 images randomly sampled from the ID test set. We set the perturbation magnitude $\eta = 0.0016$ for CIFAR-10 and $\eta = 0.0012$ for CIFAR-100.

\paragraph{Energy~\cite{liu2020energy}} Liu~\etal~proposed using energy score for OOD detection. The energy function maps the logits to a scalar output, which is relatively
lower for ID data. This score is hyperparameter free and does not require any tuning.


\paragraph{Generalized-ODIN \cite{hsu2020generalized}} Hsu \etal~propose a decomposed confidence model for the purpose of OOD detection, where the logits of a classifier are defined using a dividend/divisor structure. The authors propose three variants of OOD detectors, namely, DeConf-I, DeConf-E, and DeConf-C --- which uses Inner-Product, Negative Euclidean Distance, and Cosine Similarity respectively. In this study, we use the DeConf-C variant, since it is shown to be the most robust of all the variants. Finally, input samples are perturbed to improve OOD performance. Similar to ODIN~\cite{liang2018enhancing}, the perturbation magnitude $\epsilon$ is chosen by validating on 1000 images randomly sampled from the ID test set. We set perturbation magnitude $\epsilon = 0.02$ for both CIFAR-10/100 benchmarks.

\paragraph{ReAct~\cite{sun2021react}} ReAct is a post-hoc OOD detection approach based on activation truncation. The paper states that the optimal OOD performance is obtained with the ReAct+Energy setting. Hence, in this study, we use the energy score for OOD detection using ReAct. Following the original paper, we calculate the clipping threshold based on the $90$-th percentile of activations estimated on the ID data.

\paragraph{GradNorm~\cite{huang2021importance}} GradNorm employs the magnitude of gradient vectors for detecting OOD samples. The gradient is derived from the KL-divergence between the softmax output and uniform probability distribution. For GradNorm, following the original implementation, we set the temperature $T = 1$.

\paragraph{LogitNorm~\cite{wei2022mitigating}} LogitNorm proposes a simple fix to the common cross-entropy loss by enforcing a constant vector norm on the logits during training. A temperature parameter $\tau$ is used to modulate the magnitude of the logits. In this study, we set $\tau = 0.04$ for both CIFAR-10/100 datasets.

\paragraph{DICE~\cite{sun2022dice}} DICE ranks weights based on a measure of contribution, and selectively uses the most salient weights to derive the output for OOD detection. By pruning away irrelevant weights, DICE reduces the output variance for OOD
data, resulting in better separability between ID and OOD. Following the original implementation, we set the sparsity parameter $p = 0.9$ for both CIFAR-10/100 benchmarks.

\subsubsection{Methods using feature representations}

\paragraph{Mahalanobis \cite{lee2018simple}} This method models the feature space as a mixture of multivariate Gaussian distributions, and calculates Mahalanobis distance~\cite{mahalanobis1936generalized} for OOD detection. The basic idea is that the testing OOD samples should be relatively far away from the centroids or prototypes of ID classes. The minimum Mahalanobis distance to all class centroids is used for OOD detection. Previous works~\cite{sun2022knn, 2021ssd} have shown that for the Mahalanobis score, stronger performance is obtained using normalized penultimate feature vectors. Hence, we use normalized penultimate feature vectors for the Mahalanobis baseline.


\paragraph{KNN~\cite{sun2022knn}} Recently Sun \etal~proposed using non-parametric nearest-neighbor distance
for OOD detection. Unlike Mahalanobis~\cite{lee2018simple}, the non-parametric approach does not impose any distributional assumption about the underlying feature space, hence providing stronger
flexibility and generality. Following original implementation, we set the number of neighbors $k=50$ for CIFAR-10 and $k=200$ for CIFAR-100.


\subsection{Validation Strategy}
\label{app:validation}
For finding the optimal value of relevance ratio $r\in\{0.05,0.15,0.25,0.35,0.55,0.75\}$ and nearest-neighbors $k\in\{5,10,20,50,100,200,500,1000\}$, we use a validation set of Gaussian noise images. For generating these images, each pixel is sampled from $\mathcal{N} (0, 1)$. We do a grid search over all possible values of $r \times k$ and the configuration providing the best AUROC is chosen as optimal. Using DenseNet-101~\cite{huang2018densely}, we find that $r = 0.25$ and $k=20$ provides the optimal performance on both CIFAR-10/100 dataset. For ResNet-50~\cite{he2016deep}, $r=0.05$ and $k=20$ provides optimal performance on CIFAR-10/100 datset. For ImageNet-100, $r = 0.35$ and $k=200$ is optimal.



\subsection{Algorithm Pseudo Code}
\label{app:pseudo}
In this section, we provide the PyTorch code for implementing SNN. Specifically, we replace the final linear layer in a neural network with the \verb|SNN| layer to learn class-relevant subspaces.


{\small
\begin{lstlisting}[language=Python]
class SNN(nn.Linear):

    def __init__(self, in_features, out_features, bias=True, r=0.25):
        super(SNN, self).__init__(in_features, out_features, bias)
        self.r = r
        self.s = int(self.r * in_features) #subspace dimension

    def forward(self, input):
        vote = input[:, None, :] * self.weight
        if self.bias is not None:
            out = vote.topk(self.s, 2)[0].sum(2) + self.bias
        else:
            out = vote.topk(self.s, 2)[0].sum(2)
        return out

\end{lstlisting}}
\section{Supplementary Experimental Studies}
\subsection{Performance on Different Architectures}
\label{app:diff_arch}


 In Table~\ref{tab:cifar-100} and \ref{tab:hard_ood} (main paper), we have established the superiority of our proposed algorithm on DenseNet~\cite{huang2018densely}. Going beyond, in Table~\ref{tab:arch}, we show that \name remains competitive and outperforms the KNN counterpart for other common architectures such as ResNet~\cite{he2016deep}. From Table~\ref{tab:arch}, we observe that: (1) On ResNet-50, \name reduces FPR95 by \textbf{7.04}\% compared to the KNN baseline. This highlights precisely the benefits of using feature subspace for deriving the nearest neighbor distance. In contrast, \cite{sun2022knn} employed the original feature space, where irrelevant feature dimensions can impede the separability between ID and OOD data.
(2) Learning subspace during training time can preserve the ID test accuracy for both architectures.

\input{tables/diff_arch}

\subsection{Understanding relationship between $r$ and $k$}
\label{app:rel}

In Figure~\ref{fig:ablations} (main paper), we show how varying the relevance ratio ($r$) and nearest-neighbor ($k$) independently modulate the OOD detection performance. In Figure~\ref{fig:fpr} and Figure~\ref{fig:auroc}, we visualize the relationship between the hyper-parameters $r$ and $k$ through OOD detection performance. The model is DenseNet-101 and ID is CIFAR-100. We observe: (1) for all values of $r$, the OOD performance is relatively stable for a mild value of $k$. (2) $r=0.25$ provides the optimal OOD performance which is the same as obtained by our validation strategy (Appendix~\ref{app:validation}).

\input{tables/discuss_table_new}
\begin{figure*}[h!]
\begin{subfigure}{0.5\textwidth}

  \includegraphics[width=0.90\textwidth]{images/ablations_NEW_FPR.png}
  \caption{}
  \label{fig:fpr}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
  \includegraphics[width=0.90\textwidth]{images/ablations_NEW_AUROC.png}
  \caption{}
  \label{fig:auroc}
\end{subfigure}
\caption{\small Visualization of the relationship between the hyper-parameters $r$ and $k$ through OOD detection performance. The model is DenseNet-101 and ID is CIFAR-100. The OOD performance is averaged over six test datasets as mentioned in Section~\ref{sec:experiment}.}
\label{fig:relationship}
\end{figure*}

\subsection{Evaluation on Calibration}
\label{app:calibration}

\input{sections/calibration_new}
\subsection{Detailed Results on All OOD Datasets}
\label{app:results}

In Table~\ref{tab:ablation_complete_c10} and Table~\ref{tab:ablation_complete_c100}, we report detailed results on six OOD test datasets when ID is CIFAR-10/100 respectively. The architecture used for all methods (including baselines) is DenseNet-101~\cite{huang2018densely}.





\subsection{Additional Discussion }
\label{app:add_discuss}
\paragraph{Relations to Wong \etal~\cite{wong2021leveraging}.} Wong \etal~\cite{wong2021leveraging} proposed an elastic net formulation to enforce sparsity for model interpretability. Hence, their motivation is fundamentally different from the problem we are trying to solve. Specifically, we learn a feature subspace for better ID-OOD separability, whereas Wong \etal improve the debuggability of neural nets. Given penultimate feature representations $h(\*x)$, \cite{wong2021leveraging} learns a sparse linear model $h(\*x)^{\top}\*w + w_0$ using the following optimization:
\begin{equation*}
\small  \min_{\*w}  \cfrac{1}{2N}||h(\*x)^{\top}\*w + w_0 -  y||^2_{2} - \lambda \left ( \cfrac{(1-\alpha)}{2}||\*w||_2^2 + \alpha||\*w||_1 \right),
\end{equation*}

where $\lambda$ and $\alpha$ are hyperparameters. In Table~\ref{tab:sparsification-method}, we compare the OOD performance between \name and Wong \etal. We make two concrete observations: (1) \name clearly outperforms \cite{wong2021leveraging} in terms of OOD detection performance. This result validates the effectiveness of our proposed subspace learning algorithm. (2) Model trained using ~\cite{wong2021leveraging} leads to suboptimal ID accuracy (65.89\%). In contrast, \name maintains the ID accuracy (75.59\%) along with improved OOD performance.




\input{tables/cifar10_full_densenet}
\input{tables/cifar100_full_densenet}
\end{document}