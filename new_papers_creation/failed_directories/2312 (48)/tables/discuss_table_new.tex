
\begin{table}[t]
\small
\centering
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{lccc}
\textbf{Method} & \textbf{FPR95}  & \textbf{AUROC} & \textbf{ID Acc.}\\
& $\downarrow$ & $\uparrow$ & $\uparrow$ \\
\toprule
Wong et al.~\cite{wong2021leveraging} & 68.06 & 79.63 & 65.89\\
Unit Dropout~\cite{srivastava2014dropout} & 62.98 & 81.40 & 72.37\\
Adaptive Dropout~\cite{ba2013adaptive} & 51.39 & 81.57 & 75.39\\
Targeted Dropout~\cite{gomez2019learning} & 69.15 & 79.80 & 73.26\\
 \name (ours) &  \textbf{31.25} & \textbf{90.76} & \textbf{75.59} \\
\bottomrule
\end{tabular}}
\caption{\small Ablation on training-time regularization methods. For OOD detection using Dropout algorithms, we calculate KNN score~\cite{sun2022knn} using feature vector $h(\*x)$. }
\label{tab:sparsification-method}
\end{table}