\relax 
\bibstyle{aaai24}
\citation{chen2014semantic,chen2017deeplab,chen2018encoder}
\citation{ronneberger2015u,zhao2017pyramid}
\citation{fu2019dual,huang2019ccnet,yuan2018ocnet,zhao2018psanet,dosovitskiy2020image}
\citation{yu2018bisenet}
\citation{yu2018bisenet}
\citation{yu2021bisenet}
\citation{fan2021rethinking}
\citation{pan2022deep}
\citation{wang2022rtformer}
\citation{wan2023seaformer}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:figure1_trade-off}{{1}{1}{\textbf  {The speed-accuracy performance on Cityscapes validation set}. Our methods are presented in red starts, while others are presented in blue dots. Our SCTNet establishes a new state-of-the-art speed-accuracy trade-off.}{}{}}
\newlabel{fig:figure1_trade-off@cref}{{[figure][1][]1}{[1][1][]1}}
\citation{long2015fully}
\citation{chen2017deeplab}
\citation{zhao2017pyramid}
\citation{ronneberger2015u}
\citation{lin2017refinenet}
\citation{fu2019dual,huang2019ccnet,yuan2018ocnet,zhao2018psanet}
\citation{zheng2021rethinking}
\citation{zhang2022segvit}
\citation{wang2021pyramid}
\citation{xie2021segformer}
\citation{paszke2016enet,wu2017real}
\citation{zhao2018icnet}
\citation{yu2018bisenet}
\citation{yu2021bisenet}
\citation{fan2021rethinking}
\citation{pan2022deep}
\citation{zhang2022topformer}
\citation{wang2022rtformer}
\citation{wan2023seaformer}
\citation{chu2021twins,liu2021swin,fang2022msg}
\citation{guo2022segnext}
\citation{guo2022beyond}
\citation{wang2022rtformer}
\newlabel{fig:figure2_comparsion}{{2}{2}{\textbf  {Real-time semantic segmentation paradigms.} (a) \emph  {Decoupled bilateral network} divides a semantic branch and a spatial branch at the early stage. (b) \emph  {Feature sharing bilateral network} separates the two branches at the latter stage and adopts dense fusion modules. (c) Our \textbf  {SCTNet} applies a single hierarchy branch with a semantic extraction transformer, free from the extra branch and costly fusion module in inference. \textbf  {FM}: Fusion Module, \textbf  {SIAM}: Semantic Information Alignment Module. Dashed arrows and boxes denote training-only. }{}{}}
\newlabel{fig:figure2_comparsion@cref}{{[figure][2][]2}{[1][2][]2}}
\citation{vaswani2017attention}
\citation{ioffe2015batch}
\newlabel{fig:figure3_OverallArchitecture}{{3}{3}{\textbf  {The architecture of SCTNet}. CFBlock (Conv-Former Block, detailed in Figure\nobreakspace  {}\ref {fig:figure4_ConvFormerBlock}) takes advantage of the training-only Transformer branch (greyed-out in the dashed box) via SIAM (Semantic Information Alignment Module) which is composed of BFA (Backbone Feature Alignment) and SDHA (Shared Decoder Head Alignment).}{}{}}
\newlabel{fig:figure3_OverallArchitecture@cref}{{[figure][3][]3}{[1][2][]3}}
\newlabel{Equ:ConvFormerBlock}{{1}{3}{}{}{}}
\newlabel{Equ:ConvFormerBlock@cref}{{[equation][1][]1}{[1][3][]3}}
\newlabel{Eq:Conv-Former Attention}{{2}{3}{}{}{}}
\newlabel{Eq:Conv-Former Attention@cref}{{[equation][2][]2}{[1][3][]3}}
\citation{li2020semantic}
\citation{dong2023afformer}
\citation{dong2023afformer}
\citation{dong2023afformer}
\citation{guo2022segnext}
\citation{guo2022segnext}
\citation{xu2023pidnet}
\citation{xu2023pidnet}
\citation{yu2018bisenet}
\citation{yu2021bisenet}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{pan2022deep}
\citation{pan2022deep}
\citation{zhang2022topformer}
\citation{zhang2022topformer}
\citation{wan2023seaformer}
\citation{wan2023seaformer}
\citation{wang2022rtformer}
\citation{wang2022rtformer}
\citation{he2016deep}
\citation{pan2022deep}
\newlabel{fig:figure4_ConvFormerBlock}{{4}{4}{Design of Conv-Former Block (left) and the details of convolutional attention (right). GDN means Grouped Double Normalization. $\otimes $ means convolution operations, $\oplus $ stands for addition, and $k$ means the kernel size.}{}{}}
\newlabel{fig:figure4_ConvFormerBlock@cref}{{[figure][4][]4}{[1][4][]4}}
\citation{shu2021channel}
\citation{cordts2016cityscapes}
\citation{zhou2017scene}
\citation{caesar2018coco}
\citation{deng2009imagenet}
\newlabel{tab:sample-tableSOTA}{{1}{5}{\textbf  {Comparisons with other state-of-the-art real-time methods on Cityscapes val set.} Seg100, Seg75, Seg50 denote the input size of $1024\times 2048$, $768\times 1536$, $512\times 1024$, respectively. \#Params refers to the number of parameters. }{}{}}
\newlabel{tab:sample-tableSOTA@cref}{{[table][1][]1}{[1][4][]5}}
\newlabel{eq:cw-phi}{{4}{5}{}{}{}}
\newlabel{eq:cw-phi@cref}{{[equation][4][]4}{[1][5][]5}}
\citation{cordts2016cityscapes}
\citation{fan2021rethinking}
\citation{wang2022rtformer}
\citation{wan2023seaformer}
\citation{zhang2022topformer}
\citation{zhou2017scene}
\citation{wang2022rtformer}
\citation{zhou2017scene}
\citation{zhou2017scene}
\citation{wan2023seaformer}
\citation{fan2021rethinking}
\citation{wan2023seaformer}
\citation{fan2021rethinking}
\citation{wang2022rtformer}
\citation{guo2022segnext}
\newlabel{sample-tableADE20K}{{2}{6}{\textbf  {Comparisons with other state-of-the-art real-time methods on ADE20K.} The FPS is measured at resolution $512\times 512$. * means speed from other papers, MV2 stands for MobileNetV2.}{}{}}
\newlabel{sample-tableADE20K@cref}{{[table][2][]2}{[1][6][]6}}
\newlabel{sample-COCO-Stuff}{{3}{6}{\textbf  {Comparisons with other state-of-the-art real-time methods on COCO-Stuff-10K test set.} The FPS is measured at resolution $640\times 640$. }{}{}}
\newlabel{sample-COCO-Stuff@cref}{{[table][3][]3}{[1][6][]6}}
\newlabel{tab:Block Ablation}{{4}{6}{\textbf  {Comparison of different blocks.}}{}{}}
\newlabel{tab:Block Ablation@cref}{{[table][4][]4}{[1][6][]6}}
\citation{cordts2016cityscapes}
\newlabel{1a}{{\caption@xref {1a}{ on input line 478}}{7}{}{}{}}
\newlabel{1a@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{1b}{{\caption@xref {1b}{ on input line 480}}{7}{}{}{}}
\newlabel{1b@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{1c}{{\caption@xref {1c}{ on input line 482}}{7}{}{}{}}
\newlabel{1c@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{1d}{{\caption@xref {1d}{ on input line 484}}{7}{}{}{}}
\newlabel{1d@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{1e}{{\caption@xref {1e}{ on input line 486}}{7}{}{}{}}
\newlabel{1e@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{2a}{{\caption@xref {2a}{ on input line 488}}{7}{}{}{}}
\newlabel{2a@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{2b}{{\caption@xref {2b}{ on input line 490}}{7}{}{}{}}
\newlabel{2b@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{2c}{{\caption@xref {2c}{ on input line 492}}{7}{}{}{}}
\newlabel{2c@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{2d}{{\caption@xref {2d}{ on input line 494}}{7}{}{}{}}
\newlabel{2d@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{2e}{{\caption@xref {2e}{ on input line 496}}{7}{}{}{}}
\newlabel{2e@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{3a}{{\caption@xref {3a}{ on input line 498}}{7}{}{}{}}
\newlabel{3a@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{3b}{{\caption@xref {3b}{ on input line 500}}{7}{}{}{}}
\newlabel{3b@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{3c}{{\caption@xref {3c}{ on input line 502}}{7}{}{}{}}
\newlabel{3c@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{3d}{{\caption@xref {3d}{ on input line 504}}{7}{}{}{}}
\newlabel{3d@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{3e}{{\caption@xref {3e}{ on input line 506}}{7}{}{}{}}
\newlabel{3e@cref}{{[section][4][]4}{[1][6][]7}}
\newlabel{fig:vis_cityscapes}{{5}{7}{\textbf  {Visualization results on Cityscapes validation set.} Compared with SeaFormer-B\citep  {wan2023seaformer} and STDC2\nobreakspace  {}\citep  {fan2021rethinking}, SCTNet-B generates masks with finer details as highlighted in the light blue box and more accurate large-area predictions, as highlighted in the yellow box. }{}{}}
\newlabel{fig:vis_cityscapes@cref}{{[figure][5][]5}{[1][6][]7}}
\newlabel{tab:SIAM_Ablation}{{5}{7}{\textbf  {Comparison of the effect of the SIAM.} }{}{}}
\newlabel{tab:SIAM_Ablation@cref}{{[table][5][]5}{[1][6][]7}}
\newlabel{albation-Components}{{6}{7}{\textbf  {Ablation studies on the components of SCTNet}}{}{}}
\newlabel{albation-Components@cref}{{[table][6][]6}{[1][7][]7}}
\bibdata{aaai24}
\citation{deng2009imagenet}
\citation{liu2021swin}
\citation{cordts2016cityscapes}
\citation{cordts2016cityscapes}
\citation{loshchilov2017decoupled}
\citation{zhou2017scene}
\citation{cordts2016cityscapes}
\citation{caesar2018coco}
\citation{cordts2016cityscapes}
\newlabel{section:A}{{A}{11}{}{}{}}
\newlabel{section:A@cref}{{[appendix][1][2147483647]A}{[1][11][]11}}
\newlabel{supp-tab:settings}{{7}{11}{\textbf  {Training settings on ImageNet-1K.}}{}{}}
\newlabel{supp-tab:settings@cref}{{[table][7][2147483647]7}{[1][11][]11}}
\newlabel{supptab:Kernel Size Ablation}{{8}{11}{\textbf  {Ablation studies on the kernel size of the learnable kernels in CFBlock}. }{}{}}
\newlabel{supptab:Kernel Size Ablation@cref}{{[table][8][2147483647]8}{[1][11][]11}}
\citation{milletari2016v}
\citation{shu2021channel}
\citation{shu2021channel}
\citation{xie2021segformer}
\citation{ahn2019variational}
\citation{shu2021channel}
\newlabel{last-three}{{9}{12}{\textbf  {Ablations on the semantic alignment loss, including types, locations and weight.}}{}{}}
\newlabel{last-three@cref}{{[table][9][2147483647]9}{[1][11][]12}}
\newlabel{tab:loss type}{{9a}{12}{Ablation on different types of loss. }{}{}}
\newlabel{tab:loss type@cref}{{[subtable][1][2147483647,9]9a}{[1][11][]12}}
\newlabel{sub@tab:loss type}{{a}{12}{Ablation on different types of loss. }{}{}}
\newlabel{sub@tab:loss type@cref}{{[subtable][1][2147483647,9]9a}{[1][11][]12}}
\newlabel{tab:loss location}{{9b}{12}{Ablation on the location of alignment loss. }{}{}}
\newlabel{tab:loss location@cref}{{[subtable][2][2147483647,9]9b}{[1][11][]12}}
\newlabel{sub@tab:loss location}{{b}{12}{Ablation on the location of alignment loss. }{}{}}
\newlabel{sub@tab:loss location@cref}{{[subtable][2][2147483647,9]9b}{[1][11][]12}}
\newlabel{tab:loss weight}{{9c}{12}{Ablation on the weight of alignment loss. }{}{}}
\newlabel{tab:loss weight@cref}{{[subtable][3][2147483647,9]9c}{[1][11][]12}}
\newlabel{sub@tab:loss weight}{{c}{12}{Ablation on the weight of alignment loss. }{}{}}
\newlabel{sub@tab:loss weight@cref}{{[subtable][3][2147483647,9]9c}{[1][11][]12}}
\newlabel{Eq:TrainingLoss}{{5}{12}{}{}{}}
\newlabel{Eq:TrainingLoss@cref}{{[equation][5][2147483647]5}{[1][12][]12}}
\newlabel{section:B}{{B}{12}{}{}{}}
\newlabel{section:B@cref}{{[appendix][2][2147483647]B}{[1][12][]12}}
\citation{cordts2016cityscapes}
\citation{zhou2017scene}
\citation{caesar2018coco}
\citation{yu2018bisenet}
\citation{yu2021bisenet}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{fan2021rethinking}
\citation{pan2022deep}
\citation{pan2022deep}
\citation{zhang2022topformer}
\citation{zhang2022topformer}
\citation{wan2023seaformer}
\citation{wan2023seaformer}
\citation{wang2022rtformer}
\citation{wang2022rtformer}
\citation{wang2022rtformer}
\newlabel{supptab:Semantic Branch Ablation}{{10}{13}{\textbf  {Ablation Studies on Semantic Branch in Training Phrase}. }{}{}}
\newlabel{supptab:Semantic Branch Ablation@cref}{{[table][10][2147483647]10}{[1][13][]13}}
\newlabel{suppfig:ADE_trade-off}{{6}{13}{\textbf  {The speed-accuracy performance on ADE20K validation set.} }{}{}}
\newlabel{suppfig:ADE_trade-off@cref}{{[figure][6][2147483647]6}{[1][13][]13}}
\newlabel{section:C}{{C}{13}{}{}{}}
\newlabel{section:C@cref}{{[appendix][3][2147483647]C}{[1][13][]13}}
\newlabel{app:sec:ade-coco-tradeoff}{{C}{13}{}{}{}}
\newlabel{app:sec:ade-coco-tradeoff@cref}{{[appendix][3][2147483647]C}{[1][13][]13}}
\newlabel{suppfig:COCO_trade-off}{{7}{13}{\textbf  {The speed-accuracy performance on COCO-Stuff-10K test set.} }{}{}}
\newlabel{suppfig:COCO_trade-off@cref}{{[figure][7][2147483647]7}{[1][13][]13}}
\newlabel{suppfig:figure1_trade-off}{{8}{13}{\textbf  {Speed-Accuracy performance on Cityscapes validation set using a single NVIDIA RTX 2080Ti}. Our methods are presented in red starts, while others are presented in blue dots. Our SCTNet establishes a new state-of-the-art speed-accuracy trade-off.}{}{}}
\newlabel{suppfig:figure1_trade-off@cref}{{[figure][8][2147483647]8}{[1][13][]13}}
\newlabel{app:rtx2080}{{C}{13}{}{}{}}
\newlabel{app:rtx2080@cref}{{[appendix][3][2147483647]C}{[1][13][]13}}
\citation{dong2023afformer}
\citation{guo2022segnext}
\citation{li2022sfnet}
\citation{xu2023pidnet}
\citation{guo2022segnext}
\citation{xie2021segformer}
\citation{wang2022rtformer}
\citation{zhang2022topformer}
\citation{wan2023seaformer}
\citation{xie2021segformer}
\citation{wang2022rtformer}
\citation{zhang2022topformer}
\citation{wan2023seaformer}
\citation{yu2021bisenet}
\citation{wang2022rtformer}
\citation{yu2021bisenet}
\citation{wang2022rtformer}
\citation{hinton2015distilling}
\citation{touvron2021training,li2022locality}
\citation{liu2022cross}
\citation{zhu2023good}
\newlabel{tab:suppSOTA}{{11}{14}{\textbf  {Comparisons with bilateral real-time methods on Cityscapes val set.} All the speed is measured on a single RTX 2080Ti.}{}{}}
\newlabel{tab:suppSOTA@cref}{{[table][11][2147483647]11}{[1][13][]14}}
\newlabel{section:D}{{D}{14}{}{}{}}
\newlabel{section:D@cref}{{[appendix][4][2147483647]D}{[1][14][]14}}
\citation{zhou2017scene}
\citation{cordts2016cityscapes}
\newlabel{tab:Sup_overall}{{12}{15}{\textbf  { More comprehensive accuracy and speed performance comparison on Cityscapes val set.} All the speed in this table is from the original paper with corresponding devices. $^*$ means it uses some acceleration methods, not the original torch speed. }{}{}}
\newlabel{tab:Sup_overall@cref}{{[table][12][2147483647]12}{[1][14][]15}}
\citation{zhou2017scene}
\citation{xie2021segformer}
\citation{wang2022rtformer}
\citation{zhang2022topformer}
\citation{wan2023seaformer}
\citation{cordts2016cityscapes}
\citation{wan2023seaformer}
\citation{fan2021rethinking}
\newlabel{section:E}{{E}{16}{}{}{}}
\newlabel{section:E@cref}{{[appendix][5][2147483647]E}{[1][15][]16}}
\newlabel{ADE_1a}{{\caption@xref {ADE_1a}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1a@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2a}{{\caption@xref {ADE_2a}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2a@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3a}{{\caption@xref {ADE_3a}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3a@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4a}{{\caption@xref {ADE_4a}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4a@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1b}{{\caption@xref {ADE_1b}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1b@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2b}{{\caption@xref {ADE_2b}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2b@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3b}{{\caption@xref {ADE_3b}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3b@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4b}{{\caption@xref {ADE_4b}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4b@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1c}{{\caption@xref {ADE_1c}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1c@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2c}{{\caption@xref {ADE_2c}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2c@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3c}{{\caption@xref {ADE_3c}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3c@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4c}{{\caption@xref {ADE_4c}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4c@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1d}{{\caption@xref {ADE_1d}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1d@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2d}{{\caption@xref {ADE_2d}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2d@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3d}{{\caption@xref {ADE_3d}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3d@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4d}{{\caption@xref {ADE_4d}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4d@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1e}{{\caption@xref {ADE_1e}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1e@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2e}{{\caption@xref {ADE_2e}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2e@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3e}{{\caption@xref {ADE_3e}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3e@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4e}{{\caption@xref {ADE_4e}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4e@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1f}{{\caption@xref {ADE_1f}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1f@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2f}{{\caption@xref {ADE_2f}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2f@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3f}{{\caption@xref {ADE_3f}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3f@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4f}{{\caption@xref {ADE_4f}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4f@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_1g}{{\caption@xref {ADE_1g}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_1g@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_2g}{{\caption@xref {ADE_2g}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_2g@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_3g}{{\caption@xref {ADE_3g}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_3g@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{ADE_4g}{{\caption@xref {ADE_4g}{ on input line 1122}}{17}{}{}{}}
\newlabel{ADE_4g@cref}{{[appendix][4][2147483647]D}{[1][14][]17}}
\newlabel{suppfig:ADE_Visual}{{9}{17}{\textbf  {Visualization results on ADE20K validation set.} Compared with SegFormer-B0\nobreakspace  {}\citep  {xie2021segformer}, RTFormer-B\nobreakspace  {}\citep  {wang2022rtformer}, TopFormer-B\nobreakspace  {}\citep  {zhang2022topformer} and SeaFormer-B\citep  {wan2023seaformer}, SCTNet-B generates masks with finer details as highlighted in the dark blue box and more accurate large-area predictions, as highlighted in the yellow box. }{}{}}
\newlabel{suppfig:ADE_Visual@cref}{{[figure][9][2147483647]9}{[1][14][]17}}
\newlabel{city_1a}{{\caption@xref {city_1a}{ on input line 1138}}{18}{}{}{}}
\newlabel{city_1a@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_1b}{{\caption@xref {city_1b}{ on input line 1140}}{18}{}{}{}}
\newlabel{city_1b@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_1c}{{\caption@xref {city_1c}{ on input line 1142}}{18}{}{}{}}
\newlabel{city_1c@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_1d}{{\caption@xref {city_1d}{ on input line 1144}}{18}{}{}{}}
\newlabel{city_1d@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_1e}{{\caption@xref {city_1e}{ on input line 1146}}{18}{}{}{}}
\newlabel{city_1e@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_2a}{{\caption@xref {city_2a}{ on input line 1148}}{18}{}{}{}}
\newlabel{city_2a@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_2b}{{\caption@xref {city_2b}{ on input line 1150}}{18}{}{}{}}
\newlabel{city_2b@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_2c}{{\caption@xref {city_2c}{ on input line 1152}}{18}{}{}{}}
\newlabel{city_2c@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_2d}{{\caption@xref {city_2d}{ on input line 1154}}{18}{}{}{}}
\newlabel{city_2d@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_2e}{{\caption@xref {city_2e}{ on input line 1156}}{18}{}{}{}}
\newlabel{city_2e@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_3a}{{\caption@xref {city_3a}{ on input line 1158}}{18}{}{}{}}
\newlabel{city_3a@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_3b}{{\caption@xref {city_3b}{ on input line 1160}}{18}{}{}{}}
\newlabel{city_3b@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_3c}{{\caption@xref {city_3c}{ on input line 1162}}{18}{}{}{}}
\newlabel{city_3c@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_3d}{{\caption@xref {city_3d}{ on input line 1164}}{18}{}{}{}}
\newlabel{city_3d@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{city_3e}{{\caption@xref {city_3e}{ on input line 1166}}{18}{}{}{}}
\newlabel{city_3e@cref}{{[appendix][4][2147483647]D}{[1][14][]18}}
\newlabel{suppfig:vis_cityscapes}{{10}{18}{\textbf  {Visualization results on Cityscapes validation set.} Compared with BiSeNetV2-L\citep  {yu2021bisenet} and RTFormer-B\nobreakspace  {}\citep  {wang2022rtformer}, SCTNet-B generates masks with finer details as highlighted in the light blue box and more accurate large-area predictions, as highlighted in the yellow box.}{}{}}
\newlabel{suppfig:vis_cityscapes@cref}{{[figure][10][2147483647]10}{[1][14][]18}}
\gdef \@abspage@last{18}
