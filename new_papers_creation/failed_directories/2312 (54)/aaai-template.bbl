\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Ash et~al.(2020)Ash, Zhang, Krishnamurthy, Langford, and Agarwal}]{active3}
Ash, J.~T.; Zhang, C.; Krishnamurthy, A.; Langford, J.; and Agarwal, A. 2020.
\newblock Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds.
\newblock In \emph{ICLR}.

\bibitem[{Babu and Vijayan(2016)}]{babu2016wrapper}
Babu, R.~L.; and Vijayan, S. 2016.
\newblock Wrapper based feature selection in semantic medical information retrieval.
\newblock \emph{Journal of Medical Imaging and Health Informatics}, 6(3): 802--805.

\bibitem[{Charikar(2002)}]{charikar2002similarity}
Charikar, M.~S. 2002.
\newblock Similarity estimation techniques from rounding algorithms.
\newblock In \emph{Proceedings of the thiry-fourth annual ACM symposium on Theory of computing}, 380--388.

\bibitem[{Das and Kempe(2018)}]{das2018approximate}
Das, A.; and Kempe, D. 2018.
\newblock Approximate submodularity and its applications: Subset selection, sparse approximation and dictionary selection.
\newblock \emph{The Journal of Machine Learning Research}, 19(1): 74--107.

\bibitem[{De et~al.(2021)De, Okati, Zarezade, and Gomez-Rodriguez}]{cuha}
De, A.; Okati, N.; Zarezade, A.; and Gomez-Rodriguez, M. 2021.
\newblock Classification Under Human Assistance.
\newblock \emph{AAAI}.

\bibitem[{Dulac-Arnold et~al.(2012)Dulac-Arnold, Denoyer, Preux, and Gallinari}]{dulac2012sequential}
Dulac-Arnold, G.; Denoyer, L.; Preux, P.; and Gallinari, P. 2012.
\newblock Sequential approaches for learning datum-wise sparse representations.
\newblock \emph{Machine learning}, 89: 87--122.

\bibitem[{Elenberg et~al.(2018)Elenberg, Khanna, Dimakis, and Negahban}]{elenberg2018restricted}
Elenberg, E.~R.; Khanna, R.; Dimakis, A.~G.; and Negahban, S. 2018.
\newblock Restricted strong convexity implies weak submodularity.
\newblock \emph{The Annals of Statistics}, 46(6B): 3539--3568.

\bibitem[{Est{\'e}vez et~al.(2009)Est{\'e}vez, Tesmer, Perez, and Zurada}]{estevez2009normalized}
Est{\'e}vez, P.~A.; Tesmer, M.; Perez, C.~A.; and Zurada, J.~M. 2009.
\newblock Normalized mutual information feature selection.
\newblock \emph{IEEE Transactions on neural networks}, 20(2): 189--201.

\bibitem[{Foster, Kale, and Karloff(2016)}]{foster2016online}
Foster, D.; Kale, S.; and Karloff, H. 2016.
\newblock Online sparse linear regression.
\newblock In \emph{Conference on Learning Theory}, 960--970. PMLR.

\bibitem[{Geng et~al.(2007)Geng, Liu, Qin, and Li}]{geng2007feature}
Geng, X.; Liu, T.-Y.; Qin, T.; and Li, H. 2007.
\newblock Feature selection for ranking.
\newblock In \emph{Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval}, 407--414.

\bibitem[{Ghosh and Lan(2023)}]{difa}
Ghosh, A.; and Lan, A. 2023.
\newblock Difa: Differentiable feature acquisition.

\bibitem[{Gong et~al.(2019)Gong, Tschiatschek, Nowozin, Turner, Hern{\'a}ndez-Lobato, and Zhang}]{gong2019icebreaker}
Gong, W.; Tschiatschek, S.; Nowozin, S.; Turner, R.~E.; Hern{\'a}ndez-Lobato, J.~M.; and Zhang, C. 2019.
\newblock Icebreaker: Element-wise efficient information acquisition with a bayesian deep latent gaussian model.
\newblock In \emph{Advances in Neural Information Processing Systems}, 14820--14831.

\bibitem[{Goodfellow, Shlens, and Szegedy(2014)}]{goodfellow2014explaining}
Goodfellow, I.~J.; Shlens, J.; and Szegedy, C. 2014.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}.

\bibitem[{Hans(2009)}]{hans2009bayesian}
Hans, C. 2009.
\newblock Bayesian lasso regression.
\newblock \emph{Biometrika}, 96(4): 835--845.

\bibitem[{Harshaw et~al.(2019)Harshaw, Feldman, Ward, and Karbasi}]{harshaw2019submodular}
Harshaw, C.; Feldman, M.; Ward, J.; and Karbasi, A. 2019.
\newblock Submodular maximization beyond non-negativity: Guarantees, fast algorithms, and applications.
\newblock In \emph{International Conference on Machine Learning}, 2634--2643. PMLR.

\bibitem[{Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, and Lerchner}]{higgins2017beta}
Higgins, I.; Matthey, L.; Pal, A.; Burgess, C.; Glorot, X.; Botvinick, M.; Mohamed, S.; and Lerchner, A. 2017.
\newblock beta-vae: Learning basic visual concepts with a constrained variational framework.
\newblock In \emph{International conference on learning representations}.

\bibitem[{Hu et~al.(2018)Hu, Zhou, Li, Wang, and Wu}]{hu2018survey}
Hu, X.; Zhou, P.; Li, P.; Wang, J.; and Wu, X. 2018.
\newblock A survey on online feature selection with streaming features.
\newblock \emph{Frontiers of Computer Science}, 12: 479--493.

\bibitem[{Huang et~al.(2018)Huang, Xu, Xie, Sugiyama, Niu, and Chen}]{act3}
Huang, S.-J.; Xu, M.; Xie, M.-K.; Sugiyama, M.; Niu, G.; and Chen, S. 2018.
\newblock Active feature acquisition with supervised matrix completion.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, 1571--1579.

\bibitem[{Indyk and Motwani(1999)}]{indyk1999approximate}
Indyk, P.; and Motwani, R. 1999.
\newblock Approximate Nearest Neighbors: Towards Removing the.

\bibitem[{Ito et~al.(2017)Ito, Hatano, Sumita, Yabe, Fukunaga, Kakimura, and Kawarabayashi}]{ito2017efficient}
Ito, S.; Hatano, D.; Sumita, H.; Yabe, A.; Fukunaga, T.; Kakimura, N.; and Kawarabayashi, K.-I. 2017.
\newblock Efficient sublinear-regret algorithms for online sparse linear regression with limited observation.
\newblock \emph{Advances in Neural Information Processing Systems}, 30.

\bibitem[{Janisch, Pevn{\`y}, and Lis{\`y}(2019)}]{jaaai}
Janisch, J.; Pevn{\`y}, T.; and Lis{\`y}, V. 2019.
\newblock Classification with costly features using deep reinforcement learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~33, 3959--3966.

\bibitem[{Janisch, Pevn{\`y}, and Lis{\`y}(2020{\natexlab{a}})}]{jml}
Janisch, J.; Pevn{\`y}, T.; and Lis{\`y}, V. 2020{\natexlab{a}}.
\newblock Classification with costly features as a sequential decision-making problem.
\newblock \emph{Machine Learning}, 109: 1587--1615.

\bibitem[{Janisch, Pevn{\`y}, and Lis{\`y}(2020{\natexlab{b}})}]{cwcf}
Janisch, J.; Pevn{\`y}, T.; and Lis{\`y}, V. 2020{\natexlab{b}}.
\newblock Classification with costly features as a sequential decision-making problem.
\newblock \emph{Machine Learning}, 109: 1587--1615.

\bibitem[{Kale et~al.(2017)Kale, Karnin, Liang, and P{\'a}l}]{kale2017adaptive}
Kale, S.; Karnin, Z.; Liang, T.; and P{\'a}l, D. 2017.
\newblock Adaptive feature selection: Computationally efficient online sparse linear regression under rip.
\newblock In \emph{International Conference on Machine Learning}, 1780--1788. PMLR.

\bibitem[{Kaushal et~al.(2019)Kaushal, Iyer, Kothawade, Mahadev, Doctor, and Ramakrishnan}]{active4}
Kaushal, V.; Iyer, R.; Kothawade, S.; Mahadev, R.; Doctor, K.; and Ramakrishnan, G. 2019.
\newblock Learning from less data: A unified data subset selection and active learning framework for computer vision.
\newblock In \emph{2019 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 1289--1299. IEEE.

\bibitem[{Khanna et~al.(2017)Khanna, Elenberg, Dimakis, Negahban, and Ghosh}]{khanna2017scalable}
Khanna, R.; Elenberg, E.; Dimakis, A.; Negahban, S.; and Ghosh, J. 2017.
\newblock Scalable greedy feature selection via weak submodularity.
\newblock In \emph{Artificial Intelligence and Statistics}, 1560--1568. PMLR.

\bibitem[{Killamsetty et~al.(2021)Killamsetty, Durga, Ramakrishnan, De, and Iyer}]{killamsetty2021grad}
Killamsetty, K.; Durga, S.; Ramakrishnan, G.; De, A.; and Iyer, R. 2021.
\newblock Grad-match: Gradient matching based data subset selection for efficient deep model training.
\newblock In \emph{International Conference on Machine Learning}, 5464--5474. PMLR.

\bibitem[{Kulkarni et~al.(2018)Kulkarni, Uppalapati, Singh, and Ramakrishnan}]{active7}
Kulkarni, A.; Uppalapati, N.~R.; Singh, P.; and Ramakrishnan, G. 2018.
\newblock An Interactive Multi-Label Consensus Labeling Model for Multiple Labeler Judgments.
\newblock In \emph{Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence, (AAAI), 2018}, 1479--1486. {AAAI} Press.

\bibitem[{Li and Oliva(2021)}]{gsm}
Li, Y.; and Oliva, J. 2021.
\newblock Active feature acquisition with generative surrogate models.
\newblock In \emph{International Conference on Machine Learning}, 6450--6459. PMLR.

\bibitem[{Li and Oliva(2020)}]{acflow}
Li, Y.; and Oliva, J.~B. 2020.
\newblock Dynamic Feature Acquisition with Arbitrary Conditional Flows.
\newblock \emph{arXiv preprint arXiv:2006.07701}.

\bibitem[{Liu(2016)}]{active5}
Liu, A. 2016.
\newblock Robust classification under covariate shift with application to active learning.
\newblock In \emph{AAAI}.

\bibitem[{Liyanage, Zois, and Chelmis(2021{\natexlab{a}})}]{l1}
Liyanage, Y.~W.; Zois, D.-S.; and Chelmis, C. 2021{\natexlab{a}}.
\newblock Dynamic instance-wise joint feature selection and classification.
\newblock \emph{IEEE Transactions on Artificial Intelligence}, 2(2): 169--184.

\bibitem[{Liyanage, Zois, and Chelmis(2021{\natexlab{b}})}]{l2}
Liyanage, Y.~W.; Zois, D.-S.; and Chelmis, C. 2021{\natexlab{b}}.
\newblock Dynamic instance-wise joint feature selection and classification.
\newblock \emph{IEEE Transactions on Artificial Intelligence}, 2(2): 169--184.

\bibitem[{Ma et~al.(2018)Ma, Tschiatschek, Palla, Hern{\'a}ndez-Lobato, Nowozin, and Zhang}]{eddi}
Ma, C.; Tschiatschek, S.; Palla, K.; Hern{\'a}ndez-Lobato, J.~M.; Nowozin, S.; and Zhang, C. 2018.
\newblock Eddi: Efficient dynamic discovery of high-value information with partial vae.
\newblock \emph{arXiv preprint arXiv:1809.11142}.

\bibitem[{Melville et~al.(2004)Melville, Saar-Tsechansky, Provost, and Mooney}]{act1}
Melville, P.; Saar-Tsechansky, M.; Provost, F.; and Mooney, R. 2004.
\newblock Active feature-value acquisition for classifier induction.
\newblock In \emph{Fourth IEEE International Conference on Data Mining (ICDM'04)}, 483--486. IEEE.

\bibitem[{Mirzasoleiman et~al.(2015)Mirzasoleiman, Badanidiyuru, Karbasi, Vondr{\'a}k, and Krause}]{mirzasoleiman2015lazier}
Mirzasoleiman, B.; Badanidiyuru, A.; Karbasi, A.; Vondr{\'a}k, J.; and Krause, A. 2015.
\newblock Lazier than lazy greedy.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~29.

\bibitem[{Mualem and Feldman(2022)}]{mualem2022using}
Mualem, L.; and Feldman, M. 2022.
\newblock Using Partial Monotonicity in Submodular Maximization.
\newblock \emph{arXiv preprint arXiv:2202.03051}.

\bibitem[{Murata and Suzuki(2018)}]{murata2018sample}
Murata, T.; and Suzuki, T. 2018.
\newblock Sample efficient stochastic gradient iterative hard thresholding method for stochastic sparse linear regression with limited attribute observation.
\newblock \emph{Advances in Neural Information Processing Systems}, 31.

\bibitem[{Saar-Tsechansky, Melville, and Provost(2009)}]{act2}
Saar-Tsechansky, M.; Melville, P.; and Provost, F. 2009.
\newblock Active feature-value acquisition.
\newblock \emph{Management Science}, 55(4): 664--684.

\bibitem[{Sener and Savarese(2018)}]{active2}
Sener, O.; and Savarese, S. 2018.
\newblock Active Learning for Convolutional Neural Networks: A Core-Set Approach.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Settles(2009)}]{activeSurvey}
Settles, B. 2009.
\newblock Active learning literature survey.
\newblock Technical report, University of Wisconsin-Madison Department of Computer Sciences.

\bibitem[{Sharma, Talukdar et~al.(2018)}]{sharma2018towards}
Sharma, A.; Talukdar, P.; et~al. 2018.
\newblock Towards understanding the geometry of knowledge graph embeddings.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, 122--131.

\bibitem[{Shim, Hwang, and Yang(2018)}]{jafa}
Shim, H.; Hwang, S.~J.; and Yang, E. 2018.
\newblock Joint active feature acquisition and classification with variable-size set encoding.
\newblock In \emph{Advances in neural information processing systems}, 1368--1378.

\bibitem[{Song et~al.(2012)Song, Smola, Gretton, Bedo, and Borgwardt}]{song2012feature}
Song, L.; Smola, A.; Gretton, A.; Bedo, J.; and Borgwardt, K. 2012.
\newblock Feature Selection via Dependence Maximization.
\newblock \emph{Journal of Machine Learning Research}, 13(5).

\bibitem[{Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus}]{szegedy2013intriguing}
Szegedy, C.; Zaremba, W.; Sutskever, I.; Bruna, J.; Erhan, D.; Goodfellow, I.; and Fergus, R. 2013.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}.

\bibitem[{Tan and Le(2021)}]{tan2021efficientnetv2}
Tan, M.; and Le, Q. 2021.
\newblock Efficientnetv2: Smaller models and faster training.
\newblock In \emph{International conference on machine learning}, 10096--10106. PMLR.

\bibitem[{Wei, Iyer, and Bilmes(2015)}]{active1}
Wei, K.; Iyer, R.; and Bilmes, J. 2015.
\newblock Submodularity in data subset selection and active learning.
\newblock In \emph{International Conference on Machine Learning}, 1954--1963.

\bibitem[{Xiao et~al.(2022)Xiao, Li, Tian, and Wang}]{xiao2022group}
Xiao, Q.; Li, H.; Tian, J.; and Wang, Z. 2022.
\newblock Group-wise feature selection for supervised learning.
\newblock In \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 3149--3153. IEEE.

\bibitem[{Yamada et~al.(2020)Yamada, Lindenbaum, Negahban, and Kluger}]{yamada2020feature}
Yamada, Y.; Lindenbaum, O.; Negahban, S.; and Kluger, Y. 2020.
\newblock Feature selection using stochastic gates.
\newblock In \emph{International Conference on Machine Learning}, 10648--10659. PMLR.

\bibitem[{Yu et~al.(2016)Yu, Wu, Ding, and Pei}]{yu2016scalable}
Yu, K.; Wu, X.; Ding, W.; and Pei, J. 2016.
\newblock Scalable and accurate online feature selection for big data.
\newblock \emph{ACM Transactions on Knowledge Discovery from Data (TKDD)}, 11(2): 1--39.

\bibitem[{Zagoruyko and Komodakis(2016)}]{zagoruyko2016wide}
Zagoruyko, S.; and Komodakis, N. 2016.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}.

\bibitem[{Zhao et~al.(2020)Zhao, Liu, Anandkumar, and Yue}]{active6}
Zhao, E.; Liu, A.; Anandkumar, A.; and Yue, Y. 2020.
\newblock Active Learning under Label Shift.
\newblock \emph{arXiv preprint arXiv:2007.08479}.

\end{thebibliography}
