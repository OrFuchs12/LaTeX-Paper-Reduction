\section{Conclusion}
In this paper, we first examine the infeasibility of Sinkhorn for POT. We then propose a a novel rounding algorithm which facilitates our development of feasible Sinkhorn procedure with guarantees, APDAGD and DE. DE achieves the best theoretical complexity while APDAGD and revised Sinkhorn are practically efficient algorithms, as demonstrated in our extensive experiments. We believe the rigor and applicability of our proposed methods will further facilitate the practical adoptions of POT in machine learning applications.

\section{Acknowledgements}
We would like to thank the reviewers of AAAI 2024 for their detailed and insightful comments and Dr. Darina Dvinskikh for sharing the numerical implementations of their work \citep{pmlr-v130-dvinskikh21a}. 

% We also propose two novel gradient-based algorithms for solving the POT problem. Our first algorithm, APDAGD, has the complexity of $\mathcal{\widetilde{O}}\left(n^{5/2} \varepsilon^{-1}\right)$ and demonstrates the most favorable performance in practice. Our second algorithm, dual extrapolation, achieves the best theoretical complexity of $\mathcal{\widetilde{O}}\left(n^{2} \varepsilon^{-1}\right)$ in the POT literature. Motivated by Sinkhorn's inability to strictly enforce the total mass transported constraint, we also propose a novel rounding algorithm, which ensures primal feasibility for POT, to accompany both gradient methods in this paper. 
%Experimental findings based on both synthetic and real datasets support the validity of our methods over Sinkhorn for POT. 