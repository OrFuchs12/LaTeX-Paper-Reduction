\relax 
\bibstyle{aaai24}
\citation{Lai2023TowardsAS}
\citation{passi2022overreliance,wang2023effects}
\citation{Ma2023WhoSI}
\citation{Buccinca2021ToTO,Fogliato2022WhoGF}
\citation{kumar2021explaining,Bansal2021IsTM}
\citation{subrahmanian2017predicting}
\citation{wang2022will}
\citation{wang2022will}
\citation{kumar2021explaining}
\citation{kumar2021explaining}
\citation{callaway2022optimal}
\citation{callaway2022optimal}
\citation{Lai2023TowardsAS}
\citation{Lai2020WhyI}
\citation{PoursabziSangdeh2018ManipulatingAM,Cheng2019ExplainingDA,SmithRenner2020NoEW,Liu2021UnderstandingTE,Tsai2021ExploringAP,Bansal2020DoesTW,Zhang2020EffectOC}
\citation{Green2019ThePA,Guo2019VisualizingUA,Zhang2020EffectOC,Levy2021AssessingTI}
\citation{tejeda2022ai,wang2022will}
\citation{Park2019ASA,GrgicHlaca2019HumanDM,Lu2021HumanRO,Buccinca2021ToTO,Fogliato2022WhoGF,Ma2023WhoSI}
\citation{Lucic2019WhyDM,Alqaraawi2020EvaluatingSM,Rader2018ExplanationsAM,Schuff2022HumanIO,Berkel2021EffectOI}
\citation{Bansal2021IsTM,kumar2021explaining,tejeda2022ai,Pynadath2019AMM,Li_Lu_Yin_2023,lu2023strategic}
\citation{wang2022will}
\citation{ajenaghughrure2019predictive,Li_Lu_Yin_2023}
\citation{callaway2022optimal}
\citation{ribeiro2016should}
\citation{lundberg2017unified}
\citation{callaway2022optimal}
\newlabel{ai_treament}{{}{3}{}{}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ill_direct}{{1}{3}{The illustration of how \emph  {immediate assistance} nudges human decision makers.}{}{}}
\newlabel{average_prediction}{{2}{3}{}{}{}}
\newlabel{sample}{{3}{3}{}{}{}}
\newlabel{fig:ill_two_step}{{2}{4}{The illustration of how {\em  delayed recommendation} nudges human decision makers. }{}{}}
\newlabel{fig:ill_exp}{{3}{4}{The illustration of how \emph  {explanation only} nudges human decision makers. }{}{}}
\citation{mustafaz_dia}
\citation{lundberg2017unified}
\citation{Frederick2005CognitiveRA}
\citation{wang2022will}
\citation{wang2022will}
\citation{Frederick2005CognitiveRA}
\newlabel{tab:performance1}{{1}{6}{Comparing the performance of proposed method with baseline methods on three forms of AI assistance, in terms of NLL, Accuracy, and F1-score. ``$\downarrow $'' denotes the lower the better, ``$\uparrow $'' denotes the higher the better. Best result in each column is highlighted in bold. All results are averaged over 5 runs. ``-'' means the method can not be applied in this scenario. }{}{}}
\newlabel{fig:performance2}{{4}{6}{Comparing the performance of our method with logistic regression models when changing the size of training data under three forms of AI assistance. }{}{}}
