




\begin{table}[t]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|ccc}
\toprule
Method    & CUB-200-2011            & House Construction     & Zoo           \\
\midrule
Hi-Viscont & 74.39$\pm$7.04 & 86.41$\pm$5.28& 83.50$\pm$8.44\\
FALCON    & 73.40$\pm$5.77 & 87.17$\pm$4.17& 85.12$\pm$6.64\\
\bottomrule
\end{tabular}%
}
\caption{The average F1 score and standard deviation of Hi-Viscont and FALCON on the test concepts across all the three domains.}
\label{tab:test_three}
\end{table}



In this section, we present two sets of results.
We first present experiment results on concept learning on the visual question answering task on three different domains.
The experiment results demonstrate that our concept net model learns better representation for concepts than the baseline model, and is more robust for continual learning across all domains.
Secondly, we present the results for the human-subjects experiments.
The results for the human-subjects study demonstrate that our framework Hi-Viscont can learn visual task via an in-situ interaction with human user with more accuracy and usability than the baseline model. 
% This framework is robust in the sense that the structure of the robot is correct regardless of the concept net model that it connects to. Additionally, we are going to demonstrate that Hi-Viscont is better for this application.

\subsection{VQA Experiment Setup}
\paragraph{Domains.} We first present experimental results on VQA tasks for three domains: the \textbf{CUB-200-2011 dataset}, a \textbf{custom house-construction domain} with building blocks, and a \textbf{custom zoo domain} with terrestrial and aquatic animals. 
We created the House-Construction and Zoo domains because they allow us to construct arbitrarily hard tasks with different types of objects that a robot can grasp.
For each domain, we introduce additional general concepts on top of the existing concept classes to construct a concept hierarchy. The detailed descriptions and the statistics of the datasets can be found in the Appendix.

\noindent\textbf{Data Creation Protocol.} Following FALCON's data creation protocol, we procedurely generate training and testing examples for each domain. 
We generate descriptive sentences and questions based on the ground truth annotations of images and external knowledge, which is the relationship between concepts.
For all the descriptive sentences and the questions, we also generate the corresponding neural-symbolic programs.

\noindent\textbf{Experiment Configuration.}
We directly compare Hi-Viscont with FALCON on all the three domains.
To demonstrate that Hi-Viscont is better for continual learning, we compare these models with no pre-trained concepts.
We present the mean and standard deviation of the F1 metric across the three datasets as our major results.
Each of these results is obtained from five trials with different splits of concepts and image.
We evaluate the question-answer pairs for all concepts for all the three domains on images that are not shown in the pre-train or the train phase. 
Images used for testing are never seen by the model in any phase of training for both train concepts and test concepts.
Additional statistics(precision, recall, and t-test) and a more detailed analysis can be found in the Appendix.


\begin{table}[H]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|ccccc}
\toprule
Mtd.    & Species        & Genera         & Family         & Order          & Class          \\ 
\midrule
HV & 87.1$\pm$2.0 & \textbf{90.4$\pm$0.6} & \textbf{90.7$\pm$1.7} & \textbf{92.0$\pm$0.8} & 95.9$\pm$8.2           \\
FCN    & 86.5$\pm$1.4         & 88.2$\pm$1.0          & 84.3$\pm$1.4 & 84.3$\pm$3.2 & 99.3$\pm$1.0  \\ 
\bottomrule
\end{tabular}%
}
\caption{The average F1 score and standard deviation of Hi-Viscont (HV) and FALCON (FCN) on the CUB dataset by the depth of concepts in the hierarchy.}
\label{tab:CUB_depth}
\end{table}

\subsection{VQA Results}
In Table~\ref{tab:test_three}, we present the results on the VQA task for test concepts.
Our model, Hi-Viscont achieves comparable results to the baseline state-of-the-art FALCON model on test concepts in all three domains.
% These test concepts are sampled at random with relatively low probability of sampling a parent or ancestor node to test 
Given that in a concept network there are fewer parent concepts than leaf concepts, the performance of both models is comparable in such a general test case.
However, when we split the concepts by their depth in the hierarchy, Hi-Viscont shines and achieves a significantly better performance with the parental nodes, which will be discussed by each domain separately.



\noindent\textbf{CUB dataset:} 
We present our results for concepts by their level in the taxonomy in Table \ref{tab:CUB_depth}. 
Hi-Viscont is better with significance for concepts in the level of Genera($p<0.001$), Family($p=0.001$), and Order($p=0.001$) according to paired t-tests.
Species are the leaf level concepts where the models again perform comparably as expected. This is because the leaf level updates of Hi-Viscont and FALCON do not differ significantly.
As there is only one highest level ancestor for the Class with CUB there is no negative example for it in the dataset leading to similar performance by both models as the answer is always \texttt{True}.


\begin{table}[]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|ccc}
\toprule
Method    & Object        & Color         & Affordance           \\
\midrule
Hi-Viscont &  88.46$\pm$1.58  & \textbf{99.24$\pm$0.70} & \textbf{89.86$\pm$9.12}          \\
FALCON    & 89.28$\pm$0.93         & 87.27$\pm$5.83          & 57.35$\pm$9.23 \\ 
\bottomrule
\end{tabular}%
}
\caption{The average F1 score and standard deviation of Hi-Viscont and FALCON on the house construction domain by type of concepts.}
\label{tab:house_type}
\end{table}

\noindent\textbf{House construction domain:} 
% We present the results based on different types of concepts on the house construction domain in Table~\ref{tab:house_type}.
In this domain, the Color and  Affordance concepts are non-leaf nodes in the hierarchy, whereas the object concepts are the leaf nodes. 
Following expectations, as demonstrated in Table~\ref{tab:house_type}, Hi-Viscont has a comparable performance to FALCON in the leaf node object concepts, while achieving significant improvements in both Color ($p=0.005$) and Affordance (non-leaf) concepts ($p=0.002$) according to the pairwise t-tests.



\begin{table}[b]
\centering
\resizebox{0.75\columnwidth}{!}{%
\begin{tabular}{c|cc}
% \normalsize
\toprule
Method          & Leaf       & Non-leaf           \\
\midrule
Hi-Viscont  & 87.93$\pm$3.40 & \textbf{85.84$\pm$5.79}          \\
FALCON          & 88.99$\pm$3.75         & 66.15$\pm$5.34 \\ 
\bottomrule
\end{tabular}%
}
\caption{The average F1 score and standard deviation of Hi-Viscont and FALCON on the zoo domain by type of concepts.}
\label{tab:zoo_type}
\end{table}


\noindent\textbf{Zoo Domain} 
% We present our results on the zoo domain with Table~\ref{tab:zoo_type}.
In the zoo domain, leaf concepts are not at equivalent depths from the root node forcing us to analyze the performance crudely with respect to leaf and non-leaf nodes in Table~\ref{tab:zoo_type}.
Similarly, Hi-Viscont achieves a comparable performance at leaf level concepts, but becomes significantly better than FALCON in the non-leaf concepts ($p=0.001$).



\begin{table}[]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c}
\toprule

  Metrics                 & Hi-Viscont    & FALCON        \\ \midrule
Success Rate(\%)  & $50.00\pm51.45$ & $16.67\pm38.25$ \\ %\hline
Node Accuracy(\%) & $81.25\pm21.11$ & $61.81\pm23.67$ \\ %\hline
Comparative       & $5.44\pm2.68$   & $0.39\pm0.78$   \\ %\hline
Trust              & $58.56\pm11.60$ & $51.94\pm13.91$ \\ %\hline
SUS                & $46.72\pm10.33$ & $43.33\pm11.26$ \\ %\hline
Intelligence       & $33.00\pm5.90$  & $28.61\pm7.37$  \\ %\hline
Natural            & $13.89\pm4.19$  & $12.11\pm4.10$  \\ \bottomrule
\end{tabular}%
}
\caption{The results of the human-subjects experiment. Success Rate and Node Accuracy are measured in percentage. Hi-Viscont is better than FALCON on all metrics with significance as described in the Human Subjects Study Section.}
\label{tab:human_subject}
\end{table}
\subsection{Human Subjects Study}
We conducted a human-subjects study with $18$ participants ($22.22\%$ female, mean age = $25.36$, standard deviation = $3.49$). To design our study we conducted pilot studies with $10$ participants.
Each participant completed three phases of interaction with the robot on the house construction domain and filled out all surveys.
% Before running the statistical tests, we used Shapiro-Wilk's test to check whether our data meet normality assumptions.
% Our data for comparison survey and subjective metrics do not pass the normality test, we employ Wilcoxon signed-rank test to show significance for these data.
% For other metrics, including the scales for Trust, Intelligence, SUS, and Natural, we employed pairwise t-test to show significance.
Our experiment results with respect to each hypothesis are as follows:

\noindent\textbf{Hypothesis 1: -} Hi-Viscont achieves a $33.33\%$ improvement in success rate(SR) compared to FALCON. Results from the Wilcoxon signed-rank test indicate that Hi-Viscont's SR is significantly better than FALCON ($Z=0.0$, $p=0.014$).

\noindent\textbf{Hypothesis 2: -} Hi-Viscont achieves a $19.44\%$ improvements in accuracy at node level compared to FALCON. Results from the Wilcoxon signed-rank test indicate that Hi-Viscont's node level accuracy is significantly better than FALCON($Z=1.5$, $p=0.005$).

\noindent\textbf{Hypothesis 3: -} Hi-Viscont achieves higher ratings on subjective metrics than FALCON. Users prefer Hi-Viscont in all the scales that we measured with significance: Trust($t=2.325$, $p=0.016$, $df=17$), SUS($t=2.428$, $p=0.013$, $df=17$), Perceived Intelligence($t=2.591$, $p=0.010$, $df=17$), and Anthropomorphism ($t=2.924$, $p=0.005$, $df=17$), suggested by paired t-test. Additionally, results from Wilcoxon signed-rank test suggest Hi-Viscont is significantly preferred over FALCON($Z=0.0$, $p<0.001$).

