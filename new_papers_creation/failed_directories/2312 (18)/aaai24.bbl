\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Abdal, Qin, and Wonka(2020)}]{abdal2020image2stylegan++}
Abdal, R.; Qin, Y.; and Wonka, P. 2020.
\newblock Image2stylegan++: How to edit the embedded images?
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 8296--8305.

\bibitem[{Alaluf, Patashnik, and Cohen-Or(2021)}]{alaluf2021restyle}
Alaluf, Y.; Patashnik, O.; and Cohen-Or, D. 2021.
\newblock Restyle: A residual-based stylegan encoder via iterative refinement.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 6711--6720.

\bibitem[{Alaluf et~al.(2022)Alaluf, Tov, Mokady, Gal, and Bermano}]{alaluf2022hyperstyle}
Alaluf, Y.; Tov, O.; Mokady, R.; Gal, R.; and Bermano, A. 2022.
\newblock Hyperstyle: Stylegan inversion with hypernetworks for real image editing.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer Vision and pattern recognition}, 18511--18521.

\bibitem[{Avrahami, Lischinski, and Fried(2022)}]{avrahami2022blended}
Avrahami, O.; Lischinski, D.; and Fried, O. 2022.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 18208--18218.

\bibitem[{Choi et~al.(2021)Choi, Kim, Jeong, Gwon, and Yoon}]{choi2021ilvr}
Choi, J.; Kim, S.; Jeong, Y.; Gwon, Y.; and Yoon, S. 2021.
\newblock Ilvr: Conditioning method for denoising diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2108.02938}.

\bibitem[{Choi et~al.(2020)Choi, Uh, Yoo, and Ha}]{choi2020stargan}
Choi, Y.; Uh, Y.; Yoo, J.; and Ha, J.-W. 2020.
\newblock Stargan v2: Diverse image synthesis for multiple domains.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 8188--8197.

\bibitem[{Couairon et~al.(2022)Couairon, Verbeek, Schwenk, and Cord}]{couairon2022diffedit}
Couairon, G.; Verbeek, J.; Schwenk, H.; and Cord, M. 2022.
\newblock Diffedit: Diffusion-based semantic image editing with mask guidance.
\newblock \emph{arXiv preprint arXiv:2210.11427}.

\bibitem[{David, Andrew, and Quoc(2016)}]{david2016hypernetworks}
David, H.; Andrew, D.; and Quoc, V. 2016.
\newblock Hypernetworks.
\newblock \emph{arXiv preprint arXiv}, 1609.

\bibitem[{Dhariwal and Nichol(2021)}]{dhariwal2021diffusion}
Dhariwal, P.; and Nichol, A. 2021.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34: 8780--8794.

\bibitem[{Gal et~al.(2022{\natexlab{a}})Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or}]{gal2022image}
Gal, R.; Alaluf, Y.; Atzmon, Y.; Patashnik, O.; Bermano, A.~H.; Chechik, G.; and Cohen-Or, D. 2022{\natexlab{a}}.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}.

\bibitem[{Gal et~al.(2022{\natexlab{b}})Gal, Patashnik, Maron, Bermano, Chechik, and Cohen-Or}]{gal2022stylegan}
Gal, R.; Patashnik, O.; Maron, H.; Bermano, A.~H.; Chechik, G.; and Cohen-Or, D. 2022{\natexlab{b}}.
\newblock StyleGAN-NADA: CLIP-guided domain adaptation of image generators.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 41(4): 1--13.

\bibitem[{Goodfellow et~al.(2020)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}]{goodfellow2020generative}
Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2020.
\newblock Generative adversarial networks.
\newblock \emph{Communications of the ACM}, 63(11): 139--144.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 770--778.

\bibitem[{Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-Or}]{hertz2022prompt}
Hertz, A.; Mokady, R.; Tenenbaum, J.; Aberman, K.; Pritch, Y.; and Cohen-Or, D. 2022.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock \emph{arXiv preprint arXiv:2208.01626}.

\bibitem[{Ho, Jain, and Abbeel(2020)}]{ho2020denoising}
Ho, J.; Jain, A.; and Abbeel, P. 2020.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33: 6840--6851.

\bibitem[{Ho et~al.(2022)Ho, Saharia, Chan, Fleet, Norouzi, and Salimans}]{ho2022cascaded}
Ho, J.; Saharia, C.; Chan, W.; Fleet, D.~J.; Norouzi, M.; and Salimans, T. 2022.
\newblock Cascaded diffusion models for high fidelity image generation.
\newblock \emph{The Journal of Machine Learning Research}, 23(1): 2249--2281.

\bibitem[{Ho and Salimans(2022)}]{ho2022classifier}
Ho, J.; and Salimans, T. 2022.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}.

\bibitem[{Huang et~al.(2020)Huang, Wang, Tai, Liu, Shen, Li, Li, and Huang}]{huang2020curricularface}
Huang, Y.; Wang, Y.; Tai, Y.; Liu, X.; Shen, P.; Li, S.; Li, J.; and Huang, F. 2020.
\newblock Curricularface: adaptive curriculum learning loss for deep face recognition.
\newblock In \emph{proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 5901--5910.

\bibitem[{Karras et~al.(2017)Karras, Aila, Laine, and Lehtinen}]{karras2017progressive}
Karras, T.; Aila, T.; Laine, S.; and Lehtinen, J. 2017.
\newblock Progressive growing of gans for improved quality, stability, and variation.
\newblock \emph{arXiv preprint arXiv:1710.10196}.

\bibitem[{Karras et~al.(2020)Karras, Aittala, Hellsten, Laine, Lehtinen, and Aila}]{karras2020training}
Karras, T.; Aittala, M.; Hellsten, J.; Laine, S.; Lehtinen, J.; and Aila, T. 2020.
\newblock Training generative adversarial networks with limited data.
\newblock \emph{Advances in neural information processing systems}, 33: 12104--12114.

\bibitem[{Karras, Laine, and Aila(2019)}]{karras2019style}
Karras, T.; Laine, S.; and Aila, T. 2019.
\newblock A style-based generator architecture for generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 4401--4410.

\bibitem[{Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani}]{kawar2023imagic}
Kawar, B.; Zada, S.; Lang, O.; Tov, O.; Chang, H.; Dekel, T.; Mosseri, I.; and Irani, M. 2023.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 6007--6017.

\bibitem[{Kim, Kwon, and Ye(2022)}]{kim2022diffusionclip}
Kim, G.; Kwon, T.; and Ye, J.~C. 2022.
\newblock Diffusionclip: Text-guided diffusion models for robust image manipulation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2426--2435.

\bibitem[{Kwon, Jeong, and Uh(2022)}]{kwon2022diffusion}
Kwon, M.; Jeong, J.; and Uh, Y. 2022.
\newblock Diffusion models already have a semantic latent space.
\newblock \emph{arXiv preprint arXiv:2210.10960}.

\bibitem[{Li et~al.(2023)Li, Ma, Zhang, Hua, Liu, He, and Yi}]{li2023reganie}
Li, B.; Ma, T.; Zhang, P.; Hua, M.; Liu, W.; He, Q.; and Yi, Z. 2023.
\newblock ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, 1269--1277.

\bibitem[{Lipman et~al.(2022)Lipman, Chen, Ben-Hamu, Nickel, and Le}]{lipman2022flow}
Lipman, Y.; Chen, R.~T.; Ben-Hamu, H.; Nickel, M.; and Le, M. 2022.
\newblock Flow matching for generative modeling.
\newblock \emph{arXiv preprint arXiv:2210.02747}.

\bibitem[{Lugmayr et~al.(2022)Lugmayr, Danelljan, Romero, Yu, Timofte, and Van~Gool}]{lugmayr2022repaint}
Lugmayr, A.; Danelljan, M.; Romero, A.; Yu, F.; Timofte, R.; and Van~Gool, L. 2022.
\newblock Repaint: Inpainting using denoising diffusion probabilistic models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 11461--11471.

\bibitem[{Mao, Wang, and Aizawa(2023)}]{mao2023guided}
Mao, J.; Wang, X.; and Aizawa, K. 2023.
\newblock Guided Image Synthesis via Initial Image Editing in Diffusion Model.
\newblock \emph{arXiv preprint arXiv:2305.03382}.

\bibitem[{Matsunaga et~al.(2022)Matsunaga, Ishii, Hayakawa, Suzuki, and Narihira}]{matsunaga2022fine}
Matsunaga, N.; Ishii, M.; Hayakawa, A.; Suzuki, K.; and Narihira, T. 2022.
\newblock Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models.
\newblock \emph{arXiv preprint arXiv:2212.02024}.

\bibitem[{Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon}]{meng2021sdedit}
Meng, C.; He, Y.; Song, Y.; Song, J.; Wu, J.; Zhu, J.-Y.; and Ermon, S. 2021.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2108.01073}.

\bibitem[{Mokady et~al.(2023)Mokady, Hertz, Aberman, Pritch, and Cohen-Or}]{mokady2023null}
Mokady, R.; Hertz, A.; Aberman, K.; Pritch, Y.; and Cohen-Or, D. 2023.
\newblock Null-text inversion for editing real images using guided diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 6038--6047.

\bibitem[{Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen}]{nichol2021glide}
Nichol, A.; Dhariwal, P.; Ramesh, A.; Shyam, P.; Mishkin, P.; McGrew, B.; Sutskever, I.; and Chen, M. 2021.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}.

\bibitem[{Nichol and Dhariwal(2021)}]{nichol2021improved}
Nichol, A.~Q.; and Dhariwal, P. 2021.
\newblock Improved denoising diffusion probabilistic models.
\newblock In \emph{International Conference on Machine Learning}, 8162--8171. PMLR.

\bibitem[{Pehlivan, Dalva, and Dundar(2023)}]{pehlivan2023styleres}
Pehlivan, H.; Dalva, Y.; and Dundar, A. 2023.
\newblock Styleres: Transforming the residuals for real image editing with stylegan.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 1828--1837.

\bibitem[{Preechakul et~al.(2022)Preechakul, Chatthee, Wizadwongsa, and Suwajanakorn}]{preechakul2022diffusion}
Preechakul, K.; Chatthee, N.; Wizadwongsa, S.; and Suwajanakorn, S. 2022.
\newblock Diffusion autoencoders: Toward a meaningful and decodable representation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 10619--10629.

\bibitem[{Richardson et~al.(2021)Richardson, Alaluf, Patashnik, Nitzan, Azar, Shapiro, and Cohen-Or}]{richardson2021encoding}
Richardson, E.; Alaluf, Y.; Patashnik, O.; Nitzan, Y.; Azar, Y.; Shapiro, S.; and Cohen-Or, D. 2021.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2287--2296.

\bibitem[{Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer}]{rombach2022high}
Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Ommer, B. 2022.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 10684--10695.

\bibitem[{Ronneberger, Fischer, and Brox(2015)}]{ronneberger2015u}
Ronneberger, O.; Fischer, P.; and Brox, T. 2015.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}, 234--241. Springer.

\bibitem[{Song, Meng, and Ermon(2020)}]{song2020denoising}
Song, J.; Meng, C.; and Ermon, S. 2020.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}.

\bibitem[{Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole}]{song2020score}
Song, Y.; Sohl-Dickstein, J.; Kingma, D.~P.; Kumar, A.; Ermon, S.; and Poole, B. 2020.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}.

\bibitem[{Tov et~al.(2021)Tov, Alaluf, Nitzan, Patashnik, and Cohen-Or}]{tov2021designing}
Tov, O.; Alaluf, Y.; Nitzan, Y.; Patashnik, O.; and Cohen-Or, D. 2021.
\newblock Designing an encoder for stylegan image manipulation.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 40(4): 1--14.

\bibitem[{Wang et~al.(2022)Wang, Zhang, Fan, Wang, and Chen}]{wang2022high}
Wang, T.; Zhang, Y.; Fan, Y.; Wang, J.; and Chen, Q. 2022.
\newblock High-fidelity gan inversion for image attribute editing.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 11379--11388.

\bibitem[{Yang et~al.(2023)Yang, Gu, Zhang, Zhang, Chen, Sun, Chen, and Wen}]{yang2023paint}
Yang, B.; Gu, S.; Zhang, B.; Zhang, T.; Chen, X.; Sun, X.; Chen, D.; and Wen, F. 2023.
\newblock Paint by example: Exemplar-based image editing with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 18381--18391.

\bibitem[{Yu et~al.(2015)Yu, Seff, Zhang, Song, Funkhouser, and Xiao}]{yu2015lsun}
Yu, F.; Seff, A.; Zhang, Y.; Song, S.; Funkhouser, T.; and Xiao, J. 2015.
\newblock Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}.

\bibitem[{Zhang and Agrawala(2023)}]{zhang2023adding}
Zhang, L.; and Agrawala, M. 2023.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.05543}.

\bibitem[{Zhang, Zhao, and Lin(2022)}]{zhang2022unsupervised}
Zhang, Z.; Zhao, Z.; and Lin, Z. 2022.
\newblock Unsupervised representation learning from pre-trained diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35: 22117--22130.

\bibitem[{Zhu et~al.(2020)Zhu, Shen, Zhao, and Zhou}]{zhu2020domain}
Zhu, J.; Shen, Y.; Zhao, D.; and Zhou, B. 2020.
\newblock In-domain gan inversion for real image editing.
\newblock In \emph{European conference on computer vision}, 592--608. Springer.

\end{thebibliography}
