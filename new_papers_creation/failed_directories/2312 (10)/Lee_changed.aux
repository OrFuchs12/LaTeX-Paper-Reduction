\relax 
\bibstyle{aaai24}
\citation{niqe,lpips}
\citation{SISR2_EDSR}
\citation{hyun2020varsr,SISR9_SRFlow}
\citation{SISR2_EDSR}
\citation{PiecewiseLinear}
\citation{relu}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:main_figure}{{1}{2}{ Visualization of our method (ECO) compared to vanilla training and knowledge distillation (KD). Data points indicated in gray text are not available during training. Vanilla training leads to noisy training since it is unaware of the inherent noise $\epsilon $, which is defined as the difference of a given HR image $y^*$ and the expectation over all possible HR images, $\mu _{\text  {true}}$. On the other hand, KD benefits from noise-free targets but suffers from spatial inconsistency between the input and target images as in Eq.\eqref  {eq:construction_of_kd}. The proposed objective Eq.\eqref  {eq:train_with_sr} benefits from noise-free training while being spatially aligned. Then, we overcome the limitations that arise by removing the estimation error term $\Delta \mu :=\mu _\text  {true}-\mu _\text  {emp}$ with a smooth transition from the proposed objective to the original objective. Remarkably, the overall solution can be greatly simplified with the use of \textit  {mixup} strategy as in Eq.\eqref  {eq:final_w_mixup} (Section \ref {section:mixup_as_rescue}). Starting from synthetic data pairs ($\alpha =0$), gradually migrate to real data pairs ($\alpha =1$). This way, we enjoy noise-free training during the early steps, and finetune the network with supervision from real data samples in later steps. }{}{}}
\newlabel{eq:original_loss}{{4}{2}{}{}{}}
\citation{coo_1,coo_2,SISR6_SRGAN,SISR7_ESRGAN}
\newlabel{eq:posterior_basic}{{5}{3}{}{}{}}
\newlabel{sec:noise_free}{{3}{3}{}{}{}}
\newlabel{eq:lowerbound_true}{{6}{3}{}{}{}}
\newlabel{eq:lowerbound_with_estimationerror}{{8}{3}{}{}{}}
\newlabel{eq:construction_of_kd}{{9}{3}{}{}{}}
\citation{PiecewiseLinear}
\citation{mixup}
\newlabel{sec:ecoo_method}{{5}{4}{}{}{}}
\newlabel{eq:lowerbound_withlinearity_}{{10}{4}{}{}{}}
\newlabel{eq:train_with_sr}{{11}{4}{}{}{}}
\newlabel{section:mixup_as_rescue}{{5.2}{4}{}{}{}}
\newlabel{section:trade-off of approximated noise-free objective}{{5.2}{4}{}{}{}}
\newlabel{eq:original_loss_in_mixupform}{{12}{4}{}{}{}}
\newlabel{eq:final_w_mixup}{{14}{4}{}{}{}}
\citation{SISR2_EDSR}
\citation{how_does_batchnorm_help}
\citation{beta_smoothness,how_does_batchnorm_help}
\citation{SISR2_EDSR}
\citation{SISR2_EDSR}
\citation{SISR4_RCAN}
\citation{SISR4_RCAN}
\citation{SISR2_EDSR}
\citation{SISR2_EDSR}
\citation{SISR4_RCAN}
\citation{SISR4_RCAN}
\citation{SISR2_EDSR}
\citation{SISR2_EDSR}
\citation{SISR4_RCAN}
\citation{SISR4_RCAN}
\citation{set5}
\citation{set14}
\citation{bsd100}
\citation{urban100}
\citation{manga109}
\citation{rcanit}
\newlabel{section:experiments}{{6}{5}{}{}{}}
\newlabel{section:analysis}{{6.1}{5}{}{}{}}
\newlabel{fig:optimization_landscape}{{2}{5}{ Visualization of maximum gradient difference and the loss variation. Spikes of gradient differences indicate that the gradients are not well-bounded (i.e., not Lipschitz). }{}{}}
\newlabel{fig:different_training_schemes}{{3}{5}{ Comparison of our method (w/o mixup) with KD and vanilla training on Set5. It verifies the impact of spatial inconsistency in training image pairs. }{}{}}
\citation{liang2021swinir}
\citation{SISR1_SRCNN}
\citation{SISR5_SAN,SISR12_HAN,SISR2_EDSR,SISR3_VDSR,SISR4_RCAN,SISR11_CRAN}
\citation{chen2021pre_transformer1,liang2021swinir,zhang2022swinfir,chen2023hat}
\citation{he2022revisiting_illposed_2,ning2021uncertainty}
\citation{SISR2_EDSR}
\citation{zhang2021data_distillation1,wang2021towards_distillation2,lee2020learning_distillation3,gao2019image_distillation4}
\citation{lee2020learning_distillation3}
\citation{lew2021pixel,ikc,kernelgan}
\citation{SISR6_SRGAN,SISR7_ESRGAN,SISR8_RankSRGAN}
\citation{perceptual_loss_vgg}
\citation{jo2021tackling_illposed_1}
\citation{hyun2020varsr,SISR9_SRFlow}
\newlabel{tab:maintable}{{1}{6}{Quantitative comparison of the proposed method ECO (w/ mixup) against vanilla training. We report PSNR (dB) and SSIM scores for $\times $2, $\times $3, and $\times $4 SR over standard benchmark datasets. The best result are highlighted in \textbf  {bold}.}{}{}}
\newlabel{fig:different_batch_size}{{4}{6}{ Validation results are reported for both vanilla training and the proposed method (without mixup) across mini-batch sizes of 2, 4, 8, and 16. The shaded regions indicate the minimum and maximum PSNR values at each iteration across all settings. Noise-free optimization enables additional stability throughout various batch-size choices. }{}{}}
\newlabel{fig:longer_training}{{5}{6}{ Validation results over various configurations of mixup. Without mixup, the performance is limited due to neglecting the estimation error factor $\Delta \mu $ as in Eq.\eqref  {eq:train_with_sr}. }{}{}}
\newlabel{fig:qualitative_result}{{6}{7}{ Visual comparison of the proposed method and vanilla training for $\times $4 SR. \textbf  {Zoom in for best view.} }{}{}}
\newlabel{tab:ablation_table}{{2}{7}{ECO (ours) compared to vanilla training. PSNR (dB) and SSIM scores are reported, and the best and second-best results are highlighted in \textbf  {bold} and \underline  {underlines}. ECO* indicates training only up to 20$\%$ of the total iterations.}{}{}}
\bibdata{reference}
\newlabel{fig:alpha_visualize}{{7}{8}{Visualization of target images in Eq.\eqref  {eq:final_w_mixup} as $\alpha $ gradually changes. Unpredictable high-frequency components that can lead to unstable optimization are removed when $\alpha =0$. \textbf  {Zoom in for best view.}}{}{}}
\citation{SISR2_EDSR}
\citation{set5}
\citation{set14}
\citation{bsd100}
\citation{urban100}
\citation{manga109}
\citation{SISR2_EDSR}
\citation{SISR4_RCAN}
\citation{liang2021swinir}
\newlabel{fig:noise_comparison}{{8}{9}{ Visualization of estimated $\mathbb  {E}(\epsilon ^*$) and $\epsilon ^*$. It can be seen that $\epsilon ^*$, which corresponds to the proposed method ECO, can better spot fine-grained noise factors including almost invisible noise in the flat background region. Values are scaled for better visualization. \textbf  {Zoom in for best view}. }{}{}}
\newlabel{par:gradient_in_spectral_domain}{{C}{9}{}{}{}}
\newlabel{fig:high_frequency_gradient}{{9}{9}{Spectral analysis of training data pairs and gradients at $\alpha =0$. (a) High-resolution images in the spectral domain. (b) Low-resolution images in the spectral domain. (c) The gradient of the loss in the spectral domain.}{}{}}
\citation{div2k}
\citation{rcanit}
\citation{cosineannealing}
\citation{lamb}
\citation{SISR4_RCAN}
\gdef \@abspage@last{10}
