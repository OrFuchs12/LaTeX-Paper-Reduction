\documentclass[a4paper,11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}  

\input{defpack}
\title{Follow-up works}
\date{}
\author{}
\begin{document}
	\maketitle
	\vskip 0.1in
	
\section{Decentralized SVRG}

\begin{algorithm}[ht]
\caption{Communication-Sparsifying SVRG}
\label{alg:c}
\begin{algorithmic}
\STATE {\bfseries Input:} 
   $T$, % Time horizon
   $\mathbf{x}^0$, % Initial state
   $\mathbf{y}^0=\mathbf{0}$, % Initial y
   
\STATE {set $\mathbf{z}^0=[\mathbf{x}^0; \mathbf{y}^0]$} 
\FOR{each $s \in [0, 1, ..., T]$}
\STATE $\Tilde{w}=\Tilde{w}^{s-1}$
\STATE $\Tilde{\mu}= \frac{1}{n}\sum_{i=1}^n \nabla f_i(w_i^{s-1})$
\STATE $\mathbf{z}^0=\Tilde{w} $
\FOR{each $t \in [0, 1,..., m]$}
\STATE generate non-negative matrices $W^t_{in}$, $W^t_{out}$

\FOR{each $m \in [1, ..., d]$}
\STATE construct a row-stochastic $A^t_m$  and a column-stochastic $B^t_m$ according to \eqref{eq:normA} and \eqref{eq:normB}

\STATE construct $M^t_m$ according to \eqref{matrixdef}
\FOR{each $i \in \left\{1, ..., 2n \right\}$}
\STATE $z_{im}^{t+1}=\sum_{j=1}^{2n}[M^t_m]_{ij} Q(z_{jm}^t)-\alpha_t \Tilde{g}_{im}^t$
\ENDFOR
\ENDFOR
\ENDFOR
\STATE $\Tilde{w}^s=z^{t}$
\ENDFOR

\end{algorithmic}
\end{algorithm}

Let $\Tilde{\nabla f_i(\z_i^t)}=\nabla f_{i_m}(\z_i^t)-\nabla f_{i_m}(\Tilde{w}_e{i})+\Tilde{\mu} $ be gradient term in SVRG algorithm, 
From previous analysis, we have seen that \begin{equation}
    \|\Bar{\z}^{t+1}-\x^* \|^2= \|\Bar{\z}^{t}-\x^* \|^2+\|\frac{\alpha_t}{n}\sum_{i=1}^n \Tilde{\nabla f_i(\z_i^t)} \|^2-2\frac{\alpha_t}{n}\sum_{i=1}^n \langle \Bar{\z}^{t}-\x^*, \Tilde{\nabla f_i(\z_i^t)} \rangle.
\end{equation}
\begin{align*}
    E[\|\Bar{\z}^{t+1}-\x^* \|^2 |\mathcal{F}_t] & = \|\Bar{\z}^{t}-\x^* \|^2 + E[\|\frac{\alpha_t}{n}\sum_{i=1}^n \Tilde{\nabla f_i(\z_i^t)} \|^2 |\mathcal{F}_t]-2\frac{\alpha_t}{n}\sum_{i=1}^n \langle \Bar{\z}^{t}-\x^*, \nabla f_i(\z_i^t) \rangle \\
    & \leq \|\Bar{\z}^{t}-\x^* \|^2 + E[\|\frac{\alpha_t}{n}\sum_{i=1}^n \Tilde{\nabla f_i(\z_i^t)} \|^2 |\mathcal{F}_t]-2\frac{\alpha_t}{n}\sum_{i=1}^n (-2D'\|\Bar{\z}^{t}-\z_i^t \|+f_i(\Bar{\z}^t)-f_i(\x^*))
\end{align*}
Now take expectation, 
\begin{align*}
    E[\|\Bar{\z}^{t+1}-\x^* \|^2] & = E[\|\Bar{\z}^{t}-\x^* \|^2] + E[\|\frac{\alpha_t}{n}\sum_{i=1}^n \Tilde{\nabla f_i(\z_i^t)} \|^2 ]+4\frac{\alpha_t D'}{n}\sum_{i=1}^n E[\|\Bar{\z}^{t}-\z_i^t \| ]-2\frac{\alpha_t }{n}\sum_{i=1}^n E[f_i(\Bar{\z}^t )]-f_i(x^*)
\end{align*}
Then we can conclude that 
\begin{equation*}
    E[\mathrm{min}_{t=1, \cdots, T}f_i(\Bar{\z}^{t})] \to f_i(x^*) =f^*
\end{equation*}

%\section{Simulation}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/0327_svrg.png}
    \caption{SVRG}
    \label{fig:my_label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/0327_sgd.png}
    \caption{SAG and SGD}
    \label{fig:my_label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/linear_4algo.eps}
    \caption{SAG and SGD}
    \label{fig:my_label}
\end{figure}

\section{Strongly-convex objective functions}

For $1 \leq i \leq n$, the update for $z_{im}^{t+1}$ can be written as
\begin{equation}
z_{im}^{t+1}=\sum_{j=1}^{2n}[M_m^t]_{ij} z_{jm}^t-\alpha_t g_{im}^t,
\end{equation}
and, therefore, using the fact that $M_m$ is column-stochastic, we can represent $\Bar{\z}^{t+1}$ as
\begin{equation}
    \Bar{\z}^{t+1}=\Bar{\z}^{t}-\frac{1}{n}\sum_{j=1}^{2n}\alpha_{t}g_{j}^{t}.
\end{equation}

Let $\mathbf{v} \in \R^d$ be any arbitrary vector. For all $t \geq 0$, 
\begin{align}
    \|\Bar{\z}^{t+1}-\mathbf{v}   \|^2 & \leq \|\Bar{\z}^{t}-\mathbf{v} \|^2 -\frac{\alpha_{t}}{n}\sum_{j=1}^{2n} (g_{j}^{t})' (\Bar{\z}^{t}-\mathbf{v} )+(\frac{\alpha^2_{t}}{n^2})^2 \| \sum_{j=1}^{2n} g_{j}^{t} \|^2  \\
    & = \|\Bar{\z}^{t}-\mathbf{v} \|^2 -\frac{\alpha_{t}}{n}\sum_{j=1}^{n} (\nabla f_{j}^{t})' (\Bar{\z}^{t}-\mathbf{v} )+(\frac{\alpha^2_{t}}{n^2})^2 \| \sum_{j=1}^{n} \nabla f_{j}^{t} \|^2
\end{align}

Now, we rewrite each cross-term $(\nabla f_{jm}^{t})' (\Bar{z}_m^{t}-\mathbf{v} ) $ as follows:

\begin{align}
    (\nabla f_{j}^{t})' (\Bar{\z}^{t}-\mathbf{v} ) & = (\nabla f_{j}^{t})' (\Bar{\z}^{t}-\x_{j}^{t} )+(\nabla f_{j}^{t})' (\x_{j}^{t}-\mathbf{v} ) \\
    & \geq -L_j\| \Bar{\z}^{t}-\x_j^{t} \| + f_j(\x_{j}^t)-f_j(\mathbf{v}) +\frac{\mu_j}{2}\| \x_{j}^{t}-\mathbf{v}\|^2 \\
    & = -L_j\| \Bar{\z}^{t}-\x_j^{t} \| +
    (f_j(\x_{j}^t)-f_j(\Bar{\z}^{t}) )+(f_j(\Bar{\z}^{t})-f_j(\mathbf{v}))+\frac{\mu_j}{2}\| \x_{j}^{t}-\mathbf{v}\|^2 \\
    & \geq -2 L_j\| \Bar{\z}^{t}-\x_j^{t} \| +(f_j(\Bar{\z}^{t})-f_j(\mathbf{v})+\frac{\mu_j}{2}\| \x_{j}^{t}-\mathbf{v}\|^2 
\end{align}

Using $F(\x)=\sum_{j=1}^n f_j(\x)$, 
\begin{equation}
    \sum_{j=1}^n (\nabla f_{j}^{t})' (\Bar{\z}^{t}-\mathbf{v} ) \geq F(\x^t)-F(\mathbf{v}) + \frac{1}{2}\sum_{j=1}^n \mu_j \| \x_{j}^{t}-\mathbf{v}\|^2 - 2\sum_{j=1}^n L_j\| \Bar{\z}^{t}-\x_j^{t} \|
\end{equation}

Hence, we have shown that 
\begin{align*}
    E[\|\Bar{\z}^{t+1}-\mathbf{v} \| | \mathcal{F}_t ] & \leq \|\Bar{\z}^t-\mathbf{v} \|^2 - \frac{2\alpha_t}{n} (F(\Bar{\z}^t)-F(\mathbf{v})) - \frac{\alpha_t}{n}\sum_{j=1}^n \mu_j \|\x_j^{t+1}-\mathbf{v} \|^2 \\
    & + \frac{4\alpha_t}{n}\sum_{j=1}^n L_j\|\x_j^{t+1}-\Bar{\z}^{t} \| + \frac{\alpha_t^2}{n}\sum_{j=1}^n (L_j+c_j)^2
\end{align*}
and we can replace $\mathbf{v}$ by $\x^*$.

We consider the following estimates:
\begin{enumerate}[(1)]
    \item 
    \begin{equation}
        F(\Bar{\z}^t)-F(\x^*) \geq \frac{1}{2}(\sum_{j=1}^n \mu_j) \|\Bar{z}^t-\x^* \|
    \end{equation}
    \item 
    \begin{equation}
        F(\Bar{\z}^t)-F(\x^*) \geq -L\|\x_i^t -\Bar{\z}^t \| + F(\x_i^t)-F(\x^*)
    \end{equation}
    where $L=L_1+\cdots+L_n$, 
    for any $i = 1, \cdots, n$.
\end{enumerate}
which implies that for all $i = 1, \cdots, n$, 
\begin{equation}
    2(F(\Bar{\z}^t)-F(\x^*)) \geq \frac{1}{2}(\sum_{j=1}^n \mu_j) \|\Bar{z}^t-\x^* \| -L\|\x_i^t -\Bar{\z}^t \| + F(\x_i^t)-F(\x^*)
\end{equation}

For each $i = 1, \cdots, n$, 
\begin{align*}
    E[\|\Bar{\z}^{t+1}-\x^* \| | \mathcal{F}_t ] & \leq \|\Bar{\z}^t-\mathbf{v} \|^2 - \frac{\alpha_t}{n} (\frac{1}{2}(\sum_{j=1}^n \mu_j) \|\Bar{z}^t-\x^* \| -L\|\x_i^t -\Bar{\z}^t \| + F(\x_i^t)-F(\x^*)) \\ & - \frac{\alpha_t}{n}\sum_{j=1}^n \mu_j \|\x_j^{t+1}-\mathbf{v} \|^2 
     + \frac{4\alpha_t}{n}\sum_{j=1}^n L_j\|\x_j^{t+1}-\Bar{\z}^{t} \| + \frac{\alpha_t^2}{n}\sum_{j=1}^n (L_j+c_j)^2
\end{align*}

\textbf{Remark.} Here we set $\alpha_t=\frac{p}{t}$ to derive convergence rate $O(\log T / T)$.

\end{document}