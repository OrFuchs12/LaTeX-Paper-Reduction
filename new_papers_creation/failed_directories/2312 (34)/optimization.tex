%\subsection{Problem formulation}
In this section, we extend our average consensus results to the general decentralized convex optimization problem \eqref{eq:problem}. For simplicity of the statements and brevity, we assume $f_i$'s are convex functions but make no assumptions regarding their condition numbers (i.e., smoothness and strong convexity), and assume $\mathcal{X} = \mathbb{R}^d$. Our results can readily be extended to the case of smooth and strongly convex objectives, and to the scenarios where we only have access to stochastic gradients (left to be a part of the future work).

Recall the optimization problem we are interested in solving,
\begin{equation}\label{eq:prob}
\min_{\mathrm{\mathbf{x} \in \mathbb{R}^d}} \left[f(\mathbf{x}):=\frac{1}{n}\sum_{i=1}^n f_i(\mathbf{x})\right],
\end{equation}
where $f_i: \mathbb{R}^d \to \mathbb{R}$ represents the local convex objective function at node $i$. Node $i$ only knows its convex local objective function $f_i$. We further assume that a unique optimal solution $\x^*$ exists and that every node attempts to collaborate with others to converge to $\x^*$ in a connected, time-varying directed network with sparsified communications. 

\subsection{Proposed Distributed Algorithm}
Algorithms for solving \eqref{eq:prob} are typically developed by adding a vanishing gradient noise term to the update rule of the average consensus problem. The underlying idea behind this methodology is that by adding a small noise term which further reduces as the network progresses towards convergence ensures all the nodes in the network reach consensus. Additionally, following the direction of gradients in the noise terms guides the consensus value towards the optimal solution of \eqref{eq:prob}.
Adopting the above idea of noisy consensus with descent direction, for each $m$ and each node $i$, we propose the update rule for solving \eqref{eq:prob} of the form
\begin{equation}
z_{im}^{t+1}=\sum_{j=1}^{2n}[M^t_m]_{ij} [Q(z_{j}^t)]_m-\alpha_t g_{im}^t,
\end{equation}
where 
\begin{equation}
    \mathbf{g}_i^t =\begin{cases}
\nabla f_i(\mathbf{x}_i^t), & i \in \left\{1, ..., n \right\}\\
\mathbf{0}, & i \in \left\{n+1, ..., 2n \right\},
\end{cases}
\end{equation}
and $\alpha_t$ is the stepsize in the $t\ts{th}$ time step. The proposed optimization procedure is formalized as Algorithm \ref{alg:B}.
\subsection{Convergence Analysis}
To ensure the network reaches consensus and finds the global minimum simultaneously, we need to impose a schedule of decreasing stepsizes. Therefore, we state the following standard assumption (see, e.g. \cite{nedic2009distributed,nedic2014distributed,xi2017distributed}).
\begin{assumption}\label{assumption3}
The schedule of stepsizes $\left\{\alpha_t\right\}$ is a non-negative decreasing
sequence which satisfies $\sum_{i=0}^{\infty}\alpha_t=\infty, \   \sum_{i=0}^{\infty}\alpha_t^2<\infty$.
\end{assumption}
In addition to Assumption \ref{assumption3}, we further need to assume bounded gradients to ensure the added gradient noise term is vanishing. To this end, we state the following.
\begin{assumption}\label{assumption4}
For all $i$, $m$, and $t$, there exists $D>0$ such that $|g_{im}^t|<D$.
\end{assumption}
We now proceed to theoretically analyze the convergence properties of Algorithm \ref{alg:B}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t]
\caption{Communication-Sparsifying Gradient Descent}
\label{alg:B}
\begin{algorithmic}
\STATE {\bfseries Input:} 
   $T$, % Time horizon
   $\mathbf{x}^0$, % Initial state
   $\mathbf{y}^0=\mathbf{0}$, % Initial y
   
\STATE {set $\mathbf{z}^0=[\mathbf{x}^0; \mathbf{y}^0]$} 
\FOR{each $t \in [0, 1,..., T]$}
\STATE generate non-negative matrices $W^t_{in}$, $W^t_{out}$

\FOR{each $m \in [1, ..., d]$}
\STATE construct a row-stochastic $A^t_m$  and a column-stochastic $B^t_m$ according to \eqref{eq:normA} and \eqref{eq:normB} 
\STATE construct $M^t_m$ according to \eqref{matrixdef}
\FOR{each $i \in \left\{1, ..., 2n \right\}$}
\STATE $z_{im}^{t+1}=\sum_{j=1}^{2n}[M^t_m]_{ij} [Q(z_{j}^t)]_m -\alpha_t g_{im}^t$
\ENDFOR
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The convergence analysis can be divided in two parts: first, we show that the consensus property of the algorithm holds under the assumption of vanishing gradient noises; then, we show the optimality of the consensus value. More concretely, in the first part of the analysis, we establish that $\|\mathbf{z}^t_i-\Bar{\mathbf{z}}^t\|$ converges to zero, which in turn implies that all agents in the network ultimately approach the averaging state 
\begin{equation}
   \Bar{\mathbf{z}}^t=\frac{1}{n}\sum_{i=1}^t \mathbf{x}_i^t +\frac{1}{n}\sum_{i=1}^n \mathbf{y}_i^t .
\end{equation}
Then, we argue that the suboptimality value, i.e., the difference between the function value at the averaging state, $f(\Bar{\mathbf{z}}^t)$, and the optimal solution, $f(\mathbf{x}^*)$ (denoted as $f^*$), also goes to zero. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Consensus Property}
We start by stating an intermediate lemma that establishes an upper bound on the disagreement term $\|\mathbf{z}_i^t-\mathbf{\Bar{z}}^t\|$.
\begin{lemma}\label{lemma3}
Suppose Assumption 1 -- 4 hold and instate the notation and hypotheses of Lemma \ref{lemma2}. Then, for $t\geq 1$ it holds that:
\begin{enumerate}[(a)]
    \item For $1 \leq i \leq n$, 
    \begin{equation}
            \begin{aligned}
    \|\mathbf{z}_i^t-\mathbf{\Bar{z}}^t\| & \leq \Gamma \sigma^{t}\sum_{j=1}^{2n}\sum_{s=1}^d |z^0_{js}|\\
     & +\sqrt{d}n\Gamma D\sum_{r=1}^{t-1}\sigma^{t-r}\alpha_{r-1}+2\sqrt{d} D\alpha_{t-1};
    \end{aligned}
    \end{equation}
    \item  For $1+n \leq i \leq 2n$, 
    \begin{equation}
    \begin{aligned}
    \|\mathbf{z}_i^t\| \leq \Gamma \sigma^{t}\sum_{j=1}^{2n}\sum_{s=1}^d |z^0_{js}|  +\sqrt{d} n\Gamma D\sum_{r=1}^{t-1}\sigma^{t-r}\alpha_{r-1}.
    \end{aligned}
    \end{equation}
\end{enumerate}
\end{lemma}
%%%%%%%%%%%%%%%%%%%%
Lemma \ref{lemma3} states a nontrivial upper bound on the amount of disagreement of the network at each time step (which partly stems from having a gradient step in the consensus algorithm). 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Optimality Property}
Theorem~\ref{lemma4} states the main result which in turn establishes convergence of the proposed optimization algorithm. 
\begin{theorem}\label{lemma4}
Suppose Assumption 1 -- 4 hold and let $D':=\sqrt{d}D$. 
%satisfies $\|\nabla f\| \leq D'$. 
Then, 
\begin{equation}
  \begin{aligned}
    2\sum_{t=0}^{\infty}\alpha_t (f(\Bar{\mathbf{z}}^t)-f^*) & \leq n\|\Bar{\mathbf{z}}^0 -\mathbf{x}^*\| + nD'^2\sum_{t=0}^{\infty}\alpha_t^2 \\
    & +\frac{4D'}{n}\sum_{i=1}^n \sum_{t=0}^{\infty} \alpha_t \| \mathbf{z}_i^t-\Bar{\mathbf{z}}^t\|
\end{aligned}  
\end{equation}
\end{theorem}
Since $\sum_{i=0}^{\infty}\alpha_t=\infty$, it is straightforward to see that the result established in Theorem  \ref{lemma4} implies 
\begin{equation}
\lim_{t \to \infty}f(\mathbf{z}_i^t)=f^*
\end{equation}
for every agent $i$, thereby establishing convergence of Algorithm 2 to the global minimum of \eqref{eq:prob}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Convergence Rate of Algorithm 2} 
Next, we determine the convergence rate of Algorithm \ref{alg:B} and compare it to the convergence rate of communication schemes that do not sparsify messages, i.e., the gradient-push and D-DGD schemes \cite{nedic2014distributed,xi2017distributed}.

Upon defining $f_{\min}:=\mathrm{min}_t f(\Bar{\mathbf{z}}^t)$, we have
\begin{equation}\label{eq:temp}
(f_{\min}-f^*)\sum_{t=0}^T\alpha_t \leq \sum_{t=0}^T\alpha_t(f(\Bar{\mathbf{z}}^t)-f^* )
\leq C_1+C_2\sum_{t=0}^T\alpha_t^2,
\end{equation}
where 
\begin{equation}
\begin{aligned}
C_1&=\frac{n}{2}(\|\Bar{\mathbf{z}}^0-\mathbf{x}^*\|^2-\|\Bar{\mathbf{z}}_{T+1}-\mathbf{x}^* \|^2)\\
&\qquad+D'\Gamma \sum_{j=1}^{2n}\frac{\|\mathbf{z}_j^0\|}{1-\sigma^2},
\end{aligned}
\end{equation}
and
\begin{equation}
C_2=\frac{nD'^2}{2}+4D'^2+D'\Gamma \sum_{j=1}^{2n}\|\mathbf{z}_j^0\|+\frac{2D'^2\Gamma}{1-\sigma}.
\end{equation}
Note that we can express \eqref{eq:temp} equivalently as
\begin{equation}\label{eq:temp2}
(f_{\min}-f^*)\leq \frac{C_1}{\sum_{t=0}^T\alpha_t}+\frac{C_2 \sum_{t=0}^T\alpha_t^2}{\sum_{t=0}^T\alpha_t}.
\end{equation}
Now, by recalling the statement of Assumption \ref{lemma3}, we have that $\alpha_t=o(1/\sqrt{t})$. If we select the schedule of stepsizes according to $\alpha_t=1/\sqrt{t}$, the first term on the right hand side of \eqref{eq:temp2} satisfies 
\begin{equation}
   \frac{C_1}{\sum_{t=0}^T\alpha_t} = C_1 \frac{1/2}{\sqrt{T}-1}=\O(\frac{1}{\sqrt{T}}),
\end{equation}
while for the second term it holds that
\begin{equation}
    \frac{C_2 \sum_{t=0}^T\alpha_t^2}{\sum_{t=0}^T\alpha_t}=C_2 \frac{\mathrm{ln}T}{2(\sqrt{T}-1)}=\O(\frac{\mathrm{ln}T}{\sqrt{T}}). 
\end{equation}
Thus, by using $\alpha_t=1/\sqrt{t}$, the convergence rate of Algorithm 2 matches the $\O(\frac{\mathrm{ln}T}{\sqrt{T}})$ convergence rate of the gradient-push and D-DGD schemes \cite{nedic2014distributed,xi2017distributed} even though Algorithm 2 employs sparsified communications.