\subsection{Does Retaining Relational Information Boost Localization?}\label{ablation:relatinal_coronet}
\modelname employs a weighted directed graph as the concept graph $G_C$, where the edge weight between two nodes is the total number of relational edges from source to target nodes. In this ablation study, we analyze the impact of retaining multi-relational information in contrast to collapsing to a single weighted edge between two nodes. We replace the original $G_C$ version with a multi-relational directed graph, where each edge belongs to one of the relation types in Table 1 in the main paper, and two nodes may be connected with multiple different edges. To this end, we employ Relational Graph Convolutional Networks (RGCNs) \cite{schlichtkrull2018modeling}, where each graph convolution step is defined as
\begin{equation}
\label{eq:rgcn}
    C^{\left(l+1\right)}=\sigma\left(\sum_{r \in R} A_{r} C^{(l)} W_{r}^{(l)}\right).
\end{equation}
Here, $W_{r}^{(l)}$ is the trainable weight matrix for layer $l \in \left[0, L\right]$ and $A_r$ is the adjacency matrix for relation $r \in R$, where $R$ denotes our relation set. 
We experiment with both pre- and post-fusion enhancement in this setup and respectively denote them by \modelname-R and \modelname-R$_{post}$. 

\input{supp_sections/tables/relational}
Results in Table \ref{tab:ablation_relational} show that contrary to one's intuition, having a higher-order contextual graph with more relational information does not help localization performance. A multi-relational adjacency matrix is much sparser than its weighted counterpart, where the adjacency matrix is aggregated along the relation dimension. Having a denser adjacency matrix could possibly enhance learning. Overall, this experiment showcases that the association between two given objects is more important in integrating commonsense, rather than the specific relation type.