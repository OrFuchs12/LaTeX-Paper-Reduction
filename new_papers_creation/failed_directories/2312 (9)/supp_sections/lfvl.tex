\subsection{Does Commonsense Help in Language-free Setups?}
\label{ablation:lfvl}
\input{supp_sections/tables/lfvl}
We also conduct an experiment to test the effectiveness of our CEM approach on a language-free NLVL (LFVL) setting \cite{kim2023language}. LFVL eliminates the need for query annotations by leveraging the cross-modal understanding of CLIP~\cite{radford2021learning} to utilize visual features as textual information. We integrate our commonsense enhancement mechanism into the LFVL pipeline to analyze its impact in this setup. Table \ref{tab:lfvl} compares model performances with two variants, CEM and CEM$_{250}$, which respectively contain 300 and 250 seed concepts. Furthermore, we examine the effectiveness of commonsense enhancement in a post- and pre-fusion setup.
We find that there is a significant increase in the $mIoU$ and $R@0.3$ scores with both CEM and CEM$_{250}$ in post-fusion setup. 
This indicates that the integration of commonsense enhancement positively impacts the overall localization performance. Notably, the comparison between post- and pre-fusion enhancement reveals a striking difference in performance. These findings suggest that enhancing the fused video-query representation with commonsense information is more beneficial compared to enhancing a language-free query representation. The results imply that enhancing the fused representation allows for a more effective alignment between video and query, leading to improved localization performance.