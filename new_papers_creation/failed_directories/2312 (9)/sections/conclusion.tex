\section{Conclusion}
In this paper, we integrate commonsense in zero-shot natural language video localization, in an effort to reduce noise in pseudo-queries and enhance cross-modal grounding between video and query modalities. Our work highlights the benefits of commonsense knowledge in zero-shot natural language video localization. Experimental results demonstrate the impact of commonsense relational information in enriching video and query representations, resulting in improved recall and localization performance within the zero-shot setting.
Future research could explore more refined query representations, additional modalities such as audio or motion, and methods that capture richer query semantics.

\section{Acknowledgements}\label{acknowledgement}
This material is based upon work supported in part by the U.S. DARPA KMASS Program \#HR001121S0034, the Amazon â€“ Virginia Tech Initiative for Efficient and Robust Machine Learning, and the Amazon Alexa Prize TaskBot Challenge 2.  
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon.
The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Amazon and DARPA or the U.S. Government.