\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Cao et~al.(2022)Cao, Wang, Zhang, and Ma}]{cao_visual_2022}
Cao, S.; Wang, B.; Zhang, W.; and Ma, L. 2022.
\newblock Visual {Consensus} {Modeling} for {Video}-{Text} {Retrieval}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 167--175.

\bibitem[{Chen and Jiang(2020)}]{chen_hierarchical_2020}
Chen, S.; and Jiang, Y.-G. 2020.
\newblock Hierarchical {Visual}-{Textual} {Graph} for {Temporal} {Activity} {Localization} via {Language}.
\newblock In \emph{ECCV}, 601--618.

\bibitem[{Chen et~al.(2020)Chen, Ma, Luo, Tang, and Wong}]{chen_look_2020}
Chen, Z.; Ma, L.; Luo, W.; Tang, P.; and Wong, K.-Y.~K. 2020.
\newblock Look {Closer} to {Ground} {Better}: {Weakly}-{Supervised} {Temporal} {Grounding} of {Sentence} in {Video}.
\newblock \emph{ArXiv:2001.09308}.

\bibitem[{Ding et~al.(2021)Ding, Chen, Du, Luo, Tenenbaum, and Gan}]{ding_dynamic_2021}
Ding, M.; Chen, Z.; Du, T.; Luo, P.; Tenenbaum, J.; and Gan, C. 2021.
\newblock Dynamic {Visual} {Reasoning} by {Learning} {Differentiable} {Physics} {Models} from {Video} and {Language}.
\newblock In \emph{NeurIPS}, 887--899.

\bibitem[{Duan et~al.(2018)Duan, Huang, Gan, Wang, Zhu, and Huang}]{duan2018weakly}
Duan, X.; Huang, W.; Gan, C.; Wang, J.; Zhu, W.; and Huang, J. 2018.
\newblock {Weakly Supervised Dense Event Captioning in Videos}.
\newblock In \emph{NeurIPS}, 3062--3072.

\bibitem[{Fang et~al.(2020)Fang, Gokhale, Banerjee, Baral, and Yang}]{fang_video2commonsense_2020}
Fang, Z.; Gokhale, T.; Banerjee, P.; Baral, C.; and Yang, Y. 2020.
\newblock {Video2Commonsense}: {Generating} {Commonsense} {Descriptions} to {Enrich} {Video} {Captioning}.
\newblock In \emph{EMNLP}, 840--860.

\bibitem[{Gao et~al.(2017)Gao, Sun, Yang, and Nevatia}]{Gao_2017_ICCV}
Gao, J.; Sun, C.; Yang, Z.; and Nevatia, R. 2017.
\newblock {TALL: Temporal Activity Localization via Language Query}.
\newblock In \emph{ICCV}.

\bibitem[{Gao et~al.(2021)Gao, Sun, Xu, Zhou, and Ghanem}]{gao_relation-aware_2021}
Gao, J.; Sun, X.; Xu, M.; Zhou, X.; and Ghanem, B. 2021.
\newblock Relation-aware {Video} {Reading} {Comprehension} for {Temporal} {Language} {Grounding}.
\newblock In \emph{EMNLP}, 3978--3988.

\bibitem[{Gao and Xu(2021)}]{gao_fast_2021}
Gao, J.; and Xu, C. 2021.
\newblock Fast Video Moment Retrieval.
\newblock In \emph{ICCV}, 1503--1512.

\bibitem[{Gao et~al.(2019)Gao, Davis, Socher, and Xiong}]{gao2019wslln}
Gao, M.; Davis, L.; Socher, R.; and Xiong, C. 2019.
\newblock {{WSLLN}:Weakly Supervised Natural Language Localization Networks}.
\newblock In \emph{EMNLP-IJCNLP}, 1481--1487.

\bibitem[{Gao et~al.(2022)Gao, Luo, Chen, and Zhou}]{gao_end--end_2022}
Gao, Y.; Luo, Z.; Chen, S.; and Zhou, W. 2022.
\newblock End-to-end {Multi}-task {Learning} {Framework} for {Spatio}-{Temporal} {Grounding} in {Video} {Corpus}.
\newblock In \emph{CIKM}, 3958--3962.

\bibitem[{Goyal et~al.(2017)Goyal, Ebrahimi~Kahou, Michalski, Materzynska, Westphal, Kim, Haenel, Fruend, Yianilos, Mueller-Freitag, Hoppe, Thurau, Bax, and Memisevic}]{goyal_something_2017}
Goyal, R.; Ebrahimi~Kahou, S.; Michalski, V.; Materzynska, J.; Westphal, S.; Kim, H.; Haenel, V.; Fruend, I.; Yianilos, P.; Mueller-Freitag, M.; Hoppe, F.; Thurau, C.; Bax, I.; and Memisevic, R. 2017.
\newblock The "{Something} {Something}" {Video} {Database} for {Learning} and {Evaluating} {Visual} {Common} {Sense}.
\newblock In \emph{ICCV}, 5842--5850.

\bibitem[{Hammond, Vandergheynst, and Gribonval(2011)}]{hammond_wavelets_2011}
Hammond, D.~K.; Vandergheynst, P.; and Gribonval, R. 2011.
\newblock Wavelets on graphs via spectral graph theory.
\newblock \emph{Applied and Computational Harmonic Analysis}, 30: 129--150.

\bibitem[{He et~al.(2022)He, Mao, Zhou, Li, Gong, Li, and Wu}]{coref_commonsense_ieee}
He, K.; Mao, B.; Zhou, X.; Li, Y.; Gong, T.; Li, C.; and Wu, J. 2022.
\newblock {Knowledge Enhanced Coreference Resolution via Gated Attention}.
\newblock In \emph{IEEE BIBM}, 2287--2293.

\bibitem[{Heilbron et~al.(2015)Heilbron, Escorcia, Ghanem, and Niebles}]{heilbron2015activitynet}
Heilbron, F.~C.; Escorcia, V.; Ghanem, B.; and Niebles, J.~C. 2015.
\newblock {ActivityNet: A Large-scale Video Benchmark for Human Activity Understanding}.
\newblock In \emph{CVPR}.

\bibitem[{Huang et~al.(2021)Huang, Liu, Gong, and Jin}]{huang_cross-sentence_2021}
Huang, J.; Liu, Y.; Gong, S.; and Jin, H. 2021.
\newblock {Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation}.
\newblock In \emph{ICCV)}, 7199--7208.

\bibitem[{Jiang et~al.(2022)Jiang, Lin, Han, Song, and Huang}]{jiang_pseudo-q_2022}
Jiang, H.; Lin, Y.; Han, D.; Song, S.; and Huang, G. 2022.
\newblock Pseudo-{Q}: {Generating} {Pseudo} {Language} {Queries} for {Visual} {Grounding}.
\newblock In \emph{CVPR}, 15513--15523.

\bibitem[{Kim et~al.(2023)Kim, Park, Lee, Park, and Sohn}]{kim2023language}
Kim, D.; Park, J.; Lee, J.; Park, S.; and Sohn, K. 2023.
\newblock Language-free Training for Zero-shot Video Grounding.
\newblock In \emph{WACV}, 2539--2548.

\bibitem[{Krishna et~al.(2017{\natexlab{a}})Krishna, Hata, Ren, Fei-Fei, and Niebles}]{krishna2017dense}
Krishna, R.; Hata, K.; Ren, F.; Fei-Fei, L.; and Niebles, J.~C. 2017{\natexlab{a}}.
\newblock {Dense-Captioning Events in Videos}.
\newblock In \emph{ICCV}.

\bibitem[{Krishna et~al.(2017{\natexlab{b}})Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen, Kalantidis, Li, Shamma, Bernstein, and Fei-Fei}]{krishna_visual_2017}
Krishna, R.; Zhu, Y.; Groth, O.; Johnson, J.; Hata, K.; Kravitz, J.; Chen, S.; Kalantidis, Y.; Li, L.-J.; Shamma, D.~A.; Bernstein, M.~S.; and Fei-Fei, L. 2017{\natexlab{b}}.
\newblock Visual {Genome}: {Connecting} {Language} and {Vision} {Using} {Crowdsourced} {Dense} {Image} {Annotations}.
\newblock \emph{International Journal of Computer Vision}, 123: 32--73.

\bibitem[{Lei, Berg, and Bansal(2021)}]{detr}
Lei, J.; Berg, T.~L.; and Bansal, M. 2021.
\newblock Detecting Moments and Highlights in Videos via Natural Language Queries.
\newblock In Ranzato, M.; Beygelzimer, A.; Dauphin, Y.; Liang, P.; and Vaughan, J.~W., eds., \emph{NeurIPS}, 11846--11858.

\bibitem[{Lei et~al.(2020{\natexlab{a}})Lei, Yu, Berg, and Bansal}]{lei_tvqa_2020}
Lei, J.; Yu, L.; Berg, T.; and Bansal, M. 2020{\natexlab{a}}.
\newblock {TVQA}+: {Spatio}-{Temporal} {Grounding} for {Video} {Question} {Answering}.
\newblock In \emph{ACL}, 8211--8225.

\bibitem[{Lei et~al.(2020{\natexlab{b}})Lei, Yu, Berg, and Bansal}]{lei_what_2020}
Lei, J.; Yu, L.; Berg, T.; and Bansal, M. 2020{\natexlab{b}}.
\newblock What is {More} {Likely} to {Happen} {Next}? {Video}-and-{Language} {Future} {Event} {Prediction}.
\newblock In \emph{EMNLP}, 8769--8784.

\bibitem[{Li, Niu, and Zhang(2022)}]{li_representation_2022}
Li, J.; Niu, L.; and Zhang, L. 2022.
\newblock From {Representation} to {Reasoning}: {Towards} {Both} {Evidence} and {Commonsense} {Reasoning} for {Video} {Question}-{Answering}.
\newblock In \emph{CVPR}, 21273--21282.

\bibitem[{Li, Guo, and Wang(2021)}]{li_proposal-free_2021}
Li, K.; Guo, D.; and Wang, M. 2021.
\newblock {Proposal-free Video Grounding with Contextual Pyramid Network}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 1902--1910.

\bibitem[{Li et~al.(2023)Li, Xie, Xie, Zhao, Zhang, Zheng, Zhao, and Zhang}]{li2023momentdiff}
Li, P.; Xie, C.-W.; Xie, H.; Zhao, L.; Zhang, L.; Zheng, Y.; Zhao, D.; and Zhang, Y. 2023.
\newblock MomentDiff: Generative Video Moment Retrieval from Random to Real.
\newblock In \emph{NeurIPS}.

\bibitem[{Lin et~al.(2020)Lin, Zhao, Zhang, Wang, and Liu}]{lin_weakly-supervised_2020}
Lin, Z.; Zhao, Z.; Zhang, Z.; Wang, Q.; and Liu, H. 2020.
\newblock Weakly-{Supervised} {Video} {Moment} {Retrieval} via {Semantic} {Completion} {Network}.
\newblock In \emph{{AAAI}}.

\bibitem[{Liu et~al.(2021)Liu, Qu, Dong, Zhou, Cheng, Wei, Xu, and Xie}]{liu_context-aware_2021}
Liu, D.; Qu, X.; Dong, J.; Zhou, P.; Cheng, Y.; Wei, W.; Xu, Z.; and Xie, Y. 2021.
\newblock Context-{Aware} {Biaffine} {Localizing} {Network} for {Temporal} {Sentence} {Grounding}.
\newblock In \emph{CVPR}, 11235--11244.

\bibitem[{Liu et~al.(2022{\natexlab{a}})Liu, Qu, Wang, Di, Zou, Cheng, Xu, and Zhou}]{liu_unsupervised_2022}
Liu, D.; Qu, X.; Wang, Y.; Di, X.; Zou, K.; Cheng, Y.; Xu, Z.; and Zhou, P. 2022{\natexlab{a}}.
\newblock Unsupervised {Temporal} {Video} {Grounding} with {Deep} {Semantic} {Clustering}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 1683--1691.

\bibitem[{Liu et~al.(2022{\natexlab{b}})Liu, Qu, Zhou, and Liu}]{liu_exploring_2022}
Liu, D.; Qu, X.; Zhou, P.; and Liu, Y. 2022{\natexlab{b}}.
\newblock Exploring {Motion} and {Appearance} {Information} for {Temporal} {Sentence} {Grounding}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 1674--1682.

\bibitem[{Liu et~al.(2020)Liu, Chen, Cheng, Gan, Yu, Yang, and Liu}]{liu_violin_2020}
Liu, J.; Chen, W.; Cheng, Y.; Gan, Z.; Yu, L.; Yang, Y.; and Liu, J. 2020.
\newblock Violin: {A} {Large}-{Scale} {Dataset} for {Video}-and-{Language} {Inference}.
\newblock In \emph{CVPR}, 10900--10910.

\bibitem[{Ma et~al.(2020)Ma, Yoon, Kim, Lee, Kang, and Yoo}]{ma_vlanet_2020}
Ma, M.; Yoon, S.; Kim, J.; Lee, Y.; Kang, S.; and Yoo, C.~D. 2020.
\newblock {VLANet}: {Video}-{Language} {Alignment} {Network} for {Weakly}-{Supervised} {Video} {Moment} {Retrieval}.
\newblock In \emph{ECCV}, 156--171.

\bibitem[{Maharana and Bansal(2021)}]{maharana_integrating_2021}
Maharana, A.; and Bansal, M. 2021.
\newblock Integrating {Visuospatial}, {Linguistic}, and {Commonsense} {Structure} into {Story} {Visualization}.
\newblock In \emph{EMNLP}, 6772--6786.

\bibitem[{Mithun, Paul, and Roy-Chowdhury(2019)}]{mithun_weakly_2019}
Mithun, N.~C.; Paul, S.; and Roy-Chowdhury, A.~K. 2019.
\newblock {Weakly Supervised Video Moment Retrieval from Text Queries}.
\newblock In \emph{CVPR}, 11592--11601.

\bibitem[{Mun, Cho, and Han(2020)}]{mun_local-global_2020}
Mun, J.; Cho, M.; and Han, B. 2020.
\newblock Local-{Global} {Video}-{Text} {Interactions} for {Temporal} {Grounding}.
\newblock In \emph{CVPR}.

\bibitem[{Nam et~al.(2021)Nam, Ahn, Kang, Ha, and Choi}]{nam_zero-shot_2021}
Nam, J.; Ahn, D.; Kang, D.; Ha, S.~J.; and Choi, J. 2021.
\newblock Zero-{Shot} {Natural} {Language} {Video} {Localization}.
\newblock In \emph{ICCV}, 1470--1479.

\bibitem[{Park et~al.(2022)Park, Shen, Farhadi, Darrell, Choi, and Rohrbach}]{park_exposing_2022}
Park, J.~S.; Shen, S.; Farhadi, A.; Darrell, T.; Choi, Y.; and Rohrbach, A. 2022.
\newblock Exposing the {Limits} of {Video}-{Text} {Models} through {Contrast} {Sets}.
\newblock In \emph{NAACL-HTL}, 3574--3586.

\bibitem[{Peng et~al.(2021)Peng, Huang, Xu, Li, Liu, Rahmani, Ke, Guo, Wu, Li, Ye, Wang, Zhang, Liu, He, Zhang, Liu, and Lin}]{peng_multi-modal_2021}
Peng, H.; Huang, H.; Xu, L.; Li, T.; Liu, J.; Rahmani, H.; Ke, Q.; Guo, Z.; Wu, C.; Li, R.; Ye, M.; Wang, J.; Zhang, J.; Liu, Y.; He, T.; Zhang, F.; Liu, X.; and Lin, T. 2021.
\newblock {The Multi-Modal Video Reasoning and Analyzing Competition}.
\newblock In \emph{ICCV Workshops (ICCVW)}, 806--813.

\bibitem[{Qian et~al.(2023)Qian, Cui, Chen, Peng, Guo, and Jiang}]{qian_locate_2022}
Qian, T.; Cui, R.; Chen, J.; Peng, P.; Guo, X.; and Jiang, Y.-G. 2023.
\newblock Locate before {Answering}: {Answer} {Guided} {Question} {Localization} for {Video} {Question} {Answering}.
\newblock \emph{IEEE Transactions on Multimedia}.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Radford, A.; Kim, J.~W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et~al. 2021.
\newblock {Learning Transferable Visual Models from Natural Language Supervision}.
\newblock In \emph{ICML}, 8748--8763.

\bibitem[{Ravi et~al.(2023)Ravi, Tanner, Ng, and Shwartz}]{coref_commonsense_acl_ravi-etal-2023-happens}
Ravi, S.; Tanner, C.; Ng, R.; and Shwartz, V. 2023.
\newblock {What happens before and after: Multi-Event Commonsense in Event Coreference Resolution}.
\newblock In \emph{EACL}, 1708--1724.

\bibitem[{Rodriguez et~al.(2020)Rodriguez, Marrese-Taylor, Saleh, LI, and Gould}]{rodriguez_proposal-free_2020}
Rodriguez, C.; Marrese-Taylor, E.; Saleh, F.~S.; LI, H.; and Gould, S. 2020.
\newblock Proposal-free {Temporal} {Moment} {Localization} of a {Natural}-{Language} {Query} in {Video} using {Guided} {Attention}.
\newblock In \emph{WACV}.

\bibitem[{Rodriguez-Opazo et~al.(2021)Rodriguez-Opazo, Marrese-Taylor, Fernando, Li, and Gould}]{rodriguez-opazo_dori_2021}
Rodriguez-Opazo, C.; Marrese-Taylor, E.; Fernando, B.; Li, H.; and Gould, S. 2021.
\newblock {DORi: Discovering Object Relationships for Moment Localization of a Natural Language Query in a Video}.
\newblock In \emph{WACV}, 1079--1088.

\bibitem[{Schlichtkrull et~al.(2018)Schlichtkrull, Kipf, Bloem, vanden Berg, Titov, and Welling}]{schlichtkrull2018modeling}
Schlichtkrull, M.; Kipf, T.~N.; Bloem, P.; vanden Berg, R.; Titov, I.; and Welling, M. 2018.
\newblock {Modeling Relational Data with Graph Convolutional Networks}.
\newblock In \emph{The Semantic Web}, 593--607.

\bibitem[{Shin et~al.(2021)Shin, Kim, Choi, Heo, Kim, Lee, Zhang, and Ryu}]{shin_cogme_2021}
Shin, M.; Kim, J.; Choi, S.; Heo, Y.; Kim, D.; Lee, M.~S.; Zhang, B.; and Ryu, J. 2021.
\newblock {CogME: {A} Novel Evaluation Metric for Video Understanding Intelligence}.
\newblock \emph{ArXiv:2107.09847}.

\bibitem[{Soldan et~al.(2021)Soldan, Xu, Qu, Tegner, and Ghanem}]{soldan_vlg-net_2021}
Soldan, M.; Xu, M.; Qu, S.; Tegner, J.; and Ghanem, B. 2021.
\newblock {VLG}-{Net}: {Video}-{Language} {Graph} {Matching} {Network} for {Video} {Grounding}.
\newblock In \emph{ICCV}, 3224--3234.

\bibitem[{Speer, Chin, and Havasi(2017)}]{speer_conceptnet_2017}
Speer, R.; Chin, J.; and Havasi, C. 2017.
\newblock {ConceptNet} 5.5: {An} {Open} {Multilingual} {Graph} of {General} {Knowledge}.
\newblock In \emph{AAAI}, 4444--4451.

\bibitem[{Tan et~al.(2021)Tan, Xu, Saenko, and Plummer}]{tan_logan_2021}
Tan, R.; Xu, H.; Saenko, K.; and Plummer, B.~A. 2021.
\newblock {LoGAN}: {Latent} {Graph} {Co}-{Attention} {Network} for {Weakly}-{Supervised} {Video} {Moment} {Retrieval}.
\newblock In \emph{WACV}, 2083--2092.

\bibitem[{Tran et~al.(2015)Tran, Bourdev, Fergus, Torresani, and Paluri}]{c3d}
Tran, D.; Bourdev, L.; Fergus, R.; Torresani, L.; and Paluri, M. 2015.
\newblock {Learning Spatiotemporal Features with 3D Convolutional Networks}.
\newblock In \emph{ICCV}, 4489–4497.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}]{vaswani_attention_2017}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.; Kaiser, {\L}.; and Polosukhin, I. 2017.
\newblock Attention is {All} you {Need}.
\newblock In \emph{NeurIPS}.

\bibitem[{Wang, Ma, and Jiang(2020)}]{wang_temporally_2020}
Wang, J.; Ma, L.; and Jiang, W. 2020.
\newblock Temporally {Grounding} {Language} {Queries} in {Videos} by {Contextual} {Boundary}-{Aware} {Prediction}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 12168--12175.

\bibitem[{Wang, Zhou, and Li(2021)}]{wang_fine-grained_2021}
Wang, Y.; Zhou, W.; and Li, H. 2021.
\newblock {Fine-grained Semantic Alignment Network for Weakly Supervised Temporal Language Grounding}.
\newblock In \emph{Findings of EMNLP}, 89--99.

\bibitem[{Wu et~al.(2022)Wu, Gao, Huang, and Xu}]{wu_learning_2022}
Wu, Z.; Gao, J.; Huang, S.; and Xu, C. 2022.
\newblock Learning {Commonsense}-aware {Moment}-{Text} {Alignment} for {Fast} {Video} {Temporal} {Grounding}.
\newblock \emph{ArXiv:2204.01450}.

\bibitem[{Xiao et~al.(2021)Xiao, Chen, Zhang, Ji, Shao, Ye, and Xiao}]{xiao_boundary_2021}
Xiao, S.; Chen, L.; Zhang, S.; Ji, W.; Shao, J.; Ye, L.; and Xiao, J. 2021.
\newblock {Boundary Proposal Network for Two-Stage Natural Language Video Localization}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}.

\bibitem[{Yang et~al.(2021)Yang, Feng, Ji, Wang, and Chua}]{yang_deconfounded_2021}
Yang, X.; Feng, F.; Ji, W.; Wang, M.; and Chua, T.-S. 2021.
\newblock {Deconfounded Video Moment Retrieval with Causal Intervention}.
\newblock In \emph{ACM SIGIR}, 1–10.

\bibitem[{Yu et~al.(2021)Yu, Liang, Ji, Li, Fang, Xiao, and Duan}]{yu_hybrid_2021}
Yu, W.; Liang, J.; Ji, L.; Li, L.; Fang, Y.; Xiao, N.; and Duan, N. 2021.
\newblock Hybrid {Reasoning} {Network} for {Video}-based {Commonsense} {Captioning}.
\newblock In \emph{ACM MM}, 5213--5221.

\bibitem[{Yu et~al.(2020)Yu, Song, Yu, Wang, and Huang}]{yu_intra-_2020}
Yu, Z.; Song, Y.; Yu, J.; Wang, M.; and Huang, Q. 2020.
\newblock Intra- and {Inter}-modal {Multilinear} {Pooling} with {Multitask} {Learning} for {Video} {Grounding}.
\newblock \emph{Neural Processing Letters}, 52(3): 1863--1879.

\bibitem[{Zeng et~al.(2020)Zeng, Xu, Huang, Chen, Tan, and Gan}]{zeng_dense_2020}
Zeng, R.; Xu, H.; Huang, W.; Chen, P.; Tan, M.; and Gan, C. 2020.
\newblock Dense {Regression} {Network} for {Video} {Grounding}.
\newblock In \emph{CVPR}.

\bibitem[{Zeng et~al.(2021)Zeng, Cao, Wei, Liu, Zhao, and Qin}]{zeng_multi-modal_2021}
Zeng, Y.; Cao, D.; Wei, X.; Liu, M.; Zhao, Z.; and Qin, Z. 2021.
\newblock Multi-{Modal} {Relational} {Graph} for {Cross}-{Modal} {Video} {Moment} {Retrieval}.
\newblock In \emph{CVPR}, 2215--2224.

\bibitem[{Zhang et~al.(2021)Zhang, Sun, Jing, Nan, Zhen, Zhou, and Goh}]{zhang_video_2021}
Zhang, H.; Sun, A.; Jing, W.; Nan, G.; Zhen, L.; Zhou, J.~T.; and Goh, R. S.~M. 2021.
\newblock Video {Corpus} {Moment} {Retrieval} with {Contrastive} {Learning}.
\newblock In \emph{ACM SIGIR}, 685--695.

\bibitem[{Zhang and Radke(2022)}]{zhang_natural_2022}
Zhang, L.; and Radke, R.~J. 2022.
\newblock Natural Language Video Moment Localization Through Query-Controlled Temporal Convolution.
\newblock In \emph{WACV}, 2524--2532.

\bibitem[{Zhang et~al.(2020)Zhang, Zhao, Lin, zhu, and He}]{zhang_counterfactual_2020}
Zhang, Z.; Zhao, Z.; Lin, Z.; zhu, j.; and He, X. 2020.
\newblock {Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding}.
\newblock In \emph{NeurIPS}, 18123--18134.

\bibitem[{Zhao et~al.(2021)Zhao, Zhao, Zhang, and Lin}]{zhao_cascaded_2021}
Zhao, Y.; Zhao, Z.; Zhang, Z.; and Lin, Z. 2021.
\newblock Cascaded Prediction Network via Segment Tree for Temporal Video Grounding.
\newblock In \emph{CVPR}, 4197--4206.

\end{thebibliography}
