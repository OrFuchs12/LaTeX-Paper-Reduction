\section{Related Works}
\subsubsection{Uncertainty Estimation in Deep Learning} 
% For developing trustworthy Deep Learning (DL) model, a good estimation of prediction uncertainty is essential. Ensemble-based methods~\cite{pearce2020uncertainty,lakshminarayanan2017simple} and Bayesian neural networks~\cite{gal2016dropout,wilson2020bayesian,blundell2015weight} are commonly used to quantify predictive uncertainty. Ensemble-based methods train multiple neural networks and aggregate their predictions for uncertainty quantification. Since multiple models are required, ensemble-based methods need more parameters, which is computationally expensive for real-world applications. Alternatively, Bayesian neural networks (BNNs) treat the weights of the neural network as random variables and capture the distribution over the weights rather than point estimates.~\cite{gal2016dropout} introduced Dropout during the inference phase to obtain predictive uncertainty, approximating Bayesian inference in deep Gaussian processes. 
% %However, these methods also bring a significant increase in computational cost as they employ complex sampling methods.
% However, these methods also come with a notable rise in computational expense due to their use of intricate sampling techniques.
Developing a trustworthy Deep Learning (DL) model requires an accurate estimation of prediction uncertainty. Ensemble methods~\cite{pearce2020uncertainty,lakshminarayanan2017simple} use multiple networks for uncertainty quantification and thus are computationally expensive due to the need for more parameters. Bayesian neural networks (BNNs)~\cite{gal2016dropout,wilson2020bayesian,blundell2015weight}, treating neural network weights as random variables, capture weight distribution rather than point estimates. The introduction of Dropout to BNNs during inference~\cite{gal2016dropout} approximates Bayesian inference in deep Gaussian processes but also increases computational costs due to complex sampling techniques. 



\subsubsection{Evidential Deep Learning}
% Evidential Deep Learning (EDL)~\cite{sensoy2018evidential,NEURIPS2020_aab08546,malinin2018predictive} is a relatively recent approach to uncertainty estimation in deep learning. Evidential models incorporate a conjugate higher-order evidential prior, empowering the model to grasp the fine-grained uncertainties. In Evidential models, the neural network is trained to predict parameters of the output distribution that not only capture the target variable but also the uncertainty associated with the prediction. For example, Dirichlet prior is introduced for evidential classification~\cite{sensoy2018evidential,bao2021evidential}, and a neural network is constructed to get the desired parameters of Dirichlet distribution. Similarly, NIG prior is introduced over the Gaussian likelihood for evidential regression~\cite{NEURIPS2020_aab08546,oh2022improving}.~\citeauthor{meinert2021multivariate} further utilize NIW prior for multivariate regression.
% In contrast to the above-mentioned methods, evidential models generally have lower computational overhead.
Evidential Deep Learning (EDL)~\cite{sensoy2018evidential,NEURIPS2020_aab08546,malinin2018predictive} is a relatively recent method for uncertainty estimation in deep learning, using a conjugate higher-order evidential prior to understand fine-grained uncertainties. These models train the neural network to predict distribution parameters that capture both the target variable and its associated uncertainty. Dirichlet prior is introduced for evidential classification~\cite{sensoy2018evidential}. And NIG prior is introduced for evidential regression~\cite{NEURIPS2020_aab08546}.~\citet{meinert2021multivariate} further utilize NIW prior for multivariate regression.~\citet{pandey2023learn} first observed convergence issues in evidential models for classification, noting their incapacity to learn from certain samples. To tackle this, they introduced novel evidence regularization. However, the convergence analysis of ERN for regression tasks remains unexplored.




