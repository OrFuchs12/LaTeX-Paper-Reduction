\section{Conclusion}
% In this paper, we define High Uncertainty Area for evidential regression models and provide a theoretical analysis of a limitation of these models. We prove that the gradient of samples in HUA shrinks to zero which means evidential regression models cannot learn from these training samples. To tackle this problem, we propose a novel regularization term to guide ERN learning from all training samples. Our thorough experiments demonstrate the effectiveness of our proposed method.
% In this paper, we introduce the concept of High Uncertainty Area (HUA) for evidential regression models and conduct a theoretical analysis of a significant limitation within these models. Specifically, we prove that the gradient of samples within the HUA diminishes to zero, rendering the evidential regression models unable to learn from these training samples. To address this challenge, we propose a novel regularization term designed to guide the evidential regression models to learn from all available training samples. Our comprehensive experiments demonstrate the effectiveness of this innovative approach.
In this paper, we define High Uncertainty Area (HUA) for evidential regression models and identify a key limitation where the gradient of samples within the HUA diminishes to zero. This makes the evidential models unable to learn from these samples. To combat this issue, we introduce a novel regularization term, and our experiments validate the effectiveness of this solution.

\section{Acknowledgments}
This study is partially supported by NSF award (IIS 2045848, IIS 1837956, IIS 2319450, and IIS 2153311).

